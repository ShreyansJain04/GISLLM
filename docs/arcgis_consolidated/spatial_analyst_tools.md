# Spatial Analyst Tools Reference

*Consolidated from 275 individual documentation files*

---

## Abs (Spatial Analyst)

## Summary

Calculates the absolute value of the cells in a raster.

## Usage

- Input values can be positive or negative and can be either integer or floating point.
- If the input is integer, the output raster will be integer type. If the input is floating point, the output raster will be floating point.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input raster for which to calculate the absolute values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input raster for which to calculate the absolute values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Abs(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outAbs = Abs("negs")
outAbs.save("C:/sapyexamples/output/abs2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outAbs = Abs("negs")
outAbs.save("C:/sapyexamples/output/abs2")
```

### Example 4

```python
# Name: Abs_Ex_02.py
# Description: Calculates the absolute value of cells in a raster 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "negs"

# Execute Abs
outAbs = Abs(inRaster)

# Save the output 
outAbs.save("C:/sapyexamples/output/outabs.tif")
```

### Example 5

```python
# Name: Abs_Ex_02.py
# Description: Calculates the absolute value of cells in a raster 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "negs"

# Execute Abs
outAbs = Abs(inRaster)

# Save the output 
outAbs.save("C:/sapyexamples/output/outabs.tif")
```

---

## ACos (Spatial Analyst)

## Summary

Calculates the inverse cosine of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -1 ≤ [in_value] ≤ 1 Note that any input value that is outside this domain will receive NoData on the output raster.The Range is: 0 ≤ [out_value] ≤ pi
- The Domain is: -1 ≤ [in_value] ≤ 1 Note that any input value that is outside this domain will receive NoData on the output raster.
- The Range is: 0 ≤ [out_value] ≤ pi
- The input values to this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- The output values from this tool are in radians. To use degrees instead, the resulting raster must be multiplied by the radians-to-degrees conversion factor of 180/pi, or approximately 57.296.For further assistance, a procedure to follow and examples of converting output in radians to degrees are available.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the inverse cosine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the inverse cosine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
ACos(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outACos = ACos("degs")
outACos.save("C:/sapyexamples/output/outacos.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outACos = ACos("degs")
outACos.save("C:/sapyexamples/output/outacos.tif")
```

### Example 4

```python
# Name: ACos_Ex_02.py
# Description: Calculates the inverse cosine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute ACos
outACos = ACos(inRaster)

# Save the output 
outACos.save("C:/sapyexamples/output/outacos")
```

### Example 5

```python
# Name: ACos_Ex_02.py
# Description: Calculates the inverse cosine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute ACos
outACos = ACos(inRaster)

# Save the output 
outACos.save("C:/sapyexamples/output/outacos")
```

---

## ACosH (Spatial Analyst)

## Summary

Calculates the inverse hyperbolic cosine of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: 1 ≤ [in_value] < ∞ Note that any input value that is outside this domain will receive NoData on the output raster.The Range is: -∞ < [out_value] < ∞ Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: 1 ≤ [in_value] < ∞ Note that any input value that is outside this domain will receive NoData on the output raster.
- The Range is: -∞ < [out_value] < ∞
- The input and output values for this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the inverse hyperbolic cosine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the inverse hyperbolic cosine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
ACosH(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outACosH = ACosH("degs")
outACosH.save("C:/sapyexamples/output/outacosh.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outACosH = ACosH("degs")
outACosH.save("C:/sapyexamples/output/outacosh.img")
```

### Example 4

```python
# Name: ACosH_Ex_02.py
# Description: Calculates the inverse hyperbolic cosine of cells
#              in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute ACosH
outACosH = ACosH(inRaster)

# Save the output 
outACosH.save("C:/sapyexamples/output/outacosh")
```

### Example 5

```python
# Name: ACosH_Ex_02.py
# Description: Calculates the inverse hyperbolic cosine of cells
#              in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute ACosH
outACosH = ACosH(inRaster)

# Save the output 
outACosH.save("C:/sapyexamples/output/outacosh")
```

---

## Add Surface Information (Spatial Analyst)

## Summary

Attributes input features with height-based statistical information derived from the overlapping portions of a surface.

## Usage

- The statistics from the surface will be determined in the following ways for each supported geometry:For points, z-values will be derived from the x,y coordinates on the surface.For lines, z-properties will be acquired by interpolating surface measurements along their length.For polygons, z-properties of the triangulated surface created from the surface that intersect the polygon will be summarized. Curves in input line features will be densified into line segments using the Sampling Distance parameter value. If a sampling distance is not specified, this value will be derived from the input surface. For a raster, the default sampling distance will be the raster's cell size. For a TIN, terrain, or LAS dataset, the default sampling will be based on the edges produced by the triangulated surface. By densifying curves, not all portions of the curve will be accurately captured by the output values. If the curve is shorter than the sampling distance, the curve will be simplified into a two-point line using its start and end points.
- For points, z-values will be derived from the x,y coordinates on the surface.
- For lines, z-properties will be acquired by interpolating surface measurements along their length.
- For polygons, z-properties of the triangulated surface created from the surface that intersect the polygon will be summarized.
- The Output Property parameter options are written to the input feature's attribute table. Each feature defines the location of the surface properties being assessed, and the type of property that can be reported depends on the feature's geometry.Feature geometrySurface propertiesPoint Spot elevation interpolated from the point's x,y-coordinate on the surfaceMultipointMinimum, maximum, and mean spot elevation for all points in the multipoint recordPolyline3D distance of the line along the surfaceMinimum, maximum, and mean elevation and slope of the line along the surfacePolygon3D area of the surface overlapping the polygonMinimum, maximum, and mean of the elevation and slope from the surface
- Slope values are measured in percentage units (grade) and, for line features, are calculated at each segment along the line.Minimum slope is obtained from the segment with the value closest to 0, or horizontal grade.Maximum slope is obtained from the segment with the largest calculated value. Average slope for a polyline is obtained by taking a weighted average of the slope from each line segment. The weighting is based on the 3D length of each segment. This results in longer segments having greater influence on the resulting calculation over shorter segments.
- Minimum slope is obtained from the segment with the value closest to 0, or horizontal grade.
- Maximum slope is obtained from the segment with the largest calculated value.
- Average slope for a polyline is obtained by taking a weighted average of the slope from each line segment. The weighting is based on the 3D length of each segment. This results in longer segments having greater influence on the resulting calculation over shorter segments.
- All attributes are calculated based on a TIN surface that is used to interpolate z-information for the input features. Surfaces that are not TIN surfaces are converted into an intermediate TIN dataset. The features are clipped to the boundary of this TIN surface and only the area that is common to both the features and the surface is evaluated. The construction of this TIN may take a considerable amount of time when the input is a dense LAS dataset or a high-resolution raster. If a lower resolution TIN is acceptable for analysis, you can use the Raster To TIN or LAS Dataset To TIN tool to produce a thinned TIN surface for use with this tool.
- The mean z-value for a polygon is calculated by clipping the TIN using the polygon and deriving the results from the clipped TIN. Each triangle in this TIN will have the z-value of its midpoint multiplied by the triangle's 3D area. The results of this calculation for all the triangles are added together and that sum is divided by the cumulative 3D area of those triangles to obtain the final result. When a large polygon feature is specified along with a raster surface that contains a large number of overlapping cells, the process may fail due to insufficient memory resources needed for creating the intermediate TIN surface. If this occurs, you need to create a lower resolution TIN or use a raster-based approach to obtain the expected output properties. Several tools are available in the Zonal Statistics toolset that offer a faster way to derive properties such as area, minimum, maximum, and mean values. The Tabulate Area and Zonal Statistics As Table tools provide an output table that can be joined to the polygon feature. To obtain slope properties, you can create a slope raster and run either of these tools. If you do not have the Spatial Analyst extension but want to compute surface area and volume, you can clip the input raster with the polygon and use the Surface Volume tool, which will output both surface area and volume.
- Line features are processed by draping the lines onto the TIN surface and inserting a vertex where the line crosses a TIN edge. Lines with curved segments are densified into shorter straight segments prior to processing. The mean z-value for a given line is calculated by multiplying the midpoint of the segment by the 3D length of that segment, and adding together the results of this calculation for all the line segments and dividing that sum by the cumulative 3D length of the line segments.
- Use the Noise Filter parameter to exclude portions of the surface characterized by anomalous measurements from contributing to slope calculations. Line features are segmented by vertices that capture the profile of the surface, and filtering these segments by length removes the influence of short segments that are likely caused by unexpected surface measurements. Similarly, the area filter for polygon features excludes sliver triangles in triangulated surfaces from contributing to slope calculations. For raster surfaces, a subset of cell centroids is used to construct a triangulated surface to which the area filter is applied. Polygons are internally converted to multipatches (collections of triangles). Each such triangle, when draped onto the surface, is typically split into smaller triangles so that the entire polygon matches the surface throughout. The z-value at the midpoint of each triangle is multiplied by the 3D area of that triangle. The results of this calculation are added together, and that sum is divided by the cumulative 3D area of the triangles, yielding the weighted mean of the z-values at the triangle midpoints.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Features | The point, multipoint, polyline, or polygon features that define the locations for determining one or more surface properties. | Feature Layer |
| Input Surface | The LAS dataset, mosaic, raster, terrain, or TIN surface used for interpolating z-values. | LAS Dataset Layer; Mosaic Layer; Raster Layer; Terrain Layer; TIN Layer |
| Output Property | Specifies the surface elevation properties that will be added to the attribute table of the input feature class.Z—The surface z-values interpolated for the x,y-location of each single-point feature will be added.Minimum Z—The lowest surface z-values in the area defined by the polygon, along the length of a line, or among the interpolated values for points in a multipoint record will be added.Maximum Z—The highest surface elevation in the area defined by the polygon, along the length of a line, or among the interpolated values for points in a multipoint record will be added.Mean Z—The average surface elevation of the area defined by the polygon, along the length of a line, or among the interpolated values for points in a multipoint record will be added.Surface Area—The 3D surface area for the region defined by each polygon will be added.Surface Length—The 3D distance of the line along the surface will be added. Minimum Slope—The slope value closest to zero along the line or within the area defined by the polygon will be added.Maximum Slope—The highest slope value along the line or within the area defined by the polygon will be added.Average Slope—The average slope value along the line or within the area defined by the polygon will be added. | String |
| Method(Optional) | Specifies the interpolation method that will be used to determine information about the surface.Bilinear—An interpolation method exclusive to the raster surface that determines cell values from the four nearest cells will be used. This is the only option available for a raster surface.Linear— Elevation will be obtained from the plane defined by the triangle that contains the x,y-location of a query point. This is the default interpolation method for TINs, terrains, and LAS datasets. Natural Neighbors—Elevation will be obtained by applying area-based weights to the natural neighbors of a query point.Conflate Minimum Z— Elevation will be obtained from the smallest z-value found among the natural neighbors of a query point.Conflate Maximum Z— Elevation will be obtained from the largest z-value found among the natural neighbors of a query point.Conflate Nearest Z— Elevation will be obtained from the nearest value among the natural neighbors of a query point.Conflate Z Closest To Mean— Elevation will be obtained from the z-value that is closest to the average of all the natural neighbors of a query point. | String |
| Sampling Distance(Optional) | The spacing at which z-values will be interpolated. By default, the raster cell size is used when the input surface is a raster, and the natural densification of the triangulated surface is used when the input is a terrain or TIN dataset. | Double |
| Z Factor(Optional) | The factor by which z-values will be multiplied. This is typically used to convert z linear units to match x,y linear units. The default is 1, which leaves elevation values unchanged. This parameter is not available if the spatial reference of the input surface has a z-datum with a specified linear unit. | Double |
| Pyramid Level Resolution(Optional) | The z-tolerance or window-size resolution of the terrain pyramid level that will be used. The default is 0, or full resolution. | Double |
| Noise Filtering (Optional) | Defines whether portions of the surface that are potentially characterized by anomalous measurements will be excluded from contributing to slope calculations. Other properties are not affected by this parameter. Line features offer a length filter in which line segments with 3D lengths that are shorter than the specified value will be excluded from slope calculations. Polygon features offer an area filter in which polygons covering a surface area smaller than the specified value will be excluded. | String |
| in_feature_class | The point, multipoint, polyline, or polygon features that define the locations for determining one or more surface properties. | Feature Layer |
| in_surface | The LAS dataset, mosaic, raster, terrain, or TIN surface used for interpolating z-values. | LAS Dataset Layer; Mosaic Layer; Raster Layer; Terrain Layer; TIN Layer |
| out_property[out_property,...] | Specifies the surface elevation properties that will be added to the attribute table of the input feature class.Z—The surface z-values interpolated for the x,y-location of each single-point feature will be added.Z_MIN—The lowest surface z-values in the area defined by the polygon, along the length of a line, or among the interpolated values for points in a multipoint record will be added.Z_MAX—The highest surface elevation in the area defined by the polygon, along the length of a line, or among the interpolated values for points in a multipoint record will be added.Z_MEAN—The average surface elevation of the area defined by the polygon, along the length of a line, or among the interpolated values for points in a multipoint record will be added.SURFACE_AREA—The 3D surface area for the region defined by each polygon will be added.SURFACE_LENGTH—The 3D distance of the line along the surface will be added. MIN_SLOPE—The slope value closest to zero along the line or within the area defined by the polygon will be added.MAX_SLOPE—The highest slope value along the line or within the area defined by the polygon will be added.AVG_SLOPE—The average slope value along the line or within the area defined by the polygon will be added. | String |
| method(Optional) | Specifies the interpolation method that will be used to determine information about the surface.BILINEAR—An interpolation method exclusive to the raster surface that determines cell values from the four nearest cells will be used. This is the only option available for a raster surface.LINEAR— Elevation will be obtained from the plane defined by the triangle that contains the x,y-location of a query point. This is the default interpolation method for TINs, terrains, and LAS datasets. NATURAL_NEIGHBORS—Elevation will be obtained by applying area-based weights to the natural neighbors of a query point.CONFLATE_ZMIN— Elevation will be obtained from the smallest z-value found among the natural neighbors of a query point.CONFLATE_ZMAX— Elevation will be obtained from the largest z-value found among the natural neighbors of a query point.CONFLATE_NEAREST— Elevation will be obtained from the nearest value among the natural neighbors of a query point.CONFLATE_CLOSEST_TO_MEAN— Elevation will be obtained from the z-value that is closest to the average of all the natural neighbors of a query point. | String |
| sample_distance(Optional) | The spacing at which z-values will be interpolated. By default, the raster cell size is used when the input surface is a raster, and the natural densification of the triangulated surface is used when the input is a terrain or TIN dataset. | Double |
| z_factor(Optional) | The factor by which z-values will be multiplied. This is typically used to convert z linear units to match x,y linear units. The default is 1, which leaves elevation values unchanged. This parameter is not available if the spatial reference of the input surface has a z-datum with a specified linear unit. | Double |
| pyramid_level_resolution(Optional) | The z-tolerance or window-size resolution of the terrain pyramid level that will be used. The default is 0, or full resolution. | Double |
| noise_filtering(Optional) | Defines whether portions of the surface that are potentially characterized by anomalous measurements will be excluded from contributing to slope calculations. Other properties are not affected by this parameter. Line features offer a length filter in which line segments with 3D lengths that are shorter than the specified value will be excluded from slope calculations. Polygon features offer an area filter in which polygons covering a surface area smaller than the specified value will be excluded. | String |

## Code Samples

### Example 1

```python
AddSurfaceInformation(in_feature_class, in_surface, out_property, {method}, {sample_distance}, {z_factor}, {pyramid_level_resolution}, {noise_filtering})
```

### Example 2

```python
from arcpy.sa import *
AddSurfaceInformation("point.shp", "dtm_tin", "Z", "LINEAR")
```

### Example 3

```python
from arcpy.sa import *
AddSurfaceInformation("point.shp", "dtm_tin", "Z", "LINEAR")
```

### Example 4

```python
# Name: AddSurfaceInformation_Ex_02.py
# Description: This script demonstrates how to use AddSurfaceInformation 
# on a 2D point feature class in a target workspace.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/arcpyExamples/data"

# Set the local variables
inFeatureClass = "point.shp"
inSurface = "dtm_tin"
Prop = "Z"
method = "LINEAR"
pyramid = 5

# Execute the tool
AddSurfaceInformation(inFeatureClass, inSurface, Prop, method, 15, 1, pyramid)
```

### Example 5

```python
# Name: AddSurfaceInformation_Ex_02.py
# Description: This script demonstrates how to use AddSurfaceInformation 
# on a 2D point feature class in a target workspace.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/arcpyExamples/data"

# Set the local variables
inFeatureClass = "point.shp"
inSurface = "dtm_tin"
Prop = "Z"
method = "LINEAR"
pyramid = 5

# Execute the tool
AddSurfaceInformation(inFeatureClass, inSurface, Prop, method, 15, 1, pyramid)
```

---

## Adjust the encountered distance using a horizontal factor

## Code Samples

### Example 1

```python
0    1.40
    10   2.43
    20   2.30
    30   3.44
    40   1.25
    50   1.02
    60   0.90
    70   0.86
    80   0.25
    90   0.78
    100  1.49
    110  2.35
    120  3.32
    130  2.39
    140  3.18
    150  2.13
    160  1.89
    170  1.20
    180  2.034
```

---

## Adjust the encountered distance using a vertical factor

## Code Samples

### Example 1

```python
-90  -1
    -80  -1
    -70   2.099409721
    -60   0.060064462
    -50   0.009064613
    -40   0.00263818
    -30   0.001055449
    -20   0.000500142
    -10   0.00025934
      0   0.000198541
     10   0.000368021
     20   0.000709735
     30   0.001497754
     40   0.003743755
     50   0.012863298
     60   0.085235529
     70   2.979204206
     80  -1
     90  -1
```

### Example 2

```python
VF = cos(VRMA)power
```

### Example 3

```python
VF = cos(VRMA)power
```

### Example 4

```python
VF = sec(VRMA)power
```

### Example 5

```python
VF = sec(VRMA)power
```

---

## Aggregate Multidimensional Raster (Spatial Analyst)

## Summary

Generates a multidimensional raster dataset by combining existing multidimensional raster variables along a dimension.

## Usage

- Aggregate daily temperature data into monthly data in which the result is a multidimensional raster with 12 time slices, and each slice is the aggregate of each month across all the years. Choose Interval Keyword and set the keyword to Recurring Monthly.
- Aggregate daily temperature data into monthly data in which the result is a multidimensional raster with 360 slices, or 12 time slices per year (30 years x 12 months = 360 slices). Choose Interval Keyword and set the keyword to Monthly.
- Aggregate monthly temperature data into 4-month intervals. Choose Interval Value, set Value Interval to 4, and set Unit to Months.
- Aggregate temperature data from 0 to 25 meters, then from 25 to 50 meters, then from 50 to 100 meters. Choose Interval Ranges and specify minimum and maximum depths as 0 25; 25 50; 50 100.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Multidimensional Raster | The input multidimensional raster dataset. | Raster Dataset; Raster Layer; Mosaic Dataset; Mosaic Layer; Image Service; File |
| Dimension | The aggregation dimension. This is the dimension along which the variables will be aggregated. | String |
| Aggregation Method(Optional) | Specifies the mathematical method that will be used to combine the aggregated slices in an interval.When the method is set to Custom, the Aggregation Function parameter becomes active.Mean—The mean of a pixel's values will be calculated across all slices in the interval. This is the default.Maximum—The maximum value of a pixel will be calculated across all slices in the interval.Majority—The pixel value that occurred most frequently will be calculated across all slices in the interval.Minimum—The minimum value of a pixel will be calculated across all slices in the interval.Minority—The pixel value that occurred least frequently will be calculated across all slices in the interval.Median—The median value of a pixel will be calculated across all slices in the interval.Percentile—The percentile of values for a pixel will be calculated across all slices in the interval. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the Percentile value parameter.Range—The range of values for a pixel will be calculated across all slices in the interval.Standard Deviation—The standard deviation of a pixel's values will be calculated across all slices in the interval.Sum—The sum of a pixel's values will be calculated across all slices in the interval.Variety—The number of unique pixel values will be calculated across all slices in the interval.Custom—The pixel value will be calculated based on a custom raster function. | String |
| Variables [Dimension Info] (Description)(Optional) | The variable or variables that will be aggregated along the given dimension. If no variable is specified, all variables with the selected dimension will be aggregated.For example, to aggregate daily temperature data into monthly average values, specify temperature as the variable to be aggregated. If you do not specify any variables and you have both daily temperature and daily precipitation variables, both variables will be aggregated into monthly averages and the output multidimensional raster will include both variables. | String |
| Aggregation Definition(Optional) | Specifies the dimension interval for which the data will be aggregated.All—The data values will be aggregated across all slices. This is the default.Interval Keyword—The variable data will be aggregated using a commonly known interval.Interval Value—The variable data will be aggregated using a user-specified interval and unit.Interval Ranges—The variable data will be aggregated between specified pairs of values or dates. | String |
| Keyword Interval (Optional) | Specifies the keyword interval that will be used when aggregating along the dimension. This parameter is required when the Aggregation Definition parameter is set to Interval Keyword and the aggregation must be across time.Hourly—The data values will be aggregated into hourly time steps, and the result will include every hour in the time series.Daily—The data values will be aggregated into daily time steps, and the result will include every day in the time series.Weekly—The data values will be aggregated into weekly time steps, and the result will include every week in the time series.Dekadly—The data values will be aggregated into 3 periods of 10 days each. The last period can contain more or fewer than 10 days. The output will include 3 slices for each month.Pentadly—The data values will be aggregated into 6 periods of 5 days each. The last period can contain more or fewer than 5 days. The output will include 6 slices for each month.Monthly—The data values will be aggregated into monthly time steps, and the result will include every month in the time series.Quarterly—The data values will be aggregated into quarterly time steps, and the result will include every quarter in the time series.Yearly—The data values will be aggregated into yearly time steps, and the result will include every year in the time series.Recurring daily—The data values will be aggregated into daily time steps, and the result will include one aggregated value per Julian day. The output will include, at most, 366 daily time slices.Recurring weekly—The data values will be aggregated into weekly time steps, and the result will include one aggregated value per week. The output will include, at most, 53 weekly time slices.Recurring monthly—The data values will be aggregated into monthly time steps, and the result will include one aggregated value per month. The output will include, at most, 12 monthly time slices.Recurring quarterly—The data values will be aggregated into quarterly time steps, and the result will include one aggregated value per quarter. The output will include, at most, 4 quarterly time slices. | String |
| Value Interval(Optional) | The size of the interval that will be used for the aggregation. This parameter is required when the Aggregation Definition parameter is set to Interval Value.For example, to aggregate 30 years of monthly temperature data into 5-year increments, enter 5 as the Value Interval, and specify Unit as Years. | Double |
| Unit(Optional) | The unit that will be used for the Value Interval parameter. This parameter is required when the Dimension parameter is a time field and the Aggregation Definition parameter is set to Interval Value.If you are aggregating anything other than time, this option will not be available and the unit for the interval value will match the variable unit of the input multidimensional raster data.Hours—The data values will be aggregated into hourly time slices at the interval provided.Days—The data values will be aggregated into daily time slices at the interval provided.Weeks—The data values will be aggregated into weekly time slices at the interval provided.Months—The data values will be aggregated into monthly time slices at the interval provided.Years—The data values will be aggregated into yearly time slices at the interval provided. | String |
| Range(Optional) | Interval ranges specified in a value table will be used to aggregate groups of values. The value table consists of pairs of minimum and maximum range values, with data type Double or Date.This parameter is required when the Aggregation Definition parameter is set to Interval Ranges. | Value Table |
| Aggregation Function (Optional) | A custom raster function that will be used to compute the pixel values of the aggregated rasters. The input is a raster function JSON object or an .rft.xml file created from a function chain or a custom Python raster function. This parameter is required when the Aggregation Method parameter is set to Custom. | File; String |
| Ignore NoData(Optional) | Specifies whether NoData values will be ignored in the analysis.Checked—The analysis will include all valid pixels along a given dimension and ignore NoData pixels. This is the default.Unchecked—The analysis will result in NoData if there are NoData values for the pixels along the given dimension. | Boolean |
| Dimensionless (Optional) | Specifies whether the layer will have dimension values. This parameter is only active if a single slice is selected to create a layer.Checked—The layer will not have dimension values.Unchecked—The layer will have dimension values. This is the default. | Boolean |
| Percentile value(Optional) | The percentile that will be calculated. The default is 90, indicating the 90th percentile.The values can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to maximum. A value of 50 will produce essentially the same result as the median statistic. This parameter is only available if the Statistics type parameter is set to Percentile. | Double |
| Percentile interpolation type (Optional) | Specifies the method of percentile interpolation that will be used when there is an even number of values from the input raster to be calculated.Nearest—The nearest available value to the desired percentile will be used. In this case, the output pixel type will be the same as that of the input value raster.Linear—The weighted average of the two surrounding values from the desired percentile will be used. In this case, the output pixel type will be floating point. | String |
| in_multidimensional_raster | The input multidimensional raster dataset. | Raster Dataset; Raster Layer; Mosaic Dataset; Mosaic Layer; Image Service; File |
| dimension | The aggregation dimension. This is the dimension along which the variables will be aggregated. | String |
| aggregation_method(Optional) | Specifies the mathematical method that will be used to combine the aggregated slices in an interval.MEAN—The mean of a pixel's values will be calculated across all slices in the interval. This is the default.MAXIMUM—The maximum value of a pixel will be calculated across all slices in the interval.MAJORITY—The pixel value that occurred most frequently will be calculated across all slices in the interval.MINIMUM—The minimum value of a pixel will be calculated across all slices in the interval.MINORITY—The pixel value that occurred least frequently will be calculated across all slices in the interval.MEDIAN—The median value of a pixel will be calculated across all slices in the interval.PERCENTILE—The percentile of values for a pixel will be calculated across all slices in the interval. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the Percentile value parameter.RANGE—The range of values for a pixel will be calculated across all slices in the interval.STD—The standard deviation of a pixel's values will be calculated across all slices in the interval.SUM—The sum of a pixel's values will be calculated across all slices in the interval.VARIETY—The number of unique pixel values will be calculated across all slices in the interval.CUSTOM—The pixel value will be calculated based on a custom raster function. When aggregation_method is set to CUSTOM, the aggregation_function parameter becomes enabled. | String |
| variables[variables,...](Optional) | The variable or variables that will be aggregated along the given dimension. If no variable is specified, all variables with the selected dimension will be aggregated.For example, to aggregate daily temperature data into monthly average values, specify temperature as the variable to be aggregated. If you do not specify any variables and you have both daily temperature and daily precipitation variables, both variables will be aggregated into monthly averages and the output multidimensional raster will include both variables. | String |
| aggregation_def(Optional) | Specifies the dimension interval for which the data will be aggregated.ALL—The data values will be aggregated across all slices. This is the default.INTERVAL_KEYWORD—The variable data will be aggregated using a commonly known interval.INTERVAL_VALUE—The variable data will be aggregated using a user-specified interval and unit.INTERVAL_RANGES—The variable data will be aggregated between specified pairs of values or dates. | String |
| interval_keyword(Optional) | Specifies the keyword interval that will be used when aggregating along the dimension. This parameter is required when the aggregation_def parameter is set to INTERVAL_KEYWORD and the aggregation must be across time. HOURLY—The data values will be aggregated into hourly time steps, and the result will include every hour in the time series.DAILY—The data values will be aggregated into daily time steps, and the result will include every day in the time series.WEEKLY—The data values will be aggregated into weekly time steps, and the result will include every week in the time series.DEKADLY—The data values will be aggregated into 3 periods of 10 days each. The last period can contain more or fewer than 10 days. The output will include 3 slices for each month.PENTADLY—The data values will be aggregated into 6 periods of 5 days each. The last period can contain more or fewer than 5 days. The output will include 6 slices for each month.MONTHLY—The data values will be aggregated into monthly time steps, and the result will include every month in the time series.QUARTERLY—The data values will be aggregated into quarterly time steps, and the result will include every quarter in the time series.YEARLY—The data values will be aggregated into yearly time steps, and the result will include every year in the time series.RECURRING_DAILY—The data values will be aggregated into daily time steps, and the result will include one aggregated value per Julian day. The output will include, at most, 366 daily time slices.RECURRING_WEEKLY—The data values will be aggregated into weekly time steps, and the result will include one aggregated value per week. The output will include, at most, 53 weekly time slices.RECURRING_MONTHLY—The data values will be aggregated into monthly time steps, and the result will include one aggregated value per month. The output will include, at most, 12 monthly time slices.RECURRING_QUARTERLY—The data values will be aggregated into quarterly time steps, and the result will include one aggregated value per quarter. The output will include, at most, 4 quarterly time slices. | String |
| interval_value(Optional) | The size of the interval that will be used for the aggregation. This parameter is required when the aggregation_def parameter is set to INTERVAL_VALUE.For example, to aggregate 30 years of monthly temperature data into 5-year increments, enter 5 as the interval_value, and specify interval_unit as YEARS. | Double |
| interval_unit(Optional) | The unit that will be used for the interval_value parameter. This parameter is required when the dimension parameter is set to a time field and the aggregation_def parameter is set to INTERVAL_VALUE.If you are aggregating anything other than time, this option will not be available and the unit for the interval value will match the variable unit of the input multidimensional raster data.HOURS—The data values will be aggregated into hourly time slices at the interval provided.DAYS—The data values will be aggregated into daily time slices at the interval provided.WEEKS—The data values will be aggregated into weekly time slices at the interval provided.MONTHS—The data values will be aggregated into monthly time slices at the interval provided.YEARS—The data values will be aggregated into yearly time slices at the interval provided. | String |
| interval_ranges[interval_ranges,...](Optional) | Interval ranges specified in a value table will be used to aggregate groups of values. The value table consists of pairs of minimum and maximum range values, with data type Double or Date. This parameter is required when the aggregation_def parameter is set to INTERVAL_RANGE. | Value Table |
| aggregation_function(Optional) | A custom raster function that will be used to compute the pixel values of the aggregated rasters. The input is a raster function JSON object or an .rft.xml file created from a function chain or a custom Python raster function.This parameter is required when the aggregation_method parameter is set to CUSTOM. | File; String |
| ignore_nodata(Optional) | Specifies whether NoData values will be ignored in the analysis.DATA—The analysis will include all valid pixels along a given dimension and ignore NoData pixels. This is the default.NODATA—The analysis will result in NoData if there are NoData values for the pixels along the given dimension. | Boolean |
| dimensionless(Optional) | Specifies whether the layer will have dimension values. This parameter is only enabled if a single slice is selected to create a layer.NO_DIMENSIONS— The layer will not have dimension values.DIMENSIONS—The layer will have dimension values. This is the default. | Boolean |
| percentile_value(Optional) | The percentile that will be calculated. The default is 90, indicating the 90th percentile.The values can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to maximum. A value of 50 will produce essentially the same result as the median statistic. This parameter is only supported if the statistics_type parameter is set to PERCENTILE. | Double |
| percentile_interpolation_type(Optional) | Specifies the method of percentile interpolation that will be used when there is an even number of values from the input raster to be calculated.NEAREST—The nearest available value to the desired percentile will be used. In this case, the output pixel type will be the same as that of the input value raster.LINEAR—The weighted average of the two surrounding values from the desired percentile will be used. In this case, the output pixel type will be floating point. | String |

## Code Samples

### Example 1

```python
AggregateMultidimensionalRaster(in_multidimensional_raster, dimension, {aggregation_method}, {variables}, {aggregation_def}, {interval_keyword}, {interval_value}, {interval_unit}, {interval_ranges}, {aggregation_function}, {ignore_nodata}, {dimensionless}, {percentile_value}, {percentile_interpolation_type})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
arcpy.CheckOutExtension("Spatial")
outAggMultidim = AggregateMultidimensionalRaster("C:/sapyexamples/data/climateData.crf", 
	"StdTime", "MEAN", "temperature", "INTERVAL_KEYWORD", "YEARLY", 
	"", "", "", "", "DATA")
outAggMultidim.save("C:/sapyexamples/output/YearlyTemp.crf")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
arcpy.CheckOutExtension("Spatial")
outAggMultidim = AggregateMultidimensionalRaster("C:/sapyexamples/data/climateData.crf", 
	"StdTime", "MEAN", "temperature", "INTERVAL_KEYWORD", "YEARLY", 
	"", "", "", "", "DATA")
outAggMultidim.save("C:/sapyexamples/output/YearlyTemp.crf")
```

### Example 4

```python
# Name: AggregateMultidimensionalRaster_Ex_02.py
# Description: Aggregates daily precipitation and temperature data into
#           monthly data with the maximum precipitation and temperature values
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

""""
Usage: out_multidimensional_raster = AggregateMultidimensionalRaster(in_multidimensional_raster, dimension,
                                    {aggregation_method}, {variables}, 
                                    {aggregation_def}, {interval_keyword}, {ignore_nodata})
"""

# Define input parameters
inputFile = "C:/sapyexamples/data/dailyclimateData.crf"
dimensionName = "StdTime"
aggregationMethod = "Maximum"
variables = "temperature;precipitation"
aggregationDefinition = "INTERVAL_KEYWORD"
keyword = "MONTHLY"
ignore_nodata = "DATA"

# Execute AggregateMultidimensionalRaster
outAggMultidim = AggregateMultidimensionalRaster(inputFile, dimensionName,
	aggregationMethod, variables, aggregationDefinition, keyword, "", "", "", "",
	ignore_nodata)

# Save the output
outAggMultidim.save("C:/sapyexamples/output/monthlymaxtemp.crf")
```

### Example 5

```python
# Name: AggregateMultidimensionalRaster_Ex_02.py
# Description: Aggregates daily precipitation and temperature data into
#           monthly data with the maximum precipitation and temperature values
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

""""
Usage: out_multidimensional_raster = AggregateMultidimensionalRaster(in_multidimensional_raster, dimension,
                                    {aggregation_method}, {variables}, 
                                    {aggregation_def}, {interval_keyword}, {ignore_nodata})
"""

# Define input parameters
inputFile = "C:/sapyexamples/data/dailyclimateData.crf"
dimensionName = "StdTime"
aggregationMethod = "Maximum"
variables = "temperature;precipitation"
aggregationDefinition = "INTERVAL_KEYWORD"
keyword = "MONTHLY"
ignore_nodata = "DATA"

# Execute AggregateMultidimensionalRaster
outAggMultidim = AggregateMultidimensionalRaster(inputFile, dimensionName,
	aggregationMethod, variables, aggregationDefinition, keyword, "", "", "", "",
	ignore_nodata)

# Save the output
outAggMultidim.save("C:/sapyexamples/output/monthlymaxtemp.crf")
```

---

## Aggregate (Spatial Analyst)

## Summary

Generates a reduced-resolution version of a raster. Each output cell contains the Sum, Minimum, Maximum, Mean, or Median of the input cells that are encompassed by the extent of that cell.

## Usage

- For the Aggregation technique settings of Maximum, Minimum, or Sum, the output raster type will be the same as that of the input raster. If the setting is Mean or Median, the output type will always be float.
- The geoprocessing analysis environments Extent and Cell size are recognized by this tool. To determine the output raster's resolution when an integer cell size has been specified, multiply the cell resolution of the analysis environment by the input cell factor parameter. If the cell size for the analysis environment is set to the minimum or maximum of the inputs, the resolution of the output raster will be the product of the input raster's resolution multiplied by the specified cell factor.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster to be aggregated.It can be of integer or floating point type. | Raster Layer |
| Cell factor | The factor by which the cell size of the input raster will be multiplied. The value must be an integer greater than 1.For example, a cell factor value of 3 results in an output cell size three times larger than that of the input raster. | Long |
| Aggregation technique(Optional) | The method that will be used for aggregation.The values of the input cells encompassed by the coarser output cells are aggregated by one of the following statistics:Sum—The total of the input cell values. This is the default.Maximum—The largest value of the input cells.Mean—The average value of the input cells.Median—The median value of the input cells.Minimum—The smallest value of the input cells. | String |
| Expand extent if needed(Optional) | Specifies whether the boundaries of the input raster will be expanded when its rows or columns are not a multiple of the cell factor.Checked—The top or right boundaries of the input raster will be expanded so the total number of cells in a row or column is a multiple of the cell factor. Those expanded cells are given a value of NoData when put into the calculation. With this option, the output raster can cover a larger spatial extent than the input raster.This is the default.Unchecked—The number of rows or columns will be reduced in the output raster. This truncates the remaining cells on the top or right boundaries of the input raster, making the number of rows or columns in the input raster a multiple of the cell factor. With this option, the output raster can cover a smaller spatial extent than the input raster.If the number of rows and columns in the input raster is a multiple of the Cell factor, these keywords are not used. | Boolean |
| Ignore NoData in calculations(Optional) | Specifies whether NoData valueswill be ignored during the aggregation calculation.Checked—Specifies that if NoData values exist for any of the cells that fall within the spatial extent of a larger cell on the output raster, the NoData values will be ignored when determining the value for output cell locations. Only input cells within the extent of the output cell that have data values will be used in determining the value of the output cell. This is the default.Unchecked—Specifies that if any cell that falls within the spatial extent of a larger cell on the output raster has a value of NoData, the value for that output cell location will be NoData. When this option is used, it is implied that when cells within an aggregation contain the NoData value, there is insufficient information to perform the specified calculations necessary to determine an output value. | Boolean |
| in_raster | The input raster to be aggregated.It can be of integer or floating point type. | Raster Layer |
| cell_factor | The factor by which the cell size of the input raster will be multiplied. The value must be an integer greater than 1.For example, a cell factor value of 3 results in an output cell size three times larger than that of the input raster. | Long |
| aggregation_type(Optional) | The method that will be used for aggregation.The values of the input cells encompassed by the coarser output cells are aggregated by one of the following statistics:SUM—The total of the input cell values. This is the default.MAXIMUM—The largest value of the input cells.MEAN—The average value of the input cells.MEDIAN—The median value of the input cells.MINIMUM—The smallest value of the input cells. | String |
| extent_handling(Optional) | Specifies whether the boundaries of the input raster will be expanded when its rows or columns are not a multiple of the cell factor.EXPAND—The top or right boundaries of the input raster will be expanded so the total number of cells in a row or column is a multiple of the cell factor. Those expanded cells are given a value of NoData when put into the calculation.With this option, the output raster can cover a larger spatial extent than the input raster. This is the default.TRUNCATE—The number of rows or columns will be reduced by 1 in the output raster. This truncates the remaining cells on the top or right boundaries of the input raster, making the number of rows or columns in the input raster a multiple of the cell factor.With this option, the output raster can cover a smaller spatial extent than the input raster.If the number of rows and columns in the input raster is a multiple of the cell_factor, these keywords are not used. | Boolean |
| ignore_nodata(Optional) | Denotes whether NoData values are ignored by the aggregation calculation.DATA—Specifies that if NoData values exist for any of the cells that fall within the spatial extent of a larger cell on the output raster, the NoData values will be ignored when determining the value for output cell locations. Only input cells within the extent of the output cell that have data values will be used in determining the value of the output cell.This is the default.NODATA—Specifies that if any cell that falls within the spatial extent of a larger cell on the output raster has a value of NoData, the value for that output cell location will be NoData.When this option is used, it is implied that when cells within an aggregation contain the NoData value, there is insufficient information to perform the specified calculations necessary to determine an output value. | Boolean |

## Code Samples

### Example 1

```python
Aggregate(in_raster, cell_factor, {aggregation_type}, {extent_handling}, {ignore_nodata})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outAggreg = Aggregate("highres", 3, "MAXIMUM", "TRUNCATE", "DATA")
outAggreg.save("C:/sapyexamples/output/aggregate.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outAggreg = Aggregate("highres", 3, "MAXIMUM", "TRUNCATE", "DATA")
outAggreg.save("C:/sapyexamples/output/aggregate.tif")
```

### Example 4

```python
# Name: Aggregate_Ex_02.py
# Description: Generates a reduced resolution version of a raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "highres"
cellFactor = 3

# Execute Aggregate
outAggreg = Aggregate(inRaster, cellFactor, "MEAN", "TRUNCATE", "NODATA")

# Save the output 
outAggreg.save("C:/sapyexamples/output/aggregate02")
```

### Example 5

```python
# Name: Aggregate_Ex_02.py
# Description: Generates a reduced resolution version of a raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "highres"
cellFactor = 3

# Execute Aggregate
outAggreg = Aggregate(inRaster, cellFactor, "MEAN", "TRUNCATE", "NODATA")

# Save the output 
outAggreg.save("C:/sapyexamples/output/aggregate02")
```

---

## Applying a z-factor

## Code Samples

### Example 1

```python
Latitude    Z-factor
     0          0.00000898
    10          0.00000912
    20          0.00000956
    30          0.00001036
    40          0.00001171
    50          0.00001395
    60          0.00001792
    70          0.00002619
    80          0.00005156
```

---

## Area Solar Radiation (Spatial Analyst)

## Summary

Derives incoming solar radiation from a raster surface.

## Usage

- Calculating insolation can be very time consuming, where the calculations for a large digital elevation model (DEM) can take several hours, and for a very large DEM, even days. You may wish to do some test runs with a coarser resolution or subset of your data to ensure the settings are correct before committing a run with the full-resolution data.
- The output radiation rasters will always be floating-point type and have units of watt hours per square meter (WH/m2). The direct duration raster output will be integer with unit hours.
- The latitude for the site area (units: decimal degree, positive for the northern hemisphere and negative for the southern hemisphere) is used in calculations such as solar declination and solar position.The analysis is designed specifically for local landscape scales, so it is generally acceptable to use one latitude value for the whole DEM. With larger datasets, such as for states, countries, or continents, the insolation results will differ significantly at different latitudes (greater than 1 degree). To analyze broader geographic regions, you must divide the study area into zones with different latitudes.
- For multiday time configurations, the maximum range of days is a total of one year (365 days, or 366 days for leap years). If the start day is greater than the end day, the time calculations will proceed into the following year.For example, [start day, end day] = [365, 31] represents December 31 to January 31 of the following year. For the example of [1, 2], the time is inclusive for the first day from 0:00 hours (January 1) to 0:00 (January 2). The start day and end day cannot be equal.
- The year value for time configuration is used to determine a leap year. It does not have any other influence on the solar radiation analysis, as the calculations are a function of the time period determined by Julian days.
- For within-day time configurations, the maximum range of time is one day (24 hours). Calculations will not be performed across days (for example, from 12:00 p.m. to 12:00 p.m. the next day). The start time must be less than the end time.
- For within-day time configurations, the start and end times are displayed as solar time (units: decimal hours). Use the time conversion dialog box window to convert the local standard time and local solar time (HMS). When converting local standard time to solar time, the program accounts for equation of time.
- The use of a z-factor is essential for correcting calculations when the surface z-units are expressed in units different from the ground x,y units. For accurate results, the z-units should be the same as the x,y ground units. If the units are not the same, use a z-factor to convert z-units to x,y units. For example, if the x,y units are meters and the z-units are feet, you can specify a z-factor of 0.3048 to convert feet to meters.
- It is recommended that you have the data in a projected coordinate system with units of meters. If you run the analysis with a spherical coordinate system, you must specify an appropriate z-factor for that latitude. The following is a list of appropriate z-factors to use if the x,y units are decimal degrees and the z-units are meters: Latitude Z-factor 0 0.00000898 10 0.00000912 20 0.00000956 30 0.00001036 40 0.00001171 50 0.00001395 60 0.00001792 70 0.00002619 80 0.00005156
- The latitude for the site area (units: decimal degree, positive for the northern hemisphere and negative for the southern hemisphere) is used in calculations such as solar declination and solar position. Because the solar analysis is designed for landscape scales and local scales, it is acceptable to use one latitude value for the whole DEM. For broader geographic regions, you must divide the study area into zones with different latitudes.
- For input surface rasters containing a spatial reference, the mean latitude is automatically calculated; otherwise, the latitude default is 45 degrees. When using an input layer, the spatial reference of the data frame is used.
- Sky size is the resolution of the viewshed, sky map, and sun map rasters that are used in the radiation calculations (units: cells per side). These are upward-looking, hemispherical raster representations of the sky and do not have a geographic coordinate system. These rasters are square (equal number of rows and columns).The following are recommended sky size values when a time configuration of a whole year or multiple days is used:For a 1 day interval, use a sky size of 1000 and above.For a 0.25 day interval, use a sky size of 2000 and above.For a 0.1 hour interval, use a sky size of 4000 and above.Increasing the sky size increases calculation accuracy but also increases calculation time considerably.
- For a 1 day interval, use a sky size of 1000 and above.
- For a 0.25 day interval, use a sky size of 2000 and above.
- For a 0.1 hour interval, use a sky size of 4000 and above.
- When the day interval setting is small (for example, < 14 days), use a larger sky size. During analysis, the sun map (determined by the sky size) is used to represent sun positions (tracks) for particular time periods to calculate direct radiation. With smaller day intervals, if the sky size resolution is not large enough, sun tracks may overlap, resulting in zero or lower radiation values for that track. Increasing the resolution provides a more accurate result.
- The maximum sky size value is 10,000. A value of 200 is the default and is sufficient for whole DEMs with large day intervals (for example, > 14 days). A sky size value of 512 is sufficient for calculations at point locations where calculation time is less of an issue. At smaller day intervals (for example, < 14 days), it is recommended that you use higher values. For example, to calculate insolation for a location at the equator with day interval = 1, use a sky size of 2,800 or above.
- Day intervals greater than 3 are recommended, as sun tracks within three days typically overlap, depending on sky size and time of year. For calculations of the whole year with monthly interval, day interval is disabled and the program uses calendar month intervals. The default value is 14.
- Because the viewshed calculation can be highly intensive, horizon angles are only traced for the number of calculation directions specified. Valid values must be multiples of 8 (8, 16, 24, 32, and so on). Typically, a value of 8 or 16 is adequate for areas with gentle topography, and a value of 32 is adequate for complex topography. The default value is 32.
- The number of calculation directions needed is related to the resolution of the input DEM. Natural terrain at 30-meters resolution is usually quite smooth, so fewer directions are sufficient for most situations (16 or 32). With finer DEMs, and particularly with human-made structures incorporated in the DEMs, the number of directions needs to increase. Increasing the number of directions increases accuracy but also increase calculation time.
- The Create outputs for each interval parameter allows for the flexibility to calculate insolation integrated over a specified time period or insolation for each interval in a time series. For example, for the within-day time period with an hour interval of one, checking this parameter will create hourly insolation values; otherwise, insolation integrated for the entire day will be calculated.
- The Create outputs for each interval parameter affects the format and number of output radiation files. When checked, the output raster will contain multiple bands that correspond to the radiation or duration values for each time interval (hour interval when time configuration is less than one day, or day interval when multiple days).
- The diffuse proportion is the fraction of global normal radiation flux that is diffuse. Values range from 0 to 1. This value should be set according to atmospheric conditions. Typical values are 0.2 for very clear sky conditions and 0.3 for generally clear sky conditions.
- The amount of solar radiation received by the surface is only a portion of what would be received outside the atmosphere. Transmittivity is a property of the atmosphere that is expressed as the ratio of the energy (averaged overall wavelengths) reaching the earth's surface to that which is received at the upper limit of the atmosphere (extraterrestrial). Values range from 0 (no transmission) to 1 (complete transmission). Typically observed values are 0.6 or 0.7 for very clear sky conditions and 0.5 for a generally clear sky.The value for the energy received at the earth's surface is at the shortest path through the atmosphere (that is, the sun is at the zenith, or directly overhead) and for sea level. For areas beyond Tropic of Capricorn and Tropic of Cancer, the sun can never be at the exact zenith, even at noon; however, this value still refers to the moment when the sun is at the zenith. Because the algorithm corrects for elevation effects, transmittivity should always be given for sea level.Transmittivity has an inverse relation with the diffuse proportion parameter.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input elevation surface raster. | Raster Layer |
| Latitude(Optional) | The latitude for the site area. The units are decimal degrees with positive values for the northern hemisphere and negative values for the southern hemisphere.For input surface rasters containing a spatial reference, the mean latitude is automatically calculated; otherwise, the latitude default is 45 degrees. | Double |
| Sky size / Resolution(Optional) | The resolution or sky size for the viewshed, sky map, and sun map rasters. The units are cells.The default is a raster of 200 by 200 cells. | Long |
| Time configuration(Optional) | Specifies the time period that will be used for the calculations.Special days—Solar insolation will be calculated for the solstice days (summer and winter) and the equinox days (when the insolation for both spring and fall equinox are the same).Within day—Calculations will be performed for a specified time period within a single day. Select the Julian day and provide the start and end times. When the start time and the end time are the same, instantaneous insolation will be calculated. When the start time is before sunrise and the end time is after sunset, insolation will be calculated for the whole day.To enter the correct day, use the calendar button to open the Calendar dialog box. Multiple days—Calculations will be performed for a specific multiple-day period within a year.Specify the start year, start day, and end day. When the end day is smaller than the start day, the end day is considered to be in the following year. The default time configuration starts on day 5 and ends on day 160 of the current Julian year.To enter the correct days, use the calendar button to open the Calendar dialog box.Whole year—Calculations will be performed for an entire year using monthly intervals for calculations.If the Create outputs for each interval parameter is checked, output files will be created for each month; otherwise, a single output will be created for the whole year. | Time configuration |
| Day interval(Optional) | The time interval through the year (units: days) that will be used to calculate sky sectors for the sun map.The default value is 14 (biweekly). | Long |
| Hour interval(Optional) | The time interval through the day (units: hours) that will be used to calculate sky sectors for the sun map.The default value is 0.5. | Double |
| Create outputs for each interval(Optional) | Specifies whether a single total insolation value will be calculated for all locations or multiple values will be calculated for the specified hour and day interval. Unchecked—A single total radiation value will be calculated for the entire time configuration. This is the default.Checked—Multiple radiation values will be calculated for each time interval over the entire time configuration. The number of outputs depends on the hour or day interval. For example, for a whole year with monthly intervals, the result will contain 12 output radiation values for each location. The output raster will contain multiple bands that correspond to the radiation or duration values for each time interval. | Boolean |
| Z factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect.For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| Slope and aspect input type(Optional) | Specifies how slope and aspect information will be derived for analysis.From the input surface raster—The slope and aspect rasters will be calculated from the input surface raster. This is the default.From a flat surface—Constant values of zero will be used for slope and aspect. | String |
| Calculation directions(Optional) | The number of azimuth directions that will be used when calculating the viewshed.Valid values must be multiples of 8 (8, 16, 24, 32, and so on). The default value is 32 directions, which is adequate for complex topography. | Long |
| Zenith divisions(Optional) | The number of zenith divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to zenith). Values must be greater than zero and less than half the sky size value. | Long |
| Azimuth divisions(Optional) | The number of azimuth divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to north). Valid values must be multiples of 8. Values must be greater than zero and less than 160. | Long |
| Diffuse model type(Optional) | Specifies the type of diffuse radiation model that will be used.Uniform sky—The uniform diffuse model will be used. The incoming diffuse radiation is the same from all sky directions. This is the default.Standard overcast sky—The standard overcast diffuse model will be used. The incoming diffuse radiation flux varies with the zenith angle. | String |
| Diffuse proportion(Optional) | The proportion of global normal radiation flux that is diffuse. Values range from 0 to 1.Set this value according to atmospheric conditions. The default value is 0.3 for generally clear sky conditions. | Double |
| Transmittivity(Optional) | The fraction of radiation that passes through the atmosphere (averaged overall wavelengths). Values range from 0 (no transmission) to 1 (all transmission).The default is 0.5 for a generally clear sky. | Double |
| Output direct radiation raster(Optional) | The output raster representing the direct incoming solar radiation for each location. The output has units of watt hours per square meter (WH/m2). | Raster Dataset |
| Output diffuse radiation raster(Optional) | The output raster representing the diffuse incoming solar radiation for each location.The output has units of watt hours per square meter (WH/m2). | Raster Dataset |
| Output direct duration raster(Optional) | The output raster representing the duration of direct incoming solar radiation. The output has units of hours. | Raster Dataset |
| in_surface_raster | The input elevation surface raster. | Raster Layer |
| latitude(Optional) | The latitude for the site area. The units are decimal degrees with positive values for the northern hemisphere and negative values for the southern hemisphere.For input surface rasters containing a spatial reference, the mean latitude is automatically calculated; otherwise, the latitude default is 45 degrees. | Double |
| sky_size(Optional) | The resolution or sky size for the viewshed, sky map, and sun map rasters. The units are cells.The default is a raster of 200 by 200 cells. | Long |
| time_configuration(Optional) | Specifies the time configuration (period) that will be used for calculating solar radiation.The Time class objects will be used to specify the time configuration.The different types of time configurations available are TimeWithinDay, TimeMultipleDays, TimeSpecialDays, and TimeWholeYear.The following are the forms:TimeWithinDay({day},{startTime},{endTime})TimeMultipleDays({year},{startDay},{endDay})TimeSpecialDays()TimeWholeYear({year})The default time configuration is TimeMultipleDays with the startDay value of 5 and the endDay value of 160 for the current Julian year. | Time configuration |
| day_interval(Optional) | The time interval through the year (units: days) that will be used to calculate sky sectors for the sun map.The default value is 14 (biweekly). | Long |
| hour_interval(Optional) | The time interval through the day (units: hours) that will be used to calculate sky sectors for the sun map.The default value is 0.5. | Double |
| each_interval(Optional) | Specifies whether a single total insolation value will be calculated for all locations or multiple values will be calculated for the specified hour and day interval. NOINTERVAL—A single total radiation value will be calculated for the entire time configuration. This is the default.INTERVAL—Multiple radiation values will be calculated for each time interval over the entire time configuration. The number of outputs depends on the hour or day interval. For example, for a whole year with monthly intervals, the result will contain 12 output radiation values for each location. The output raster will contain multiple bands that correspond to the radiation or duration values for each time interval. | Boolean |
| z_factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect.For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| slope_aspect_input_type(Optional) | Specifies how slope and aspect information will be derived for analysis. FROM_DEM—The slope and aspect rasters will be calculated from the input surface raster. This is the default.FLAT_SURFACE—Constant values of zero will be used for slope and aspect. | String |
| calculation_directions(Optional) | The number of azimuth directions that will be used when calculating the viewshed.Valid values must be multiples of 8 (8, 16, 24, 32, and so on). The default value is 32 directions, which is adequate for complex topography. | Long |
| zenith_divisions(Optional) | The number of zenith divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to zenith). Values must be greater than zero and less than half the sky size value. | Long |
| azimuth_divisions(Optional) | The number of azimuth divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to north). Valid values must be multiples of 8. Values must be greater than zero and less than 160. | Long |
| diffuse_model_type(Optional) | Specifies the type of diffuse radiation model that will be used.UNIFORM_SKY—The uniform diffuse model will be used. The incoming diffuse radiation is the same from all sky directions. This is the default.STANDARD_OVERCAST_SKY—The standard overcast diffuse model will be used. The incoming diffuse radiation flux varies with the zenith angle. | String |
| diffuse_proportion(Optional) | The proportion of global normal radiation flux that is diffuse. Values range from 0 to 1.Set this value according to atmospheric conditions. The default value is 0.3 for generally clear sky conditions. | Double |
| transmittivity(Optional) | The fraction of radiation that passes through the atmosphere (averaged overall wavelengths). Values range from 0 (no transmission) to 1 (all transmission).The default is 0.5 for a generally clear sky. | Double |
| out_direct_radiation_raster(Optional) | The output raster representing the direct incoming solar radiation for each location. The output has units of watt hours per square meter (WH/m2). | Raster Dataset |
| out_diffuse_radiation_raster(Optional) | The output raster representing the diffuse incoming solar radiation for each location.The output has units of watt hours per square meter (WH/m2). | Raster Dataset |
| out_direct_duration_raster(Optional) | The output raster representing the duration of direct incoming solar radiation. The output has units of hours. | Raster Dataset |

## Code Samples

### Example 1

```python
Latitude     Z-factor
       0         0.00000898
      10         0.00000912
      20         0.00000956
      30         0.00001036
      40         0.00001171
      50         0.00001395
      60         0.00001792
      70         0.00002619
      80         0.00005156
```

### Example 2

```python
AreaSolarRadiation(in_surface_raster, {latitude}, {sky_size}, {time_configuration}, {day_interval}, {hour_interval}, {each_interval}, {z_factor}, {slope_aspect_input_type}, {calculation_directions}, {zenith_divisions}, {azimuth_divisions}, {diffuse_model_type}, {diffuse_proportion}, {transmittivity}, {out_direct_radiation_raster}, {out_diffuse_radiation_raster}, {out_direct_duration_raster})
```

### Example 3

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "C:/sapyexamples/data"
outGlobalRadiation = AreaSolarRadiation("dem30", "", "400", TimeMultipleDays(2008,91,152))
outGlobalRadiation.save("C:/sapyexamples/output/glob_rad")
```

### Example 4

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "C:/sapyexamples/data"
outGlobalRadiation = AreaSolarRadiation("dem30", "", "400", TimeMultipleDays(2008,91,152))
outGlobalRadiation.save("C:/sapyexamples/output/glob_rad")
```

### Example 5

```python
# Name: AreaSolarRadiation_example02.py
# Description: Derives incoming solar radiation from a raster surface. 
#              Outputs a global radiation raster and optional direct, diffuse and direct duration rasters
#              for a specified time period. (April to July).
#              
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/output"

# Set local variables
inRaster = "C:/sapyexamples/data/solar_dem"
latitude = 35.75
skySize = 400
timeConfig = TimeMultipleDays(2008, 91, 212)
dayInterval = 14
hourInterval = 0.5
zFactor = 0.3048
calcDirections = 32
zenithDivisions = 16
azimuthDivisions = 16
diffuseProp = 0.7
transmittivity = 0.4
outDirectRad = ""
outDiffuseRad = ""
outDirectDur = Raster("C:/sapyexamples/output/dir_dur")


# Execute AreaSolarRadiation
outGlobalRad = AreaSolarRadiation(inRaster, latitude, skySize, timeConfig,
   dayInterval, hourInterval, "NOINTERVAL", zFactor, "FLAT_SURFACE",
   calcDirections, zenithDivisions, azimuthDivisions, "UNIFORM_SKY",
   diffuseProp, transmittivity, outDirectRad, outDiffuseRad, outDirectDur)

# Save the output 
outGlobalRad.save("C:/sapyexamples/output/glob_rad")
```

### Example 6

```python
# Name: AreaSolarRadiation_example02.py
# Description: Derives incoming solar radiation from a raster surface. 
#              Outputs a global radiation raster and optional direct, diffuse and direct duration rasters
#              for a specified time period. (April to July).
#              
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/output"

# Set local variables
inRaster = "C:/sapyexamples/data/solar_dem"
latitude = 35.75
skySize = 400
timeConfig = TimeMultipleDays(2008, 91, 212)
dayInterval = 14
hourInterval = 0.5
zFactor = 0.3048
calcDirections = 32
zenithDivisions = 16
azimuthDivisions = 16
diffuseProp = 0.7
transmittivity = 0.4
outDirectRad = ""
outDiffuseRad = ""
outDirectDur = Raster("C:/sapyexamples/output/dir_dur")


# Execute AreaSolarRadiation
outGlobalRad = AreaSolarRadiation(inRaster, latitude, skySize, timeConfig,
   dayInterval, hourInterval, "NOINTERVAL", zFactor, "FLAT_SURFACE",
   calcDirections, zenithDivisions, azimuthDivisions, "UNIFORM_SKY",
   diffuseProp, transmittivity, outDirectRad, outDiffuseRad, outDirectDur)

# Save the output 
outGlobalRad.save("C:/sapyexamples/output/glob_rad")
```

---

## ASin (Spatial Analyst)

## Summary

Calculates the inverse sine of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -1 ≤ [in_value] ≤ 1 Note that any input value that is outside this domain will receive NoData on the output raster.The Range is: -pi/2 ≤ [out_value] ≤ pi/2
- The Domain is: -1 ≤ [in_value] ≤ 1 Note that any input value that is outside this domain will receive NoData on the output raster.
- The Range is: -pi/2 ≤ [out_value] ≤ pi/2
- The input values to this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- The output values from this tool are in radians. To use degrees instead, the resulting raster must be multiplied by the radians-to-degrees conversion factor of 180/pi, or approximately 57.296.For further assistance, a procedure to follow and examples of converting output in radians to degrees are available.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the inverse sine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the inverse sine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
ASin(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outASin = ASin("degs")
outASin.save("C:/sapyexamples/output/outasin")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outASin = ASin("degs")
outASin.save("C:/sapyexamples/output/outasin")
```

### Example 4

```python
# Name: ASin_Ex_02.py
# Description: Calculates the inverse sine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute ASin
outASin = ASin(inRaster)

# Save the output 
outASin.save("C:/sapyexamples/output/outasin.img")
```

### Example 5

```python
# Name: ASin_Ex_02.py
# Description: Calculates the inverse sine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute ASin
outASin = ASin(inRaster)

# Save the output 
outASin.save("C:/sapyexamples/output/outasin.img")
```

---

## ASinH (Spatial Analyst)

## Summary

Calculates the inverse hyperbolic sine of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -∞ < [in_value] < ∞ The Range is: -∞ < [out_value] < ∞ Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: -∞ < [in_value] < ∞
- The Range is: -∞ < [out_value] < ∞
- The input and output values for this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the inverse hyperbolic sine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the inverse hyperbolic sine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
ASinH(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outASinH = ASinH("degs")
outASinH.save("C:/sapyexamples/output/outasinh")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outASinH = ASinH("degs")
outASinH.save("C:/sapyexamples/output/outasinh")
```

### Example 4

```python
# Name: ASinH_Ex_02.py
# Description: Calculates the inverse hyperbolic sine of cells
#              in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute ASinH
outASinH = ASinH(inRaster)

# Save the output 
outASinH.save("C:/sapyexamples/output/outasinh.img")
```

### Example 5

```python
# Name: ASinH_Ex_02.py
# Description: Calculates the inverse hyperbolic sine of cells
#              in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute ASinH
outASinH = ASinH(inRaster)

# Save the output 
outASinH.save("C:/sapyexamples/output/outasinh.img")
```

---

## Aspect (Spatial Analyst)

## Summary

Derives the aspect from each cell of a raster surface.

## Usage

- The Surface Parameters tool provides a newer implementation of aspect and is recommended to be used instead of the Aspect tool. The Aspect tool fits a plane to the nine local cells, but a plane may not be a good descriptor of the landscape and may mask or exaggerate natural variations of interest. The Surface Parameters tool fits a surface to the neighborhood of cells instead of a plane, which provides a more natural fit to the terrain.The Aspect tool uses a 3 by 3 window of cells to compute the value, while the Surface Parameters tool allows window sizes from 3 by 3 to 15 by 15 cells. Larger window sizes are useful with high resolution elevation data to capture land surface processes at an appropriate scale. The Surface Parameters tool also provides an adaptive window option that evaluates the local variability of the terrain and identifies the largest appropriate neighborhood size for each cell. This can be useful with gradual homogeneous terrain interrupted by streams, roads, or sharp breaks in slope.You can continue to use the traditional approach of the Aspect tool if you need the results to exactly match previous tool runs or if fast processing time is more important than a better algorithm.
- This tool uses a 3 by 3 cell moving window to process the data. If the processing cell is NoData, the output for that location will be NoData.
- Of the eight cells neighboring the processing cell, this tool requires that at least seven of them have a valid value. If there are fewer than seven valid cells, the calculation will not be performed, and the output at that processing cell will be NoData.
- The cells in the outermost rows and columns of the output raster will be NoData. This is because along the boundary of the input dataset, those cells do not have enough valid neighbors.
- Aspect is expressed in positive degrees from 0 to 360, measured clockwise from north.
- Cells in the input raster that are flat—with zero slope—are assigned an aspect of -1.
- For the geodesic method, specifying the surface z-unit ensures the accuracy of the output. The Z unit parameter will be enabled only when the geodesic method is selected.
- If a z-unit is available in the vertical coordinate system of the input raster, it will be applied automatically. It is recommended that you define a z-unit for the input raster if it is missing. You can use the Define Projection tool to specify a z-unit. If it is undefined, meter will be used by default.
- The Project geodesic azimuths (project_geodesic_azimuths in Python) parameter is available only when the Method parameter is set to Geodesic.For the Geodesic method, if the Project geodesic azimuths parameter is checked (project_geodesic_azimuths is set to PROJECT_GEODESIC_AZIMUTHS in Python), the following are true: North is always represented by 360 degrees.Azimuths will be projected to correct the distortion caused by a nonconformal Output Coordinate System environment value. These angles can be used to accurately locate points along the steepest downhill slope. Check the Project geodesic azimuths parameter if you're using the Aspect output as a back direction input for a tool in the Distance toolset.
- North is always represented by 360 degrees.
- Azimuths will be projected to correct the distortion caused by a nonconformal Output Coordinate System environment value. These angles can be used to accurately locate points along the steepest downhill slope.
- When the input raster needs to be resampled, the bilinear technique will be used. An example of when an input raster may be resampled is when the output coordinate system, extent, or cell size is different from that of the input.
- If the Input raster parameter value is high resolution with a cell size of less than a few meters, or particularly noisy, consider using the Surface Parameters tool and its user-defined neighborhood distance option instead of the immediate 3 by 3 neighborhood of this tool. Using a larger neighborhood can minimize the effect of noisy surfaces. Using a larger neighborhood can also better represent landforms and surface characteristics when using high resolution surfaces.
- This tool can be GPU accelerated, which means that if a compatible graphics processing unit (GPU) is available on your system, it will be used to enhance the performance of the tool. Use the Target device for analysis (analysis_target_device in Python) parameter to control whether the GPU or CPU will be used to run the tool.See GPU processing with Spatial Analyst for details on compatible GPUs, configuring and working with GPU devices, as well as troubleshooting tips.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input surface raster. | Raster Layer |
| Method(Optional) | Specifies whether the calculation will be based on a planar (flat earth) or a geodesic (ellipsoid) method.The planar method is appropriate to use on local areas in a projection that maintains correct distance and area. It is suitable for analyses that cover areas such cities, counties, or smaller states in area. The geodesic method produces a more accurate result, at the potential cost of an increase in processing time.Planar—The calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default method.Geodesic—The calculation will be performed in a 3D Cartesian coordinate system by considering the shape of the earth as an ellipsoid. | String |
| Z unit(Optional) | Specifies the linear unit that will be used for vertical z-values.It is defined by a vertical coordinate system if it exists. If no vertical coordinate system exists, define the z-unit using the unit list to ensure correct geodesic computation. The default is meter.Inch—The linear unit will be inches.Foot—The linear unit will be feet.Yard—The linear unit will be yards.Mile US—The linear unit will be miles.Nautical mile—The linear unit will be nautical miles.Millimeter—The linear unit will be millimeters.Centimeter—The linear unit will be centimeters.Meter—The linear unit will be meters.Kilometer—The linear unit will be kilometers.Decimeter—The linear unit will be decimeters. | String |
| Project geodesic azimuths(Optional) | Specifies whether geodesic azimuths will be projected to correct the angle distortion caused by the output spatial reference. Unchecked—Geodesic azimuths will not be projected. This is the default.Checked—Geodesic azimuths will be projected. This option supports CPU processing only. | Boolean |
| Target device for analysis(Optional) | Specifies the device that will be used to perform the calculation.GPU then CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU only—The calculation will only be performed on the CPU.GPU only—The calculation will only be performed on the GPU. | String |
| in_raster | The input surface raster. | Raster Layer |
| method(Optional) | Specifies whether the calculation will be based on a planar (flat earth) or a geodesic (ellipsoid) method.PLANAR—The calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default method.GEODESIC—The calculation will be performed in a 3D Cartesian coordinate system by considering the shape of the earth as an ellipsoid. The planar method is appropriate to use on local areas in a projection that maintains correct distance and area. It is suitable for analyses that cover areas such cities, counties, or smaller states in area. The geodesic method produces a more accurate result, at the potential cost of an increase in processing time. | String |
| z_unit(Optional) | Specifies the linear unit that will be used for vertical z-values.It is defined by a vertical coordinate system if it exists. If no vertical coordinate system exists, define the z-unit using the unit list to ensure correct geodesic computation. The default is meter.INCH—The linear unit will be inches.FOOT—The linear unit will be feet.YARD—The linear unit will be yards.MILE_US—The linear unit will be miles.NAUTICAL_MILE—The linear unit will be nautical miles.MILLIMETER—The linear unit will be millimeters.CENTIMETER—The linear unit will be centimeters.METER—The linear unit will be meters.KILOMETER—The linear unit will be kilometers.DECIMETER—The linear unit will be decimeters. | String |
| project_geodesic_azimuths(Optional) | Specifies whether geodesic azimuths will be projected to correct the angle distortion caused by the output spatial reference. GEODESIC_AZIMUTHS—Geodesic azimuths will not be projected. This is the default.PROJECT_GEODESIC_AZIMUTHS—Geodesic azimuths will be projected. | Boolean |
| analysis_target_device(Optional) | Specifies the device that will be used to perform the calculation.GPU_THEN_CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU_ONLY—The calculation will only be performed on the CPU.GPU_ONLY—The calculation will only be performed on the GPU. | String |

## Code Samples

### Example 1

```python
Aspect(in_raster, {method}, {z_unit}, {project_geodesic_azimuths}, {analysis_target_device})
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outAspect = Aspect("elevation")
outAspect.save("C:/sapyexamples/output/outaspect01.img")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outAspect = Aspect("elevation")
outAspect.save("C:/sapyexamples/output/outaspect01.img")
```

### Example 4

```python
# Name: Aspect_Ex_02.py
# Description: Derives aspect from a raster surface.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
method = "GEODESIC"
zUnit = "FOOT"
# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute Aspect
outAspect = Aspect(inRaster, method, zUnit)

# Save the output 
outAspect.save("C:/sapyexamples/output/outaspect02")
```

### Example 5

```python
# Name: Aspect_Ex_02.py
# Description: Derives aspect from a raster surface.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
method = "GEODESIC"
zUnit = "FOOT"
# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute Aspect
outAspect = Aspect(inRaster, method, zUnit)

# Save the output 
outAspect.save("C:/sapyexamples/output/outaspect02")
```

---

## ATan (Spatial Analyst)

## Summary

Calculates the inverse tangent of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -∞ < [in_value] < ∞ The Range is: -pi/2 ≤ [out_value] ≤ pi/2 Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: -∞ < [in_value] < ∞
- The Range is: -pi/2 ≤ [out_value] ≤ pi/2
- The input values to this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- The output values from this tool are in radians. To use degrees instead, the resulting raster must be multiplied by the radians-to-degrees conversion factor of 180/pi, or approximately 57.296.For further assistance, a procedure to follow and examples of converting output in radians to degrees are available.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the inverse tangent values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the inverse tangent values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
ATan(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outATan = ATan("degs")
outATan.save("C:/sapyexamples/output/outatan")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outATan = ATan("degs")
outATan.save("C:/sapyexamples/output/outatan")
```

### Example 4

```python
# Name: ATan_Ex_02.py
# Description: Calculates the inverse tangent of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute ATan
outATan = ATan(inRaster)

# Save the output 
outATan.save("C:/sapyexamples/output/outatan.tif")
```

### Example 5

```python
# Name: ATan_Ex_02.py
# Description: Calculates the inverse tangent of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute ATan
outATan = ATan(inRaster)

# Save the output 
outATan.save("C:/sapyexamples/output/outatan.tif")
```

---

## ATan2 (Spatial Analyst)

## Summary

Calculates the inverse tangent (based on x,y) of cells in a raster.

## Usage

- ATan2 converts rectangular coordinates (x,y) to polar (r,θ), where r is the distance from the origin and θ is the angle from the x-axis.Conversion of rectangular to polar coordinatesThe equation for determining ATan2 is: tanθ = y / x (where θ is the angle).The ATan2 operation represents all quadrants in a Cartesian matrix (based on sign).
- The values of the first specified input are used as the numerator in the calculation of the tangent angle (y). The values of the second specified input are used as the denominator in the calculation of the angle (x).
- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -∞ < [in_value] < ∞ This domain applies to both inputs.The Range is: -pi < [out_value] ≤ pi Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: -∞ < [in_value] < ∞ This domain applies to both inputs.
- The Range is: -pi < [out_value] ≤ pi
- If both input values are 0, the output will be NoData.If first input value is 0, the output will be 0.
- The input values to ATan2 are interpreted as being in linear units, and to give meaningful results, they should both be in the same unit.
- Output values are always floating point, regardless of the input data type.
- The output values from this tool are in radians. To use degrees instead, the resulting raster must be multiplied by the radians-to-degrees conversion factor of 180/pi, or approximately 57.296.For further assistance, a procedure to follow and examples of converting output in radians to degrees are available.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input that specifies the numerator, or y value, to use when calculating the inverse tangent.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input that specifies the denominator, or x value, to use when calculating the inverse tangent.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input that specifies the numerator, or y value, to use when calculating the inverse tangent.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input that specifies the denominator, or x value, to use when calculating the inverse tangent.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
ATan2(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outATan2 = ATan2("degs", "negs")
outATan2.save("C:/sapyexamples/output/outatan2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outATan2 = ATan2("degs", "negs")
outATan2.save("C:/sapyexamples/output/outatan2")
```

### Example 4

```python
# Name: ATan2_Ex_02.py
# Description: Calculates the inverse tangent of cells based
#              on (y, x) values from two rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute ATan2
outATan2 = ATan2(inRaster1, inRaster2)

# Save the output 
outATan2.save("C:/sapyexamples/output/outatan2.tif")
```

### Example 5

```python
# Name: ATan2_Ex_02.py
# Description: Calculates the inverse tangent of cells based
#              on (y, x) values from two rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute ATan2
outATan2 = ATan2(inRaster1, inRaster2)

# Save the output 
outATan2.save("C:/sapyexamples/output/outatan2.tif")
```

---

## ATanH (Spatial Analyst)

## Summary

Calculates the inverse hyperbolic tangent of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -1 < [in_value] < 1 Note that any input value that is outside this domain will receive NoData on the output raster.The Range is: -∞ < [out_value] < ∞ Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: -1 < [in_value] < 1 Note that any input value that is outside this domain will receive NoData on the output raster.
- The Range is: -∞ < [out_value] < ∞
- The input and output values for this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the inverse hyperbolic tangent values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the inverse hyperbolic tangent values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
ATanH(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outATanH = ATanH("degs")
outATanH.save("C:/sapyexamples/output/outatanh")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outATanH = ATanH("degs")
outATanH.save("C:/sapyexamples/output/outatanh")
```

### Example 4

```python
# Name: ATanH_Ex_02.py
# Description: Calculates the inverse hyperbolic tangent of cells 
#    in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute TanH
outATanH = ATanH(inRaster)

# Save the output 
outATanH.save("C:/sapyexamples/output/outatanh.img")
```

### Example 5

```python
# Name: ATanH_Ex_02.py
# Description: Calculates the inverse hyperbolic tangent of cells 
#    in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute TanH
outATanH = ATanH(inRaster)

# Save the output 
outATanH.save("C:/sapyexamples/output/outatanh.img")
```

---

## Band Collection Statistics (Spatial Analyst)

## Summary

Calculates the statistics for a set of raster bands.

## Usage

- When a multiband raster is specified as one of the Input raster bands (in_raster_bands in Python), all the bands will be used.To process a selection of bands from a multiband raster, you can first create a new raster dataset composed of those particular bands with the Composite Bands tool, and use the result in the list of the Input raster bands (in_raster_bands in Python).
- The raster bands must have a common intersection. If there are none, an error occurs and no output is created.
- If the extents of the raster bands are not the same, the statistics will be calculated on the common spatial extent of all the input raster bands. The cell size will be that of the maximum of the input rasters.
- For the Compute covariance and correlation matrices parameter, the default unchecked setting (BRIEF in scripting) indicates that only the minimum, maximum, mean, and standard deviation of the input raster bands will be computed. To calculate the covariance and correlation matrices in addition to these statistics, check this option on in the tool dialog box (or use DETAILED in scripting).A covariance matrix presents the variances of all raster bands along the diagonal from the upper left to lower right and covariances between all raster bands in the remaining entries. The correlation matrix provides the correlation coefficients between each combination of two input bands.
- In the calculation of the covariance matrix, the mean value of the band is used for any input cells that are NoData.
- The statistics are written to the output file in ASCII text format. The extension for the output must be .txt.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster bands | The input raster bands.They can be integer or floating point type. | Raster Layer |
| Output statistics file | The output ASCII file containing the statistics.A .txt extension is required. | File |
| Compute covariance and correlation matrices(Optional) | Specifies whether covariance and correlation matrices are calculated.Unchecked—Only the basic statistical measures (minimum, maximum, mean, and standard deviation) will be calculated for every layer. This is the default.Checked—In addition to the standard statistics calculated, the covariance and correlation matrices will also be determined. | Boolean |
| in_raster_bands[in_raster_band,...] | The input raster bands.They can be integer or floating point type. | Raster Layer |
| out_stat_file | The output ASCII file containing the statistics.A .txt extension is required. | File |
| compute_matrices(Optional) | Specifies whether covariance and correlation matrices are calculated.BRIEF—Only the basic statistical measures (minimum, maximum, mean, and standard deviation) will be calculated for every layer. This is the default.DETAILED—In addition to the standard statistics calculated with {BRIEF}, the covariance and correlation matrices will also be determined. | Boolean |

## Code Samples

### Example 1

```python
BandCollectionStats(in_raster_bands, out_stat_file, {compute_matrices})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
BandCollectionStats("redlands", "c:/sapyexamples/output/redbandstats.txt", "BRIEF")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
BandCollectionStats("redlands", "c:/sapyexamples/output/redbandstats.txt", "BRIEF")
```

### Example 4

```python
# Name: BandCollectionStats_Ex_02.py
# Description: Calculates the statistics for a set of raster bands.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasterBand1 = "sb/sbc1"
inRasterBand2 = "sb/sbc2"
outStatFile = "C:/sapyexamples/output/bandstatfile.txt"

# Execute BandCollectionStats
BandCollectionStats([inRasterBand1, inRasterBand2], outStatFile, "DETAILED")
```

### Example 5

```python
# Name: BandCollectionStats_Ex_02.py
# Description: Calculates the statistics for a set of raster bands.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasterBand1 = "sb/sbc1"
inRasterBand2 = "sb/sbc2"
outStatFile = "C:/sapyexamples/output/bandstatfile.txt"

# Execute BandCollectionStats
BandCollectionStats([inRasterBand1, inRasterBand2], outStatFile, "DETAILED")
```

---

## Basin (Spatial Analyst)

## Summary

Creates a raster delineating all drainage basins.

## Usage

- The drainage basins are delineated within the analysis window by identifying ridge lines between basins. The input flow direction raster is analyzed to find all sets of connected cells that belong to the same drainage basin. The drainage basins are created by locating the pour points at the edges of the analysis window (where water would pour out of the raster), as well as sinks, then identifying the contributing area above each pour point. This results in a raster of drainage basins.
- To create the input D8 flow direction raster, the Flow Direction tool must be run using the default flow direction type D8.The best results will be obtained if when the input D8 Flow Direction raster was created, the Force all edge cells to flow outward option (FORCE in Python) was enabled.
- All cells in the raster will belong to a basin, even if that basin is only one cell.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input D8 flow direction raster | The input raster that shows the direction of flow out of each cell. A flow direction raster can be created with the Flow Direction tool, using the default D8 flow direction type . | Raster Layer |
| in_flow_direction_raster | The input raster that shows the direction of flow out of each cell. A flow direction raster can be created with the Flow Direction tool, using the default D8 flow direction type . | Raster Layer |

## Code Samples

### Example 1

```python
Basin(in_flow_direction_raster)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBasin = Basin("flowdir")
outBasin.save("C:/sapyexamples/output/outbasin01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBasin = Basin("flowdir")
outBasin.save("C:/sapyexamples/output/outbasin01")
```

### Example 4

```python
# Name: Basin_Ex_02.py
# Description: Creates a raster delineating all drainage basins.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFlowDirectionRaster = "flowdir"

# Execute FlowDirection
outBasin = Basin(inFlowDirectionRaster)

# Save the output 
outBasin.save("C:/sapyexamples/output/outbasin02")
```

### Example 5

```python
# Name: Basin_Ex_02.py
# Description: Creates a raster delineating all drainage basins.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFlowDirectionRaster = "flowdir"

# Execute FlowDirection
outBasin = Basin(inFlowDirectionRaster)

# Save the output 
outBasin.save("C:/sapyexamples/output/outbasin02")
```

---

## Bitwise And (Spatial Analyst)

## Summary

Performs a Bitwise And operation on the binary values of two input rasters.

## Usage

- Two inputs are necessary for this bitwise operation to take place.
- The order of inputs is irrelevant for this tool.
- If an input is floating point, the values are converted to integer values through truncation before the bitwise operation is performed.
- In bitwise operations, the following are true: Binary values are stored in two's complement.The tools work on 32-bit integers.The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- Binary values are stored in two's complement.
- The tools work on 32-bit integers.
- The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- The Bitwise And operation treats the sign bit as it would any other bit. If one or both inputs for a cell location are positive, the output is positive; if both inputs are negative, the output is negative.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The first input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The second input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The first input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The second input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
BitwiseAnd(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseAnd = BitwiseAnd("degs", "negs")
outBitwiseAnd.save("C:/sapyexamples/output/bitand")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseAnd = BitwiseAnd("degs", "negs")
outBitwiseAnd.save("C:/sapyexamples/output/bitand")
```

### Example 4

```python
# Name: BitwiseAnd_Ex_02.py
# Description: Performs a Bitwise And operation on the binary values
#              of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BitwiseAnd
outBitwiseAnd = BitwiseAnd(inRaster1, inRaster2)

# Save the output 
outBitwiseAnd.save("C:/sapyexamples/output/outband")
```

### Example 5

```python
# Name: BitwiseAnd_Ex_02.py
# Description: Performs a Bitwise And operation on the binary values
#              of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BitwiseAnd
outBitwiseAnd = BitwiseAnd(inRaster1, inRaster2)

# Save the output 
outBitwiseAnd.save("C:/sapyexamples/output/outband")
```

---

## Bitwise Left Shift (Spatial Analyst)

## Summary

Performs a Bitwise Left Shift operation on the binary values of two input rasters.

## Usage

- Two inputs are necessary for this bitwise operation to take place.
- The order of inputs is relevant for this tool.
- If an input is floating point, the values are converted to integer values through truncation before the bitwise operation is performed.
- In bitwise operations, the following are true: Binary values are stored in two's complement.The tools work on 32-bit integers.The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- Binary values are stored in two's complement.
- The tools work on 32-bit integers.
- The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- The Bitwise Left Shift operation does no wrapping of bits. The leftmost bit is dropped.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "<<" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input on which to perform the shift.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input defining the number of positions to shift the bits.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input on which to perform the shift.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input defining the number of positions to shift the bits.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
BitwiseLeftShift(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseLS = BitwiseLeftShift("degs", "negs")
outBitwiseLS.save("C:/sapyexamples/output/outbitls.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseLS = BitwiseLeftShift("degs", "negs")
outBitwiseLS.save("C:/sapyexamples/output/outbitls.tif")
```

### Example 4

```python
# Name: BitwiseLeftShift_Ex_02.py
# Description: Performs a Bitwise Left Shift operation on the binary
#              values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BitwiseLeftShift
outBitwiseLShift = BitwiseLeftShift(inRaster1, inRaster2)

# Save the output 
outBitwiseLShift.save("C:/sapyexamples/output/outlshift")
```

### Example 5

```python
# Name: BitwiseLeftShift_Ex_02.py
# Description: Performs a Bitwise Left Shift operation on the binary
#              values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BitwiseLeftShift
outBitwiseLShift = BitwiseLeftShift(inRaster1, inRaster2)

# Save the output 
outBitwiseLShift.save("C:/sapyexamples/output/outlshift")
```

---

## Bitwise Not (Spatial Analyst)

## Summary

Performs a Bitwise Not (complement) operation on the binary value of an input raster.

## Usage

- If an input is floating point, the values are converted to integer values through truncation before the bitwise operation is performed.
- In bitwise operations, the following are true: Binary values are stored in two's complement.The tools work on 32-bit integers.The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- Binary values are stored in two's complement.
- The tools work on 32-bit integers.
- The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- The Bitwise Not operation treats the sign bit as it would any other bit. If the input for a cell location is negative, the output is negative; if the input is positive, the output is positive.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input raster on which to perform the Bitwise Not (complement) operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input raster on which to perform the Bitwise Not (complement) operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
BitwiseNot(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseNot = BitwiseNot("degs")
outBitwiseNot.save("C:/sapyexamples/output/outbitn")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseNot = BitwiseNot("degs")
outBitwiseNot.save("C:/sapyexamples/output/outbitn")
```

### Example 4

```python
# Name: BitwiseNot_Ex_02.py
# Description: Performs a Bitwise Complement operation on the
#              binary value of an input raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute BitwiseNot
outBitwiseNot = BitwiseNot(inRaster)

# Save the output 
outBitwiseNot.save("C:/sapyexamples/output/outbitnot")
```

### Example 5

```python
# Name: BitwiseNot_Ex_02.py
# Description: Performs a Bitwise Complement operation on the
#              binary value of an input raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute BitwiseNot
outBitwiseNot = BitwiseNot(inRaster)

# Save the output 
outBitwiseNot.save("C:/sapyexamples/output/outbitnot")
```

---

## Bitwise Or (Spatial Analyst)

## Summary

Performs a Bitwise Or operation on the binary values of two input rasters.

## Usage

- Two inputs are necessary for this bitwise operation to take place.
- The order of inputs is irrelevant for this tool.
- If an input is floating point, the values are converted to integer values through truncation before the bitwise operation is performed.
- In bitwise operations, the following are true: Binary values are stored in two's complement.The tools work on 32-bit integers.The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- Binary values are stored in two's complement.
- The tools work on 32-bit integers.
- The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- The Bitwise Or operation treats the sign bit as it would any other bit. If one or both inputs for a cell location are negative, the output is negative; if both inputs are positive, the output is positive.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The first input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The second input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The first input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The second input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
BitwiseOr(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseOr = BitwiseOr("degs", "negs")
outBitwiseOr.save("C:/sapyexamples/output/outbitor")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseOr = BitwiseOr("degs", "negs")
outBitwiseOr.save("C:/sapyexamples/output/outbitor")
```

### Example 4

```python
# Name: BitwiseOr_Ex_02.py
# Description: Performs a Bitwise Or operation on the binary values
#              of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BitwiseOr
outBitwiseOr = BitwiseOr(inRaster1, inRaster2)

# Save the output 
outBitwiseOr.save("C:/sapyexamples/output/outbitwiseor.tif")
```

### Example 5

```python
# Name: BitwiseOr_Ex_02.py
# Description: Performs a Bitwise Or operation on the binary values
#              of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BitwiseOr
outBitwiseOr = BitwiseOr(inRaster1, inRaster2)

# Save the output 
outBitwiseOr.save("C:/sapyexamples/output/outbitwiseor.tif")
```

---

## Bitwise Right Shift (Spatial Analyst)

## Summary

Performs a Bitwise Right Shift operation on the binary values of two input rasters.

## Usage

- Two inputs are necessary for this bitwise operation to take place.
- The order of inputs is relevant for this tool.
- If an input is floating point, the values are converted to integer values through truncation before the bitwise operation is performed.
- In bitwise operations, the following are true: Binary values are stored in two's complement.The tools work on 32-bit integers.The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- Binary values are stored in two's complement.
- The tools work on 32-bit integers.
- The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- The Bitwise Right Shift operation does no wrapping of bits. The rightmost bit is dropped.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is ">>" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input on which to perform the shift.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input defining the number of positions to shift the bits.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input on which to perform the shift.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input defining the number of positions to shift the bits.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
BitwiseRightShift(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseRShift = BitwiseRightShift("degs", "negs")
outBitwiseRShift.save("C:/sapyexamples/output/outbitrs")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseRShift = BitwiseRightShift("degs", "negs")
outBitwiseRShift.save("C:/sapyexamples/output/outbitrs")
```

### Example 4

```python
# Name: BitwiseRightShift_Ex_02.py
# Description: Performs a Bitwise Right Shift operation on the binary
#              values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BitwiseRightShift
outBitwiseRShift = BitwiseRightShift(inRaster1, inRaster2)

# Save the output 
outBitwiseRShift.save("C:/sapyexamples/output/outbitrshift.img")
```

### Example 5

```python
# Name: BitwiseRightShift_Ex_02.py
# Description: Performs a Bitwise Right Shift operation on the binary
#              values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BitwiseRightShift
outBitwiseRShift = BitwiseRightShift(inRaster1, inRaster2)

# Save the output 
outBitwiseRShift.save("C:/sapyexamples/output/outbitrshift.img")
```

---

## Bitwise XOr (Spatial Analyst)

## Summary

Performs a Bitwise eXclusive Or operation on the binary values of two input rasters.

## Usage

- Two inputs are necessary for this bitwise operation to take place.
- The order of inputs is irrelevant for this tool.
- If an input is floating point, the values are converted to integer values through truncation before the bitwise operation is performed.
- In bitwise operations, the following are true: Binary values are stored in two's complement.The tools work on 32-bit integers.The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- Binary values are stored in two's complement.
- The tools work on 32-bit integers.
- The leftmost bit position is reserved for the sign (positive or negative) of the value. If the integer is positive, the bit position is 0; if it's negative, the bit position is 1.
- The Bitwise XOr operation treats the sign bit as it would any other bit. If one or both inputs for a cell location are negative, the output is negative; if both inputs are positive, the output is positive.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The first input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The second input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The first input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The second input to use in this bitwise operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
BitwiseXOr(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseXOr = BitwiseXOr("degs", "negs")
outBitwiseXOr.save("C:/sapyexamples/output/outbitxor")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBitwiseXOr = BitwiseXOr("degs", "negs")
outBitwiseXOr.save("C:/sapyexamples/output/outbitxor")
```

### Example 4

```python
# Name: BitwiseXOr_Ex_02.py
# Description: Performs a Bitwise XOr operation on the binary values
#              of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BitwiseXOr
outBitwiseXOr = BitwiseXOr(inRaster1, inRaster2)

# Save the output 
outBitwiseXOr.save("C:/sapyexamples/output/outbitwisexor.img")
```

### Example 5

```python
# Name: BitwiseXOr_Ex_02.py
# Description: Performs a Bitwise XOr operation on the binary values
#              of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BitwiseXOr
outBitwiseXOr = BitwiseXOr(inRaster1, inRaster2)

# Save the output 
outBitwiseXOr.save("C:/sapyexamples/output/outbitwisexor.img")
```

---

## Block Statistics (Spatial Analyst)

## Summary

Partitions the input into non-overlapping blocks and calculates the statistic of the values within each block. The value is assigned to all of the cells in each block in the output.

## Usage

- There are several neighborhood shapes and statistics types to choose from. The available statistics depend on the type of the input raster.
- The available neighborhood shapes are annulus (a donut or ring), circle, rectangle, and wedge. A custom neighborhood shape can be defined using a kernel file.
- When a circular, annulus-shaped, or wedge-shaped neighborhood is specified, depending on the size of the neighborhood, cells that are not perpendicular to the x- or y-axis may not be considered in the calculations. However, these cell locations will receive the resulting value from the calculations of the neighborhood because they fall within the minimum-bounding rectangle (or the output block) of these circular neighborhood types.
- The irregular and weight Neighborhood types require that a Kernel file value be specified. A kernel file is an ASCII text file that specifies the values and shape of the neighborhood. The file can be created with any plain text editor. The file must have a .txt extension and no spaces in the file name.See the Irregular and Weight sections of How Block Statistics works for information about creating and using kernel files.
- For integer input rasters, the valid choices for Statistics type are: majority, maximum, mean, median, minimum, minority, range, standard deviation, sum, and variety. For float input rasters, the valid statistics are: maximum, mean, minimum, range, standard deviation, and sum. Majority, median, minority, and variety are not available.
- If the input raster is integer, the output raster will be integer for the following statistics: majority, maximum, median, minimum, minority, range, sum, and variety. The output will be float for the mean and standard deviation statistics.If the input raster is of float type, the output will be float for all of the available statistic types.
- For median calculations, if a block neighborhood has an odd number of cells, the values will be ranked and the middle value will be reported as the median. If a block has an even number of cells, the values are ranked and from the two middle values, the lower one is selected.
- For majority and minority calculations, when there is a tie, the output will be the lowest of the tied values.
- The Neighborhood parameter can be set to Weight only for the Mean, Standard deviation, and Sum statistics types.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The raster for which a statistic will be calculated for blocks of cells. | Raster Layer |
| Neighborhood(Optional) | The cells of the processing block that will be used in the statistic calculation. There are several predefined neighborhood types to choose from, or a custom kernel can be defined.Once the neighborhood type is selected, other parameters can be set to fully define the shape, size, and units of measure. The default neighborhood is a square rectangle with a width and height of three cells. The following are the forms of the available neighborhood types: Annulus, Inner radius, Outer radius, Units type A ring or donut-shaped neighborhood defined by an inner radius and an outer radius. The minimum value for radius is 1 cell, and the outer radius must be larger than the inner. The maximum inner radius is 2046 cells, and the maximum outer radius is 2047 cells. The default annulus is an inner radius of 1 cell and an outer radius of 3 cells. Circle, Radius, Units type A circular neighborhood with the given radius. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The default radius is 3 cells. Rectangle, Height, Width, Units type A rectangular neighborhood defined by width and height. The minimum value for width or height is 1 cell, and the maximum value is 4096 cells. The default is a square with a width and height of 3 cells. Wedge, Radius, Start angle, End angle, Units type A wedge-shaped neighborhood defined by a radius, a start angle, and an end angle. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The wedge extends counterclockwise from the starting angle to the ending angle. Angles are specified in degrees, with 0 or 360 representing east. Negative angles can be used. The default wedge is from 0 to 90 degrees, with a radius of 3 cells. Irregular, Kernel file A custom neighborhood with specifications set by the identified kernel text file. The minimum value for width or height of the kernel is 1 cell, and the maximum value is 4096 cells. Weight, Kernel file A custom neighborhood with specifications set by the identified kernel text file, which can apply weights to the members of the neighborhood. The minimum value for width or height of the kernel is 1 cell, and the maximum value is 4096 cells.For the annulus, circle, rectangle and wedge neighborhood types, the distance units for the parameters can be specified in Cell units or Map units. Cell units is the default.For kernel neighborhoods, the first line in the kernel file defines the width and height of the neighborhood in numbers of cells. The subsequent lines indicate how the input value that corresponds to that location in the kernel will be processed. A value of 0 in the kernel file for either the irregular or the weight neighborhood type indicates the corresponding location will not be included in the calculation. For the irregular neighborhood, a value of 1 in the kernel file indicates that the corresponding input cell will be included in the operation. For the weight neighborhood, the value at each position indicates what the corresponding input cell value is to be multiplied by. Positive, negative, and decimal values can be used. | Neighborhood |
| Statistics type(Optional) | Specifies the statistic type to be calculated.The default statistic type is Mean.If the input raster is integer, all the statistics types will be available. If the input raster is floating point, only the Mean, Maximum, Minimum, Range, Standard deviation, and Sum statistic types will be available.Mean—The mean (average value) of the cells in the neighborhood will be calculated.Majority—The majority (value that occurs most often) of the cells in the neighborhood will be identified.Maximum—The maximum (largest value) of the cells in the neighborhood will be identified.Median—The median of the cells in the neighborhood will be calculated.Minimum—The minimum (smallest value) of the cells in the neighborhood will be identified.Minority—The minority (value that occurs least often) of the cells in the neighborhood will be identified.Range—The range (difference between largest and smallest value) of the cells in the neighborhood will be calculated.Standard deviation—The standard deviation of the cells in the neighborhood will be calculated.Sum—The sum of the cells in the neighborhood will be calculated.Variety—The variety (the number of unique values) of the cells in the neighborhood will be calculated. | String |
| Ignore NoData in calculations(Optional) | Specifies whether NoData values will be ignored by the statistic calculation.Checked—If a NoData value exists within a block neighborhood, the NoData value will be ignored. Only cells within the neighborhood that have data values will be used in determining the output value. This is the default.Unchecked—If any cell in a block neighborhood has a value of NoData, the output for each cell in the corresponding block will be NoData. The presence of a NoData value implies that there is insufficient information to determine the statistic value for the neighborhood. | Boolean |
| in_raster | The raster for which a statistic will be calculated for blocks of cells. | Raster Layer |
| neighborhood(Optional) | The cells of the processing block that will be used in the statistic calculation. There are several predefined neighborhood types to choose from, or a custom kernel can be defined.Once the neighborhood type is selected, other parameters can be set to fully define the shape, size, and units of measure. The default neighborhood is a square rectangle with a width and height of three cells. The shape of the neighborhoods are defined by the Neighborhood class. The available neighborhood types are NbrAnnulus, NbrCircle, NbrRectangle, NbrWedge, NbrIrregular, and NbrWeight.The following are the forms of the available neighborhood types:NbrAnnulus({innerRadius}, {outerRadius}, {units})A ring or donut-shaped neighborhood defined by an inner radius and an outer radius. The minimum value for radius is 1 cell, and the outer radius must be larger than the inner. The maximum inner radius is 2046 cells, and the maximum outer radius is 2047 cells. The default annulus is an inner radius of 1 cell and an outer radius of 3 cells.NbrCircle({radius}, {units}A circular neighborhood with the given radius. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The default radius is 3 cells.NbrRectangle({width}, {height}, {units})A rectangular neighborhood defined by width and height. The minimum value for width or height is 1 cell, and the maximum value is 4096 cells. The default is a square with a width and height of 3 cells.NbrWedge({radius}, {startAngle}, {endAngle}, {units})A wedge-shaped neighborhood defined by a radius, a start angle, and an end angle. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The wedge extends counterclockwise from the starting angle to the ending angle. Angles are specified in degrees, with 0 or 360 representing east. Negative angles can be used. The default wedge is from 0 to 90 degrees, with a radius of 3 cells.NbrIrregular(inKernelFile)A custom neighborhood with specifications set by the identified kernel text file. The minimum value for width or height of the kernel is 1 cell, and the maximum value is 4096 cells.NbrWeight(inKernelFile)A custom neighborhood with specifications set by the identified kernel text file, which can apply weights to the members of the neighborhood. The minimum value for width or height of the kernel is 1 cell, and the maximum value is 4096 cells.For the NbrAnnulus, Nbrcircle, NbrRectangle and NbrWedge neighborhoods, the distance units for the parameters can be specified in CELL units or MAP units. Cell units is the default.For kernel neighborhoods, the first line in the kernel file defines the width and height of the neighborhood in numbers of cells. The subsequent lines indicate how the input value that corresponds to that location in the kernel will be processed. A value of 0 in the kernel file for either the irregular or the weight neighborhood type indicates the corresponding location will not be included in the calculation. For the irregular neighborhood, a value of 1 in the kernel file indicates that the corresponding input cell will be included in the operation. For the weight neighborhood, the value at each position indicates what the corresponding input cell value is to be multiplied by. Positive, negative, and decimal values can be used. | Neighborhood |
| statistics_type(Optional) | Specifies the statistic type to be calculated. MEAN—The mean (average value) of the cells in the neighborhood will be calculated.MAJORITY—The majority (value that occurs most often) of the cells in the neighborhood will be identified.MAXIMUM—The maximum (largest value) of the cells in the neighborhood will be identified.MEDIAN—The median of the cells in the neighborhood will be calculated.MINIMUM—The minimum (smallest value) of the cells in the neighborhood will be identified.MINORITY—The minority (value that occurs least often) of the cells in the neighborhood will be identified.RANGE—The range (difference between largest and smallest value) of the cells in the neighborhood will be calculated.STD—The standard deviation of the cells in the neighborhood will be calculated.SUM—The sum of the cells in the neighborhood will be calculated.VARIETY—The variety (the number of unique values) of the cells in the neighborhood will be calculated.The default statistic type is MEAN.If the input raster is integer, all the statistics types will be available. If the input raster is floating point, only the MEAN, MAXIMUM, MINIMUM, RANGE, STD, and SUM statistic types will be available. | String |
| ignore_nodata(Optional) | Specifies whether NoData values will be ignored by the statistic calculation.DATA—If a NoData value exists within a block neighborhood, the NoData value will be ignored. Only cells within the neighborhood that have data values will be used in determining the output value. This is the default.NODATA—If any cell in a block neighborhood has a value of NoData, the output for each cell in the corresponding block will be NoData. The presence of a NoData value implies that there is insufficient information to determine the statistic value for the neighborhood. | Boolean |

## Code Samples

### Example 1

```python
BlockStatistics(in_raster, {neighborhood}, {statistics_type}, {ignore_nodata})
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
nbr = NbrAnnulus(1, 3, "MAP")
outBlockStat = BlockStatistics("block", nbr, "MINIMUM", "")
outBlockStat.save("C:/sapyexamples/output/blockstat")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
nbr = NbrAnnulus(1, 3, "MAP")
outBlockStat = BlockStatistics("block", nbr, "MINIMUM", "")
outBlockStat.save("C:/sapyexamples/output/blockstat")
```

### Example 4

```python
# Name: BlockStatistics_Ex_02.py
# Description: Calculates statistics for a nonoverlapping 
#              neighborhood.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "block"
nbr = NbrAnnulus(1, 3, "MAP")

# Execute BlockStatistics
outBlockStat = BlockStatistics(inRaster, nbr, "MINIMUM", "NODATA")

# Save the output 
outBlockStat.save("C:/sapyexamples/output/blockstat")
```

### Example 5

```python
# Name: BlockStatistics_Ex_02.py
# Description: Calculates statistics for a nonoverlapping 
#              neighborhood.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "block"
nbr = NbrAnnulus(1, 3, "MAP")

# Execute BlockStatistics
outBlockStat = BlockStatistics(inRaster, nbr, "MINIMUM", "NODATA")

# Save the output 
outBlockStat.save("C:/sapyexamples/output/blockstat")
```

---

## Boolean And (Spatial Analyst)

## Summary

Performs a Boolean And operation on the cell values of two input rasters.

## Usage

- The Boolean math tools interpret the inputs as Boolean values in which nonzero values are considered true and zero is considered false.
- Two inputs are necessary for this Boolean evaluation to take place.
- The order of inputs is irrelevant for this tool.
- If the input values are floating point, they are converted to integer values of either 0 or 1 before the operation is performed. If the input value is a floating point 0.0, it is converted to an integer 0. If the input is any value other than 0.0, it is converted to an integer 1. For example, input float values of 0.6, 32.22 and -4.2 will all be treated as 1. The output values are always integer.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "&" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The first input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The second input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The first input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The second input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
BooleanAnd(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBooleanAnd = BooleanAnd("degs", "negs")
outBooleanAnd.save("C:/sapyexamples/output/outbooland.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBooleanAnd = BooleanAnd("degs", "negs")
outBooleanAnd.save("C:/sapyexamples/output/outbooland.img")
```

### Example 4

```python
# Name: BooleanAnd_Ex_02.py
# Description: Performs a Boolean And operation on the cell values
#              of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BooleanAnd
outBooleanAnd = BooleanAnd(inRaster1, inRaster2)

# Save the output 
outBooleanAnd.save("C:/sapyexamples/output/outbooland")
```

### Example 5

```python
# Name: BooleanAnd_Ex_02.py
# Description: Performs a Boolean And operation on the cell values
#              of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BooleanAnd
outBooleanAnd = BooleanAnd(inRaster1, inRaster2)

# Save the output 
outBooleanAnd.save("C:/sapyexamples/output/outbooland")
```

---

## Boolean Not (Spatial Analyst)

## Summary

Performs a Boolean Not (complement) operation on the cell values of the input raster.

## Usage

- The Boolean math tools interpret the inputs as Boolean values in which nonzero values are considered true and zero is considered false.
- Only a single input is necessary for this Boolean evaluation to take place.
- If the input values are floating point, they are converted to integer values of either 0 or 1 before the operation is performed. If the input value is a floating point 0.0, it is converted to an integer 0. If the input is any value other than 0.0, it is converted to an integer 1. For example, input float values of 0.6, 32.22 and -4.2 will all be treated as 1. The output values are always integer.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- In map algebra, the equivalent operator symbol for this tool is "~" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input to use in this Boolean operation.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input to use in this Boolean operation.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
BooleanNot(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBooleanNot = BooleanNot("degs")
outBooleanNot.save("C:/sapyexamples/output/outboolnot.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBooleanNot = BooleanNot("degs")
outBooleanNot.save("C:/sapyexamples/output/outboolnot.tif")
```

### Example 4

```python
# Name: BooleanNot_Ex_02.py
# Description: Performs a Boolean complement (NOT) operation on the
#              cell values of an input raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute BooleanNot
outBooleanNot = BooleanNot(inRaster)

# Save the output 
outBooleanNot.save("C:/sapyexamples/output/outboolnot")
```

### Example 5

```python
# Name: BooleanNot_Ex_02.py
# Description: Performs a Boolean complement (NOT) operation on the
#              cell values of an input raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute BooleanNot
outBooleanNot = BooleanNot(inRaster)

# Save the output 
outBooleanNot.save("C:/sapyexamples/output/outboolnot")
```

---

## Boolean Or (Spatial Analyst)

## Summary

Performs a Boolean Or operation on the cell values of two input rasters.

## Usage

- The Boolean math tools interpret the inputs as Boolean values in which nonzero values are considered true and zero is considered false.
- Two inputs are necessary for this Boolean evaluation to take place.
- The order of inputs is irrelevant for this tool.
- If the input values are floating point, they are converted to integer values of either 0 or 1 before the operation is performed. If the input value is a floating point 0.0, it is converted to an integer 0. If the input is any value other than 0.0, it is converted to an integer 1. For example, input float values of 0.6, 32.22 and -4.2 will all be treated as 1. The output values are always integer.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "|" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The first input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The second input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The first input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The second input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
BooleanOr(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBooleanOr = BooleanOr("degs", "negs")
outBooleanOr.save("C:/sapyexamples/output/outboolor2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBooleanOr = BooleanOr("degs", "negs")
outBooleanOr.save("C:/sapyexamples/output/outboolor2")
```

### Example 4

```python
# Name: BooleanOr_Ex_02.py
# Description: Performs a Boolean Or operation on the cell values of
#              two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BooleanOr
outBooleanOr = BooleanOr(inRaster1, inRaster2)

# Save the output 
outBooleanOr.save("C:/sapyexamples/output/outboolor")
```

### Example 5

```python
# Name: BooleanOr_Ex_02.py
# Description: Performs a Boolean Or operation on the cell values of
#              two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BooleanOr
outBooleanOr = BooleanOr(inRaster1, inRaster2)

# Save the output 
outBooleanOr.save("C:/sapyexamples/output/outboolor")
```

---

## Boolean XOr (Spatial Analyst)

## Summary

Performs a Boolean eXclusive Or operation on the cell values of two input rasters.

## Usage

- The Boolean math tools interpret the inputs as Boolean values in which nonzero values are considered true and zero is considered false.
- Two inputs are necessary for this Boolean evaluation to take place.
- The order of inputs is irrelevant for this tool.
- If the input values are floating point, they are converted to integer values of either 0 or 1 before the operation is performed. If the input value is a floating point 0.0, it is converted to an integer 0. If the input is any value other than 0.0, it is converted to an integer 1. For example, input float values of 0.6, 32.22 and -4.2 will all be treated as 1. The output values are always integer.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "^" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The first input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The second input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The first input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The second input to use in this Boolean operation.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
BooleanXOr(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBooleanXOr = BooleanXOr("degs", "negs")
outBooleanXOr.save("C:/sapyexamples/output/outboolxor.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBooleanXOr = BooleanXOr("degs", "negs")
outBooleanXOr.save("C:/sapyexamples/output/outboolxor.tif")
```

### Example 4

```python
# Name: BooleanXOr_Ex_02.py
# Description: Performs a Boolean Exclusive Or operation on the
#              cell values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BooleanXOr
outBooleanXOr = BooleanXOr(inRaster1, inRaster2)

# Save the output 
outBooleanXOr.save("C:/sapyexamples/output/outboolxor")
```

### Example 5

```python
# Name: BooleanXOr_Ex_02.py
# Description: Performs a Boolean Exclusive Or operation on the
#              cell values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute BooleanXOr
outBooleanXOr = BooleanXOr(inRaster1, inRaster2)

# Save the output 
outBooleanXOr.save("C:/sapyexamples/output/outboolxor")
```

---

## Boundary Clean (Spatial Analyst)

## Summary

Smooths the boundary between zones in a raster.

## Usage

- The Boundary Clean tool generalizes, or simplifies, rasters by smoothing the boundaries between zones. The tool provides options for controlling how the cells of the zones in the input influence the smoothing and the amount of smoothing that will be applied.
- The tool applies the mathematical morphology techniques of expansion (dilation) and shrinking (erosion) when smoothing the boundaries (Serra, 1982). Each input cell is evaluated using its immediate orthogonal and diagonal neighbors.
- The smoothing process first sorts the neighbor cells by a particular priority. The priority determines which zone from the neighboring cells can replace the value of the processing cell in the output.
- The priority can be based on either the value of the zones or the size of the zones. The Sort type parameter (sort_type in Python) determines the sorting type to use.The default method, Do not sort (NO_SORT in Python), assesses the priority based on the value of the zones. Cells from zones with larger values will have a higher priority to expand into zones with smaller values. The size of the zones is not considered.The size, or total area, of the zones can be used to sort the priority. The size is determined by the count of cells that compose each zone. With the Descending setting (DESCEND in Python), the zones are sorted by size in descending order. The zones with larger total areas will have the priority to expand into zones with smaller areas. With the Ascending setting (ASCEND in Python), the opposite is true: zones with smaller total areas will have the priority to expand into zones with larger total areas.
- The amount of smoothing is controlled by the Run expansion and shrinking twice parameter (number_of_runs in Python), which determines the number of times the expand and shrinking process will be performed.With the unchecked setting (ONE_WAY in Python), the expand and shrink process is performed once. With the checked setting (TWO_WAY in Python), the expand and shrink process is performed twice, resulting in an additional degree of smoothing of the zone boundaries.For additional details about the algorithm, see the Boundary Clean section of Smoothing zone edges with Boundary Clean and Majority Filter.
- If the values of all eight neighbor cells are the same as the processing cell, the output cell will retain the value of the input cell.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- Reference:Serra, J. Image Analysis and Mathematical Morphology, Academic Press, London 1982.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster for which the boundary between zones will be smoothed.It must be of integer type. | Raster Layer |
| Sort type(Optional) | Specifies the type of sorting to use in the smoothing process. The sorting determines the priority by which cells can expand into their neighbors.The sorting can be based on zone value or zone size.Do not sort—The priority is determined by zone value. The size of the zones is not considered. Zones with larger values will have a higher priority to expand into zones with smaller values in the smoothed output. This is the default.Descending—Zones are sorted in descending order by size. Zones with larger total areas have a higher priority to expand into zones with smaller total areas. This option tends to eliminate or reduce the prevalence of cells from smaller zones in the smoothed output.Ascending—Zones are sorted in ascending order by size. Zones with smaller total areas have a higher priority to expand into zones with larger total areas. This option tends to preserve or increase the prevalence of cells from smaller zones in the smoothed output. | String |
| Run expansion and shrinking twice(Optional) | Specifies the number of times the smoothing process will occur, twice or once.Checked—The expansion and shrinking operation is performed twice. The first time, the operation is performed according to the specified sort type. The second time, an additional expansion and shrinking operation is performed with the priority reversed. This is the default.Unchecked—The expansion and shrinking operation is performed once according to the sort type. | Boolean |
| in_raster | The input raster for which the boundary between zones will be smoothed.It must be of integer type. | Raster Layer |
| sort_type(Optional) | Specifies the type of sorting to use in the smoothing process. The sorting determines the priority by which cells can expand into their neighbors.The sorting can be based on zone value or zone size.NO_SORT—The priority is determined by zone value. The size of the zones is not considered. Zones with larger values will have a higher priority to expand into zones with smaller values in the smoothed output. This is the default.DESCEND—Zones are sorted in descending order by size. Zones with larger total areas have a higher priority to expand into zones with smaller total areas. This option tends to eliminate or reduce the prevalence of cells from smaller zones in the smoothed output.ASCEND—Zones are sorted in ascending order by size. Zones with smaller total areas have a higher priority to expand into zones with larger total areas. This option tends to preserve or increase the prevalence of cells from smaller zones in the smoothed output. | String |
| number_of_runs(Optional) | Specifies the number of times the smoothing process will occur, twice or once.TWO_WAY—The expansion and shrinking operation is performed twice. The first time, the operation is performed according to the specified sort type. The second time, an additional expansion and shrinking operation is performed with the priority reversed. This is the default.ONE_WAY—The expansion and shrinking operation is performed once according to the sort type. | Boolean |

## Code Samples

### Example 1

```python
BoundaryClean(in_raster, {sort_type}, {number_of_runs})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
OutBndCln = BoundaryClean("land", "DESCEND", "TWO_WAY")
OutBndCln.save("c:/sapyexamples/output/bndcln_des2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
OutBndCln = BoundaryClean("land", "DESCEND", "TWO_WAY")
OutBndCln.save("c:/sapyexamples/output/bndcln_des2")
```

### Example 4

```python
# Name: BoundaryClean_Ex_02.py
# Description: Smoothes the boundary between zones 
#              by expanding and shrinking it.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"

# Execute BoundaryClean
OutBndCln = BoundaryClean(inRaster, "ASCEND", "TWO_WAY")

# Save the output 
OutBndCln.save("c:/sapyexamples/output/bndcln_asc2")
```

### Example 5

```python
# Name: BoundaryClean_Ex_02.py
# Description: Smoothes the boundary between zones 
#              by expanding and shrinking it.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"

# Execute BoundaryClean
OutBndCln = BoundaryClean(inRaster, "ASCEND", "TWO_WAY")

# Save the output 
OutBndCln.save("c:/sapyexamples/output/bndcln_asc2")
```

---

## Calculate Kernel Density Ratio (Spatial Analyst)

## Summary

Calculates a spatial relative risk surface using two input feature datasets. The numerator in the ratio represents cases, such as number of crimes or number of patients, and the denominator represents the control, such as the total population.

## Usage

- This tool uses the same calculations to create density surfaces as the Kernel Density tool. The outputs of the Kernel Density and the Calculate Kernel Density Ratio tools may appear similar; however, the output of the Calculate Kernel Density Ratio tool is normalized, meaning it displays a proportional value. The output of the Kernel Density tool does not. Use a density ratio when the phenomenon being analyzed requires a control, such as total population.The individual density surfaces are calculated using the Kernel Density tool before the ratio is calculated.
- Very large or very small values in the population field can produce results that may seem nonintuitive. If the mean of the population field is much larger than 1 (for example, city populations), the default search radius may be very small, resulting in small rings around the input points. If the mean of the population field is much smaller than 1, the calculated search radius may seem unreasonably large. In these cases, you can provide a search radius.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Larger values of the search radius produce a smoother, more generalized density raster. Smaller values produce a raster that shows more detail.
- The default search radius is calculated based on the spatial configuration and number of input points. This approach corrects spatial outliers—input points that are very far away from the rest—so they will not make the search radius unreasonably large.
- The Output cell values (out_cell_values in Python) parameter specifies what the output raster values represent. If Densities is chosen, the values represent the kernel density value per unit area for each cell. If Expected counts is chosen, the values represent the kernel density per cell area. The equation that calculates the counts from the density values is Count = Density × Area.
- The Planar option in the Method (method in Python) parameter is appropriate if the analysis is to be performed at a local scale with a projection that accurately maintains the correct distance and area. The Geodesic option is appropriate if the analysis is to be performed at a regional or large scale (for example, using Web Mercator or any geographic coordinate system). This method takes into account the curvature of the spheroid and correctly handles data near the poles and the international dateline.
- Only the points or portions of a line that fall within the neighborhood are considered when calculating density. If no points or line sections fall within the neighborhood of a particular cell, that cell is assigned NoData.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- When a feature of Input point or polyline features as denominator (in_features_denominator in Python) is zero, the output result within the search radius of the feature will be NoData.
- The default output coordinate system is based on the Input point or polyline features as numerator (in_features_numerator in Python).The default values for the Search radius of numerator (search_radius_numerator in Python) and Search radius of denominator (search_radius_denominator in Python) are based on the linear unit of the output coordinate system of the Input point or polyline features as numerator. If the Output Coordinate System environment setting is used, the Search radius of numerator and Search radius of denominator parameter values will be based on the linear unit of the Output Coordinate System environment setting.The default analysis extent is the intersection of the extent of the Input point or polyline features as numerator and Input point or polyline features as denominator values.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- References: Silverman, B. W. Density Estimation for Statistics and Data Analysis. New York: Chapman and Hall, 1986.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point or polyline features as numerator | The input features (point or line) of the cases for which density will be calculated. | Feature Layer |
| Input point or polyline features as denominator | The input features (point or line) of the control for which density will be calculated. | Feature Layer |
| Population field of numerator | The field denoting population values for each feature. The population field is the count or quantity to be spread across the landscape to create a continuous surface. Use OID or FID if no item or special value will be used and each feature will be counted once.Values in the population field can be integer or floating point.You can use the Shape field if input features contain z-values. | Field |
| Population field of denominator | The field denoting population values for each feature. The population field is the count or quantity to be spread across the landscape to create a continuous surface. Use OID or FID if no item or special value will be used and each feature will be counted once.Values in the population field can be integer or floating point.You can use the Shape field if input features contain z-values. | Field |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Search radius of numerator(Optional) | The search radius within which density will be calculated. Units are based on the linear unit of the projection of the output spatial reference.For example, if the units are meters—to include all features within a one-mile neighborhood—set the search radius equal to 1609.344 (1 mile = 1609.344 meters).The default search radius is computed specifically for the input dataset using a spatial variant of Silverman's Rule of Thumb (Silverman, 1986) that is robust enough for spatial outliers (points that are far away from the rest of the points). See the usage tips for a description of the algorithm. | Double |
| Search radius of denominator(Optional) | The search radius within which density will be calculated. Units are based on the linear unit of the projection of the output spatial reference.For example, if the units are meters—to include all features within a one-mile neighborhood—set the search radius equal to 1609.344 (1 mile = 1609.344 meters).The default search radius is computed specifically for the input dataset using a spatial variant of Silverman's Rule of Thumb (Silverman, 1986) that is robust enough for spatial outliers (points that are far away from the rest of the points). See the usage tips for a description of the algorithm. | Double |
| Output cell values(Optional) | Specifies what the values in the output raster represent.Since the cell value is linked to the specified cell size, the resulting raster cannot be resampled to a different cell size.Densities—The output values represent the calculated density value per unit area for each cell. This is the default.Expected counts—The output values represent the calculated density value per cell area. | String |
| Method(Optional) | Specifies whether the flat earth (planar) or the shortest path on a spheroid (geodesic) distance will be used.The geodesic method only supports points as input features.Planar—The planar distance between features will be used. This is the default.Geodesic—The geodesic distance between features will be used. | String |
| Input barrier features for numerator(Optional) | The dataset that defines the barriers. The barriers can be a feature layer of polyline or polygon features. | Feature Layer |
| Input barrier features for denominator(Optional) | The dataset that defines the barriers.The barriers can be a feature layer of polyline or polygon features. | Feature Layer |
| in_features_numerator | The input features (point or line) of the cases for which density will be calculated. | Feature Layer |
| in_features_denominator | The input features (point or line) of the control for which density will be calculated. | Feature Layer |
| population_field_numerator | The field denoting population values for each feature. The population field is the count or quantity to be spread across the landscape to create a continuous surface. Use OID or FID if no item or special value will be used and each feature will be counted once.Values in the population field can be integer or floating point.You can use the Shape field if input features contain z-values. | Field |
| population_field_denominator | The field denoting population values for each feature. The population field is the count or quantity to be spread across the landscape to create a continuous surface. Use OID or FID if no item or special value will be used and each feature will be counted once.Values in the population field can be integer or floating point.You can use the Shape field if input features contain z-values. | Field |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| search_radius_numerator(Optional) | The search radius within which density will be calculated. Units are based on the linear unit of the projection of the output spatial reference.For example, if the units are meters—to include all features within a one-mile neighborhood—set the search radius equal to 1609.344 (1 mile = 1609.344 meters).The default search radius is computed specifically for the input dataset using a spatial variant of Silverman's Rule of Thumb (Silverman, 1986) that is robust enough for spatial outliers (points that are far away from the rest of the points). See the usage tips for a description of the algorithm. | Double |
| search_radius_denominator(Optional) | The search radius within which density will be calculated. Units are based on the linear unit of the projection of the output spatial reference.For example, if the units are meters—to include all features within a one-mile neighborhood—set the search radius equal to 1609.344 (1 mile = 1609.344 meters).The default search radius is computed specifically for the input dataset using a spatial variant of Silverman's Rule of Thumb (Silverman, 1986) that is robust enough for spatial outliers (points that are far away from the rest of the points). See the usage tips for a description of the algorithm. | Double |
| out_cell_values(Optional) | Specifies what the values in the output raster represent.DENSITIES—The output values represent the calculated density value per unit area for each cell. This is the default.EXPECTED_COUNTS—The output values represent the calculated density value per cell area. Since the cell value is linked to the specified cell size, the resulting raster cannot be resampled to a different cell size. | String |
| method(Optional) | Specifies whether the flat earth (planar) or the shortest path on a spheroid (geodesic) distance will be used.PLANAR—The planar distance between features will be used. This is the default.GEODESIC—The geodesic distance between features will be used. The geodesic method only supports points as input features. | String |
| in_barriers_numerator(Optional) | The dataset that defines the barriers. The barriers can be a feature layer of polyline or polygon features. | Feature Layer |
| in_barriers_denominator(Optional) | The dataset that defines the barriers.The barriers can be a feature layer of polyline or polygon features. | Feature Layer |

## Code Samples

### Example 1

```python
CalculateKernelDensityRatio(in_features_numerator, in_features_denominator, population_field_numerator, population_field_denominator, {cell_size}, {search_radius_numerator}, {search_radius_denominator}, {out_cell_values}, {method}, {in_barriers_numerator}, {in_barriers_denominator})
```

### Example 2

```python
from arcpy import env 
from arcpy.sa import * 
env.workspace = r"C:/sapyexamples/data" 
outKDenRa = CalculateKernelDensityRatio("rec_sites.shp", "rec_sites.shp", "Crime", "POP", 45, 1200, 1200, "", "GEODESIC") 
outKDenRa.save(r"C:/sapyexamples/output/KD_out.tif")
```

### Example 3

```python
from arcpy import env 
from arcpy.sa import * 
env.workspace = r"C:/sapyexamples/data" 
outKDenRa = CalculateKernelDensityRatio("rec_sites.shp", "rec_sites.shp", "Crime", "POP", 45, 1200, 1200, "", "GEODESIC") 
outKDenRa.save(r"C:/sapyexamples/output/KD_out.tif")
```

### Example 4

```python
# Name: CalculateKernelDensityRatio_Ex_02.py 
# Description: Calculates the ozone concentration per population of each county out of 
#              Sierra Nevada Mountain in California 
#              based on the two point samples using a kernel function to 
#              fit a smoothly tapered surface of density ratio. 
# Requirements: Spatial Analyst Extension 

# Import system modules 
import arcpy 
from arcpy import env 
from arcpy.sa import * 

# Set environment settings 
env.workspace = r"C:/sapyexamples/data" 

# Set local variables 
inFeatures1 = "ozone_california.shp" 
inFeatures2 = "pop_california.shp" 
populationField1 = "OZONE" 
populationField2 = "POP" 
cellSize = 60 
searchRadius1 = 2500 
searchRadius2 = 500 
inBarriers1 = "SierraNevada.shp" 
inBarriers2 = "county.shp" 

# Execute CalculateKernelDensityRatio 
outKernelDensityRatio = CalculateKernelDensityRatio(inFeatures1, inFeatures2, populationField1, populationField2,
                                                    cellSize, searchRadius1, searchRadius2, "DENSITIES", "PLANAR",
                                                    inBarriers1, inBarriers2) 

# Save the output  
outKernelDensityRatio.save(r"C:/sapyexamples/output/KD_ozone_california.tif")
```

### Example 5

```python
# Name: CalculateKernelDensityRatio_Ex_02.py 
# Description: Calculates the ozone concentration per population of each county out of 
#              Sierra Nevada Mountain in California 
#              based on the two point samples using a kernel function to 
#              fit a smoothly tapered surface of density ratio. 
# Requirements: Spatial Analyst Extension 

# Import system modules 
import arcpy 
from arcpy import env 
from arcpy.sa import * 

# Set environment settings 
env.workspace = r"C:/sapyexamples/data" 

# Set local variables 
inFeatures1 = "ozone_california.shp" 
inFeatures2 = "pop_california.shp" 
populationField1 = "OZONE" 
populationField2 = "POP" 
cellSize = 60 
searchRadius1 = 2500 
searchRadius2 = 500 
inBarriers1 = "SierraNevada.shp" 
inBarriers2 = "county.shp" 

# Execute CalculateKernelDensityRatio 
outKernelDensityRatio = CalculateKernelDensityRatio(inFeatures1, inFeatures2, populationField1, populationField2,
                                                    cellSize, searchRadius1, searchRadius2, "DENSITIES", "PLANAR",
                                                    inBarriers1, inBarriers2) 

# Save the output  
outKernelDensityRatio.save(r"C:/sapyexamples/output/KD_ozone_california.tif")
```

---

## Cell Statistics (Spatial Analyst)

## Summary

Calculates a per-cell statistic from multiple rasters.

## Usage

- The order of the input rasters is irrelevant for this tool.
- For the Maximum, Minimum, Mean, Median, Majority, Minority, Percentile, and Sum statistic types, if a single raster is used as the input, the output cell values will be the same as the input cell values. For Range and Standard deviation, the output cell values will all be 0. For Variety, it will be 1.
- If the Process as multiband parameter is unchecked (process_as_multiband is set to SINGLE_BAND in Python), each band from a multiband raster input will be processed separately as a single band raster, and the output will be a single band raster.The Cell Statistics tool creates a single-band output when processed as SINGLE_BAND.
- If the Process as multiband parameter is checked (process_as_multiband is set to MULTI_BAND in Python), each multiband raster input will be processed as a multiband raster, and the output will be a multiband raster. The output raster will also be multiband if the inputs are a combination of a multiband raster and constants. The number of bands in each multiband input must be the same.The tool will perform the operation on each band from one input using the corresponding band from the other input. If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input.The Cell Statistics tool creates a multiband output when processed as MULTI_BAND.
- If all inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process, otherwise an error will occur.If all of the inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before performing the operation.If one or more of the inputs are multidimensional rasters and the other inputs are constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- For majority and minority calculations, when there is a tie, the output will be the lowest of the tied values.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input rasters or constant values | A list of input rasters for which a statistical operation will be calculated for each cell in the analysis window.A number can be used as an input; however, the cell size and extent must first be set in the environment.If the Process as multiband parameter is checked, all multiband inputs must have an equal number of bands. | Raster Layer; Constant |
| Overlay statistic(Optional) | Specifies the statistic type to be calculated.The default statistic type is Mean.Mean—The mean (average) of the inputs will be calculated. This is the default.Majority—The majority (value that occurs most often) of the inputs will be determined.Maximum—The maximum (largest value) of the inputs will be determined.Median—The median of the inputs will be calculated.Minimum—The minimum (smallest value) of the inputs will be determined.Minority—The minority (value that occurs least often) of the inputs will be determined.Percentile—The percentile of the inputs will be calculated. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the Percentile value parameter.Range—The range (difference between largest and smallest value) of the inputs will be calculated.Standard deviation—The standard deviation of the inputs will be calculated.Sum—The sum (total of all values) of the inputs will be calculated.Variety—The variety (number of unique values) of the inputs will be calculated. | String |
| Ignore NoData in calculations(Optional) | Specifies whether NoData values will be ignored by the statistic calculation.Checked—At the processing cell location, if any of the input rasters has NoData, that NoData value will be ignored. The statistics will be computed by only considering the cells with valid data. This is the default.Unchecked—If the processing cell location for any of the input rasters is NoData, the output for that cell will be NoData. | Boolean |
| Process as multiband(Optional) | Specifies how the input multiband raster bands will be processed. Unchecked—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.Checked—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |
| Percentile value(Optional) | The percentile value that will be calculated. The default is 90, indicating the 90th percentile.The value can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to the maximum statistic. A value of 50 will produce essentially the same result as the median statistic.This parameter is only available if the Overlay statistic parameter is set to Percentile. | Double |
| Percentile interpolation type(Optional) | Specifies the method of interpolation that will be used when the specified percentile value is between two input cell values.Auto-detect—If the input rasters are of integer pixel type, the Nearest method will be used. If the input rasters are of floating point pixel type, the Linear method will be used. This is the default.Nearest—The nearest available value to the desired percentile will be used. In this case, the output pixel type will be the same as that of the input rasters.Linear—The weighted average of the two surrounding values from the percentile will be used. In this case, the output pixel type will be floating point. | String |
| in_rasters_or_constants[in_raster_or_constant,...] | A list of input rasters for which a statistical operation will be calculated for each cell in the analysis window.A number can be used as an input; however, the cell size and extent must first be set in the environment.If the processing_as_multiband parameter is set to MULTI_BAND, all multiband inputs should have an equal number of bands. | Raster Layer; Constant |
| statistics_type(Optional) | Specifies the statistic type to be calculated.MEAN—The mean (average) of the inputs will be calculated. This is the default.MAJORITY—The majority (value that occurs most often) of the inputs will be determined.MAXIMUM—The maximum (largest value) of the inputs will be determined.MEDIAN—The median of the inputs will be calculated.MINIMUM—The minimum (smallest value) of the inputs will be determined.MINORITY—The minority (value that occurs least often) of the inputs will be determined.PERCENTILE—The percentile of the inputs will be calculated. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the percentile_value parameter.RANGE—The range (difference between largest and smallest value) of the inputs will be calculated.STD—The standard deviation of the inputs will be calculated.SUM—The sum (total of all values) of the inputs will be calculated.VARIETY—The variety (number of unique values) of the inputs will be calculated.The default statistic type is MEAN. | String |
| ignore_nodata(Optional) | Specifies whether NoData values will be ignored by the statistic calculation.DATA—At the processing cell location, if any of the input rasters has NoData, that NoData value will be ignored. The statistics will be computed by only considering the cells with valid data. This is the default.NODATA—If the processing cell location for any of the input rasters is NoData, the output for that cell will be NoData. | Boolean |
| process_as_multiband(Optional) | Specifies how the input multiband raster bands will be processed. SINGLE_BAND—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.MULTI_BAND—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |
| percentile_value(Optional) | The percentile value that will be calculated. The default is 90, indicating the 90th percentile.The value can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to the maximum statistic. A value of 50 will produce essentially the same result as the median statistic.This parameter is only supported if the statistics_type parameter is set to PERCENTILE. | Double |
| percentile_interpolation_type(Optional) | Specifies the method of interpolation that will be used when the specified percentile value is between two input cell values.AUTO_DETECT—If the input rasters are of integer pixel type, the NEAREST method will be used. If the input rasters are of floating point pixel type, the LINEAR method will be used. This is the default.NEAREST—The nearest available value to the desired percentile will be used. In this case, the output pixel type will be the same as that of the input rasters.LINEAR—The weighted average of the two surrounding values from the percentile will be used. In this case, the output pixel type will be floating point. | String |

## Code Samples

### Example 1

```python
CellStatistics(in_rasters_or_constants, {statistics_type}, {ignore_nodata}, {process_as_multiband}, {percentile_value}, {percentile_interpolation_type})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCellStats = CellStatistics(["degs", "negs", "cost"], "STD", "DATA")
outCellStats.save("C:/sapyexamples/output/outcellstats.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCellStats = CellStatistics(["degs", "negs", "cost"], "STD", "DATA")
outCellStats.save("C:/sapyexamples/output/outcellstats.img")
```

### Example 4

```python
# Name: CellStatistics_Ex_standalone.py
# Description: Calculates a per-cell statistic from multiple multiband rasters
#               and process as multiband.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/sapyexamples/data"

# Set the local variables
inRaster01 = "degs_MB"
inRaster02 = "negs_MB"
inRaster03 = "cost_MB"

# Execute CellStatistics
outCellStatistics = CellStatistics([inRaster01, inRaster02, inRaster03], "RANGE", "NODATA", "MULTI_BAND")

# Save the output 
outCellStatistics.save("C:/sapyexamples/output/cellstats_MB.tif")
```

### Example 5

```python
# Name: CellStatistics_Ex_standalone.py
# Description: Calculates a per-cell statistic from multiple multiband rasters
#               and process as multiband.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/sapyexamples/data"

# Set the local variables
inRaster01 = "degs_MB"
inRaster02 = "negs_MB"
inRaster03 = "cost_MB"

# Execute CellStatistics
outCellStatistics = CellStatistics([inRaster01, inRaster02, inRaster03], "RANGE", "NODATA", "MULTI_BAND")

# Save the output 
outCellStatistics.save("C:/sapyexamples/output/cellstats_MB.tif")
```

---

## Class Probability (Spatial Analyst)

## Summary

Creates a multiband raster of probability bands, with one band being created for each class represented in the input signature file.

## Usage

- When a multiband raster is specified as one of the Input raster bands (in_raster_bands in Python), all the bands will be used.To process a selection of bands from a multiband raster, you can first create a new raster dataset composed of those particular bands with the Composite Bands tool, and use the result in the list of the Input raster bands (in_raster_bands in Python).
- Any signature file created by the Create Signature, Edit Signature, or Iso Cluster tools is a valid entry for the input signature file. These will have a .gsg extension.
- This tool employs Bayesian statistics to estimate class probabilities. Bayesian statistics involves starting with prior information about the data, then updating that information after the data is collected. The prior information about the data values is quantified with a priori probabilities, which are then adjusted by the likelihood function to receive posterior probabilities (the updated information). The likelihood function is defined by the data values for each class/cluster.
- The input a priori probability file must be an ASCII file consisting of two columns. The values in the left column represent class IDs. The values in the right column represent the a priori probabilities for the respective classes. Valid values for class a priori probabilities must be greater than or equal to zero. If zero is specified as a probability, no associated probability band will be created for the class in the output multiband raster. The sum of the specified a priori probabilities must be less than or equal to one. An example showing the format of the file as follows: 1 .3 2 .1 4 .0 5 .15 7 .05 8 .2The classes omitted in the file will receive the average a priori probability of the remaining portion of the value of one. In the above example, all classes from 1 to 8 are represented in the signature file. The a priori probabilities of classes 3 and 6 are missing in the input a priori probability file. Since the sum of all probabilities specified in the above file is equal to 0.8, the remaining portion of the probability (0.2) is divided by the number of classes not specified (2). Therefore, classes 3 and 6 will each be assigned a probability of 0.1.The extension for the input a priori probability file can be .txt or .asc.
- The value entered for maximum output value sets the upper range of the values in the output probability bands. The default value of 100 creates a multiband raster with each band containing integer values ranging from 0 to 100. Any integer value greater than zero is valid for maximum output value. Only the value of one for the maximum output value argument will result in bands having floating-point values.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster bands | The input raster bands.They can be integer or floating point type. | Raster Layer |
| Input signature file | Input signature file whose class signatures are used to generate the a priori probability bands.A .gsg extension is required. | File |
| Maximum output value(Optional) | Factor for scaling the range of values in the output probability bands.By default, the values range from 0 to 100. | Long |
| A priori probability weighting(Optional) | Specifies how a priori probabilities will be determined.Equal—All classes will have the same a priori probability.Sample—A priori probabilities will be proportional to the number of cells in each class relative to the total number of cells sampled in all classes in the signature file.File—The a priori probabilities will be assigned to each class from an input ASCII a priori probability file. | String |
| Input a priori probability file(Optional) | A text file containing a priori probabilities for the input signature classes.An input for the a priori probability file is only required when the File option is used.The extension for the a priori file can be .txt or .asc. | File |
| in_raster_bands[in_raster_band,...] | The input raster bands.They can be integer or floating point type. | Raster Layer |
| in_signature_file | Input signature file whose class signatures are used to generate the a priori probability bands.A .gsg extension is required. | File |
| maximum_output_value(Optional) | Factor for scaling the range of values in the output probability bands.By default, the values range from 0 to 100. | Long |
| a_priori_probabilities(Optional) | Specifies how a priori probabilities will be determined. EQUAL—All classes will have the same a priori probability.SAMPLE—A priori probabilities will be proportional to the number of cells in each class relative to the total number of cells sampled in all classes in the signature file.FILE—The a priori probabilities will be assigned to each class from an input ASCII a priori probability file. | String |
| in_a_priori_file(Optional) | A text file containing a priori probabilities for the input signature classes.An input for the a priori probability file is only required when the File option is used.The extension for the a priori file can be .txt or .asc. | File |

## Code Samples

### Example 1

```python
1  .3
    2  .1
    4  .0
    5  .15
    7  .05
    8  .2
```

### Example 2

```python
ClassProbability(in_raster_bands, in_signature_file, {maximum_output_value}, {a_priori_probabilities}, {in_a_priori_file})
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outClassProbability = ClassProbability("redlands","C:/sapyexamples/data/wedit5.gsg",
                    100,"EQUAL","")
outClassProbability.save("c:/sapyexamples/output/classprob")
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outClassProbability = ClassProbability("redlands","C:/sapyexamples/data/wedit5.gsg",
                    100,"EQUAL","")
outClassProbability.save("c:/sapyexamples/output/classprob")
```

### Example 5

```python
# Name: ClassProbability_Ex_02.py
# Description: Creates probability layers for each class in a signature file.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "redl123"
inSigFile = "c:/sapyexamples/data/wedit5.gsg"
maxValue = 100
aPrioriWeight = "EQUAL"
aPrioriFile = ""

# Execute ClassProbability
outClassProbability = ClassProbability(inRaster,inSigFile,
                    maxValue, aPrioriWeight, aPrioriFile)

# Save the output 
outClassProbability.save("c:/sapyexamples/output/classprob01")
```

### Example 6

```python
# Name: ClassProbability_Ex_02.py
# Description: Creates probability layers for each class in a signature file.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "redl123"
inSigFile = "c:/sapyexamples/data/wedit5.gsg"
maxValue = 100
aPrioriWeight = "EQUAL"
aPrioriFile = ""

# Execute ClassProbability
outClassProbability = ClassProbability(inRaster,inSigFile,
                    maxValue, aPrioriWeight, aPrioriFile)

# Save the output 
outClassProbability.save("c:/sapyexamples/output/classprob01")
```

---

## Classify Raster (Spatial Analyst)

## Summary

Classifies a raster dataset based on an Esri classifier definition file (.ecd) and raster dataset inputs.

## Usage

- The input raster can be any Esri-supported raster and any valid bit depth.
- The input .ecd file contains attribute statistics suitable for the appropriate classifier.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The raster dataset to classify. | Mosaic Layer; Raster Layer; Image Service; String; Raster Dataset; Mosaic Dataset |
| Input Classifier Definition File | The input Esri classifier definition file (.ecd) containing the statistics for the chosen attributes for the classifier. | File |
| Additional Input Raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for the classifier. This raster is necessary when calculating attributes such as mean or standard deviation. This parameter is optional. | Mosaic Layer; Raster Layer; Image Service; String; Raster Dataset; Mosaic Dataset |
| in_raster | The raster dataset to classify. | Mosaic Layer; Raster Layer; Image Service; String; Raster Dataset; Mosaic Dataset |
| in_classifier_definition | The input Esri classifier definition file (.ecd) containing the statistics for the chosen attributes for the classifier. | File |
| in_additional_raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for the classifier. This raster is necessary when calculating attributes such as mean or standard deviation. This parameter is optional. | Mosaic Layer; Raster Layer; Image Service; String; Raster Dataset; Mosaic Dataset |

## Code Samples

### Example 1

```python
ClassifyRaster(in_raster, in_classifier_definition, {in_additional_raster})
```

### Example 2

```python
# Import system modules
import arcpy
from arcpy.sa import *

classifiedraster = ClassifyRaster("c:/classifydata/moncton_seg.tif", 
                                  "c:/classifydata/moncton_sig.ecd", 
                                  "c:/classifydata/moncton.tif")

classifiedraster.save("c:/test/moncton_classified.tif")
```

### Example 3

```python
# Import system modules
import arcpy
from arcpy.sa import *

classifiedraster = ClassifyRaster("c:/classifydata/moncton_seg.tif", 
                                  "c:/classifydata/moncton_sig.ecd", 
                                  "c:/classifydata/moncton.tif")

classifiedraster.save("c:/test/moncton_classified.tif")
```

### Example 4

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
insegras = "c:/classifydata/moncton_seg.tif"
indef_file = "c:/classifydata/moncton_sig.ecd"
in_additional_raster = "c:/classifydata/moncton.tif"


# Execute 
classifiedraster = ClassifyRaster(insegras, indef_file, in_additional_raster)

#save output
classifiedraster.save("c:/test/moncton_classified.tif")
```

### Example 5

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
insegras = "c:/classifydata/moncton_seg.tif"
indef_file = "c:/classifydata/moncton_sig.ecd"
in_additional_raster = "c:/classifydata/moncton.tif"


# Execute 
classifiedraster = ClassifyRaster(insegras, indef_file, in_additional_raster)

#save output
classifiedraster.save("c:/test/moncton_classified.tif")
```

---

## Combinatorial And (Spatial Analyst)

## Summary

Performs a Combinatorial And operation on the cell values of two input rasters.

## Usage

- The Combinatorial math tools interpret the inputs as Boolean values in which nonzero values are considered true and zero is considered false.
- Two inputs are necessary for this combinatorial evaluation to take place.
- The order of inputs for this tool is only relevant for the output attribute table.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The first input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The second input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The first input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The second input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
CombinatorialAnd(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCAnd = CombinatorialAnd("degs", "cost")
outCAnd.save("C:/sapyexamples/output/outcand.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCAnd = CombinatorialAnd("degs", "cost")
outCAnd.save("C:/sapyexamples/output/outcand.tif")
```

### Example 4

```python
# Name: CombinatorialAnd_Ex_02.py
# Description: Performs a Combinatorial And operation on the cell
#              values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "cost"

# Execute CombinatorialAnd
outCAnd = CombinatorialAnd(inRaster1, inRaster2)

# Save the output 
outCAnd.save("C:/sapyexamples/output/outcand")
```

### Example 5

```python
# Name: CombinatorialAnd_Ex_02.py
# Description: Performs a Combinatorial And operation on the cell
#              values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "cost"

# Execute CombinatorialAnd
outCAnd = CombinatorialAnd(inRaster1, inRaster2)

# Save the output 
outCAnd.save("C:/sapyexamples/output/outcand")
```

---

## Combinatorial Or (Spatial Analyst)

## Summary

Performs a Combinatorial Or operation on the cell values of two input rasters.

## Usage

- The Combinatorial math tools interpret the inputs as Boolean values in which nonzero values are considered true and zero is considered false.
- Two inputs are necessary for this combinatorial evaluation to take place.
- The order of inputs for this tool is only relevant for the output attribute table.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The first input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The second input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The first input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The second input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
CombinatorialOr(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCOr = CombinatorialOr("degs", "cost")
outCOr.save("C:/sapyexamples/output/outcor.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCOr = CombinatorialOr("degs", "cost")
outCOr.save("C:/sapyexamples/output/outcor.img")
```

### Example 4

```python
# Name: CombinatorialOr_Ex_02.py
# Description: Performs a Combinatorial Or operation on the cell
#              values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "cost"

# Execute CombinatorialOr
outCOr = CombinatorialOr(inRaster1, inRaster2)

# Save the output 
outCOr.save("C:/sapyexamples/output/outcor")
```

### Example 5

```python
# Name: CombinatorialOr_Ex_02.py
# Description: Performs a Combinatorial Or operation on the cell
#              values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "cost"

# Execute CombinatorialOr
outCOr = CombinatorialOr(inRaster1, inRaster2)

# Save the output 
outCOr.save("C:/sapyexamples/output/outcor")
```

---

## Combinatorial XOr (Spatial Analyst)

## Summary

Performs a Combinatorial eXclusive Or operation on the cell values of two input rasters.

## Usage

- The Combinatorial math tools interpret the inputs as Boolean values in which nonzero values are considered true and zero is considered false.
- Two inputs are necessary for this combinatorial evaluation to take place.
- The order of inputs for this tool is only relevant for the output attribute table.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The first input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The second input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The first input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The second input to use in this combinatorial operation.It must be of integer type.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
CombinatorialXOr(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCXOr = CombinatorialXOr("degs", "cost")
outCXOr.save("C:/sapyexamples/output/outcxor.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCXOr = CombinatorialXOr("degs", "cost")
outCXOr.save("C:/sapyexamples/output/outcxor.img")
```

### Example 4

```python
# Name: CombinatorialXOr_Ex_02.py
# Description: Performs a Combinatorial Exclusive Or operation on
#              the cell values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "cost"

# Execute CombinatorialXOr
outCXOr = CombinatorialXOr(inRaster1, inRaster2)

# Save the output 
outCXOr.save("C:/sapyexamples/output/outcxor")
```

### Example 5

```python
# Name: CombinatorialXOr_Ex_02.py
# Description: Performs a Combinatorial Exclusive Or operation on
#              the cell values of two input rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "cost"

# Execute CombinatorialXOr
outCXOr = CombinatorialXOr(inRaster1, inRaster2)

# Save the output 
outCXOr.save("C:/sapyexamples/output/outcxor")
```

---

## Combine (Spatial Analyst)

## Summary

Combines multiple rasters so that a unique output value is assigned to each unique combination of input values.

## Usage

- The Combine tool works on integer values and their associated attribute tables. If the values on the input are floating point, they will be automatically truncated, tested for uniqueness with the other input, and sent to the output attribute table.
- The Combine tool is similar to the Combinatorial Or tool. They both assign a new number to each unique combination of input values. However, in the Combine tool, you can specify a list of rasters, whereas in the Combinatorial Or tool, you can specify only two inputs, which can be rasters or constant values.
- When a multiband raster is specified as one of the Input rasters parameter values (in_rasters in Python), all the bands will be used.To process a selection of bands from a multiband raster, first create a raster dataset composed of those particular bands using the Composite Bands tool; then use the result in the list in the Input rasters parameter (in_rasters in Python).
- The output raster is always of integer type.
- Each raster input is represented by a field in the output raster attribute table (RAT) in which the order of the fields in the output matches the order of the input rasters.If multiband inputs are present, the output identifies each band as an individual raster and the corresponding number of fields will be created.If the same raster is used multiple times, it will be considered as individual inputs; however, a warning will be returned.
- The field name in the output RAT is based on the raster dataset name. If the field name is too long, it will be truncated to meet the field name length limitation. Any special character in the raster name that is not supported by the database will be replaced by an underscore. In the case of multiband inputs, the field name is constructed using two parts, separated by an underscore. The first part is derived from the name of the raster, followed by the index of the band, starting from 1.In the case of duplicate field names, each subsequent field name is made unique by modifying the raster name with an index starting from 1.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input rasters | The list of input rasters to be combined. | Raster Layer |
| in_rasters[in_raster,...] | The list of input rasters to be combined. | Raster Layer |

## Code Samples

### Example 1

```python
Combine(in_rasters)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCombine = Combine(["filter", "zone", "source.img", "dec.tif"])
outCombine.save("C:/sapyexamples/output/outcombine2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCombine = Combine(["filter", "zone", "source.img", "dec.tif"])
outCombine.save("C:/sapyexamples/output/outcombine2")
```

### Example 4

```python
# Name: Combine_Ex_02.py
# Description: Combines multiple rasters such that a unique value is
#              assigned to each unique combination of input values
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster01 = "filter"
inRaster02 = "zone"
inRaster03 = "source.img"
inRaster04 = "dec.tif"

# Execute Combine
outCombine = Combine([inRaster01,inRaster02,inRaster03,inRaster04])

# Save the output 
outCombine.save("C:/sapyexamples/output/outcombine")
```

### Example 5

```python
# Name: Combine_Ex_02.py
# Description: Combines multiple rasters such that a unique value is
#              assigned to each unique combination of input values
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster01 = "filter"
inRaster02 = "zone"
inRaster03 = "source.img"
inRaster04 = "dec.tif"

# Execute Combine
outCombine = Combine([inRaster01,inRaster02,inRaster03,inRaster04])

# Save the output 
outCombine.save("C:/sapyexamples/output/outcombine")
```

---

## Compute Confusion Matrix (Spatial Analyst)

## Summary

Computes a confusion matrix with errors of omission and commission and derives a kappa index of agreement, Intersection over Union (IoU), and an overall accuracy between the classified map and the reference data.

## Usage

- The accuracy assessment workflow usually uses the following three tools in this order: Create Accuracy Assessment Points, Update Accuracy Assessment Points, and Compute Confusion Matrix.
- This tool computes a confusion matrix using the random accuracy assessment points. The accuracy assessment points are generated by the Create Accuracy Assessment Points tool and updated by the Update Accuracy Assessment Points tool. These two tools ensure that each point will have valid class values for the Classified and GrndTruth fields. These fields are both long integer field types. The tool calculates the user's accuracy and producer's accuracy for each class as well as an overall kappa index of agreement. These accuracy rates range from 0 to 1 in which 1 represents 100 percent accuracy. The following is an example of a confusion matrix:c_1c_2c_3TotalU_AccuracyKappa c_14944570.85940c_22402440.90910c_33359650.90770Total54476516600P_Accuracy0.90740.85110.907700.89160Kappa000000.8357Confusion matrix example
- User's accuracy shows false positives in which pixels are incorrectly classified as a known class when they should have been classified as something else. An example is when the classified image identifies a pixel as impervious, but the reference identifies it as forest. The impervious class has extra pixels that it should not have according to the reference data.User's accuracy is also referred to as errors of commission, or type 1 error. The data to compute this error rate is read from the rows of the table.The Total row shows the number of points that should have been identified as a given class according to the reference data.
- Producer's accuracy is a false negative in which pixels of a known class are classified as something other than that class. An example is when the classified image identifies a pixel as forest, but it should be impervious. In this case, the impervious class is missing pixels according to the reference data. Producer's accuracy is also referred to as errors of omission, or type 2 error. The data to compute this error rate is read in the columns of the table.The Total column shows the number of points that were identified as a given class according to the classified map.
- Kappa index of agreement provides an overall assessment of the accuracy of the classification.
- Intersection over Union (IoU) is the area of overlap between the predicted segmentation and the ground truth divided by the area of union between the predicted segmentation and the ground truth. The mean IoU value is computed for each class.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Accuracy Assessment Points | The accuracy assessment point feature class created from the Create Accuracy Assessment Points tool, containing the Classified and GrndTruth fields. These fields are both long integer field types. | Feature Layer |
| Output Confusion Matrix | The output file name of the confusion matrix in table format.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table. If the path is not in a geodatabase, specify a .dbf extension to save it in dBASE format. | Table |
| in_accuracy_assessment_points | The accuracy assessment point feature class created from the Create Accuracy Assessment Points tool, containing the Classified and GrndTruth fields. These fields are both long integer field types. | Feature Layer |
| out_confusion_matrix | The output file name of the confusion matrix in table format.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table. If the path is not in a geodatabase, specify a .dbf extension to save it in dBASE format. | Table |

## Code Samples

### Example 1

```python
ComputeConfusionMatrix(in_accuracy_assessment_points, out_confusion_matrix)
```

### Example 2

```python
import arcpy
from arcpy.sa import *

arcpy.gp.ComputeConfusionMatrix("aapnt2.shp", "confm.dbf")
```

### Example 3

```python
import arcpy
from arcpy.sa import *

arcpy.gp.ComputeConfusionMatrix("aapnt2.shp", "confm.dbf")
```

---

## Compute Segment Attributes (Spatial Analyst)

## Summary

Computes a set of attributes associated with the segmented image. The input raster can be a single-band or 3-band, 8-bit segmented image.

## Usage

- This tool generates the attributes for each segment that exists in the image. Attributes include mean, standard deviation, segment size, converged color (from the Segment Mean Shift tool), and compactness.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Segmented RGB Or Gray Raster | The input segmented raster dataset, where all the pixels belonging to a segment have the same converged RGB color. Usually, it is an 8-bit, 3-band RGB raster, but it can also be a 1-band grayscale raster. | Raster Layer; Mosaic Layer |
| Additional Input Raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for the classifier. This raster is necessary when calculating attributes such as mean or standard deviation. This parameter is optional. | Raster Layer; Mosaic Layer |
| Segment Attributes Used(Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster.If the only input into the tool is a segmented image, the default attributes are Average chromaticity color, Count of pixels, Compactness, and Rectangularity. If an Additional Input Raster is also included as an input along with a segmented image, then Mean digital number and Standard deviation are available as options.Converged color—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.Mean digital number—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.Standard deviation—The standard deviation will be derived from the optional pixel image on a per-segment basis.Count of pixels—The number of pixels composing the segment, on a per-segment basis.Compactness—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.Rectangularity—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle. | String |
| in_segmented_raster | The input segmented raster dataset, where all the pixels belonging to a segment have the same converged RGB color. Usually, it is an 8-bit, 3-band RGB raster, but it can also be a 1-band grayscale raster. | Raster Layer; Mosaic Layer |
| in_additional_raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for the classifier. This raster is necessary when calculating attributes such as mean or standard deviation. This parameter is optional. | Raster Layer; Mosaic Layer |
| used_attributes[used_attributes,...](Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster.COLOR—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.MEAN—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.STD—The standard deviation will be derived from the optional pixel image on a per-segment basis.COUNT—The number of pixels composing the segment, on a per-segment basis.COMPACTNESS—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.RECTANGULARITY—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle. If the only input into the tool is a segmented image, the default attributes are COLOR, COUNT, COMPACTNESS, and RECTANGULARITY. If an in_additional_raster is also included as an input along with a segmented image, then MEAN and STD are available as options. | String |

## Code Samples

### Example 1

```python
ComputeSegmentAttributes(in_segmented_raster, {in_additional_raster}, {used_attributes})
```

### Example 2

```python
import arcpy
from arcpy.sa import *

compute_att = ComputeSegmentAttributes(
                  "c:/test/moncton_seg.tif", "c:/test/moncton.tif", 
                  "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")

compute_att.save("c:/test/moncton_computeseg.tif")
```

### Example 3

```python
import arcpy
from arcpy.sa import *

compute_att = ComputeSegmentAttributes(
                  "c:/test/moncton_seg.tif", "c:/test/moncton.tif", 
                  "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")

compute_att.save("c:/test/moncton_computeseg.tif")
```

### Example 4

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
inSegRaster = "c:/test/moncton_seg.tif"
in_additional_raster = "c:/test/moncton.tif"
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"

# Execute 
compute_att = ComputeSegmentAttributes(inSegRaster, in_additional_raster, 
                                       attributes)
#save output 
compute_att.save("c:/test/moncton_computeseg.tif")
```

### Example 5

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
inSegRaster = "c:/test/moncton_seg.tif"
in_additional_raster = "c:/test/moncton.tif"
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"

# Execute 
compute_att = ComputeSegmentAttributes(inSegRaster, in_additional_raster, 
                                       attributes)
#save output 
compute_att.save("c:/test/moncton_computeseg.tif")
```

---

## Con (Spatial Analyst)

## Summary

Performs a conditional if/else evaluation on each of the input cells of an input raster.

## Usage

- If either the true raster or the optional false raster is floating point, the output raster will be floating point. If both the true expression and the optional false raster are integer, the output raster will be integer.
- If the Input conditional raster (in_conditional_raster in Python) is a single-band raster and either the Input true raster or constant value (in_true_raster_or_constant In Python) raster or the optional Input false raster or constant value (in_false_raster_or_constant In Python) raster is a constant, the output will be a single-band raster.
- If all inputs are multiband rasters, the output will be a multiband raster. The output raster will also be multiband if either the true input or the optional false input is a constant. The number of bands in each multiband input must be the same.
- The tool will perform the operation on each band from the conditional raster using the corresponding band from the other inputs. If the conditional input is a multiband raster and the true or false raster input is a constant, the tool will perform the operation using the constant value for each band in the multiband input.
- If the evaluation of the expression is nonzero, it is treated as true.
- If no Input false raster or constant value is specified, NoData will be assigned to those cells that do not result in true from the expression.
- If NoData does not satisfy the expression, it does not receive the value of the input false raster; it remains NoData.
- The Expression uses an SQL query. See the following topics for details on creating queries: Build an SQL querySQL reference for query expressions used in ArcGIS
- Build an SQL query
- SQL reference for query expressions used in ArcGIS
- In order to use a {where_clause} in Python, it should be enclosed in quotes. For example, "Value > 5000".You can consult the help for more information on specifying a query in Python.
- In Python, you can avoid using a {where_clause} that specifies the Value field by using a Map Algebra expression as the in_conditional_raster instead.For example, the following expression: Con("elev", 0, 1, "value > 1000")can be rewritten as follows: Con(Raster("elev") > 1000, 0, 1)For more information, see the code samples listed below or review Build complex statements in Map Algebra.
- Con("elev", 0, 1, "value > 1000")
- Con(Raster("elev") > 1000, 0, 1)
- The maximum length of the logical expression is 4,096 characters.
- If at least one of the inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise. an error will occur.If any two inputs are multidimensional rasters and share one variable but with different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If the Input conditional raster value is a multidimensional raster and the Input true raster or constant value and Input false raster or constant value parameters are set to constant values, the tool will perform the operation for all slices for all variables using the constant values, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input conditional raster | The input raster representing the true or false result of the desired condition.It can be of integer or floating point type. | Raster Layer |
| Input true raster or constant value | The input whose values will be used as the output cell values if the condition is true.It can be an integer or a floating-point raster, or a constant value. | Raster Layer; Constant |
| Input false raster or constant value(Optional) | The input whose values will be used as the output cell values if the condition is false.It can be an integer or a floating-point raster, or a constant value. | Raster Layer; Constant |
| Expression(Optional) | A logical expression that determines which of the input cells are to be true or false. The Where clause follows the general form of an SQL expression. It can be entered directly, for example, VALUE > 100, if you click the Edit SQL mode button . If in the Edit Clause Mode , you can begin constructing the expression by clicking on the Add Clause Mode button. | SQL Expression |
| in_conditional_raster | The input raster representing the true or false result of the desired condition.It can be of integer or floating point type. | Raster Layer |
| in_true_raster_or_constant | The input whose values will be used as the output cell values if the condition is true.It can be an integer or a floating-point raster, or a constant value. | Raster Layer; Constant |
| in_false_raster_or_constant(Optional) | The input whose values will be used as the output cell values if the condition is false.It can be an integer or a floating-point raster, or a constant value. | Raster Layer; Constant |
| where_clause(Optional) | A logical expression that determines which of the input cells are to be true or false. The expression follows the general form of an SQL expression. An example of a where_clause is "VALUE > 100". | SQL Expression |

## Code Samples

### Example 1

```python
Con(in_conditional_raster, in_true_raster_or_constant, {in_false_raster_or_constant}, {where_clause})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCon = Con("elevation", "elevation", "", "VALUE > 2000")
outCon.save("C:/sapyexamples/output/outcon.img")

# Execute Con using a map algebra expression instead of a where clause
outCon2 = Con(Raster("elevation") > 2000, "elevation")
outCon2.save("C:/sapyexamples/output/outcon2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCon = Con("elevation", "elevation", "", "VALUE > 2000")
outCon.save("C:/sapyexamples/output/outcon.img")

# Execute Con using a map algebra expression instead of a where clause
outCon2 = Con(Raster("elevation") > 2000, "elevation")
outCon2.save("C:/sapyexamples/output/outcon2")
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCon = Con(IsNull("elevation"),0, "elevation")
outCon.save("C:/sapyexamples/output/outcon")
```

### Example 5

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCon = Con(IsNull("elevation"),0, "elevation")
outCon.save("C:/sapyexamples/output/outcon")
```

### Example 6

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
inRaster1 = Raster("landuse")
inRaster2 = Raster("landuse2")
outCon = Con(((inRaster1 == 1) & (inRaster2 == 5)), inRaster1 + inRaster2, 99)
outCon.save("C:/sapyexamples/output/outcon")
```

### Example 7

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
inRaster1 = Raster("landuse")
inRaster2 = Raster("landuse2")
outCon = Con(((inRaster1 == 1) & (inRaster2 == 5)), inRaster1 + inRaster2, 99)
outCon.save("C:/sapyexamples/output/outcon")
```

### Example 8

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
inRas1 = Raster("inRaster")
outCon = Con(inRas1 < 45,1, Con((inRas1 >= 45) & (inRas1 < 47),2, Con((inRas1 >= 47) & (inRas1 < 49),3, Con(inRas1 >= 49,4))))
outCon.save("C:/sapyexamples/output/outcon")
```

### Example 9

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
inRas1 = Raster("inRaster")
outCon = Con(inRas1 < 45,1, Con((inRas1 >= 45) & (inRas1 < 47),2, Con((inRas1 >= 47) & (inRas1 < 49),3, Con(inRas1 >= 49,4))))
outCon.save("C:/sapyexamples/output/outcon")
```

### Example 10

```python
# Name: Con_Ex_02.py
# Description: Performs a conditional if/else evaluation 
#              on each cell of an input raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = Raster("elevation")
inTrueRaster = 1
inFalseConstant = 0
whereClause = "VALUE >= 1500"

# Execute Con
outCon = Con(inRaster, inTrueRaster, inFalseConstant, whereClause)

# Execute Con using a map algebra expression instead of a where clause
outCon2 = Con(inRaster >= 1500, inTrueRaster, inFalseConstant)

# Save the outputs 
outCon.save("C:/sapyexamples/output/outcon")
outCon2.save("C:/sapyexamples/output/outcon2")
```

### Example 11

```python
# Name: Con_Ex_02.py
# Description: Performs a conditional if/else evaluation 
#              on each cell of an input raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = Raster("elevation")
inTrueRaster = 1
inFalseConstant = 0
whereClause = "VALUE >= 1500"

# Execute Con
outCon = Con(inRaster, inTrueRaster, inFalseConstant, whereClause)

# Execute Con using a map algebra expression instead of a where clause
outCon2 = Con(inRaster >= 1500, inTrueRaster, inFalseConstant)

# Save the outputs 
outCon.save("C:/sapyexamples/output/outcon")
outCon2.save("C:/sapyexamples/output/outcon2")
```

---

## Conditional evaluation with Con

## Code Samples

### Example 1

```python
OutRas = Con(SlopeRas, 10, 1, "VALUE < 15")
```

### Example 2

```python
OutRas = Con(SlopeRas, 10, 1, "VALUE < 15")
```

### Example 3

```python
Con(in_conditional_raster, true_raster, {false_raster})
```

### Example 4

```python
OutRas = Con(InRas < 15, 10, 1)
```

### Example 5

```python
OutRas = Con(InRas < 15, 10, 1)
```

### Example 6

```python
OutRas = Con(InRas < 15, 10)
```

### Example 7

```python
OutRas = Con(InRas < 15, 10)
```

### Example 8

```python
OutRas = Con(InRas1 > 5, Sin(InRas1), Cos(InRas1))
```

### Example 9

```python
OutRas = Con(InRas1 > 5, Sin(InRas1), Cos(InRas1))
```

### Example 10

```python
OutRas = Con(InRas1 < 5, Sin(InRas1), Con(InRas1 < 20, Cos(InRas1), Con(InRas1 > 50, 100, 0)))
```

### Example 11

```python
OutRas = Con(InRas1 < 5, Sin(InRas1), Con(InRas1 < 20, Cos(InRas1), Con(InRas1 > 50, 100, 0)))
```

### Example 12

```python
OutRas = Con((InRas1 > 5) & (InRas1 < 10), 5, 100)
```

### Example 13

```python
OutRas = Con((InRas1 > 5) & (InRas1 < 10), 5, 100)
```

### Example 14

```python
OutRas = Con(Sin(InRas1) > .5, 10, 100)
OutRas2 = Con((InRas1 + InRas2) > 10, 100, 5)
OutRas3 = Con(InRas1 > 5, Cos(InRas1), Sin(InRas1))
```

### Example 15

```python
OutRas = Con(Sin(InRas1) > .5, 10, 100)
OutRas2 = Con((InRas1 + InRas2) > 10, 100, 5)
OutRas3 = Con(InRas1 > 5, Cos(InRas1), Sin(InRas1))
```

### Example 16

```python
OutRas = Con(InRas1 > 23, 5, Con(InRas1 > 20, 12, Con((InRas1 > 2) & (InRas1 < 17), Sin(InRas1), 100)))
```

### Example 17

```python
OutRas = Con(InRas1 > 23, 5, Con(InRas1 > 20, 12, Con((InRas1 > 2) & (InRas1 < 17), Sin(InRas1), 100)))
```

### Example 18

```python
OutRas = Con(InRas1 + InRas2 > 7, Sin(InRas1), Cos(InRas2))
OutRas2 = Con(InRas1 < 9, InRas1 * InRas2 + Tan(InRas3), Cos(InRas1))
```

### Example 19

```python
OutRas = Con(InRas1 + InRas2 > 7, Sin(InRas1), Cos(InRas2))
OutRas2 = Con(InRas1 < 9, InRas1 * InRas2 + Tan(InRas3), Cos(InRas1))
```

---

## Contour List (Spatial Analyst)

## Summary

Creates a feature class of selected contour values from a raster surface.

## Usage

- Contours do not extend beyond the spatial extent of the raster, and they are not generated in areas of NoData. Edgematch adjacent contour inputs into a continuous feature dataset first. As an alternative to edgematching, you can merge the adjacent rasters before computing contours.
- Contours can be generated in areas of negative raster values. The contour values will be negative in those areas. Negative contour intervals are not allowed.
- The contour values do not need to be sorted in order.
- Smoother but less accurate contours can be obtained by preprocessing the input raster using the Focal Statistics tool with the Mean option or the Filter tool with the Low option.
- By default, this tool will use multicore processors if available. The maximum number of cores that can be used is four.To use fewer cores, use the Parallel Processing Factor environment setting.
- If the Extent environment is specified and the lower left corner of the output extent does not match any cell corner of the input raster, a shift of the cell alignment of the input raster will occur during processing to match the specified extent. This shift will trigger a resampling of the input raster using the Bilinear method. Consequently, the output features will shift as well, and the resultant output features may not overlay the original input raster exactly. You can avoid this shift by using the input raster for the Snap Raster environment.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input surface raster. | Raster Layer |
| Output polyline features | The output contour polyline features. | Feature Class |
| Contour values | List of z-values for which to create contours. | Double |
| in_raster | The input surface raster. | Raster Layer |
| out_polyline_features | The output contour polyline features. | Feature Class |
| contour_values[contour_value,...] | List of z-values for which to create contours. | Double |

## Code Samples

### Example 1

```python
ContourList(in_raster, out_polyline_features, contour_values)
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
ContourList("elevation", "C:/sapyexamples/output/outcontourlist.shp", [600, 935, 1237.4])
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
ContourList("elevation", "C:/sapyexamples/output/outcontourlist.shp", [600, 935, 1237.4])
```

### Example 4

```python
# Name: ContourList_Ex_02.py
# Description: CCreates contours or isolines based on a list of contour values.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
contourIntervalList = [600, 935, 1237.4]
outContours = "C:/sapyexamples/output/outcontourlist02.shp"

# Execute ContourList
ContourList(inRaster, outContours, contourIntervalList)
```

### Example 5

```python
# Name: ContourList_Ex_02.py
# Description: CCreates contours or isolines based on a list of contour values.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
contourIntervalList = [600, 935, 1237.4]
outContours = "C:/sapyexamples/output/outcontourlist02.shp"

# Execute ContourList
ContourList(inRaster, outContours, contourIntervalList)
```

---

## Contour with Barriers (Spatial Analyst)

## Summary

Creates contours from a raster surface. The inclusion of barrier features allows you to independently generate contours on either side of a barrier.

## Usage

- The current version of Contour with Barriers only supports polyline output. If the polygon output option is used it will be ignored and polyline output will be created.
- Smoother but less accurate contours can be obtained by preprocessing the input raster using the Focal Statistics tool with the Mean option or the Filter tool with the Low option.
- Contours will extend into the raster's NoData cell by a distance of half the raster's cell size. This will mean that the contours will be generated over single NoData cells. However, a 3-cell-by-3-cell area of NoData will only have the contours extending into this area by half the cell size distance.
- The Type field in the output contour feature class can have values such as: 1 for contours 2 for indexed contours 3 for explicit contours
- An indexed contour interval can be used to generate additional contours and their Type value will be coded as 2 in the output feature class.
- A base contour is used, for example, when you want to create contours every 15 meters, starting at 10 meters. Here, 10 would be used for the base contour, and 15 would be the contour interval. The values to be contoured would be 10, 25, 40, 55, and so on.
- Specifying a base contour does not prevent contours from being created above or below that value.
- A text file containing contour value specifications can include the following:Any line that starts with a non-numeric value will be ignored and treated as a comment line.A line with a single value will be treated as an explicit contour value.A line with three values will be treated as base, contour interval, and indexed contour.A line with four values will treated as from, to, by, and indexed contours.For example, if a raster has a minimum value of 102 and a maximum of 500, then a text file with: # contour values and ranges 122.75 485 500 5 12 4 100 99will produce contours at: 122.75 104, 204, 304, 404 103, 202, 301, 400, 499 485, 490, 495, 500 497
- Any line that starts with a non-numeric value will be ignored and treated as a comment line.
- A line with a single value will be treated as an explicit contour value.
- A line with three values will be treated as base, contour interval, and indexed contour.
- A line with four values will treated as from, to, by, and indexed contours.
- If there are cell values of the raster within a barrier polygon feature the contour lines will be split at the barrier. If the cell values within the polygon feature are to be ignored, change those cell values to NoData.
- If the input raster surface is very large or many output features are requested, a large number of temporary files will be created in the operating system's temporary file location. If any problems are encountered as a result of this do one of the following:Increase the available disk space for temporary files.Reduce the number of contours specified, or split the contour range up and process each group separately, and combine the results from each range into a final result.Process the input data in sections (tiles), and merge the individual results into one dataset.
- Increase the available disk space for temporary files.
- Reduce the number of contours specified, or split the contour range up and process each group separately, and combine the results from each range into a final result.
- Process the input data in sections (tiles), and merge the individual results into one dataset.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The input surface raster. | Raster Layer; Raster Dataset; Mosaic Layer; Mosaic Dataset |
| Output Contour Features | The output contour features. | Feature Class |
| Input Barrier Features(Optional) | The input barrier features.The features can be polyline or polygon type. | Feature Layer |
| Type of Contours(Optional) | The type of contour to create.Polylines— The contour or isoline representation of the input raster.Polygons— Closed polygons representing the contours.Note:The current version of this tool only supports polyline output. If the polygon output option is used, it will be ignored and polyline output will be created. | String |
| File Containing Contour Value Specifications(Optional) | The base contour, contour interval, indexed contour interval, and explicit contour values can also be specified via a text file. | File |
| Enter Explicit Contour Values Only(Optional) | Only explicit contour values are used. Base contour, contour interval, and indexed contour intervals are not specified.Unchecked—The default, contour interval must be specified.Checked—Only explicit contour values are specified. | Boolean |
| Base Contour(Optional) | The base contour value.Contours are generated above and below this value as needed to cover the entire value range of the input raster. The default is zero. | Double |
| Contour Interval(Optional) | The interval, or distance, between contour lines.This can be any positive number. | Double |
| Indexed Contour Interval(Optional) | Contours will also be generated for this interval and will be flagged accordingly in the output feature class. | Double |
| Explicit Contour Values(Optional) | Explicit values at which to create contours. | Double |
| Factor Applied to Raster Z-values(Optional) | The unit conversion factor used when generating contours. The default value is 1.The contour lines are generated based on the z-values in the input raster, which are often measured in units of meters or feet. With the default value of 1, the contours will be in the same units as the z-values of the input raster. To create contours in a unit other than that of the z-values, set an appropriate value for the z-factor. It is not necessary to have the ground x,y and surface z-units be consistent for this tool.For example, if the elevation values in the input raster are in feet, but you want the contours to be generated based on units of meters, set the z-factor to 0.3048 (1 foot = 0.3048 meter). | Double |
| in_raster | The input surface raster. | Raster Layer; Raster Dataset; Mosaic Layer; Mosaic Dataset |
| out_contour_feature_class | The output contour features. | Feature Class |
| in_barrier_features(Optional) | The input barrier features.The features can be polyline or polygon type. | Feature Layer |
| in_contour_type(Optional) | The type of contour to create.POLYLINES— The contour or isoline representation of the input raster.POLYGONS— Closed polygons representing the contours. Note:The current version of this tool only supports polyline output. If the polygon output option is used, it will be ignored and polyline output will be created. | String |
| in_contour_values_file(Optional) | The base contour, contour interval, indexed contour interval, and explicit contour values can also be specified via a text file. | File |
| explicit_only(Optional) | Only explicit contour values are used. Base contour, contour interval, and indexed contour intervals are not specified.NO_EXPLICIT_VALUES_ONLY— The default, contour interval must be specified.EXPLICIT_VALUES_ONLY— Only explicit contour values are specified. | Boolean |
| in_base_contour(Optional) | The base contour value.Contours are generated above and below this value as needed to cover the entire value range of the input raster. The default is zero. | Double |
| in_contour_interval(Optional) | The interval, or distance, between contour lines.This can be any positive number. | Double |
| in_indexed_contour_interval(Optional) | Contours will also be generated for this interval and will be flagged accordingly in the output feature class. | Double |
| in_contour_list[in_explicit_contour,...](Optional) | Explicit values at which to create contours. | Double |
| in_z_factor(Optional) | The unit conversion factor used when generating contours. The default value is 1.The contour lines are generated based on the z-values in the input raster, which are often measured in units of meters or feet. With the default value of 1, the contours will be in the same units as the z-values of the input raster. To create contours in a unit other than that of the z-values, set an appropriate value for the z-factor. It is not necessary to have the ground x,y and surface z-units be consistent for this tool.For example, if the elevation values in the input raster are in feet, but you want the contours to be generated based on units of meters, set the z-factor to 0.3048 (1 foot = 0.3048 meter). | Double |

## Code Samples

### Example 1

```python
1 for contours
    2 for indexed contours
    3 for explicit contours
```

### Example 2

```python
# contour values and ranges
    122.75
    485 500 5 12
    4 100 99
```

### Example 3

```python
122.75
    104, 204, 304, 404
    103, 202, 301, 400, 499
    485, 490, 495, 500
    497
```

### Example 4

```python
ContourWithBarriers(in_raster, out_contour_feature_class, {in_barrier_features}, {in_contour_type}, {in_contour_values_file}, {explicit_only}, {in_base_contour}, {in_contour_interval}, {in_indexed_contour_interval}, {in_contour_list}, {in_z_factor})
```

### Example 5

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
ContourWithBarriers("elevation", "C:/sapyexamples/output/outcontourwithbarriers.shp", "elevation_barrier.shp", "POLYLINES",
                    "", "", 0, 300)
```

### Example 6

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
ContourWithBarriers("elevation", "C:/sapyexamples/output/outcontourwithbarriers.shp", "elevation_barrier.shp", "POLYLINES",
                    "", "", 0, 300)
```

### Example 7

```python
# Name: ContourWithBarriers_Ex_02.py
# Description: Creates contours from a raster surface.
#           The inclusion of barrier features will allow one to independently generate contours on either side of a barrier.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inBarrier = "elevation_barrier.shp"
inTextFile = ""
explicitValues = "NO_EXPLICIT_VALUES_ONLY"
contourInterval = 200
contourList = [600, 935, 1237.4]
baseContour = 0
outContours = "C:/sapyexamples/output/outcontourwithbarriers02.shp"

# Execute Contour
ContourWithBarriers(inRaster, outContours, inBarrier, "POLYLINES", inTextFile, 
                    explicitValues, baseContour, contourInterval, "", 
                    contourList, "")
```

### Example 8

```python
# Name: ContourWithBarriers_Ex_02.py
# Description: Creates contours from a raster surface.
#           The inclusion of barrier features will allow one to independently generate contours on either side of a barrier.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inBarrier = "elevation_barrier.shp"
inTextFile = ""
explicitValues = "NO_EXPLICIT_VALUES_ONLY"
contourInterval = 200
contourList = [600, 935, 1237.4]
baseContour = 0
outContours = "C:/sapyexamples/output/outcontourwithbarriers02.shp"

# Execute Contour
ContourWithBarriers(inRaster, outContours, inBarrier, "POLYLINES", inTextFile, 
                    explicitValues, baseContour, contourInterval, "", 
                    contourList, "")
```

---

## Contour (Spatial Analyst)

## Summary

Creates a feature class of contours from a raster surface.

## Usage

- Contours do not extend beyond the spatial extent of the raster, and they are not generated in areas of NoData. Edgematch adjacent contour inputs into a continuous feature dataset first. As an alternative to edgematching, you can merge the adjacent rasters before computing contours.However, the contour polygons are extrapolated to the outer edge of the raster when Contour type is not equal to Contour.
- Contours can be generated in areas of negative raster values. The contour values will be negative in those areas. Negative contour intervals are not allowed.
- Smoother but less accurate contours can be obtained by preprocessing the input raster using the Focal Statistics tool with the Mean option or the Filter tool with the Low option.
- A base contour is used, for example, to create contours every 15 meters, starting at 10 meters. In this case, 10 is used for the base contour and 15 is the contour interval. The values to be contoured are 10, 25, 40, 55, and so on.
- Specifying a base contour does not prevent contours from being created above or below that value.
- Contour type is used to produce either contour lines or polygons. For example, if you have a raster with values between 0 and 575 and your contour interval is 250, the following are the various output feature classes that will be created. The actual output is presented, as well as the individual component polygons separately.CONTOUR—Lines at 250 and 500CONTOUR_POLYGON—Nonoverlapping polygons between 0-250, 250-500, and 500-575 (Fig. 1) Figure 1. The Contour polygon option creates three nonoverlapping polygons between 0-250, 250-500, and 500-575.CONTOUR_SHELL—Overlapping polygons between 0-575, 0-500, and 0-250 (Fig. 2) Figure 2. The Contour shell option creates three overlapping polygons between 0-575, 0-500, and 0-250.CONTOUR_SHELL_UP—Overlapping polygons between 0-575, 250-575, and 500-575 (Fig. 3) Figure 3. The Contour shell up option creates three overlapping polygons between 0-575, 250-575, and 500-575.
- CONTOUR—Lines at 250 and 500
- CONTOUR_POLYGON—Nonoverlapping polygons between 0-250, 250-500, and 500-575 (Fig. 1) Figure 1. The Contour polygon option creates three nonoverlapping polygons between 0-250, 250-500, and 500-575.
- CONTOUR_SHELL—Overlapping polygons between 0-575, 0-500, and 0-250 (Fig. 2) Figure 2. The Contour shell option creates three overlapping polygons between 0-575, 0-500, and 0-250.
- CONTOUR_SHELL_UP—Overlapping polygons between 0-575, 250-575, and 500-575 (Fig. 3) Figure 3. The Contour shell up option creates three overlapping polygons between 0-575, 250-575, and 500-575.
- The Maximum vertices per feature parameter can be used to subdivide a feature. This should only be used when output features would contain a very large number of vertices (many millions). This parameter produces similar output to that created by the Dice tool.This parameter is intended as a way to subdivide extremely large features that can cause issues later on, for example, when storing, analyzing, or drawing the features.Choosing a limit is dependent on the available memory on the machine where the tool is being run and the size of the feature (larger features require more memory). Most modern machines running 64-bit software do not typically have issues with individual features containing hundreds of thousands or millions of vertices. If you do encounter any problems, setting this parameter to a large value, such as 1 million, may alleviate issues due to the size of a feature.The vertex limit parameter can be used to subdivide a feature. This should only be used when output features would contain a very large number of vertices (many millions).
- By default, this tool will use multicore processors if available. The maximum number of cores that can be used is four.To use fewer cores, use the Parallel Processing Factor environment setting.
- If the Extent environment is specified and the lower left corner of the output extent does not match any cell corner of the input raster, a shift of the cell alignment of the input raster will occur during processing to match the specified extent. This shift will trigger a resampling of the input raster using the Bilinear method. Consequently, the output features will shift as well, and the resultant output features may not overlay the original input raster exactly. You can avoid this shift by using the input raster for the Snap Raster environment.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input surface raster. | Raster Layer |
| Output feature class | The output contour features. | Feature Class |
| Contour interval | The interval, or distance, between contour lines.This can be any positive number. | Double |
| Base contour(Optional) | The base contour value.Contours are generated above and below this value as needed to cover the entire value range of the input raster. The default is zero. | Double |
| Z factor(Optional) | The unit conversion factor used when generating contours. The default value is 1.The contour lines are generated based on the z-values in the input raster, which are often measured in units of meters or feet. With the default value of 1, the contours will be in the same units as the z-values of the input raster. To create contours in a unit other than that of the z-values, set an appropriate value for the z-factor. It is not necessary to have the ground x,y and surface z-units be consistent for this tool.For example, if the elevation values in the input raster are in feet, but you want the contours to be generated based on units of meters, set the z-factor to 0.3048 (1 foot = 0.3048 meter). For another example, an input raster is in WGS84 geographic coordinates and elevation units of meters, and you want to generate contour lines every 100 feet with a base of 50 feet (so the contours will be 50 ft, 150 ft, 250 ft, and so on). To do this, set Contour interval to 100, Base contour to 50, and Z factor to 3.2808 (1 meter = 3.2808 feet). | Double |
| Contour type(Optional) | Specifies the type of output. The output can represent the contours as either lines or polygons. There are several options for polygons.Contour—A polyline feature class of contours (isolines). This is the default.Contour polygon—A polygon feature class of filled contours.Contour shell—A polygon feature class in which the upper bound of the polygon increases cumulatively by the interval value. The lower bound remains constant at the raster minimum.Contour shell up—A polygon feature class in which the lower bound of the polygon increases cumulatively, from the raster minimum, by the interval value. The upper bound remains constant at the raster maximum. | String |
| Maximum vertices per feature(Optional) | The vertex limit when subdividing a feature. This should only be used when output features contain a very large number of vertices (many millions). This parameter is intended as a way to subdivide extremely large features that can cause issues later on, for example, when storing, analyzing, or drawing the features.If left empty, the output features will not be split. The default is empty. | Long |
| in_raster | The input surface raster. | Raster Layer |
| out_polyline_features | The output contour features. | Feature Class |
| contour_interval | The interval, or distance, between contour lines.This can be any positive number. | Double |
| base_contour(Optional) | The base contour value.Contours are generated above and below this value as needed to cover the entire value range of the input raster. The default is zero. | Double |
| z_factor(Optional) | The unit conversion factor used when generating contours. The default value is 1.The contour lines are generated based on the z-values in the input raster, which are often measured in units of meters or feet. With the default value of 1, the contours will be in the same units as the z-values of the input raster. To create contours in a unit other than that of the z-values, set an appropriate value for the z-factor. It is not necessary to have the ground x,y and surface z-units be consistent for this tool.For example, if the elevation values in the input raster are in feet, but you want the contours to be generated based on units of meters, set the z-factor to 0.3048 (1 foot = 0.3048 meter). For another example, an input raster is in WGS84 geographic coordinates and elevation units of meters, and you want to generate contour lines every 100 feet with a base of 50 feet (so the contours will be 50 ft, 150 ft, 250 ft, and so on). To do this, set contour_interval to 100, base_contour to 50, and z_factor to 3.2808 (1 meter = 3.2808 feet). | Double |
| contour_type(Optional) | Specifies the type of output. The output can represent the contours as either lines or polygons. There are several options for polygons. CONTOUR—A polyline feature class of contours (isolines). This is the default.CONTOUR_POLYGON—A polygon feature class of filled contours.CONTOUR_SHELL—A polygon feature class in which the upper bound of the polygon increases cumulatively by the interval value. The lower bound remains constant at the raster minimum.CONTOUR_SHELL_UP—A polygon feature class in which the lower bound of the polygon increases cumulatively, from the raster minimum, by the interval value. The upper bound remains constant at the raster maximum. | String |
| max_vertices_per_feature(Optional) | The vertex limit when subdividing a feature. This should only be used when output features contain a very large number of vertices (many millions). This parameter is intended as a way to subdivide extremely large features that can cause issues later on, for example, when storing, analyzing, or drawing the features.If left empty, the output features will not be split. The default is empty. | Long |

## Code Samples

### Example 1

```python
Contour(in_raster, out_polyline_features, contour_interval, {base_contour}, {z_factor}, {contour_type}, {max_vertices_per_feature})
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
Contour("elevation", "C:/sapyexamples/output/outcontours.shp", 200, 0)
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
Contour("elevation", "C:/sapyexamples/output/outcontours.shp", 200, 0)
```

### Example 4

```python
# Name: Contour_Ex_02.py
# Description: Creates contours or isolines from a raster surface.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
contourInterval = 200
baseContour = 0
outContours = "C:/sapyexamples/output/outcontours02.shp"

# Execute Contour
Contour(inRaster, outContours, contourInterval, baseContour)
```

### Example 5

```python
# Name: Contour_Ex_02.py
# Description: Creates contours or isolines from a raster surface.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
contourInterval = 200
baseContour = 0
outContours = "C:/sapyexamples/output/outcontours02.shp"

# Execute Contour
Contour(inRaster, outContours, contourInterval, baseContour)
```

---

## Converting inputs from degrees to radians for Trigonometric tools

## Code Samples

### Example 1

```python
>>> import math
>>> from arcpy.sa import *
>>> OutRas = Cos (InRas * math.pi / 180.0)
```

### Example 2

```python
>>> import math
>>> from arcpy.sa import *
>>> OutRas = Cos (InRas * math.pi / 180.0)
```

### Example 3

```python
>>> import math
>>> deg2rad = math.pi / 180.0
>>> from arcpy.sa import *
>>> OutRas = Cos (InRas * deg2rad)
```

### Example 4

```python
>>> import math
>>> deg2rad = math.pi / 180.0
>>> from arcpy.sa import *
>>> OutRas = Cos (InRas * deg2rad)
```

---

## Converting output in radians to degrees for trigonometric tools

## Code Samples

### Example 1

```python
>>> import math
>>> from arcpy.sa import *
>>> OutRas = ACos (InRas) * 180.0 / math.pi
```

### Example 2

```python
>>> import math
>>> from arcpy.sa import *
>>> OutRas = ACos (InRas) * 180.0 / math.pi
```

### Example 3

```python
>>> import math
>>> rad2deg = 180.0 / math.pi
>>> from arcpy.sa import *
>>> OutRas = ACos (InRas) * rad2deg
```

### Example 4

```python
>>> import math
>>> rad2deg = 180.0 / math.pi
>>> from arcpy.sa import *
>>> OutRas = ACos (InRas) * rad2deg
```

---

## Corridor (Spatial Analyst)

## Summary

Calculates the sum of accumulative costs for two input accumulative cost rasters.

## Usage

- While any two rasters can be used for the input, to obtain a meaningful result they should be unaltered accumulative cost output rasters.
- The order of the two inputs is irrelevant.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input cost distance raster 1 | The first input distance raster.It should be an accumulated cost distance output from a distance tool such as Cost Distance or Path Distance. | Raster Layer |
| Input cost distance raster 2 | The second input distance raster.It should be an accumulated cost distance output from a distance tool such as Cost Distance or Path Distance. | Raster Layer |
| in_distance_raster1 | The first input distance raster.It should be an accumulated cost distance output from a distance tool such as Cost Distance or Path Distance. | Raster Layer |
| in_distance_raster2 | The second input distance raster.It should be an accumulated cost distance output from a distance tool such as Cost Distance or Path Distance. | Raster Layer |

## Code Samples

### Example 1

```python
Corridor(in_distance_raster1, in_distance_raster2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCorr = Corridor("costraster", "focalcost.tif")
outCorr.save("c:/sapyexamples/output/corridor")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCorr = Corridor("costraster", "focalcost.tif")
outCorr.save("c:/sapyexamples/output/corridor")
```

### Example 4

```python
# Name: Corridor_Ex_02.py
# Description: Calculate a potential wildlife corridor between 
#              two known protected areas.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inCostRaster = "costdist01"
nextCostRaster = "cotdist02"

# Execute Corridor
outCorridor = Corridor(inCostRaster, nextCostRaster) 

#Limit the corridor to a threshold to show a potential corridor
corridor = Con(outCorridor, 1, 0, "VALUE < 100")

# Save the output 
outCorridor.save("C:/sapyexamples/output/costout")
```

### Example 5

```python
# Name: Corridor_Ex_02.py
# Description: Calculate a potential wildlife corridor between 
#              two known protected areas.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inCostRaster = "costdist01"
nextCostRaster = "cotdist02"

# Execute Corridor
outCorridor = Corridor(inCostRaster, nextCostRaster) 

#Limit the corridor to a threshold to show a potential corridor
corridor = Con(outCorridor, 1, 0, "VALUE < 100")

# Save the output 
outCorridor.save("C:/sapyexamples/output/costout")
```

---

## Cos (Spatial Analyst)

## Summary

Calculates the cosine of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -∞ < [in_value] < ∞ The Range is: -1 ≤ [out_value] ≤ 1 Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: -∞ < [in_value] < ∞
- The Range is: -1 ≤ [out_value] ≤ 1
- The input values for this tool are interpreted to be in radians. If the input you want to use is in degrees, the values must first be divided by the radians-to-degrees conversion factor of 180/pi, or approximately 57.296.For further assistance, a procedure to follow and examples of converting input values in degrees to radians are available.
- The output values from this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- Due to the range of values, applying a linear stretch renderer can be useful to better see the results.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the cosine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the cosine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Cos(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCos = Cos("degs")
outCos.save("C:/sapyexamples/output/outcos")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCos = Cos("degs")
outCos.save("C:/sapyexamples/output/outcos")
```

### Example 4

```python
# Name: Cos_Ex_02.py
# Description: Calculates the cosine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Cos
outCos = Cos(inRaster)

# Save the output 
outCos.save("C:/sapyexamples/output/outcos.tif")
```

### Example 5

```python
# Name: Cos_Ex_02.py
# Description: Calculates the cosine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Cos
outCos = Cos(inRaster)

# Save the output 
outCos.save("C:/sapyexamples/output/outcos.tif")
```

---

## CosH (Spatial Analyst)

## Summary

Calculates the hyperbolic cosine of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -∞ < [in_value] < ∞ The Range is: 1 ≤ [out_value] < ∞ Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: -∞ < [in_value] < ∞
- The Range is: 1 ≤ [out_value] < ∞
- The input and output values for this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the hyperbolic cosine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the hyperbolic cosine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
CosH(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCosH = CosH("degs")
outCosH.save("C:/sapyexamples/output/outcosh")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCosH = CosH("degs")
outCosH.save("C:/sapyexamples/output/outcosh")
```

### Example 4

```python
# Name: CosH_Ex_02.py
# Description: Calculates the hyperbolic cosine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute CosH
outCosH = CosH(inRaster)

# Save the output 
outCosH.save("C:/sapyexamples/output/outcosh.img")
```

### Example 5

```python
# Name: CosH_Ex_02.py
# Description: Calculates the hyperbolic cosine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute CosH
outCosH = CosH(inRaster)

# Save the output 
outCosH.save("C:/sapyexamples/output/outcosh.img")
```

---

## Cost Allocation (Spatial Analyst)

## Summary

Calculates, for each cell, its least-cost source based on the least accumulative cost over a cost surface.

## Usage

- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted internally to a raster before performing the analysis. The resolution of the raster can be controlled with the Cell Size environment. By default, the resolution will be set to the resolution of the input cost raster.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- To calculate allocation, source locations can have an associated value, which can be specified by the Source Field parameter. If the input source is an integer raster, the default field is VALUE. If it is a feature, it will be the first integer field in the attribute table. If the input source data is a floating-point raster, an integer value raster parameter must be specified.
- When the source input is a feature, the first valid available field will be used by default. If no valid fields exist, the ObjectID field (for example, OID or FID, depending on the type of feature input) will be used.
- Cell locations with NoData in the Input Cost Raster parameter value act as barriers in the cost surface tools. Any cell location that is assigned NoData on the input cost surface will receive NoData on all output rasters (cost distance, allocation, and backlink).
- The Input value raster is useful when alternative values or zones are to be used or if source was derived from an operation that results in a binary result of either 0 or 1, losing the original zone values that are associated with these locations. The value raster can restore these values or allow for analysis on additional combinations of zone values within the source locations.If the value raster is used, it may change the configuration and results of the cost allocation output; it will not affect the optional cost distance or the back link results.
- The Maximum Distance parameter value is specified in the same cost units as those on the cost raster.
- For the output distance raster, the least-cost distance (or minimum accumulative cost distance) of a cell from or to a set of source locations is the lower bound of the least-cost distances from the cell to all source locations.
- The characteristics of the source, or the movers from or to a source, can be controlled by specific parameters. The Source cost multiplier parameter specifies the mode of travel or magnitude at the source, Source start cost sets the starting cost before the movement begins, Source resistance rate is a dynamic adjustment accounting for the impact of accumulated cost, for example, simulating how much a hiker is getting fatigued, and Source capacity sets how much cost a source can assimilate before reaching its limit. Travel direction identifies whether the mover is starting at a source and moving to nonsource locations or starting at nonsource locations and moving back to a source.
- If any of the source characteristic parameters are specified using a field, the source characteristic will be applied on a source-by-source basis, according to the information in the specified field for the source data. When a keyword or a constant value is provided, it will be applied to all sources.
- If the Source start cost parameter value is specified and Travel direction is set to Travel from source, the source locations on the output cost distance surface will be set to the Source start cost value; otherwise, the source locations on the output cost distance surface will be set to zero.
- The default processing extent for this tool is the extent of the Input Cost Raster parameter value.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature source data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point.If the input source raster is floating point, the Input value raster parameter must be set, and it must be integer. The value raster will take precedence over the Source field parameter setting. | Raster Layer; Feature Layer |
| Input cost raster | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| Maximum distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| Input value raster(Optional) | The input integer raster that identifies the zone values that will be used for each input source location.For each source location (cell or feature), this value will be assigned to all cells allocated to the source location for the computation. The value raster will take precedence over the Source field parameter setting. | Raster Layer |
| Source field(Optional) | The field used to assign values to the source locations. It must be of integer type.If the Input value raster parameter has been set, the values in that input will have precedence over this parameter setting. | Field |
| Output distance raster(Optional) | The output cost distance raster.The cost distance raster identifies, for each cell, the least accumulative cost distance over a cost surface to the identified source locations.A source can be a cell, a set of cells, or one or more feature locations.The output raster is of floating-point type. | Raster Dataset |
| Output backlink raster(Optional) | The output cost backlink raster.The backlink raster contains values 0 through 8, which define the direction or identify the next neighboring cell (the succeeding cell) along the least accumulative cost path from a cell to reach its least-cost source.If the path is to pass into the right neighbor, the cell will be assigned the value 1, 2 for the lower right diagonal cell, and continue clockwise. The value 0 is reserved for source cells. | Raster Dataset |
| Multiplier to apply to costs(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| Start cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| Accumulative cost resistance rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| Capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| Travel direction(Optional) | Specifies the direction of the traveler when applying the source resistance rate and the source starting cost.If you select the String option, you can choose between from and to options, which will be applied to all sources.If you select the Field option, you can select the field from the source data that determines the direction to use for each source. The field must contain the text string FROM_SOURCE or TO_SOURCE.Travel from source—The source resistance rate and source starting cost will be applied beginning at the input source and travel out to the nonsource cells. This is the default.Travel to source—The source resistance rate and source starting cost will be applied beginning at each nonsource cell and travel back to the input source. | String; Field |
| in_source_data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point.If the input source raster is floating point, the in_value_raster parameter must be set, and it must integer. The value raster will take precedence over the source_field parameter setting. | Raster Layer; Feature Layer |
| in_cost_raster | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| maximum_distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| in_value_raster(Optional) | The input integer raster that identifies the zone values that will be used for each input source location.For each source location (cell or feature), this value will be assigned to all cells allocated to the source location for the computation. The value raster will take precedence over the source_field parameter setting. | Raster Layer |
| source_field(Optional) | The field used to assign values to the source locations. It must be of integer type.If the in_value_raster parameter has been set, the values in that input will have precedence over this parameter setting. | Field |
| out_distance_raster(Optional) | The output cost distance raster.The cost distance raster identifies, for each cell, the least accumulative cost distance over a cost surface to the identified source locations.A source can be a cell, a set of cells, or one or more feature locations.The output raster is of floating-point type. | Raster Dataset |
| out_backlink_raster(Optional) | The output cost backlink raster.The backlink raster contains values 0 through 8, which define the direction or identify the next neighboring cell (the succeeding cell) along the least accumulative cost path from a cell to reach its least-cost source.If the path is to pass into the right neighbor, the cell will be assigned the value 1, 2 for the lower right diagonal cell, and continue clockwise. The value 0 is reserved for source cells. | Raster Dataset |
| source_cost_multiplier(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| source_start_cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| source_resistance_rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| source_capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| source_direction(Optional) | Specifies the direction of the traveler when applying the source resistance rate and the source starting cost.FROM_SOURCE—The source resistance rate and source starting cost will be applied beginning at the input source and travel out to the nonsource cells. This is the default.TO_SOURCE—The source resistance rate and source starting cost will be applied beginning at each nonsource cell and travel back to the input source. Specify the FROM_SOURCE or TO_SOURCE keyword, which will be applied to all sources, or specify a field in the source data that contains the keywords to identify the direction of travel for each source. That field must contain the string FROM_SOURCE or TO_SOURCE. | String; Field |

## Code Samples

### Example 1

```python
CostAllocation(in_source_data, in_cost_raster, {maximum_distance}, {in_value_raster}, {source_field}, {out_distance_raster}, {out_backlink_raster}, {source_cost_multiplier}, {source_start_cost}, {source_resistance_rate}, {source_capacity}, {source_direction})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
out = ()
costAllocOut = CostAllocation("observers.shp", "costraster", "", "elevation",
                               "FID", "c:/sapyexamples/output/distout", 
                               "c:/sapyexamples/output/backlinkout", "Multiplier", "StartCost", "Resistance", 500000)
costAllocOut.save("c:/sapyexamples/output/costalloc")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
out = ()
costAllocOut = CostAllocation("observers.shp", "costraster", "", "elevation",
                               "FID", "c:/sapyexamples/output/distout", 
                               "c:/sapyexamples/output/backlinkout", "Multiplier", "StartCost", "Resistance", 500000)
costAllocOut.save("c:/sapyexamples/output/costalloc")
```

### Example 4

```python
# Name: CostAllocation_Ex_02.py
# Description: Calculates for each cell its nearest source 
#              based on the least accumulative cost over a 
#              cost surface.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFeature = "observers.shp"
costRaster = "costraster"
maxDist = 25000
valRaster = "elevation"
featField = "FID"
outDistanceRaster = "c:/sapyexamples/output/distout"
outBacklink = "c:/sapyexamples/output/backlinkout"

# Execute CostAllocation
costAllocOut = CostAllocation(inFeature, costRaster, maxDist,
                              valRaster, featField, outDistanceRaster,
                              outBacklink)

# Save the output 
costAllocOut.save("c:/sapyexamples/output/costalloc01")
```

### Example 5

```python
# Name: CostAllocation_Ex_02.py
# Description: Calculates for each cell its nearest source 
#              based on the least accumulative cost over a 
#              cost surface.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFeature = "observers.shp"
costRaster = "costraster"
maxDist = 25000
valRaster = "elevation"
featField = "FID"
outDistanceRaster = "c:/sapyexamples/output/distout"
outBacklink = "c:/sapyexamples/output/backlinkout"

# Execute CostAllocation
costAllocOut = CostAllocation(inFeature, costRaster, maxDist,
                              valRaster, featField, outDistanceRaster,
                              outBacklink)

# Save the output 
costAllocOut.save("c:/sapyexamples/output/costalloc01")
```

---

## Cost Back Link (Spatial Analyst)

## Summary

Defines the neighbor that is the next cell on the least accumulative cost path to the least-cost source.

## Usage

- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted internally to a raster before performing the analysis. The resolution of the raster can be controlled with the Cell Size environment. By default, the resolution will be set to the resolution of the input cost raster.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- Cell locations with NoData in the Input Cost Raster parameter value act as barriers in the cost surface tools. Any cell location that is assigned NoData on the input cost surface will receive NoData on all output rasters (cost distance, allocation, and backlink).
- The Maximum Distance parameter value is specified in the same cost units as those on the cost raster.
- For the output distance raster, the least-cost distance (or minimum accumulative cost distance) of a cell from or to a set of source locations is the lower bound of the least-cost distances from the cell to all source locations.
- The characteristics of the source, or the movers from or to a source, can be controlled by specific parameters. The Source cost multiplier parameter specifies the mode of travel or magnitude at the source, Source start cost sets the starting cost before the movement begins, Source resistance rate is a dynamic adjustment accounting for the impact of accumulated cost, for example, simulating how much a hiker is getting fatigued, and Source capacity sets how much cost a source can assimilate before reaching its limit. Travel direction identifies whether the mover is starting at a source and moving to nonsource locations or starting at nonsource locations and moving back to a source.
- If any of the source characteristic parameters are specified using a field, the source characteristic will be applied on a source-by-source basis, according to the information in the specified field for the source data. When a keyword or a constant value is provided, it will be applied to all sources.
- If the Source start cost parameter value is specified and Travel direction is set to Travel from source, the source locations on the output cost distance surface will be set to the Source start cost value; otherwise, the source locations on the output cost distance surface will be set to zero.
- The default processing extent for this tool is the extent of the Input Cost Raster parameter value.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature source data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| Input cost raster | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| Maximum distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| Output distance raster(Optional) | The output cost distance raster.The cost distance raster identifies, for each cell, the least accumulative cost distance over a cost surface to the identified source locations.A source can be a cell, a set of cells, or one or more feature locations.The output raster is of floating-point type. | Raster Dataset |
| Multiplier to apply to costs(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| Start cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| Accumulative cost resistance rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| Capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| Travel direction(Optional) | Specifies the direction of the traveler when applying the source resistance rate and the source starting cost.If you select the String option, you can choose between from and to options, which will be applied to all sources.If you select the Field option, you can select the field from the source data that determines the direction to use for each source. The field must contain the text string FROM_SOURCE or TO_SOURCE.Travel from source—The source resistance rate and source starting cost will be applied beginning at the input source and travel out to the nonsource cells. This is the default.Travel to source—The source resistance rate and source starting cost will be applied beginning at each nonsource cell and travel back to the input source. | String; Field |
| in_source_data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| in_cost_raster | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| maximum_distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| out_distance_raster(Optional) | The output cost distance raster.The cost distance raster identifies, for each cell, the least accumulative cost distance over a cost surface to the identified source locations.A source can be a cell, a set of cells, or one or more feature locations.The output raster is of floating-point type. | Raster Dataset |
| source_cost_multiplier(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| source_start_cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| source_resistance_rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| source_capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| source_direction(Optional) | Specifies the direction of the traveler when applying the source resistance rate and the source starting cost.FROM_SOURCE—The source resistance rate and source starting cost will be applied beginning at the input source and travel out to the nonsource cells. This is the default.TO_SOURCE—The source resistance rate and source starting cost will be applied beginning at each nonsource cell and travel back to the input source. Specify the FROM_SOURCE or TO_SOURCE keyword, which will be applied to all sources, or specify a field in the source data that contains the keywords to identify the direction of travel for each source. That field must contain the string FROM_SOURCE or TO_SOURCE. | String; Field |

## Code Samples

### Example 1

```python
CostBackLink(in_source_data, in_cost_raster, {maximum_distance}, {out_distance_raster}, {source_cost_multiplier}, {source_start_cost}, {source_resistance_rate}, {source_capacity}, {source_direction})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBacklink = CostBackLink("observers","costraster", "", 
                           "c:/sapyexamples/output/distRast", "Multiplier", "StartCost", "Resistance", 500000)
outBacklink.save("c:/sapyexamples/output/backlink")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outBacklink = CostBackLink("observers","costraster", "", 
                           "c:/sapyexamples/output/distRast", "Multiplier", "StartCost", "Resistance", 500000)
outBacklink.save("c:/sapyexamples/output/backlink")
```

### Example 4

```python
# Name: CostBackLink_Ex_02.py
# Description: Defines the neighbor that is the next cell on 
#              the least accumulative cost path to the nearest 
#              source.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
inCostRaster = "costraster"
inMaxDist = 100000
outDistRast = "c:/sapyexamples/output/distRast"

# Execute CostBackLink
outBacklink = CostBackLink(inSource,inCostRaster, inMaxDist,
                           outDistRast)

# Save the output 
outBacklink.save("c:/sapyexamples/output/backlink.tif")
```

### Example 5

```python
# Name: CostBackLink_Ex_02.py
# Description: Defines the neighbor that is the next cell on 
#              the least accumulative cost path to the nearest 
#              source.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
inCostRaster = "costraster"
inMaxDist = 100000
outDistRast = "c:/sapyexamples/output/distRast"

# Execute CostBackLink
outBacklink = CostBackLink(inSource,inCostRaster, inMaxDist,
                           outDistRast)

# Save the output 
outBacklink.save("c:/sapyexamples/output/backlink.tif")
```

---

## Cost Connectivity (Spatial Analyst)

## Summary

Produces the least-cost connectivity network between two or more input regions.

## Usage

- The input regions can be either raster or feature data.
- In a raster, a region is a group of cells with the same value that are contiguous to one another (adjacent). When your input regions are identified by a raster, if any zones (cells with the same value) are composed of multiple regions, first run the Region Group tool as a preprocessing step to assign unique values to each region. Use the resulting raster as the input regions to the Cost Connectivity tool.
- When input regions are identified by polygon, line, or point data, they are converted to raster using the feature ID to ensure the resulting regions have unique values. Therefore, multipart polygons cannot be input. When multipoint data is entered, Cost Connectivity randomly selects one of the points at the location as the region value.You can control the resolution of the rasterized input feature regions with the Cell Size environment. By default, the resolution will be set to the resolution of the input cost raster.
- When using polygon feature data for the input region data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process employs the same default Cell assignment type method as the Polygon to Raster tool, which is Cell center. This means that data not located at the center of the cell will not be included in the intermediate rasterized region and so will not be represented in the distance calculations. For example, if your regions are a series of small polygons, such as building footprints that are small relative to the output cell size, it is possible that only a few of them will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you could rasterize the input features directly with the Polygon to Raster tool, set a Priority field, and use the resulting output as input to the Cost Connectivity tool. Alternatively, you could select a small enough cell size to capture the appropriate amount of detail from the input features.
- When the region input is a feature, the ObjectID field (for example, OID or FID, depending on the type of the feature input) will be used as the region identifier.
- If the input regions are raster and the range of the row IDs is very large (even if there are only a few regions), the performance of the tool may be negatively impacted.
- Cell locations with NoData in the Input cost raster act as barriers.
- The default processing extent is the same as that of the Input cost raster.
- The cost raster cannot contain values of zero since the algorithm is a multiplicative process. If your cost raster does contain values of zero, and these values represent areas of lowest cost, change values of zero to a small positive value (such as 0.01) before running Cost Connectivity, by first running the Con tool. If areas with a value of zero represent areas that should be excluded from the analysis, these values should be turned to NoData before running Cost Connectivity, by first running the Set Null tool.
- For Output feature class of neighboring connections, the neighbors are not identified by Euclidean distance but instead are identified by cost distance. Therefore, a region's closest neighbor is the cheapest one to travel to, not the one that is closest in distance. A cost allocation operation is performed to identify which regions are neighbors to one another.
- The optimum output network is created from the paths produced in the optional neighboring connections output. The paths in the optional neighboring connections output are converted to graph theory. The regions are the vertices, the paths are the edges, and the accumulative costs are the weights for the edges. The minimum spanning tree is calculated from the graph representation of the paths to determine the least-cost path network necessary to travel between the regions.
- Each least-cost path first reaches the outer boundary of the polygon or multicell region. From the perimeter of the region, the tool then continues the paths with additional line segments, allowing for points of entry and exit between regions, and movement within them. There is no additional cost of movement along these line segments.
- The Cost Distance and Cost Path tools can be used to connect regions that are not directly connected in the minimum spanning tree based on a priori information. For example, a particular region may need an alternative escape route for fire fighters to evacuate from the region. Since the resulting paths from Cost Path only reach the edge of a region, if you want to use these additional paths in the integrated network to perform subsequent network analysis, you will need to extend these paths within the region to connect them to the paths in the minimum spanning tree network.
- The optional neighboring connections output can be used as an alternative network to the minimum spanning tree network. This output connects each region to its neighboring cost regions, thus producing a more complex network with many paths. The feature class can be used as is, or as the base from which to create your own desired network. To do that, you can select the specific paths you want within the network using the Select By Attributes button or the Select group on the Map tab, or the Select geoprocessing tool. Deciding which paths to select can be based on knowledge of the area and the statistics associated with the paths in the resulting attribute table.
- The resulting network, either from the minimum spanning tree or the optional neighboring connections, can be converted to a Network Analyst network to perform additional network analysis.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature region data | The input regions that are to be connected by the least-cost network.Regions can be defined by either a raster or a feature dataset.If the region input is a raster, the regions are defined by groups of contiguous (adjacent) cells of the same value. Each region must be uniquely numbered. The cells that are not part of any region must be NoData. The raster type must be integer, and the values can be either positive or negative.If the region input is a feature dataset, it can be either polygons, lines, or points. Polygon feature regions cannot be composed of multipart polygons. | Raster Layer; Feature Layer |
| Input cost raster | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| Output feature class | The output polyline feature class of the optimum (least-cost) network of paths necessary to connect each of the input regions.Each path (or line) is uniquely numbered, and additional fields in the attribute table store specific information about the path. Those fields include the following:PATHID—Unique identifier for the pathPATHCOST—Total accumulative cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connectsThis information provides you insight into the paths within the network.Since each path is represented by a unique line, there will be multiple lines in locations where paths travel the same route. | Feature Class |
| Output feature class of neighboring connections(Optional) | The output polyline feature class identifying all paths from each region to each of its closest-cost neighbors.Each path (or line) is uniquely numbered, and additional fields in the attribute table store specific information about the path. Those fields include the following:PATHID—Unique identifier for the pathPATHCOST—Total accumulative cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connectsThis information provides you insight into the paths within the network and is particularly useful when deciding which paths should be removed if necessary.Since each path is represented by a unique line, there will be multiple lines in locations where paths travel the same route. | Feature Class |
| in_regions | The input regions that are to be connected by the least-cost network.Regions can be defined by either a raster or a feature dataset.If the region input is a raster, the regions are defined by groups of contiguous (adjacent) cells of the same value. Each region must be uniquely numbered. The cells that are not part of any region must be NoData. The raster type must be integer, and the values can be either positive or negative.If the region input is a feature dataset, it can be either polygons, lines, or points. Polygon feature regions cannot be composed of multipart polygons. | Raster Layer; Feature Layer |
| in_cost_raster | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| out_feature_class | The output polyline feature class of the optimum (least-cost) network of paths necessary to connect each of the input regions.Each path (or line) is uniquely numbered, and additional fields in the attribute table store specific information about the path. Those fields include the following:PATHID—Unique identifier for the pathPATHCOST—Total accumulative cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connectsThis information provides you insight into the paths within the network.Since each path is represented by a unique line, there will be multiple lines in locations where paths travel the same route. | Feature Class |
| out_neighbor_paths(Optional) | The output polyline feature class identifying all paths from each region to each of its closest-cost neighbors.Each path (or line) is uniquely numbered, and additional fields in the attribute table store specific information about the path. Those fields include the following:PATHID—Unique identifier for the pathPATHCOST—Total accumulative cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connectsThis information provides you insight into the paths within the network and is particularly useful when deciding which paths should be removed if necessary.Since each path is represented by a unique line, there will be multiple lines in locations where paths travel the same route. | Feature Class |

## Code Samples

### Example 1

```python
CostConnectivity(in_regions, in_cost_raster, out_feature_class, {out_neighbor_paths})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outOptRegConnect = OptimalRegionConnections("sources.shp", "cost_surface.tif")
outOptRegConnect.save("C:/sapyexamples/output/optregconnect.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outOptRegConnect = OptimalRegionConnections("sources.shp", "cost_surface.tif")
outOptRegConnect.save("C:/sapyexamples/output/optregconnect.tif")
```

### Example 4

```python
# Name: CostConnectivity_Ex_02.py
# Description: Calculates for least-cost connectivity network between regions.
#
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSourceData = "sources.shp"
inCostRaster = "cost_surface.tif"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute the tool
outOptRegConnect = OptimalRegionConnections(inSourceData, inCostRaster)

# Save the output 
outOptRegConnect.save("C:/sapyexamples/output/optregconnect.tif")
```

### Example 5

```python
# Name: CostConnectivity_Ex_02.py
# Description: Calculates for least-cost connectivity network between regions.
#
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSourceData = "sources.shp"
inCostRaster = "cost_surface.tif"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute the tool
outOptRegConnect = OptimalRegionConnections(inSourceData, inCostRaster)

# Save the output 
outOptRegConnect.save("C:/sapyexamples/output/optregconnect.tif")
```

---

## Cost Distance (Spatial Analyst)

## Summary

Calculates the least accumulative cost distance for each cell from or to the least-cost source over a cost surface.

## Usage

- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted internally to a raster before performing the analysis. The resolution of the raster can be controlled with the Cell Size environment. By default, the resolution will be set to the resolution of the input cost raster.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- When the source input is a feature, the first valid available field will be used by default. If no valid fields exist, the ObjectID field (for example, OID or FID, depending on the type of feature input) will be used.
- Cell locations with NoData in the Input Cost Raster parameter value act as barriers in the cost surface tools. Any cell location that is assigned NoData on the input cost surface will receive NoData on all output rasters (cost distance, allocation, and backlink).
- The Maximum Distance parameter value is specified in the same cost units as those on the cost raster.
- For the output distance raster, the least-cost distance (or minimum accumulative cost distance) of a cell from or to a set of source locations is the lower bound of the least-cost distances from the cell to all source locations.
- The cost raster cannot contain values of zero since the algorithm is a multiplicative process. If your cost raster does contain values of zero, and these values represent areas of lowest cost, change values of zero to a small positive value (such as 0.01) before running Cost Distance, by first running the Con tool. If areas with a value of zero represent areas that should be excluded from the analysis, these values should be turned to NoData before running Cost Distance, by first running the Set Null tool.
- The characteristics of the source, or the movers from or to a source, can be controlled by specific parameters. The Source cost multiplier parameter specifies the mode of travel or magnitude at the source, Source start cost sets the starting cost before the movement begins, Source resistance rate is a dynamic adjustment accounting for the impact of accumulated cost, for example, simulating how much a hiker is getting fatigued, and Source capacity sets how much cost a source can assimilate before reaching its limit. Travel direction identifies whether the mover is starting at a source and moving to nonsource locations or starting at nonsource locations and moving back to a source.
- If the Source start cost parameter value is specified and Travel direction is set to Travel from source, the source locations on the output cost distance surface will be set to the Source start cost value; otherwise, the source locations on the output cost distance surface will be set to zero.
- If any of the source characteristic parameters are specified using a field, the source characteristic will be applied on a source-by-source basis, according to the information in the specified field for the source data. When a keyword or a constant value is provided, it will be applied to all sources.
- The default processing extent for this tool is the extent of the Input Cost Raster parameter value.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature source data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| Input cost raster | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| Maximum distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| Output backlink raster(Optional) | The output cost backlink raster.The backlink raster contains values 0 through 8, which define the direction or identify the next neighboring cell (the succeeding cell) along the least accumulative cost path from a cell to reach its least-cost source.If the path is to pass into the right neighbor, the cell will be assigned the value 1, 2 for the lower right diagonal cell, and continue clockwise. The value 0 is reserved for source cells. | Raster Dataset |
| Multiplier to apply to costs(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| Start cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| Accumulative cost resistance rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| Capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| Travel direction(Optional) | Specifies the direction of the traveler when applying the source resistance rate and the source starting cost.If you select the String option, you can choose between from and to options, which will be applied to all sources.If you select the Field option, you can select the field from the source data that determines the direction to use for each source. The field must contain the text string FROM_SOURCE or TO_SOURCE.Travel from source—The source resistance rate and source starting cost will be applied beginning at the input source and travel out to the nonsource cells. This is the default.Travel to source—The source resistance rate and source starting cost will be applied beginning at each nonsource cell and travel back to the input source. | String; Field |
| in_source_data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| in_cost_raster | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| maximum_distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| out_backlink_raster(Optional) | The output cost backlink raster.The backlink raster contains values 0 through 8, which define the direction or identify the next neighboring cell (the succeeding cell) along the least accumulative cost path from a cell to reach its least-cost source.If the path is to pass into the right neighbor, the cell will be assigned the value 1, 2 for the lower right diagonal cell, and continue clockwise. The value 0 is reserved for source cells. | Raster Dataset |
| source_cost_multiplier(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| source_start_cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| source_resistance_rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| source_capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| source_direction(Optional) | Specifies the direction of the traveler when applying the source resistance rate and the source starting cost.FROM_SOURCE—The source resistance rate and source starting cost will be applied beginning at the input source and travel out to the nonsource cells. This is the default.TO_SOURCE—The source resistance rate and source starting cost will be applied beginning at each nonsource cell and travel back to the input source. Specify the FROM_SOURCE or TO_SOURCE keyword, which will be applied to all sources, or specify a field in the source data that contains the keywords to identify the direction of travel for each source. That field must contain the string FROM_SOURCE or TO_SOURCE. | String; Field |

## Code Samples

### Example 1

```python
CostDistance(in_source_data, in_cost_raster, {maximum_distance}, {out_backlink_raster}, {source_cost_multiplier}, {source_start_cost}, {source_resistance_rate}, {source_capacity}, {source_direction})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCostDist = CostDistance("source.shp", "elevation", "", "backlink", "Multiplier", "StartCost", "Resistance", 500000)
outCostDist.save("C:/sapyexamples/output/costdist")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCostDist = CostDistance("source.shp", "elevation", "", "backlink", "Multiplier", "StartCost", "Resistance", 500000)
outCostDist.save("C:/sapyexamples/output/costdist")
```

### Example 4

```python
# Name: CostDistance_Ex_02.py
# Description: Calculates for each cell the least accumulative cost distance
#    to the nearest source over a cost  surface. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSourceData = "source.shp"
inCostRaster = "elevation"
maxDistance = 20000000   
outBkLinkRaster = "C:/sapyexamples/output/outbklink"

# Execute CostDistance
outCostDistance = CostDistance(inSourceData, inCostRaster, maxDistance, outBkLinkRaster)

# Save the output 
outCostDistance.save("C:/sapyexamples/output/outcostdist")
```

### Example 5

```python
# Name: CostDistance_Ex_02.py
# Description: Calculates for each cell the least accumulative cost distance
#    to the nearest source over a cost  surface. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSourceData = "source.shp"
inCostRaster = "elevation"
maxDistance = 20000000   
outBkLinkRaster = "C:/sapyexamples/output/outbklink"

# Execute CostDistance
outCostDistance = CostDistance(inSourceData, inCostRaster, maxDistance, outBkLinkRaster)

# Save the output 
outCostDistance.save("C:/sapyexamples/output/outcostdist")
```

---

## Cost Path As Polyline (Spatial Analyst)

## Summary

Calculates the least-cost path from a source to a destination as a line feature.

## Usage

- The Cost Path as Polyline tool produces an output polyline feature that records the least-cost path or paths from sources to the closest destination, defined within the accumulative cost surface, in terms of cost distance.
- One or more of the weighted cost tools (Cost Distance, Cost Back Link, or Cost Allocation) are generally required to have been run prior to running Cost Path as Polyline to create the input cost distance and back link rasters. These are mandatory input rasters to Cost Path as Polyline.
- When the input destination data is a raster, the set of destination cells consists of all cells in the Input raster or feature destination data that have valid values. Cells that have NoData values are not included in the source set. The value zero is considered a legitimate destination. A destination raster can be created using the extraction tools.
- When the source input is a feature, the first valid available field will be used by default. If no valid fields exist, the ObjectID field (for example, OID or FID, depending on the type of feature input) will be used.
- When using polygon feature data for the input feature destinations, care must be taken with how the output cell size is handled, particularly when it is coarse relative to the detail present in the input. An internal rasterization process using the Polygon to Raster tool is applied, with a default setting for the Cell assignment type of Cell center. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized destination output, and will not be represented in the distance calculations. For example, if your destinations are a series of small polygons, such as building footprints, that are small relative to the output cell size, it is possible that only a few of them will fall under the centers of the output raster cells, seemingly causing many of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- The output polyline feature has a field called DestID that identifies to which destination each line leads. If the output is written to a file geodatabase, there is a field called shape_length that contains the total length of the least-cost path.
- Cost Path as Polyline will ignore the Cell size environment setting and use the cell size of the Input cost backlink raster for the output raster. The pattern of the back link raster would be seriously altered if it were resampled to a different resolution. To avoid any confusion, the cell size should not be set when using this tool.
- Cost Path as Polyline can be used to determine the flow path based on D8 flow direction. To use Cost Path as Polyline in this way, use a D8 flow direction raster as input for the Input cost backlink raster. You also need to supply an Input cost distance raster; the Input cost distance raster is not used to determine the path. Whether you use a constant raster or a digital elevation model (DEM), your path will be the same; only an attribute value on your path will vary. See the Flow Direction tool for more information on D8 flow direction rasters.
- Cost Path as Polyline can be used to determine a path around barriers based on the Output back direction raster generated from the Euclidean tools. To use Cost Path as Polyline in this way, first run any of the Euclidean tools with Input raster or feature barrier data defined to generate the Output distance raster and Output back direction raster. Use the outputs generated from the Euclidean tools as input to Cost Path as Polyline.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature destination data | A raster or feature dataset that identifies those cells from which the least-cost path is determined to the least costly source.If the input is a raster, it must consist of cells that have valid values for the destinations, and the remaining cells must be assigned NoData. Zero is a valid value. | Raster Layer; Feature Layer |
| Input cost distance or euclidean distance raster | The cost distance raster to be used to determine the least-cost path from the sources to the destinations.The cost distance raster is usually created with the Cost Distance, Cost Allocation, or Cost Back Link tools. The cost distance raster stores, for each cell, the minimum accumulative cost distance over a cost surface from each cell to a set of source cells. | Raster Layer |
| Input cost backlink, back direction or flow direction raster | The cost backlink raster to be used to determine the path to return to a source via the least-cost path, or the shortest path.For each cell in a backlink, back direction, or flow direction raster, the value identifies the neighbor that is the next cell on the path from that cell to a source cell. | Raster Layer |
| Output polyline features | The output feature class that will hold the least cost path. | Feature Class |
| Path type(Optional) | Specifies a keyword defining the manner in which the values and zones on the input destination data will be interpreted in the cost path calculations.Best single— For all cells on the input destination data, the least-cost path is derived from the cell with the minimum of the least-cost paths to source cells.Each zone— For each zone on the input destination data, a least-cost path is determined and saved on the output raster. With this option, the least-cost path for each zone begins at the cell with the lowest cost distance weighting in the zone.Each cell— For each cell with valid values on the input destination data, a least-cost path is determined and saved on the output raster. With this option, each cell of the input destination data is treated separately, and a least-cost path is determined for each cell. | String |
| Destination field(Optional) | The field to be used to obtain values for the destination locations.If the input destination data is feature, it must contain at least one valid integer field. The first integer field in that attribute table is used by default.If a raster is specified the default is the Value field. | Field |
| Force flow direction convention for backlink raster(Optional) | Specifies whether the input backlink raster will be treated as a flow direction raster. Flow direction rasters can have integer values that range from 0-255. Unchecked—The Input cost backlink raster parameter value will be interpreted based on the range of values and whether it is integer or float. For a value range of 0-8, the Input cost backlink raster value will be treated as a backlink raster. For values 0-255 and integer, the Input cost backlink raster value will be treated as a flow direction raster. For a value range of 0-360 and floating point, the Input cost backlink raster value will be treated as a back direction raster.Checked—The Input cost backlink raster parameter value will be treated as a flow direction raster. This is necessary if the flow direction raster has a maximum value of 8 or less. | Boolean |
| in_destination_data | A raster or feature dataset that identifies those cells from which the least-cost path is determined to the least costly source.If the input is a raster, it must consist of cells that have valid values for the destinations, and the remaining cells must be assigned NoData. Zero is a valid value. | Raster Layer; Feature Layer |
| in_cost_distance_raster | The cost distance raster to be used to determine the least-cost path from the sources to the destinations.The cost distance raster is usually created with the Cost Distance, Cost Allocation, or Cost Back Link tools. The cost distance raster stores, for each cell, the minimum accumulative cost distance over a cost surface from each cell to a set of source cells. | Raster Layer |
| in_cost_backlink_raster | The cost backlink raster to be used to determine the path to return to a source via the least-cost path, or the shortest path.For each cell in a backlink, back direction, or flow direction raster, the value identifies the neighbor that is the next cell on the path from that cell to a source cell. | Raster Layer |
| out_polyline_features | The output feature class that will hold the least cost path. | Feature Class |
| path_type(Optional) | Specifies a keyword defining the manner in which the values and zones on the input destination data will be interpreted in the cost path calculations.BEST_SINGLE— For all cells on the input destination data, the least-cost path is derived from the cell with the minimum of the least-cost paths to source cells.EACH_ZONE— For each zone on the input destination data, a least-cost path is determined and saved on the output raster. With this option, the least-cost path for each zone begins at the cell with the lowest cost distance weighting in the zone.EACH_CELL— For each cell with valid values on the input destination data, a least-cost path is determined and saved on the output raster. With this option, each cell of the input destination data is treated separately, and a least-cost path is determined for each cell. | String |
| destination_field(Optional) | The field to be used to obtain values for the destination locations.If the input destination data is feature, it must contain at least one valid integer field. The first integer field in that attribute table is used by default.If a raster is specified the default is the Value field. | Field |
| force_flow_direction_convention(Optional) | Specifies whether the input backlink raster will be treated as a flow direction raster. Flow direction rasters can have integer values that range from 0-255.INPUT_RANGE—The in_cost_backlink_raster parameter value will be interpreted based on the range of values and whether it is integer or float. For a value range of 0-8, the value will be treated as a backlink raster. For values 0-255 and integer, the value will be treated as a flow direction raster. For a value range of 0-360 and floating point, the value will be treated as a back direction raster. FLOW_DIRECTION—The in_cost_backlink_raster parameter value will be treated as a flow direction raster. This is necessary if the flow direction raster has a maximum value of 8 or less. | Boolean |

## Code Samples

### Example 1

```python
CostPathAsPolyline(in_destination_data, in_cost_distance_raster, in_cost_backlink_raster, out_polyline_features, {path_type}, {destination_field}, {force_flow_direction_convention})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
CostPathAsPolyline("observers", "costdistraster", "backlink2", "c:/sapyexamples/output/outcostpth01.shp")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
CostPathAsPolyline("observers", "costdistraster", "backlink2", "c:/sapyexamples/output/outcostpth01.shp")
```

### Example 4

```python
# Name: CostPathAsPolyline_Ex_02.py
# Description: Calculates the least-cost path from a source to 
#              a destination.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inDestination = "observers.shp"
inCostDistRaster = "costdistraster"
inBacklink = "backlink2"
outCostPathFeat = "c:/sapyexamples/output.gdb/outcostpathfeat02"
method = "EACH_CELL"
destField = "FID"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute
CostPathAsPolyline(inDestination, inCostDistRaster, inBacklink, 
                   outCostPathFeat, method, destField)
```

### Example 5

```python
# Name: CostPathAsPolyline_Ex_02.py
# Description: Calculates the least-cost path from a source to 
#              a destination.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inDestination = "observers.shp"
inCostDistRaster = "costdistraster"
inBacklink = "backlink2"
outCostPathFeat = "c:/sapyexamples/output.gdb/outcostpathfeat02"
method = "EACH_CELL"
destField = "FID"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute
CostPathAsPolyline(inDestination, inCostDistRaster, inBacklink, 
                   outCostPathFeat, method, destField)
```

---

## Cost Path (Spatial Analyst)

## Summary

Calculates the least-cost path from a source to a destination.

## Usage

- The Cost Path tool produces an output raster that records the least-cost path or paths from selected locations to the closest source cell defined within the accumulative cost surface, in terms of cost distance.
- One or more of the weighted cost tools (Cost Distance, Cost Back Link, or Cost Allocation) are generally required to run prior to running Cost Path to create the input cost distance and back link rasters. These are mandatory input rasters to Cost Path.
- Each least-cost path is assigned a value when encountered in the scanning process. The ending cell on the original source raster (from which the cost distance and back link were derived) of a cost path receives one, the first path receives three, the second four, and so on. The value two is reserved for the merged portion of paths that have portions of a common cost path.
- When the input destination data is a raster, the set of destination cells consists of all cells in the input raster or feature destination data that have valid values. Cells that have NoData values are not included in the source set. The value zero is considered a legitimate destination. A destination raster can be easily created using the extraction tools.
- When the source input is a feature, the first valid available field will be used by default. If no valid fields exist, the ObjectID field (for example, OID or FID, depending on the type of feature input) will be used.
- When using polygon feature data for the input feature destinations, care must be taken with how the output cell size is handled when it is coarse relative to the detail present in the input. In the internal rasterization process that employs the Polygon to Raster tool, the default setting of Cell assignment type will be Cell center. This means that data not located at the center of the cell will not be included in the intermediate rasterized destination output, and so will not be represented in the distance calculations. For example, if your destinations are a series of small polygons, such as building footprints, that are small relative to the output cell size, it is possible that only a few of them will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- When multiple paths merge and follow the remaining distance back to a source on the same route, the segment where the two paths travel together is assigned the value 2. The merged portion of the path cannot be assigned the value of one of the paths, since the merged portion belongs to both routes.Example of Each zone option with merged paths
- Cost Path will ignore the Cell size environment setting and use the cell size of the Input cost backlink raster for the output raster. The pattern of the back link raster would be seriously altered if it were resampled to a different resolution. To avoid any confusion, the cell size should not be set when using this tool.
- Cost Path can be used to determine the flow path based on D8 flow direction. To use Cost Path in this way, use a D8 flow direction raster as input for the Input cost backlink raster. You also need to supply an Input cost distance raster; the Input cost distance raster is not used to determine the path. Whether you use a constant raster or a digital elevation model (DEM), your path will be the same; only an attribute value on your path will vary. See the Flow Direction tool for more information on D8 flow direction rasters.
- When the input destination data is feature, it must contain at least one valid field.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature destination data | A raster or feature dataset that identifies those cells from which the least-cost path is determined to the least costly source.If the input is a raster, the input consists of cells that have valid values (zero is a valid value), and the remaining cells must be assigned NoData. | Raster Layer; Feature Layer |
| Input cost distance raster | The name of a cost distance raster to be used to determine the least-cost path from the destination locations to a source.The cost distance raster is usually created with the Cost Distance, Cost Allocation or Cost Back Link tools. The cost distance raster stores, for each cell, the minimum accumulative cost distance over a cost surface from each cell to a set of source cells. | Raster Layer |
| Input cost backlink raster | The name of a cost back link raster used to determine the path to return to a source via the least-cost path.For each cell in the back link raster, a value identifies the neighbor that is the next cell on the least accumulative cost path from the cell to a single source cell or set of source cells. | Raster Layer |
| Path type(Optional) | A keyword defining the manner in which the values and zones on the input destination data will be interpreted in the cost path calculations.Each cell— For each cell with valid values on the input destination data, a least-cost path is determined and saved on the output raster. With this option, each cell of the input destination data is treated separately, and a least-cost path is determined for each from cell. Each zone— For each zone on the input destination data, a least-cost path is determined and saved on the output raster. With this option, the least-cost path for each zone begins at the cell with the lowest cost distance weighting in the zone. Best single— For all cells on the input destination data, the least-cost path is derived from the cell with the minimum of the least-cost paths to source cells. | String |
| Destination field(Optional) | The field used to obtain values for the destination locations.Input feature data must contain at least one valid field. | Field |
| Force flow direction convention for backlink raster(Optional) | Specifies whether the input backlink raster will be treated as a flow direction raster. Flow direction rasters can have integer values that range from 0-255.Unchecked—The Input cost backlink raster parameter value will be interpreted based on the range of values and whether it is integer or float. For a value range of 0-8, the Input cost backlink raster value will be treated as a backlink raster. For values 0-255 and integer, the Input cost backlink raster value will be treated as a flow direction raster. For a value range of 0-360 and floating point, the Input cost backlink raster value will be treated as a back direction raster.Checked—The Input cost backlink raster parameter value will be treated as a flow direction raster. This is necessary if the flow direction raster has a maximum value of 8 or less. | Boolean |
| in_destination_data | A raster or feature dataset that identifies those cells from which the least-cost path is determined to the least costly source.If the input is a raster, the input consists of cells that have valid values (zero is a valid value), and the remaining cells must be assigned NoData. | Raster Layer; Feature Layer |
| in_cost_distance_raster | The name of a cost distance raster to be used to determine the least-cost path from the destination locations to a source.The cost distance raster is usually created with the Cost Distance, Cost Allocation or Cost Back Link tools. The cost distance raster stores, for each cell, the minimum accumulative cost distance over a cost surface from each cell to a set of source cells. | Raster Layer |
| in_cost_backlink_raster | The name of a cost back link raster used to determine the path to return to a source via the least-cost path.For each cell in the back link raster, a value identifies the neighbor that is the next cell on the least accumulative cost path from the cell to a single source cell or set of source cells. | Raster Layer |
| path_type(Optional) | A keyword defining the manner in which the values and zones on the input destination data will be interpreted in the cost path calculations.EACH_CELL— For each cell with valid values on the input destination data, a least-cost path is determined and saved on the output raster. With this option, each cell of the input destination data is treated separately, and a least-cost path is determined for each from cell. EACH_ZONE— For each zone on the input destination data, a least-cost path is determined and saved on the output raster. With this option, the least-cost path for each zone begins at the cell with the lowest cost distance weighting in the zone. BEST_SINGLE— For all cells on the input destination data, the least-cost path is derived from the cell with the minimum of the least-cost paths to source cells. | String |
| destination_field(Optional) | The field used to obtain values for the destination locations.Input feature data must contain at least one valid field. | Field |
| force_flow_direction_convention(Optional) | Specifies whether the input backlink raster will be treated as a flow direction raster. Flow direction rasters can have integer values that range from 0-255. INPUT_RANGE—The in_cost_backlink_raster parameter value will be interpreted based on the range of values and whether it is integer or float. For a value range of 0-8, the value will be treated as a backlink raster. For values 0-255 and integer, the value will be treated as a flow direction raster. For a value range of 0-360 and floating point, the value will be treated as a back direction raster. FLOW_DIRECTION—The in_cost_backlink_raster parameter value will be treated as a flow direction raster. This is necessary if the flow direction raster has a maximum value of 8 or less. | Boolean |

## Code Samples

### Example 1

```python
CostPath(in_destination_data, in_cost_distance_raster, in_cost_backlink_raster, {path_type}, {destination_field}, {force_flow_direction_convention})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCostPath = CostPath("observers", "costraster", "backlink2", "EACH_CELL")
outCostPath.save("c:/sapyexamples/output/costpath")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCostPath = CostPath("observers", "costraster", "backlink2", "EACH_CELL")
outCostPath.save("c:/sapyexamples/output/costpath")
```

### Example 4

```python
# Name: CostPath_Ex_02.py
# Description: Calculates the least-cost path from a source to 
#              a destination.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inDestination = "observers.shp"
costDistanceRaster = "costdistraster"
backLink = "backlink2"
method = "EACH_CELL"
destField = "FID"

# Execute CostPath
outCostPath = CostPath(inDestination, costDistanceRaster, backLink, method,
                       destField)

# Save the output 
outCostPath.save("c:/sapyexamples/output/costpath02")
```

### Example 5

```python
# Name: CostPath_Ex_02.py
# Description: Calculates the least-cost path from a source to 
#              a destination.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inDestination = "observers.shp"
costDistanceRaster = "costdistraster"
backLink = "backlink2"
method = "EACH_CELL"
destField = "FID"

# Execute CostPath
outCostPath = CostPath(inDestination, costDistanceRaster, backLink, method,
                       destField)

# Save the output 
outCostPath.save("c:/sapyexamples/output/costpath02")
```

---

## Create Accuracy Assessment Points (Spatial Analyst)

## Summary

Creates randomly sampled points for postclassification accuracy assessment.

## Usage

- This tool creates a set of random points and assigns a class to them based on reference data.
- This tool can also assign a class to the set of points using a previously classified image or a feature class.
- The accuracy assessment workflow usually uses the following three tools in this order: Create Accuracy Assessment Points, Update Accuracy Assessment Points, and Compute Confusion Matrix.
- When a polygon feature class is used for training or accuracy assessment, the feature class must have a Classvalue or value field that has a unique integer value for each class. For example, a polygon feature class with three different classes can have values such as [1, 2, 3] or [10, 20, 40].
- When the Input Raster or Feature Class Data parameter value is a multidimensional raster, the random points generated will use all images in the time series with a date field indicating the image the points are generated from. To generate points for a subset of images, use the Make Multidimensional Raster Layer tool to create an intermediate layer, or the Subset Multidimensional Raster tool to create an intermediate dataset before using this tool.
- After running this tool, you can edit the table to manually assign a class to some or all of the points.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Class Data | The input classification image or other thematic GIS reference data. The input can be a raster or feature class.Typical data is a classification image of a single band, integer data type.If using polygons as input, only use those that are not used as training samples. They can also be GIS land-cover data in shapefile or feature class format. | Raster Layer; Mosaic Layer; Feature Layer |
| Output Accuracy Assessment Points | The output point shapefile or feature class that contains the random points to be used for accuracy assessment. | Feature Class |
| Target Field(Optional) | Specifies whether the input data is a classified image or ground truth data.Classified—The input is a classified image. This is the default.Ground truth—The input is reference data. | String |
| Number of Random Points(Optional) | The total number of random points that will be generated.The actual number may exceed but never fall below this number, depending on sampling strategy and number of classes. The default number of randomly generated points is 500. | Long |
| Sampling Strategy(Optional) | Specifies the sampling scheme that will be used.Stratified random—Randomly distributed points will be created in each class, in which each class has a number of points proportional to its relative area. This is the defaultEqualized stratified random—Randomly distributed points will be created in each class, in which each class has the same number of points.Random—Randomly distributed points will be created throughout the image. | String |
| Dimension Field for Feature Class(Optional) | A field that defines the dimension (time) of the features. This parameter is used only if the classification result is a multidimensional raster and you want to generate assessment points from a feature class, such as land classification polygons for multiple years. | Field |
| in_class_data | The input classification image or other thematic GIS reference data. The input can be a raster or feature class.Typical data is a classification image of a single band, integer data type.If using polygons as input, only use those that are not used as training samples. They can also be GIS land-cover data in shapefile or feature class format. | Raster Layer; Mosaic Layer; Feature Layer |
| out_points | The output point shapefile or feature class that contains the random points to be used for accuracy assessment. | Feature Class |
| target_field(Optional) | Specifies whether the input data is a classified image or ground truth data.CLASSIFIED—The input is a classified image. This is the default.GROUND_TRUTH—The input is reference data. | String |
| num_random_points(Optional) | The total number of random points that will be generated.The actual number may exceed but never fall below this number, depending on sampling strategy and number of classes. The default number of randomly generated points is 500. | Long |
| sampling(Optional) | Specifies the sampling scheme that will be used.STRATIFIED_RANDOM—Randomly distributed points will be created in each class, in which each class has a number of points proportional to its relative area. This is the defaultEQUALIZED_STRATIFIED_RANDOM—Randomly distributed points will be created in each class, in which each class has the same number of points.RANDOM—Randomly distributed points will be created throughout the image. | String |
| polygon_dimension_field(Optional) | A field that defines the dimension (time) of the features. This parameter is used only if the classification result is a multidimensional raster and you want to generate assessment points from a feature class, such as land classification polygons for multiple years. | Field |

## Code Samples

### Example 1

```python
CreateAccuracyAssessmentPoints(in_class_data, out_points, {target_field}, {num_random_points}, {sampling}, {polygon_dimension_field})
```

### Example 2

```python
import arcpy
from arcpy.sa import *

arcpy.gp.CreateAccuracyAssessmentPoints("cls.tif", "aapnt1.shp", "COMPUTED", "1500", "RANDOM")
```

### Example 3

```python
import arcpy
from arcpy.sa import *

arcpy.gp.CreateAccuracyAssessmentPoints("cls.tif", "aapnt1.shp", "COMPUTED", "1500", "RANDOM")
```

---

## Create Constant Raster (Spatial Analyst)

## Summary

Creates a raster of a constant value within the extent and cell size of the analysis window.

## Usage

- The Create Constant Raster tool assigns the specified value to every cell in the output raster.
- The constant value must be a numeric value. Scientific notation is acceptable (for example, 3.048e-4 for 0.003048).
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size has not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is 1.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Since the tool does not have any input, the output spatial reference is derived from other settings in a particular order. First, the Output Coordinate System environment will be used, if specified, followed by the coordinate system of the map view. If neither of these conditions are met, the output spatial reference will be set to Unknown.
- Based on the cell size, the default output extent is computed to create a raster of 250 rows and 250 columns. Thus, for the default cell size of 1, the Output extent is (0, 0, 250, 250). The extent value is adjusted based on the Cell Size, Snap Raster, and Output Coordinate System environments, if specified.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Constant value | The constant value with which to populate all the cells in the output raster. | Double |
| Output data type(Optional) | Data type of the output raster dataset.If the specified data type is floating-point, the values of the cells in the output raster will only be accurate to the constant value of 7 decimal places, regardless of the output format.Integer—An integer raster will be created.Float—A floating-point raster will be created. | String |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Output extent(Optional) | The extent for the output raster dataset.The extent will be the value in the environment if specifically set. If not specifically set, the default is 0, 0, 250, 250. | Envelope; Extent |
| constant_value | The constant value with which to populate all the cells in the output raster. | Double |
| data_type(Optional) | Data type of the output raster dataset.INTEGER—An integer raster will be created.FLOAT—A floating-point raster will be created. If the specified data type is floating-point, the values of the cells in the output raster will only be accurate to the constant value of 7 decimal places, regardless of the output format. | String |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| extent(Optional) | The extent for the output raster dataset.The Extent is a Python class.In this tool, it is in the form Extent(XMin, YMin, XMax, YMax)where XMin and YMin define the lower left coordinate of the extent, and XMax and YMax define the upper right coordinate.The coordinates are specified in the same map units as the Output Coordinate System environment setting.The extent will be the value in the environment if specifically set. If not specifically set, the default is 0, 0, 250, 250. | Envelope; Extent |

## Code Samples

### Example 1

```python
CreateConstantRaster(constant_value, {data_type}, {cell_size}, {extent})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outConstRaster = CreateConstantRaster(12.7, "FLOAT", 2, Extent(0, 0, 250, 250))
outConstRaster.save("C:/sapyexamples/output/outconst2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outConstRaster = CreateConstantRaster(12.7, "FLOAT", 2, Extent(0, 0, 250, 250))
outConstRaster.save("C:/sapyexamples/output/outconst2")
```

### Example 4

```python
# Name: CreateConstantRaster_Ex_02.py
# Description: Creates a raster from a constant value
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set local variables
constantValue = 12
cellSize = 2
outExtent = Extent(0, 0, 250, 250)

# Execute CreateConstantRaster
outConstRaster = CreateConstantRaster(constantValue, "FLOAT", cellSize,
                                      outExtent)

# Save the output 
outConstRaster.save("C:/sapyexamples/output/outconst")
```

### Example 5

```python
# Name: CreateConstantRaster_Ex_02.py
# Description: Creates a raster from a constant value
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set local variables
constantValue = 12
cellSize = 2
outExtent = Extent(0, 0, 250, 250)

# Execute CreateConstantRaster
outConstRaster = CreateConstantRaster(constantValue, "FLOAT", cellSize,
                                      outExtent)

# Save the output 
outConstRaster.save("C:/sapyexamples/output/outconst")
```

---

## Create Normal Raster (Spatial Analyst)

## Summary

Creates a raster of random values with a normal (Gaussian) distribution within the extent and cell size of the analysis window.

## Usage

- The Create Normal Raster tool generates values for every cell in the output raster.
- The output raster from this tool is always floating point.
- The cell values will have up to 7 digits of precision after the decimal point.
- The output values will have a mean of 0.0 and a standard deviation of 1.0. If a different standard deviation is desired, multiply the output raster by that value. If a different mean is desired, add that value to the raster. For example, to create a raster where the values are characterized by a mean of 39 and a standard deviation of 2.5, multiply the results of Create Normal Raster by 2.5, then add 39.In Map Algebra, you could do something like:import arcpy from arcpy import env from arcpy.sa import * env.workspace = "C:/data" outNorm = CreateNormalRaster(1, Extent(0, 0, 100, 100)) * 2.5 + 39 outNorm.save("C:/output/norm2")
- In Map Algebra, you could do something like:import arcpy from arcpy import env from arcpy.sa import * env.workspace = "C:/data" outNorm = CreateNormalRaster(1, Extent(0, 0, 100, 100)) * 2.5 + 39 outNorm.save("C:/output/norm2")
- The random number generator is automatically seeded with the current value of the system clock (seconds since January 1, 1970). Reseeding the Create Random Raster tool also reseeds Create Normal Raster.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size has not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is 1.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Since the tool does not have any input, the output spatial reference is derived from other settings in a particular order. First, the Output Coordinate System environment will be used, if specified, followed by the coordinate system of the map view. If neither of these conditions are met, the output spatial reference will be set to Unknown.
- Based on the cell size, the default output extent is computed to create a raster of 250 rows and 250 columns. Thus, for the default cell size of 1, the Output extent is (0, 0, 250, 250). The extent value is adjusted based on the Cell Size, Snap Raster, and Output Coordinate System environments, if specified.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Output extent(Optional) | The extent for the output raster dataset.The extent will be the value in the environment if specifically set. If not specifically set, the default is 0, 0, 250, 250. | Envelope; Extent |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| extent(Optional) | The extent for the output raster dataset.The Extent is a Python class.In this tool, it is in the form Extent(XMin, YMin, XMax, YMax)where XMin and YMin define the lower left coordinate of the extent, and XMax and YMax define the upper right coordinate.The coordinates are specified in the same map units as the Output Coordinate System environment setting.The extent will be the value in the environment if specifically set. If not specifically set, the default is 0, 0, 250, 250. | Envelope; Extent |

## Code Samples

### Example 1

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/data"
outNorm = CreateNormalRaster(1, Extent(0, 0, 100, 100)) * 2.5 + 39
outNorm.save("C:/output/norm2")
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/data"
outNorm = CreateNormalRaster(1, Extent(0, 0, 100, 100)) * 2.5 + 39
outNorm.save("C:/output/norm2")
```

### Example 3

```python
CreateNormalRaster({cell_size}, {extent})
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outNormalRaster = CreateNormalRaster(2, Extent(0, 0, 150, 150))
outNormalRaster.save("C:/sapyexamples/output/outnormal")
```

### Example 5

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outNormalRaster = CreateNormalRaster(2, Extent(0, 0, 150, 150))
outNormalRaster.save("C:/sapyexamples/output/outnormal")
```

### Example 6

```python
# Name: CreateNormalRaster_Ex_02.py
# Description: Creates a raster of random values from a normal distribution
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
cellSize = 2
extent = Extent(0, 0, 150, 150)

# Execute CreateNormalRaster
outNormalRaster = CreateNormalRaster(cellSize, extent) 

# Save the output 
outNormalRaster.save("C:/sapyexamples/output/outnormraster")
```

### Example 7

```python
# Name: CreateNormalRaster_Ex_02.py
# Description: Creates a raster of random values from a normal distribution
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
cellSize = 2
extent = Extent(0, 0, 150, 150)

# Execute CreateNormalRaster
outNormalRaster = CreateNormalRaster(cellSize, extent) 

# Save the output 
outNormalRaster.save("C:/sapyexamples/output/outnormraster")
```

---

## Create Random Raster (Spatial Analyst)

## Summary

Creates a raster of random floating-point values between 0.0 and 1.0 within the extent and cell size of the analysis window.

## Usage

- The Create Random Raster tool generates values for every cell in the output raster.
- The output raster from this tool is always floating point.
- The cell values will have up to 7 digits of precision after the decimal point.
- Repeatedly using the same seed value or the default will not produce the same raster.
- You can change the seed through a parameter to ensure you obtain different starting points for the random number generator.
- To generate the values, the ACM algorithm 599 random number generator is used.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size has not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is 1.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Since the tool does not have any input, the output spatial reference is derived from other settings in a particular order. First, the Output Coordinate System environment will be used, if specified, followed by the coordinate system of the map view. If neither of these conditions are met, the output spatial reference will be set to Unknown.
- Based on the cell size, the default output extent is computed to create a raster of 250 rows and 250 columns. Thus, for the default cell size of 1, the Output extent is (0, 0, 250, 250). The extent value is adjusted based on the Cell Size, Snap Raster, and Output Coordinate System environments, if specified.
- The Data Management toolbox has a Create Random Raster tool that offers some more options for the distribution of the values.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Seed value(Optional) | A value to be used to reseed the random number generator.This may be an integer or floating-point number. Rasters are not permitted as input.The random number generator is automatically seeded with the current value of the system clock (seconds since January 1, 1970). The range of permissible values for the seed value is -231 + 1 to 231 (or -2,147,483,647 to 2,147,483,648). | Double |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Output extent(Optional) | The extent for the output raster dataset.The extent will be the value in the environment if specifically set. If not specifically set, the default is 0, 0, 250, 250. | Envelope; Extent |
| seed_value(Optional) | A value to be used to reseed the random number generator.This may be an integer or floating-point number. Rasters are not permitted as input.The random number generator is automatically seeded with the current value of the system clock (seconds since January 1, 1970). The range of permissible values for the seed value is -231 + 1 to 231 (or -2,147,483,647 to 2,147,483,648). | Double |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| extent(Optional) | The extent for the output raster dataset.The Extent is a Python class.In this tool, it is in the form Extent(XMin, YMin, XMax, YMax)where XMin and YMin define the lower left coordinate of the extent, and XMax and YMax define the upper right coordinate.The coordinates are specified in the same map units as the Output Coordinate System environment setting.The extent will be the value in the environment if specifically set. If not specifically set, the default is 0, 0, 250, 250. | Envelope; Extent |

## Code Samples

### Example 1

```python
CreateRandomRaster({seed_value}, {cell_size}, {extent})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRandRaster = CreateRandomRaster(100, 2, Extent(0, 0, 150, 150))
outRandRaster.save("C:/sapyexamples/output/outrandom")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRandRaster = CreateRandomRaster(100, 2, Extent(0, 0, 150, 150))
outRandRaster.save("C:/sapyexamples/output/outrandom")
```

### Example 4

```python
# Name: CreateRandomRaster_Ex_02.py
# Description: Creates a raster of random floating point values
#              between 0 and 1
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
seedValue = 1
cellSize = 2
extent = Extent(0, 0, 150, 150)

# Execute CreateRandomRaster
outRandomRaster = CreateRandomRaster(seedValue, cellSize, extent) 

# Save the output 
outRandomRaster.save("C:/sapyexamples/output/outrand")
```

### Example 5

```python
# Name: CreateRandomRaster_Ex_02.py
# Description: Creates a raster of random floating point values
#              between 0 and 1
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
seedValue = 1
cellSize = 2
extent = Extent(0, 0, 150, 150)

# Execute CreateRandomRaster
outRandomRaster = CreateRandomRaster(seedValue, cellSize, extent) 

# Save the output 
outRandomRaster.save("C:/sapyexamples/output/outrand")
```

---

## Create Signatures (Spatial Analyst)

## Summary

Creates an ASCII signature file of classes defined by input sample data and a set of raster bands.

## Usage

- When a multiband raster is specified as one of the Input raster bands (in_raster_bands in Python), all the bands will be used.To process a selection of bands from a multiband raster, you can first create a new raster dataset composed of those particular bands with the Composite Bands tool, and use the result in the list of the Input raster bands (in_raster_bands in Python).
- A .gsg extension should be used for the output signature file.
- The input raster bands and the input raster or feature sample data must have overlapping extents. The statistics will be computed for the common area only.
- The minimum valid number of class samples in the sample data is two. There is no maximum number of classes.
- If the signature file is to be used in further multivariate analysis tools that use covariance matrices, such as Maximum Likelihood Classification and Class Probability, the covariance matrices must be present. This information is generated when the Compute covariance matrices option in the dialog box is enabled, or the COVARIANCE option is specified in scripting. Note that this is the default setting. See How Create Signatures works to compare signature files when the covariance matrices are generated versus only the means.
- You should not change anything in the signature file except to enter the names of classes. The statistics in the file should be created and altered by Multivariate tools only.
- The names of the classes in the output signature file are optional. They're used for reference only. The class names can be entered through the Sample field or any text editor can be used on the resulting signature file to input the names. Each class name must consist of a single string no more than 31 alphanumeric characters in length.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster bands | The input raster bands for which to create the signatures.They can be integer or floating point type. | Raster Layer |
| Input raster or feature sample data | The input delineating the set of class samples.The input can be an integer raster or a feature dataset. | Raster Layer; Feature Layer |
| Output signature file | The output signature file.A .gsg extension must be specified. | File |
| Compute covariance matrices(Optional) | Specifies whether covariance matrices in addition to the means are calculated.Checked—Both the covariance matrices and the means for all classes of the input sample data will be computed. This is the default.Unchecked—Only the means for all classes of the input sample data will be calculated. | Boolean |
| Sample field(Optional) | Field of the input raster or feature sample data to assign values to the sampled locations (classes).Only integer or string fields are valid fields. The specified number or string will be used as the Class name in the output signature file. | Field |
| in_raster_bands[in_raster_band,...] | The input raster bands for which to create the signatures.They can be integer or floating point type. | Raster Layer |
| in_sample_data | The input delineating the set of class samples.The input can be an integer raster or a feature dataset. | Raster Layer; Feature Layer |
| out_signature_file | The output signature file.A .gsg extension must be specified. | File |
| compute_covariance(Optional) | Specifies whether covariance matrices in addition to the means are calculated.COVARIANCE—Both the covariance matrices and the means for all classes of the in_sample_data will be computed. This is the default.MEAN_ONLY—Only the means for all classes of the in_sample_data will be calculated. | Boolean |
| sample_field(Optional) | Field of the input raster or feature sample data to assign values to the sampled locations (classes).Only integer or string fields are valid fields. The specified number or string will be used as the Class name in the output signature file. | Field |

## Code Samples

### Example 1

```python
CreateSignatures(in_raster_bands, in_sample_data, out_signature_file, {compute_covariance}, {sample_field})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
CreateSignatures("sb", "sbtrain", "c:/sapyexamples/output/rbsig.gsg", 
                 "COVARIANCE", "")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
CreateSignatures("sb", "sbtrain", "c:/sapyexamples/output/rbsig.gsg", 
                 "COVARIANCE", "")
```

### Example 4

```python
# Name: CreateSignatures_Ex_02.py
# Description: Creates an ASCII signature file of classes defined by input 
#    sample data and a set of raster bands.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "sb"
inSamples = "sbtrain"
outSig = "c:/sapyexamples/output/rbsig02.gsg"
sampField = ""

# Execute CreateSignatures
CreateSignatures(inRaster, inSamples, outSig, "COVARIANCE", sampField)
```

### Example 5

```python
# Name: CreateSignatures_Ex_02.py
# Description: Creates an ASCII signature file of classes defined by input 
#    sample data and a set of raster bands.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "sb"
inSamples = "sbtrain"
outSig = "c:/sapyexamples/output/rbsig02.gsg"
sampField = ""

# Execute CreateSignatures
CreateSignatures(inRaster, inSamples, outSig, "COVARIANCE", sampField)
```

---

## Curvature (Spatial Analyst)

## Summary

Calculates the curvature of a raster surface and, optionally, includes profile and plan curvature.

## Usage

- The Curvature tool fits a plane to the nine local cells, but a plane may not be a good descriptor of the landscape and may mask or exaggerate natural variations of interest. The Surface Parameters tool fits a surface to the neighborhood of cells instead of a plane, which provides a more natural fit to the terrain.The Curvature tool uses a 3 by 3 window of cells to compute the value, while the Surface Parameters tool allows window sizes from 3 by 3 to 15 by 15 cells. Larger window sizes are useful with high resolution elevation data to capture land surface processes at an appropriate scale. The Surface Parameters tool also provides an adaptive window option that evaluates the local variability of the terrain and identifies the largest appropriate neighborhood size for each cell. This can be useful with gradual homogeneous terrain interrupted by streams, roads, or sharp breaks in slope.The Surface Parameters tool includes three curvature types, which use updated formulas and create different results than the Curvature tool.
- The primary output is the curvature of the surface on a cell-by-cell basis, as fitted through that cell and its eight surrounding neighbors. Two optional output curvature types are possible: the profile curvature is in the direction of the maximum slope, and the plan curvature is perpendicular to the direction of the maximum slope.
- A positive curvature indicates the surface is upwardly convex at that cell. A negative curvature indicates the surface is upwardly concave at that cell. A value of 0 indicates the surface is flat.
- In the profile output, a negative value indicates the surface is upwardly convex at that cell. A positive profile indicates the surface is upwardly concave at that cell. A value of 0 indicates the surface is flat.
- In the plan output, a positive value indicates the surface is upwardly convex at that cell. A negative plan indicates the surface is upwardly concave at that cell. A value of 0 indicates the surface is flat.
- Units of the curvature output raster, as well as the units for the optional output profile curve raster and output plan curve raster, are one hundredth (1/100) of a z-unit. The reasonably expected values of all three output rasters for a hilly area (moderate relief) can vary from -0.5 to 0.5; while for steep, rugged mountains (extreme relief), the values can vary between -4 and 4. Note that it is possible to exceed this range for certain raster surfaces.
- When the input raster needs to be resampled, the bilinear technique will be used. An example of when an input raster may be resampled is when the output coordinate system, extent, or cell size is different from that of the input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input surface raster. | Raster Layer |
| Z factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| Output profile curve raster(Optional) | Output profile curve raster dataset.This is the curvature of the surface in the direction of slope.It will be floating-point type. | Raster Dataset |
| Output plan curve raster(Optional) | Output plan curve raster dataset.This is the curvature of the surface perpendicular to the slope direction.It will be floating-point type. | Raster Dataset |
| in_raster | The input surface raster. | Raster Layer |
| z_factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| out_profile_curve_raster(Optional) | Output profile curve raster dataset.This is the curvature of the surface in the direction of slope.It will be floating-point type. | Raster Dataset |
| out_plan_curve_raster(Optional) | Output plan curve raster dataset.This is the curvature of the surface perpendicular to the slope direction.It will be floating-point type. | Raster Dataset |

## Code Samples

### Example 1

```python
Curvature(in_raster, {z_factor}, {out_profile_curve_raster}, {out_plan_curve_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCurve = Curvature("elevation", 1.094)
outCurve.save("C:/sapyexamples/output/outcurv01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCurve = Curvature("elevation", 1.094)
outCurve.save("C:/sapyexamples/output/outcurv01")
```

### Example 4

```python
# Name: Curvature_Ex_02.py
# Description: Calculates the curvature of a raster surface, 
#              optionally including profile and plan curvature.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
zFactor = 1.094

# Execute Curvature
outCurve = Curvature(inRaster, 1.094)

# Save the output 
outCurve.save("C:/sapyexamples/output/outcurv02")
```

### Example 5

```python
# Name: Curvature_Ex_02.py
# Description: Calculates the curvature of a raster surface, 
#              optionally including profile and plan curvature.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
zFactor = 1.094

# Execute Curvature
outCurve = Curvature(inRaster, 1.094)

# Save the output 
outCurve.save("C:/sapyexamples/output/outcurv02")
```

---

## Cut Fill (Spatial Analyst)

## Summary

Calculates the volume change between two surfaces. This is typically used for cut and fill operations.

## Usage

- The Cut Fill tool enables you to create a map based on two input surfaces—before and after—displaying the areas and volumes of surface materials that have been modified by the removal or addition of surface material.
- Both the input raster surfaces must be coincident. That is, they must have a common origin, the same number of rows and columns of cells, and the same cell size.
- For accurate results, the z-units should be the same as the x,y ground units. This ensures that the resulting volumes are meaningful cubic measures (for example, cubic meters). If they are not the same, use a z-factor to convert z units to x,y units. For example, if your x,y units are meters and your z units are feet, you could specify a z-factor of 0.3048 to convert feet to meters.Alternatively, use the Times math tool to create a surface raster in which the z-values have been adjusted to correspond to the ground units.
- The attribute table of the output raster presents the changes in the surface volumes following the cut/fill operation. Positive values for the volume difference indicate regions of the before raster surface that have been cut (material removed). Negative values indicate areas that have been filled (material added).See How Cut Fill works for more details on how the results are calculated.
- When the cut/fill operation is performed from the tool, by default a specialized renderer is applied that highlights the locations of cut and of fill. The renderer draws areas that have been cut in blue, and areas that have been filled in red. Areas that have not changed are displayed in grey.
- When the input raster needs to be resampled, the bilinear technique will be used. An example of when an input raster may be resampled is when the output coordinate system, extent, or cell size is different from that of the input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input before raster surface | The input representing the surface before the cut or fill operation. | Raster Layer |
| Input after raster surface | The input representing the surface after the cut or fill operation. | Raster Layer |
| Z factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| in_before_surface | The input representing the surface before the cut or fill operation. | Raster Layer |
| in_after_surface | The input representing the surface after the cut or fill operation. | Raster Layer |
| z_factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |

## Code Samples

### Example 1

```python
CutFill(in_before_surface, in_after_surface, {z_factor})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCutFill = CutFill("elevation01", "elevation02", 1)
outCutFill.save("C:/sapyexamples/output/outcutfill01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outCutFill = CutFill("elevation01", "elevation02", 1)
outCutFill.save("C:/sapyexamples/output/outcutfill01")
```

### Example 4

```python
# Name: Cutfill_Ex_02.py
# Description: Calculates the volume and area of cut and 
#              fill locations.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inBeforeRaster = "elevation01"
inAfterRaster =  "elevation02"
zFactor = 0.5

# Execute CutFill
outCutFill = CutFill(inBeforeRaster, inAfterRaster, zFactor)

# Save the output 
outCutFill.save("C:/sapyexamples/output/outcutfill02")
```

### Example 5

```python
# Name: Cutfill_Ex_02.py
# Description: Calculates the volume and area of cut and 
#              fill locations.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inBeforeRaster = "elevation01"
inAfterRaster =  "elevation02"
zFactor = 0.5

# Execute CutFill
outCutFill = CutFill(inBeforeRaster, inAfterRaster, zFactor)

# Save the output 
outCutFill.save("C:/sapyexamples/output/outcutfill02")
```

---

## Darcy Flow (Spatial Analyst)

## Summary

Calculates the groundwater volume balance residual and other outputs for steady flow in an aquifer.

## Usage

- The differences between Darcy Flow and Darcy Velocity are:Darcy Flow produces an output volume raster; Darcy Velocity does not.Darcy Velocity outputs only direction and magnitude rasters as required output; Darcy Flow optionally produces these outputs.
- Darcy Flow produces an output volume raster; Darcy Velocity does not.
- Darcy Velocity outputs only direction and magnitude rasters as required output; Darcy Flow optionally produces these outputs.
- All input rasters must have the same extent and cell size.
- All input rasters must be floating point.
- The direction of the velocity vector is recorded in compass coordinates (degrees clockwise from north), the magnitude in units of length over time.
- No particular system of units is specified by this tool. Data should be consistent, using the same unit for time (seconds, days, years) and length (feet, meters) for all data.
- The head elevation raster can come from a variety of sources. It can be interpolated from observation well data by using one of the surface interpolation tools, such as Kriging or Spline. The head values can also be obtained from the results of a separate modeling program.However the head elevation raster is obtained, the head must be consistent with the transmissivity raster; that is, the head must reflect the flow through the transmissivity field. It is not sufficient to use values obtained by measurement and testing in the field—the rasterized values must be analyzed for consistency with the aid of a proper porous medium flow program. Consistency implies that the heads would actually be produced by the modeled transmissivity field. Since the true and modeled transmissivity fields often differ in practice, the true and modeled head fields differ, as well. Check the heads for consistency by examining the residual raster produced by Darcy Flow. The residual will reflect the consistency of the dataset. Any analysis using Darcy Velocity on inconsistent datasets will produce meaningless results.
- The effective porosity field, a physical property of the aquifer, is generally estimated from geological data. It is defined as the volume of void space that contributes to fluid flow divided by the entire volume. Porosity is expressed as a number between 0 and 1, with typical values around 0.35, and is dimensionless. A value of effective porosity of 0.35 means that 35 percent of the volume of the porous medium contributes to fluid flow. The remaining 65 percent, consisting of solid matrix and unconnected pores, does not contribute to fluid flow.
- The saturated thickness, measured in units of length, is interpreted from geological information. For a confined aquifer, this measure is the thickness of the formation between the upper and lower confining layers. For an unconfined aquifer, the saturated thickness is the distance between the water table and the lower confining layer.
- The output rasters are floating point.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input groundwater head elevation raster | The input raster where each cell value represents the groundwater head elevation at that location.The head is typically an elevation above some datum, such as mean sea level. | Raster Layer |
| Input effective formation porosity raster | The input raster where each cell value represents the effective formation porosity at that location. | Raster Layer |
| Input saturated thickness raster | The input raster where each cell value represents the saturated thickness at that location.The value for the thickness is interpreted from geological properties of the aquifer. | Raster Layer |
| Input formation transmissivity raster | The input raster where each cell value represents the formation transmissivity at that location.The transmissivity of an aquifer is defined as the hydraulic conductivity K times the saturated aquifer thickness b, as units of length squared over time. This property is generally estimated from field experimental data such as pumping tests. Tables 1 and 2 in How Darcy Flow and Darcy Velocity work list ranges of hydraulic conductivities for some generalized geologic materials. | Raster Layer |
| Output direction raster(Optional) | The output flow direction raster.Each cell value represents the direction of the seepage velocity vector (average linear velocity) at the center of the cell, calculated as the average value of the seepage velocity through the four faces of the cell.It is used with the output magnitude raster to describe the flow vector. | Raster Dataset |
| Output magnitude raster(Optional) | An optional output raster where each cell value represents the magnitude of the seepage velocity vector (average linear velocity) at the center of the cell, calculated as the average value of the seepage velocity through the four faces of the cell.It is used with the output direction raster to describe the flow vector. | Raster Dataset |
| in_head_raster | The input raster where each cell value represents the groundwater head elevation at that location.The head is typically an elevation above some datum, such as mean sea level. | Raster Layer |
| in_porosity_raster | The input raster where each cell value represents the effective formation porosity at that location. | Raster Layer |
| in_thickness_raster | The input raster where each cell value represents the saturated thickness at that location.The value for the thickness is interpreted from geological properties of the aquifer. | Raster Layer |
| in_transmissivity_raster | The input raster where each cell value represents the formation transmissivity at that location.The transmissivity of an aquifer is defined as the hydraulic conductivity K times the saturated aquifer thickness b, as units of length squared over time. This property is generally estimated from field experimental data such as pumping tests. Tables 1 and 2 in How Darcy Flow and Darcy Velocity work list ranges of hydraulic conductivities for some generalized geologic materials. | Raster Layer |
| out_direction_raster(Optional) | The output flow direction raster.Each cell value represents the direction of the seepage velocity vector (average linear velocity) at the center of the cell, calculated as the average value of the seepage velocity through the four faces of the cell.It is used with the output magnitude raster to describe the flow vector. | Raster Dataset |
| out_magnitude_raster(Optional) | An optional output raster where each cell value represents the magnitude of the seepage velocity vector (average linear velocity) at the center of the cell, calculated as the average value of the seepage velocity through the four faces of the cell.It is used with the output direction raster to describe the flow vector. | Raster Dataset |

## Code Samples

### Example 1

```python
DarcyFlow(in_head_raster, in_porosity_raster, in_thickness_raster, in_transmissivity_raster, {out_direction_raster}, {out_magnitude_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDarcyFlow = DarcyFlow("gwhead", "gwporo", "gwthick","gwtrans", 
                         "C:/sapyexamples/output/outdarcydir",
                         "C:/sapyexamples/output/outdarcymag")
outDarcyFlow.save("C:/sapyexamples/output/outdarcyflo")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDarcyFlow = DarcyFlow("gwhead", "gwporo", "gwthick","gwtrans", 
                         "C:/sapyexamples/output/outdarcydir",
                         "C:/sapyexamples/output/outdarcymag")
outDarcyFlow.save("C:/sapyexamples/output/outdarcyflo")
```

### Example 4

```python
# Name: DarcyFlow_Ex_02.py
# Description: Calculates the groundwater volume balance residual and other
#    outputs for steady flow in an aquifer.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inHeadRaster = "gwhead"
inPorosityRaster = "gwporo"
inThicknessRaster = "gwthick"
inTransmissivityRaster = "gwtrans"
outDirectionRaster = "C:/sapyexamples/output/outdarcydir"
outMagnitudeRaster = "C:/sapyexamples/output/outdarcymag"

# Execute DarcyFlow
outDarcyFlow = DarcyFlow(inHeadRaster, inPorosityRaster, inThicknessRaster,
                         inTransmissivityRaster, outDirectionRaster,
                         outMagnitudeRaster)

# Save the output 
outDarcyFlow.save("C:/sapyexamples/output/outdarcyflow")
```

### Example 5

```python
# Name: DarcyFlow_Ex_02.py
# Description: Calculates the groundwater volume balance residual and other
#    outputs for steady flow in an aquifer.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inHeadRaster = "gwhead"
inPorosityRaster = "gwporo"
inThicknessRaster = "gwthick"
inTransmissivityRaster = "gwtrans"
outDirectionRaster = "C:/sapyexamples/output/outdarcydir"
outMagnitudeRaster = "C:/sapyexamples/output/outdarcymag"

# Execute DarcyFlow
outDarcyFlow = DarcyFlow(inHeadRaster, inPorosityRaster, inThicknessRaster,
                         inTransmissivityRaster, outDirectionRaster,
                         outMagnitudeRaster)

# Save the output 
outDarcyFlow.save("C:/sapyexamples/output/outdarcyflow")
```

---

## Darcy Velocity (Spatial Analyst)

## Summary

Calculates the groundwater seepage velocity vector (direction and magnitude) for steady flow in an aquifer.

## Usage

- The differences between Darcy Flow and Darcy Velocity are:Darcy Flow produces an output volume raster; Darcy Velocity does not.Darcy Velocity outputs only direction and magnitude rasters as required output; Darcy Flow optionally produces these outputs.
- Darcy Flow produces an output volume raster; Darcy Velocity does not.
- Darcy Velocity outputs only direction and magnitude rasters as required output; Darcy Flow optionally produces these outputs.
- All input rasters must have the same extent and cell size.
- All input rasters must be floating point.
- The direction of the velocity vector is recorded in compass coordinates (degrees clockwise from north), the magnitude in units of length over time.
- No particular system of units is specified by this tool. Data should be consistent, using the same unit for time (seconds, days, years) and length (feet, meters) for all data.
- The head elevation raster can come from a variety of sources. It can be interpolated from observation well data by using one of the surface interpolation tools, such as Kriging or Spline. The head values can also be obtained from the results of a separate modeling program.However the head elevation raster is obtained, the head must be consistent with the transmissivity raster; that is, the head must reflect the flow through the transmissivity field. It is not sufficient to use values obtained by measurement and testing in the field—the rasterized values must be analyzed for consistency with the aid of a proper porous medium flow program. Consistency implies that the heads would actually be produced by the modeled transmissivity field. Since the true and modeled transmissivity fields often differ in practice, the true and modeled head fields differ, as well. Check the heads for consistency by examining the residual raster produced by Darcy Flow. The residual will reflect the consistency of the dataset. Any analysis using Darcy Velocity on inconsistent datasets will produce meaningless results.
- The effective porosity field, a physical property of the aquifer, is generally estimated from geological data. It is defined as the volume of void space that contributes to fluid flow divided by the entire volume. Porosity is expressed as a number between 0 and 1, with typical values around 0.35, and is dimensionless. A value of effective porosity of 0.35 means that 35 percent of the volume of the porous medium contributes to fluid flow. The remaining 65 percent, consisting of solid matrix and unconnected pores, does not contribute to fluid flow.
- The saturated thickness, measured in units of length, is interpreted from geological information. For a confined aquifer, this measure is the thickness of the formation between the upper and lower confining layers. For an unconfined aquifer, the saturated thickness is the distance between the water table and the lower confining layer.
- The output rasters are floating point.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input groundwater head elevation raster | The input raster where each cell value represents the groundwater head elevation at that location.The head is typically an elevation above some datum, such as mean sea level. | Raster Layer |
| Input effective formation porosity raster | The input raster where each cell value represents the effective formation porosity at that location. | Raster Layer |
| Input saturated thickness raster | The input raster where each cell value represents the saturated thickness at that location.The value for the thickness is interpreted from geological properties of the aquifer. | Raster Layer |
| Input formation transmissivity raster | The input raster where each cell value represents the formation transmissivity at that location.The transmissivity of an aquifer is defined as the hydraulic conductivity K times the saturated aquifer thickness b, as units of length squared over time. This property is generally estimated from field experimental data such as pumping tests. Tables 1 and 2 in How Darcy Flow and Darcy Velocity work list ranges of hydraulic conductivities for some generalized geologic materials. | Raster Layer |
| Output magnitude raster | The output flow direction raster.Each cell value represents the direction of the seepage velocity vector (average linear velocity) at the center of the cell, calculated as the average value of the seepage velocity through the four faces of the cell.It is used with the output magnitude raster to describe the flow vector. | Raster Dataset |
| in_head_raster | The input raster where each cell value represents the groundwater head elevation at that location.The head is typically an elevation above some datum, such as mean sea level. | Raster Layer |
| in_porosity_raster | The input raster where each cell value represents the effective formation porosity at that location. | Raster Layer |
| in_thickness_raster | The input raster where each cell value represents the saturated thickness at that location.The value for the thickness is interpreted from geological properties of the aquifer. | Raster Layer |
| in_transmissivity_raster | The input raster where each cell value represents the formation transmissivity at that location.The transmissivity of an aquifer is defined as the hydraulic conductivity K times the saturated aquifer thickness b, as units of length squared over time. This property is generally estimated from field experimental data such as pumping tests. Tables 1 and 2 in How Darcy Flow and Darcy Velocity work list ranges of hydraulic conductivities for some generalized geologic materials. | Raster Layer |
| out_magnitude_raster | The output flow direction raster.Each cell value represents the direction of the seepage velocity vector (average linear velocity) at the center of the cell, calculated as the average value of the seepage velocity through the four faces of the cell.It is used with the output magnitude raster to describe the flow vector. | Raster Dataset |

## Code Samples

### Example 1

```python
DarcyVelocity(in_head_raster, in_porosity_raster, in_thickness_raster, in_transmissivity_raster, out_magnitude_raster)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDarcyVelocity = DarcyVelocity("gwhead", "gwporo", "gwthick", "gwtrans", 
                            "C:/sapyexamples/output/outdarcymag")
outDarcyVelocity.save("c:/sapyexamples/output/outdarcyvel")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDarcyVelocity = DarcyVelocity("gwhead", "gwporo", "gwthick", "gwtrans", 
                            "C:/sapyexamples/output/outdarcymag")
outDarcyVelocity.save("c:/sapyexamples/output/outdarcyvel")
```

### Example 4

```python
# Name: DarcyVelocity_Ex_02.py
# Description: Calculates the groundwater seepage velocity 
#              vector (direction and magnitude) for steady 
#              flow in an aquifer.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inHeadRaster = "gwhead"
inPorosityRaster = "gwporo"
inThicknessRaster = "gwthick"
inTransmissivityRaster = "gwtrans"
outMagnitudeRaster = "C:/sapyexamples/output/outdarcymag"

# Execute DarcyVelocity
outDarcyVelocity = DarcyVelocity(inHeadRaster, inPorosityRaster, inThicknessRaster,
                            inTransmissivityRaster, outMagnitudeRaster)

# Save the output 
outDarcyVelocity.save("C:/sapyexamples/output/outdarcyvel")
```

### Example 5

```python
# Name: DarcyVelocity_Ex_02.py
# Description: Calculates the groundwater seepage velocity 
#              vector (direction and magnitude) for steady 
#              flow in an aquifer.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inHeadRaster = "gwhead"
inPorosityRaster = "gwporo"
inThicknessRaster = "gwthick"
inTransmissivityRaster = "gwtrans"
outMagnitudeRaster = "C:/sapyexamples/output/outdarcymag"

# Execute DarcyVelocity
outDarcyVelocity = DarcyVelocity(inHeadRaster, inPorosityRaster, inThicknessRaster,
                            inTransmissivityRaster, outMagnitudeRaster)

# Save the output 
outDarcyVelocity.save("C:/sapyexamples/output/outdarcyvel")
```

---

## Deep Learning Model To Ecd (Spatial Analyst)

## Summary

Converts a deep learning model to an Esri classifier definition file (.ecd).

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Deep Learning Model File | The binary model file generated by a deep learning package such as Google TensorFlow, Microsoft CNTK, or similar application. | File |
| Input Esri Extra Info File | The class information JSON file. See the JSON file example above. | File |
| Output Classifier Definition File | The .ecd file that can be used in the Classify function and Classify Raster tool.The .ecd output file only works as input to the Esri Python Classify or Detect adaptor function. | File |
| in_deep_learning_model | The binary model file generated by a deep learning package such as Google TensorFlow, Microsoft CNTK, or similar application. | File |
| in_classification_info_json | The class information JSON file. See the JSON file example above. | File |
| out_classifier_definition | The .ecd file that can be used in the Classify function and Classify Raster tool.The .ecd output file only works as input to the Esri Python Classify or Detect adaptor function. | File |

## Code Samples

### Example 1

```python
{  
   "ImportDeepLearningModelToEsriExtraInfo":0,
   "Version":1,
   "Classifier":"CNTK",
   "NumberRasterBands":4,
   "MiniBatchSize":16,
   "Classes":[  
      {  
         "Value":100,
         "Name":"Impervious",
         "Color":[204, 204, 204]
      },
      {  
         "Value":200,
         "Name":" Other (Pervious)",
         "Color":[56, 168, 0]
      }
   ]
}
```

### Example 2

```python
{  
   "ImportDeepLearningModelToEsriExtraInfo":0,
   "Version":1,
   "Classifier":"CNTK",
   "NumberRasterBands":4,
   "MiniBatchSize":16,
   "Classes":[  
      {  
         "Value":100,
         "Name":"Impervious",
         "Color":[204, 204, 204]
      },
      {  
         "Value":200,
         "Name":" Other (Pervious)",
         "Color":[56, 168, 0]
      }
   ]
}
```

### Example 3

```python
DeepLearningModelToEcd(in_deep_learning_model, in_classification_info_json, out_classifier_definition)
```

### Example 4

```python
from arcpy.sa import *

DeepLearningModelToEcd("c:/test/cntk.model", "c:/test/classInfo.json", 
                       "c:/test/deeplearningtoecd.ecd")
```

### Example 5

```python
from arcpy.sa import *

DeepLearningModelToEcd("c:/test/cntk.model", "c:/test/classInfo.json", 
                       "c:/test/deeplearningtoecd.ecd")
```

### Example 6

```python
# Import system modules and check out ArcGIS Spatial Analyst extension license
import arcpy
arcpy.CheckOutExtension("Spatial")
from arcpy.sa import *

# Set local variables
in_deep_learning_model = "c:/test/cntk.model"
in_classification_info_json = "c:/test/classInfo.json"
out_classifier_definition = "c:/test/deeplearningtoecd.ecd"

# Execute 
DeepLearningModelToEcd(in_deep_learning_model, in_classification_info_json, 
                      out_classifier_definition)
```

### Example 7

```python
# Import system modules and check out ArcGIS Spatial Analyst extension license
import arcpy
arcpy.CheckOutExtension("Spatial")
from arcpy.sa import *

# Set local variables
in_deep_learning_model = "c:/test/cntk.model"
in_classification_info_json = "c:/test/classInfo.json"
out_classifier_definition = "c:/test/deeplearningtoecd.ecd"

# Execute 
DeepLearningModelToEcd(in_deep_learning_model, in_classification_info_json, 
                      out_classifier_definition)
```

---

## Dendrogram (Spatial Analyst)

## Summary

Constructs a tree diagram (dendrogram) showing attribute distances between sequentially merged classes in a signature file.

## Usage

- The input signature file must in the prescribed signature file format. A signature file can be created with the Iso Cluster or Create Signatures tools. The file must have a minimum of two classes. A signature file can be recognized by its .gsg extension.
- The output of Dendrogram is an ASCII text file. The file has two components: a table and a graph.The first component is a table of distances between pairs of classes, presented in the sequence for merging. The second component is a graphical representation using ASCII characters of the classes that demonstrates the relationships and the hierarchy of the merging. The graph illustrates relative distances between pairs of merged classes in the signature file, which are based on statistically determined similarities. The classes themselves represent clusters of cells or cells from training samples extracted from the study site.By analyzing the graph and the associate table, you can determine the potential of merging classes.
- The default extension for the output text file is .txt. It can also be .asc.
- The proximity of a pair of classes within a signature file is measured by the attribute distance.
- The value entered for the line width specifies the width of the graph based on the number of characters. The default value of 78 is also the minimum valid number of characters. If numbers less than this are entered, the default value of 78 will be applied. When specifying values higher than the default, the resolution of the graph will increase, which may provide more accurate interpolation of the distances.
- To make the display of the dendrogram meaningful, the ASCII file should be displayed with a nonproportional font such as Courier.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input signature file | Input signature file whose class signatures are used to produce a dendrogram.A .gsg extension is required. | File |
| Output dendrogram file | The output dendrogram ASCII file.The extension can be .txt or .asc. | File |
| Use variance in distance calculations(Optional) | Specifies the manner in which the distances between classes in multidimensional attribute space are defined.Checked—The distances between classes will be computed based on the variances and the Euclidean distance between the means of their signatures. Unchecked—The distances between classes will be determined by the Euclidean distances between the means of the class signatures only. | Boolean |
| Line width of dendrogram(Optional) | Sets the width of the dendrogram in number of characters on a line.The default is 78. | Long |
| in_signature_file | Input signature file whose class signatures are used to produce a dendrogram.A .gsg extension is required. | File |
| out_dendrogram_file | The output dendrogram ASCII file.The extension can be .txt or .asc. | File |
| distance_calculation(Optional) | Specifies the manner in which the distances between classes in multidimensional attribute space are defined.VARIANCE— The distances between classes will be computed based on the variances and the Euclidean distance between the means of their signatures. MEAN_ONLY— The distances between classes will be determined by the Euclidean distances between the means of the class signatures only. | Boolean |
| line_width(Optional) | Sets the width of the dendrogram in number of characters on a line.The default is 78. | Long |

## Code Samples

### Example 1

```python
Dendrogram(in_signature_file, out_dendrogram_file, {distance_calculation}, {line_width})
```

### Example 2

```python
import arcpy
from arcpy.sa import *
Dendrogram("c:/sapyexamples/data/zsamp12.gsg", 
           "c:/sapyexamples/output/z12dendro.txt", "VARIANCE", "")
```

### Example 3

```python
import arcpy
from arcpy.sa import *
Dendrogram("c:/sapyexamples/data/zsamp12.gsg", 
           "c:/sapyexamples/output/z12dendro.txt", "VARIANCE", "")
```

### Example 4

```python
# Name: Dendrogram_Ex_02.py
# Description: Constructs a tree diagram showing attribute distances between
#     sequentially merged classes in a signature file.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set local variables
inSig = "c:/sapyexamples/data/zsamp12.gsg"
outDendro = "c:/sapyexamples/output/z12dend.txt"
lineLength = ""

# Execute Dendrogram
Dendrogram(inSig, outDendro, "VARIANCE", lineLength)
```

### Example 5

```python
# Name: Dendrogram_Ex_02.py
# Description: Constructs a tree diagram showing attribute distances between
#     sequentially merged classes in a signature file.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set local variables
inSig = "c:/sapyexamples/data/zsamp12.gsg"
outDendro = "c:/sapyexamples/output/z12dend.txt"
lineLength = ""

# Execute Dendrogram
Dendrogram(inSig, outDendro, "VARIANCE", lineLength)
```

---

## Derive Continuous Flow (Spatial Analyst)

## Summary

Generates a raster of accumulated flow into each cell from an input surface raster with no prior sink or depression filling required.

## Usage

- The input surface raster can be a digital elevation model (DEM) with no prior sink filling or a hydroconditioned DEM. The tool is not sensitive to errors in the surface raster that can act as depressions or sinks where flow terminates; filling sinks or depressions is not necessary.
- Flow direction and flow accumulation are derived on a cell-by-cell basis by optimally traversing the input surface raster by following the direction of the minimum upslope neighbor (Metz et al., 2011; Ehlschlaeger, 1989).
- The Output flow accumulation raster (out_accumulation_raster in Python) value is the primary output. This is a raster representing the accumulated flow at each cell as determined by accumulating the weight for all cells that flow into each cell. The current processing cell is not considered in this accumulation.
- You can save flow direction raster output by specifying the Output flow direction raster (out_flow_direction_raster in Python) value. This raster represents the direction of flow.
- An Input accumulation weight raster (in_weight_raster in Python) value can be specified to apply a weight to each cell when deriving flow accumulation.
- When the input surface raster contains real depressions within the surface raster, the depressions must be specified in Input raster or feature depressions data (in_depressions_data in Python) to be considered cells where water can flow into but not outward (an outlet). Depression area information can be either a raster or a feature class. The feature class can be a point, polyline, or polygon.
- The Derive Continuous Flow tool supports the D8 and multiple flow direction (MFD) flow direction modeling algorithms.When the D8 option is specified for Flow direction type (flow_direction_type in Python), flow can take a single direction, which is toward the steepest drop. The steepest drop is calculated by taking the difference in z-value divided by the path length between cell centers (1 for cardinal cells and the square root of 2 for diagonal cells) (Jenson and Domingue, 1988) . The output raster takes only integer values from 1 to 255. The values from the center of each direction are specified in the following diagram:If a cell has the same change in z-value in multiple directions, the D8 flow direction is undefined. In this case, the value for such cell in the output flow direction raster will be the sum of the possible directions.When the MFD option is specified for Flow direction type, flow is partitioned across all downslope neighbors. Flow partition across neighboring cells (as a fraction) is estimated as a function of maximum slope gradient, which considers local terrain conditions (Qin et al., 2007). The output flow direction raster takes only integer values showing the predominant flow direction (toward the cell that receives the largest fraction of flow according to the partition scheme) for ease of interpretation. However, the Output flow accumulation raster parameter value reflects the flow partition scheme.
- When the D8 option is specified for Flow direction type (flow_direction_type in Python), flow can take a single direction, which is toward the steepest drop. The steepest drop is calculated by taking the difference in z-value divided by the path length between cell centers (1 for cardinal cells and the square root of 2 for diagonal cells) (Jenson and Domingue, 1988) . The output raster takes only integer values from 1 to 255. The values from the center of each direction are specified in the following diagram:If a cell has the same change in z-value in multiple directions, the D8 flow direction is undefined. In this case, the value for such cell in the output flow direction raster will be the sum of the possible directions.
- When the MFD option is specified for Flow direction type, flow is partitioned across all downslope neighbors. Flow partition across neighboring cells (as a fraction) is estimated as a function of maximum slope gradient, which considers local terrain conditions (Qin et al., 2007). The output flow direction raster takes only integer values showing the predominant flow direction (toward the cell that receives the largest fraction of flow according to the partition scheme) for ease of interpretation. However, the Output flow accumulation raster parameter value reflects the flow partition scheme.
- With the Force all edge cells to flow outward parameter unchecked (force_flow = "NORMAL" in Python), the default setting, a cell at the edge of the surface raster will flow toward the inner cell with the steepest drop in z-value. If the drop is less than or equal to zero, the cell will flow out of the surface raster.
- NoData cells are considered noise and by definition do not have an associated value. The tool will ignore these cells when identifying the direction of the least steep uphill neighbor, as well as in the determination of flow direction and accumulation.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- References:Ehlschlaeger, C. R. 1989. "Using the AT Search Algorithm to Develop Hydrologic Models from Digital Elevation Data." International Geographic Information Systems (IGIS) Symposium 89: 275-281.Jenson, S. K., and Domingue, J. O. 1988. "Extracting Topographic Structure from Digital Elevation Data for Geographic Information System Analysis." Photogrammetric Engineering and Remote Sensing 54 (11): 1593–1600.Metz, M., Mitasova, H., & Harmon, R. S. 2011. "Efficient extraction of drainage networks from massive, radar-based elevation models with least cost path search." Hydrology and Earth System Sciences 15(2): 667-678.Qin, C., Zhu, A. X., Pei, T., Li, B., Zhou, C., & Yang, L. 2007. "An adaptive approach to selecting a flow partition exponent for a multiple flow direction algorithm." International Journal of Geographical Information Science 21(4): 443-458.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input surface raster | The input raster representing a continuous surface. | Raster Layer |
| Input raster or feature depressions data(Optional) | An optional dataset that defines real depressions.The depressions can be defined either through a raster or a feature layer.If input is a raster, the depression cells must take a valid value, including zero, and the areas that are not depressions must be NoData. | Composite Geodataset |
| Input accumulation weight raster(Optional) | An optional input raster dataset that defines the fraction of flow that contributes to flow accumulation at each cell.The weight is only applied to the accumulation of flow.If no accumulation weight raster is specified, a default weight of 1 will be applied to each cell. | Raster Layer |
| Output flow direction raster(Optional) | The output raster that shows the direction of flow at each cell using the D8 or Multiple Flow Direction (MFD) method.The output is of integer type. | Raster Dataset |
| Flow direction type(Optional) | Specifies the type of flow method that will be used when computing flow directions.D8—Flow direction will be determined by the D8 method. This method assigns flow direction to the steepest downslope neighbor. This is the default.MFD—Flow direction will be based on the MFD flow method. Flow direction will be partitioned across downslope neighbors according to an adaptive partition exponent. | String |
| Force all edge cells to flow outward(Optional) | Specifies whether edge cells will always flow outward or follow normal flow rules.Unchecked—If the maximum drop on the inside of an edge cell is greater than zero, the flow direction will be determined as usual; otherwise, the flow direction will be toward the edge. Cells that should flow from the edge of the surface raster inward will do so. This is the default.Checked—All cells at the edge of the surface raster will flow outward from the surface raster. | Boolean |
| in_surface_raster | The input raster representing a continuous surface. | Raster Layer |
| in_depressions_data(Optional) | An optional dataset that defines real depressions.The depressions can be defined either through a raster or a feature layer.If input is a raster, the depression cells must take a valid value, including zero, and the areas that are not depressions must be NoData. | Composite Geodataset |
| in_weight_raster(Optional) | An optional input raster dataset that defines the fraction of flow that contributes to flow accumulation at each cell.The weight is only applied to the accumulation of flow.If no accumulation weight raster is specified, a default weight of 1 will be applied to each cell. | Raster Layer |
| out_flow_direction_raster(Optional) | The output raster that shows the direction of flow at each cell using the D8 or Multiple Flow Direction (MFD) method.The output is of integer type. | Raster Dataset |
| flow_direction_type(Optional) | Specifies the type of flow method that will be used when computing flow directions.D8—Flow direction will be determined by the D8 method. This method assigns flow direction to the steepest downslope neighbor. This is the default.MFD—Flow direction will be based on the MFD flow method. Flow direction will be partitioned across downslope neighbors according to an adaptive partition exponent. | String |
| force_flow(Optional) | Specifies whether edge cells will always flow outward or follow normal flow rules. NORMAL—If the maximum drop on the inside of an edge cell is greater than zero, the flow direction will be determined as usual; otherwise, the flow direction will be toward the edge. Cells that should flow from the edge of the surface raster inward will do so. This is the default.FORCE—All cells at the edge of the surface raster will flow outward from the surface raster. | Boolean |

## Code Samples

### Example 1

```python
DeriveContinuousFlow(in_surface_raster, {in_depressions_data}, {in_weight_raster}, {out_flow_direction_raster}, {flow_direction_type}, {force_flow})
```

### Example 2

```python
from arcpy.sa import *
out_derivecontinuousflow_raster = DeriveContinuousFlow("surface.tif", "", "",
                                 "", "", "")
out_derivecontinuousflow_raster.save("C:/arcpyExamples/outputs/out_facc.tif")
```

### Example 3

```python
from arcpy.sa import *
out_derivecontinuousflow_raster = DeriveContinuousFlow("surface.tif", "", "",
                                 "", "", "")
out_derivecontinuousflow_raster.save("C:/arcpyExamples/outputs/out_facc.tif")
```

### Example 4

```python
# Name: DeriveContinuousFlow_standalone.py
# Description: Generates a flow accumulation raster considering real depressions
#              specified through a raster dataset.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/arcpyExamples/data"

# Set the local variables
in_surface_raster = "surface.tif"
in_depressions_data = "depressions.tif"

# Execute DeriveContinuousFlow
out_derivecontinuousflow_raster = DeriveContinuousFlow(in_surface_raster, in_depressions_data,
                                 "", "", "", "")

# Save the output
out_derivecontinuousflow_raster.save("C:/arcpyExamples/outputs/out_facc.tif")
```

### Example 5

```python
# Name: DeriveContinuousFlow_standalone.py
# Description: Generates a flow accumulation raster considering real depressions
#              specified through a raster dataset.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/arcpyExamples/data"

# Set the local variables
in_surface_raster = "surface.tif"
in_depressions_data = "depressions.tif"

# Execute DeriveContinuousFlow
out_derivecontinuousflow_raster = DeriveContinuousFlow(in_surface_raster, in_depressions_data,
                                 "", "", "", "")

# Save the output
out_derivecontinuousflow_raster.save("C:/arcpyExamples/outputs/out_facc.tif")
```

---

## Derive Stream As Line (Spatial Analyst)

## Summary

Generates stream line features from an input surface raster with no prior sink or depression filling required.

## Usage

- The input surface raster can be a digital elevation model (DEM) with no prior sink filling or a hydroconditioned DEM. The tool is not sensitive to errors in the surface raster that can act as depressions or sinks where flow terminates; filling sinks or depressions is not necessary.
- The Output stream features parameter produces an output polyline feature that corresponds to stream lines that met the accumulation threshold, specified through the optional Accumulation threshold (accumulation_threshold in Python) parameter. If no Accumulation threshold value is provided, the tool calculates an area threshold based on the input surface raster size (0.2 percent of the total number of cells) by default While flow direction and accumulation will be calculated internally to derive streams, they are not an output. Use Derive Continuous Flow to obtain flow accumulation and flow direction rasters using the same methodology.
- When the input surface raster contains real depressions within the surface raster, the depressions must be specified in Input raster or feature depressions data (in_depressions_data in Python) to be considered cells where water can flow into but not outward (an outlet). Depression area information can be either a raster or a feature class. The feature class can be a point, polyline, or polygon.
- An Input accumulation weight raster (in_weight_raster in Python) value can be specified to apply a weight to each cell when deriving accumulation, which is an intermediate step. If a weight raster is applied, select an appropriate flow accumulation threshold for Accumulation threshold (accumulation_threshold in Python).
- Specify an Accumulation threshold (accumulation_threshold in Python) value that reflects the complexity of the terrain in the study area or that matches the size of a contributing area of your choice. For example, if the threshold is equal to 20 hectares, only cells with 20 or more hectares of upstream flow will define a stream raster
- If the Input raster or features depressions data parameter, the Input accumulation weight raster parameter, or data to apply environment settings is used, the default Accumulation threshold value will be recalculated based on the area of intersection between the inputs. However, once you specify a value for the Accumulation threshold parameter, it will no longer be recalculated based on changes in input selection. You may encounter the same situation when running the tool in batch mode using the Input surface raster value as a batch parameter in which the Accumulation threshold value will be calculated based on the first input and will not change as other raster layers are processed in batch mode.
- Use the Stream designation method parameter to assign a unique value of stream sections between intersections or an order to the segments of streams. The Constant option is the default value, and all streams are assigned the same value equal to 1. When Unique is specified, each stream section between intersections will be assigned a unique value. Additional ordering methods are Strahler, Shreve, and Hack. The Strahler method increases the order of a stream when streams of the same order intersect. The Shreve method assigns order to streams based on magnitude. All links with no tributaries are assigned a magnitude (order) of one. Magnitudes are additive downslope. When two links intersect, their magnitudes are added and assigned to the downslope link. The Hack method increases the order of a stream by one with respect to the order of a stream to which it discharges. The main river channel is assigned a magnitude of 1, and all streams discharging to it are assigned a magnitude of 2, and so on.
- When the Simplify features parameter is checked (simplify in Python), the output stream feature lines will be simplified by removing vertices using the Douglas-Peucker algorithm with a tolerance of sqrt(0.5) * cell size. This algorithm retains critical points by identifying and removing relatively redundant vertices.
- NoData cells are considered noise and by definition do not have an associated value. The tool will ignore these cells when identifying the direction of the least steep uphill neighbor, as well as in the determination of flow direction and accumulation.
- With the Force all edge cells to flow outward parameter unchecked (force_flow = "NORMAL" in Python), the default setting, a cell at the edge of the surface raster will flow toward the inner cell with the steepest drop in z-value. If the drop is less than or equal to zero, the cell will flow out of the surface raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- References: Douglas, David H., and Thomas K. Peucker. 1973. "Algorithms for the Reduction of the Number of Points Required to Represent a Digitised Line or its Caricature." The Canadian Cartographer, 10(2): 112–122.Ehlschlaeger, C. R. 1989. "Using the AT Search Algorithm to Develop Hydrologic Models from Digital Elevation Data." International Geographic Information Systems (IGIS) Symposium 89: 275-281.Hack, J. T. 1957. "Studies of Longitudinal Stream Profiles in Virginia and Maryland." Geological Survey Professional Paper 294: 45–95.Jenson, S. K., and Domingue, J. O. 1988. "Extracting Topographic Structure from Digital Elevation Data for Geographic Information System Analysis." Photogrammetric Engineering and Remote Sensing 54 (11): 1593–1600.Metz, M., Mitasova, H., & Harmon, R. S. 2011. "Efficient extraction of drainage networks from massive, radar-based elevation models with least cost path search." Hydrology and Earth System Sciences 15(2): 667-678.Shreve, R. 1966. "Statistical Law of Stream Numbers" Journal of Geology.74: 17-35Strahler, A. N. 1957. "Quantitative analysis of watershed geomorphology" Transactions of the American Geophysical Union8 (6): 913-920
- Douglas, David H., and Thomas K. Peucker. 1973. "Algorithms for the Reduction of the Number of Points Required to Represent a Digitised Line or its Caricature." The Canadian Cartographer, 10(2): 112–122.
- Ehlschlaeger, C. R. 1989. "Using the AT Search Algorithm to Develop Hydrologic Models from Digital Elevation Data." International Geographic Information Systems (IGIS) Symposium 89: 275-281.
- Hack, J. T. 1957. "Studies of Longitudinal Stream Profiles in Virginia and Maryland." Geological Survey Professional Paper 294: 45–95.
- Jenson, S. K., and Domingue, J. O. 1988. "Extracting Topographic Structure from Digital Elevation Data for Geographic Information System Analysis." Photogrammetric Engineering and Remote Sensing 54 (11): 1593–1600.
- Metz, M., Mitasova, H., & Harmon, R. S. 2011. "Efficient extraction of drainage networks from massive, radar-based elevation models with least cost path search." Hydrology and Earth System Sciences 15(2): 667-678.
- Shreve, R. 1966. "Statistical Law of Stream Numbers" Journal of Geology.74: 17-35
- Strahler, A. N. 1957. "Quantitative analysis of watershed geomorphology" Transactions of the American Geophysical Union8 (6): 913-920

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input surface raster | The input surface raster. | Raster Layer |
| Output polyline features | The output feature class that will contain the identified streams. | Feature Class |
| Input raster or feature depressions data(Optional) | An optional dataset that defines real depressions.The depressions can be defined either through a raster or a feature layer.If input is a raster, the depression cells must take a valid value, including zero, and the areas that are not depressions must be NoData. | Composite Geodataset |
| Input accumulation weight raster(Optional) | An optional input raster dataset that defines the fraction of flow that contributes to flow accumulation at each cell.The weight is only applied to the accumulation of flow.If no accumulation weight raster is specified, a default weight of 1 will be applied to each cell. | Raster Layer |
| Accumulation threshold(Optional) | The threshold for determining whether a given cell is part of a stream in terms of the total area that flows into such cell. | Areal Unit |
| Stream designation method(Optional) | Specifies the unique value or order of the streams in the output attribute table.Constant—The output stream segments will all equal 1. This is the default.Unique—Each stream will have a unique ID between intersections in the output.Strahler—The Strahler method, in which stream order only increases when streams of the same order intersect, will be used. The intersection of a first-order and second-order link will remain a second-order link, rather than creating a third-order link.Shreve—The Shreve method, in which stream order is assigned by magnitude, will be used. All links with no tributaries are assigned a magnitude (order) of one. Magnitudes are additive downslope. When two links intersect, their magnitudes are added and assigned to the downslope link.Hack—The Hack method, in which each stream segment is assigned an order greater than the stream or river to which it discharges, will be used. For example, the main river channel is assigned an order of 1, all stream segments discharging to it are assigned an order of 2, any stream discharging to an order 2 stream is assigned an order of 3, and so on.All—The output attribute table will show each stream segment designation based on all methods. | String |
| Simplify features(Optional) | Specifies whether the output stream lines will be smoothed into simpler shapes. Checked—The stream feature lines will be simplified using the Douglas-Peucker algorithm with a tolerance of sqrt(0.5) * cell size. This is the default.Unchecked—The stream feature lines will not be smoothed. | Boolean |
| in_surface_raster | The input surface raster. | Raster Layer |
| out_stream_features | The output feature class that will contain the identified streams. | Feature Class |
| in_depressions_data(Optional) | An optional dataset that defines real depressions.The depressions can be defined either through a raster or a feature layer.If input is a raster, the depression cells must take a valid value, including zero, and the areas that are not depressions must be NoData. | Composite Geodataset |
| in_weight_raster(Optional) | An optional input raster dataset that defines the fraction of flow that contributes to flow accumulation at each cell.The weight is only applied to the accumulation of flow.If no accumulation weight raster is specified, a default weight of 1 will be applied to each cell. | Raster Layer |
| accumulation_threshold(Optional) | The threshold for determining whether a given cell is part of a stream in terms of the total area that flows into such cell. | Areal Unit |
| stream_designation_method(Optional) | Specifies the unique value or order of the streams in the output attribute table.CONSTANT—The output stream segments will all equal 1. This is the default.UNIQUE—Each stream will have a unique ID between intersections in the output.STRAHLER—The Strahler method, in which stream order only increases when streams of the same order intersect, will be used. The intersection of a first-order and second-order link will remain a second-order link, rather than creating a third-order link.SHREVE—The Shreve method, in which stream order is assigned by magnitude, will be used. All links with no tributaries are assigned a magnitude (order) of one. Magnitudes are additive downslope. When two links intersect, their magnitudes are added and assigned to the downslope link.HACK—The Hack method, in which each stream segment is assigned an order greater than the stream or river to which it discharges, will be used. For example, the main river channel is assigned an order of 1, all stream segments discharging to it are assigned an order of 2, any stream discharging to an order 2 stream is assigned an order of 3, and so on.ALL—The output attribute table will show each stream segment designation based on all methods. | String |
| simplify(Optional) | Specifies whether the output stream lines will be smoothed into simpler shapes.NO_SIMPLIFY—The stream feature lines will not be smoothed.SIMPLIFY—The stream feature lines will be simplified using the Douglas-Peucker algorithm with a tolerance of sqrt(0.5) * cell size. This is the default. | Boolean |

## Code Samples

### Example 1

```python
DeriveStreamAsLine(in_surface_raster, out_stream_features, {in_depressions_data}, {in_weight_raster}, {accumulation_threshold}, {stream_designation_method}, {simplify})
```

### Example 2

```python
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapy/examples/data" 
DeriveStreamAsLine("surface.tif", "C:/sapyexamples/output/streams.shp", "", "", "", "")
```

### Example 3

```python
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapy/examples/data" 
DeriveStreamAsLine("surface.tif", "C:/sapyexamples/output/streams.shp", "", "", "", "")
```

### Example 4

```python
# Name: DeriveStreamAsLine_standalone.py
# Description: Generates stream lines from an input surface raster without prior sink filling. 
#              The streams start from locations where the accumulated flow is collected from an area 
#              larger or equal to 2 Hectares considering depressions (polygons).
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
env.workspace = "C:/sapyexamples/data"

# Set the local variables
in_surface_raster = "surface.tif"
in_depressions_data = "depressions.shp"
in_weight_raster = ""
out_streams = "C:/sapyexamples/output/streams.shp"
area_threshold = "2 Hectares"
stream_designation_method = "CONSTANT"

# Execute
DeriveStreamAsLine(in_surface_raster, out_streams, in_depressions_data, 
                   in_weight_raster, area_threshold, stream_designation_method)
```

### Example 5

```python
# Name: DeriveStreamAsLine_standalone.py
# Description: Generates stream lines from an input surface raster without prior sink filling. 
#              The streams start from locations where the accumulated flow is collected from an area 
#              larger or equal to 2 Hectares considering depressions (polygons).
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
env.workspace = "C:/sapyexamples/data"

# Set the local variables
in_surface_raster = "surface.tif"
in_depressions_data = "depressions.shp"
in_weight_raster = ""
out_streams = "C:/sapyexamples/output/streams.shp"
area_threshold = "2 Hectares"
stream_designation_method = "CONSTANT"

# Execute
DeriveStreamAsLine(in_surface_raster, out_streams, in_depressions_data, 
                   in_weight_raster, area_threshold, stream_designation_method)
```

---

## Derive Stream As Raster (Spatial Analyst)

## Summary

Generates a stream raster from an input surface raster with no prior sink or depression filling required.

## Usage

- The input surface raster can be a digital elevation model (DEM) with no prior sink filling or a hydroconditioned DEM. The tool is not sensitive to errors in the surface raster that can act as depressions or sinks where flow terminates; filling sinks or depressions is not necessary.
- The Output stream raster parameter value represents the cells with a higher or equal flow accumulation threshold, specified through the optional Accumulation threshold (accumulation_threshold in Python) parameter. If no Accumulation threshold value is provided, by default, the tool calculates an area threshold based on the input surface raster size (0.2 percent of the total number of cells). While flow direction and accumulation are calculated internally to derive streams, they are not an output. Use Derive Continuous Flow to obtain flow accumulation and flow direction rasters using the same methodology.
- When the input surface raster contains real depressions within the surface raster, the depressions must be specified in Input raster or feature depressions data (in_depressions_data in Python) to be considered cells where water can flow into but not outward (an outlet). Depression area information can be either a raster or a feature class. The feature class can be a point, polyline, or polygon.
- An Input accumulation weight raster (in_weight_raster in Python) value can be specified to apply a weight to each cell when deriving accumulation, which is an intermediate step. If a weight raster is applied, select an appropriate flow accumulation threshold for Accumulation threshold (accumulation_threshold in Python).
- If Input raster or features depressions data, Input accumulation weight raster parameters or data to apply environment settings is used, the default Accumulation threshold will be recalculated based on the area of intersection between the inputs. However, once you have specified a value for the Accumulation threshold, it will no longer be recalculated based on changes in input selection. You may encounter the same situation when running the tool in batch using the Input surface raster as batch parameter, where the Accumulation threshold is calculated based on the first input and will not change as other raster layers are being processed in batch.
- Specify an Accumulation threshold (accumulation_threshold in Python) value that reflects the complexity of the terrain in the study area or that matches the size of a contributing area of your choice. For example, if the threshold is equal to 20 hectares, only cells with 20 or more hectares of upstream flow will define a stream raster
- Use the Stream designation method parameter to assign a unique value of stream sections between intersections or an order to the segments of streams. The Constant option is set by default, and all streams are assigned the same value equal to 1. When Unique is selected, each stream section between intersections will be assigned a unique value. Additional ordering methods are Strahler, Shreve, and Hack (Strahler, 1957; Shreve, 1966; Hack, 1957). The Strahler order of a stream increases when streams of the same order intersect. The Shreve order assigns order to streams based on magnitude. All links with no tributaries are assigned a magnitude (order) of one. Magnitudes are additive downslope. When two links intersect, their magnitudes are added and assigned to the downslope link. The Hack order of a stream increases by one with respect to the order of a stream to which it discharges. The main river channel is assigned a magnitude of 1, and all streams discharging to it are assigned a magnitude of 2, and so on.
- NoData cells are considered noise and by definition do not have an associated value. The tool will ignore these cells when identifying the direction of the least steep uphill neighbor, as well as in the determination of flow direction and accumulation.
- With the Force all edge cells to flow outward parameter unchecked (force_flow = "NORMAL" in Python), the default setting, a cell at the edge of the surface raster will flow toward the inner cell with the steepest drop in z-value. If the drop is less than or equal to zero, the cell will flow out of the surface raster.This will affect the direction of flow at the edge of the surface raster, as well as the accumulation and ultimately the definition of streams.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- References:Ehlschlaeger, C. R. 1989. "Using the AT Search Algorithm to Develop Hydrologic Models from Digital Elevation Data." International Geographic Information Systems (IGIS) Symposium 89: 275-281.Hack, J. T. 1957. "Studies of Longitudinal Stream Profiles in Virginia and Maryland." Geological Survey Professional Paper 294: 45–95.Jenson, S. K., and Domingue, J. O. 1988. "Extracting Topographic Structure from Digital Elevation Data for Geographic Information System Analysis." Photogrammetric Engineering and Remote Sensing 54 (11): 1593–1600.Metz, M., Mitasova, H., & Harmon, R. S. 2011. "Efficient extraction of drainage networks from massive, radar-based elevation models with least cost path search." Hydrology and Earth System Sciences 15(2): 667-678.Shreve, R. 1966. "Statistical Law of Stream Numbers" Journal of Geology.74: 17-35Strahler, A. N. 1957. "Quantitative analysis of watershed geomorphology" Transactions of the American Geophysical Union8 (6): 913-920
- Ehlschlaeger, C. R. 1989. "Using the AT Search Algorithm to Develop Hydrologic Models from Digital Elevation Data." International Geographic Information Systems (IGIS) Symposium 89: 275-281.
- Hack, J. T. 1957. "Studies of Longitudinal Stream Profiles in Virginia and Maryland." Geological Survey Professional Paper 294: 45–95.
- Jenson, S. K., and Domingue, J. O. 1988. "Extracting Topographic Structure from Digital Elevation Data for Geographic Information System Analysis." Photogrammetric Engineering and Remote Sensing 54 (11): 1593–1600.
- Metz, M., Mitasova, H., & Harmon, R. S. 2011. "Efficient extraction of drainage networks from massive, radar-based elevation models with least cost path search." Hydrology and Earth System Sciences 15(2): 667-678.
- Shreve, R. 1966. "Statistical Law of Stream Numbers" Journal of Geology.74: 17-35
- Strahler, A. N. 1957. "Quantitative analysis of watershed geomorphology" Transactions of the American Geophysical Union8 (6): 913-920

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input surface raster | The input surface raster. | Raster Layer |
| Input raster or feature depressions data(Optional) | An optional dataset that defines real depressions.The depressions can be defined either through a raster or a feature layer.If input is a raster, the depression cells must take a valid value, including zero, and the areas that are not depressions must be NoData. | Composite Geodataset |
| Input accumulation weight raster(Optional) | An optional input raster dataset that defines the fraction of flow that contributes to flow accumulation at each cell.The weight is only applied to the accumulation of flow.If no accumulation weight raster is specified, a default weight of 1 will be applied to each cell. | Raster Layer |
| Accumulation threshold(Optional) | The threshold for determining whether a given cell is part of a stream in terms of the total area that flows into such cell. | Areal Unit |
| Stream designation method(Optional) | Specifies the unique or order of the streams in the output.Constant—The output cell values will all equal 1. This is the default.Unique—Each stream will have a unique ID between intersections in the output.Strahler—The Strahler method, in which stream order only increases when streams of the same order intersect, will be used. The intersection of a first-order and second-order link will remain a second-order link, rather than creating a third-order link.Shreve—The Shreve method, in which stream order is assigned by magnitude, will be used. All links with no tributaries are assigned a magnitude (order) of one. Magnitudes are additive downslope. When two links intersect, their magnitudes are added and assigned to the downslope link.Hack—The Hack method, in which each stream segment is assigned an order greater than the stream or river to which it discharges, will be used. For example, the main river channel is assigned an order of 1, all stream segments discharging to it are assigned an order of 2, any stream discharging to an order 2 stream is assigned an order of 3, and so on. | String |
| Force all edge cells to flow outward(Optional) | Specifies whether edge cells will always flow outward or follow normal flow rules.Unchecked—If the maximum drop on the inside of an edge cell is greater than zero, the flow direction will be determined as usual; otherwise, the flow direction will be toward the edge. Cells that should flow from the edge of the surface raster inward will do so. This is the default.Checked—All cells at the edge of the surface raster will flow outward from the surface raster. | Boolean |
| in_surface_raster | The input surface raster. | Raster Layer |
| in_depressions_data(Optional) | An optional dataset that defines real depressions.The depressions can be defined either through a raster or a feature layer.If input is a raster, the depression cells must take a valid value, including zero, and the areas that are not depressions must be NoData. | Composite Geodataset |
| in_weight_raster(Optional) | An optional input raster dataset that defines the fraction of flow that contributes to flow accumulation at each cell.The weight is only applied to the accumulation of flow.If no accumulation weight raster is specified, a default weight of 1 will be applied to each cell. | Raster Layer |
| accumulation_threshold(Optional) | The threshold for determining whether a given cell is part of a stream in terms of the total area that flows into such cell. | Areal Unit |
| stream_designation_method(Optional) | Specifies the unique or order of the streams in the output.CONSTANT—The output cell values will all equal 1. This is the default.UNIQUE—Each stream will have a unique ID between intersections in the output.STRAHLER—The Strahler method, in which stream order only increases when streams of the same order intersect, will be used. The intersection of a first-order and second-order link will remain a second-order link, rather than creating a third-order link.SHREVE—The Shreve method, in which stream order is assigned by magnitude, will be used. All links with no tributaries are assigned a magnitude (order) of one. Magnitudes are additive downslope. When two links intersect, their magnitudes are added and assigned to the downslope link.HACK—The Hack method, in which each stream segment is assigned an order greater than the stream or river to which it discharges, will be used. For example, the main river channel is assigned an order of 1, all stream segments discharging to it are assigned an order of 2, any stream discharging to an order 2 stream is assigned an order of 3, and so on. | String |
| force_flow(Optional) | Specifies whether edge cells will always flow outward or follow normal flow rules. NORMAL—If the maximum drop on the inside of an edge cell is greater than zero, the flow direction will be determined as usual; otherwise, the flow direction will be toward the edge. Cells that should flow from the edge of the surface raster inward will do so. This is the default.FORCE—All cells at the edge of the surface raster will flow outward from the surface raster. | Boolean |

## Code Samples

### Example 1

```python
DeriveStreamAsRaster(in_surface_raster, {in_depressions_data}, {in_weight_raster}, {accumulation_threshold}, {stream_designation_method}, {force_flow})
```

### Example 2

```python
from arcpy.sa import *
out_stream_raster = DeriveStreamAsRaster("surface.tif", "", "", "", 
                                        "", "")
out_stream_raster.save("C:/arcpyExamples/outputs/out_stream_raster.tif")
```

### Example 3

```python
from arcpy.sa import *
out_stream_raster = DeriveStreamAsRaster("surface.tif", "", "", "", 
                                        "", "")
out_stream_raster.save("C:/arcpyExamples/outputs/out_stream_raster.tif")
```

### Example 4

```python
# Name: DeriveStreamAsRaster_standalone.py
# Description: Generates a stream raster considering real depressions where 
#              streams start from locations with catchment areas larger than 2 Hectares.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/arcpyExamples/data"

# Set the local variables
in_surface_raster = "surface.tif"
in_depressions_data = "depressions.tif"
stream_raster = "C:/arcpyExamples/outputs/stream_raster.tif"

# Execute DeriveStreamAsRaster
out_stream_raster = DeriveStreamAsRaster(in_surface_raster, in_depressions_data, 
                                        "", "2 Hectares", "UNIQUE", "")
# Save the output
out_stream_raster.save(stream_raster)
```

### Example 5

```python
# Name: DeriveStreamAsRaster_standalone.py
# Description: Generates a stream raster considering real depressions where 
#              streams start from locations with catchment areas larger than 2 Hectares.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/arcpyExamples/data"

# Set the local variables
in_surface_raster = "surface.tif"
in_depressions_data = "depressions.tif"
stream_raster = "C:/arcpyExamples/outputs/stream_raster.tif"

# Execute DeriveStreamAsRaster
out_stream_raster = DeriveStreamAsRaster(in_surface_raster, in_depressions_data, 
                                        "", "2 Hectares", "UNIQUE", "")
# Save the output
out_stream_raster.save(stream_raster)
```

---

## Diff (Spatial Analyst)

## Summary

Determines which values from the first input are logically different from the values of the second input on a cell-by-cell basis.

## Usage

- Two inputs are necessary for this logical evaluation to take place.
- The order of inputs is relevant for this tool.
- If both inputs are integer, the output will be an integer raster; otherwise, it will be a floating-point raster.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input to which the second input will be compared.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input to which the first input will be compared.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input to which the second input will be compared.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input to which the first input will be compared.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Diff(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDiff = Diff("degs", "negs")
outDiff.save("C:/sapyexamples/output/outdiff.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDiff = Diff("degs", "negs")
outDiff.save("C:/sapyexamples/output/outdiff.img")
```

### Example 4

```python
# Name: Diff_Ex_02.py
# Description: Determines which values from the first input are
#              logically different from the values of the second input
#              on a cell-by-cell basis within the Analysis window
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute Diff
outDiff = Diff(inRaster1, inRaster2)

# Save the output 
outDiff.save("C:/sapyexamples/output/outdiff")
```

### Example 5

```python
# Name: Diff_Ex_02.py
# Description: Determines which values from the first input are
#              logically different from the values of the second input
#              on a cell-by-cell basis within the Analysis window
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute Diff
outDiff = Diff(inRaster1, inRaster2)

# Save the output 
outDiff.save("C:/sapyexamples/output/outdiff")
```

---

## Dimensional Moving Statistics (Spatial Analyst)

## Summary

Calculates statistics over a moving window on multidimensional data along a specified dimension.

## Usage

- Moving statistics can also be called moving window statistics, rolling statistics, or running statistics. A predefined window around each dimension value is used to calculate various statistics before moving to the next. The Backward Window and Forward Window parameters allow you to define window sizes on both sides of the dimension.
- The input raster can only be a multidimensional raster in Cloud Raster Format (.crf file).
- Only one dimension will be processed by this tool. By default, the first dimension other than x,y will be used as the processing dimension.
- The Circular Mean statistics type calculates the mean for angles or other cyclic quantities, such as compass direction in degrees. When this option is selected, the Circular Wrap Value parameter becomes available. Use this parameter to designate a value to wrap around to calculate the circular mean. For example, for angle calculation, the circular wrap value should be 360 degrees, which means the value 360 will be wrapped to 0, and the value 370 will be wrapped to 10. Another use is for time calculations of months in a year, in which case the circular wrap value should be 12. In this case, an input value of 13 will be wrapped to 1.
- If the input multidimensional raster is integer, the valid options for Statistics Type are Mean, Circular Mean, Majority, Maximum, Median, Minimum, and Percentile. If the input raster is float, Majority is not available.
- If the input raster is integer, the output raster will be integer for the Majority, Maximum, and Minimum options. The output will be float for Mean, Circular Mean, Median, and Percentile.If the input raster is of float type, the output will be float for all of the available statistic types.
- For the Majority option, when there is a tie, the output will be the lowest of the tied values.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Multidimensional Raster | The input raster can only be a multidimensional raster in Cloud Raster Format (.crf file). | Raster Layer |
| Dimension(Optional) | The name of the dimension along which the window will move.The default value is the first dimension other than x,y found in the input multidimensional raster. | String |
| Backward Window(Optional) | The value of how many slices before or above to be included in the defined window. The value must be a positive integer from 1 to 100. The default value is 1.The unit of this parameter is slice. | Long |
| Forward Window(Optional) | The value of how many slices after or below to be included in the defined window. The value must be a positive integer from 1 to 100. The default value is 1.The unit of this parameter is slice. | Long |
| NoData Handling(Optional) | Specifies how NoData values will be handled by the statistic calculation.Data—NoData values in the value input will be ignored in the results of the defined window that they fall within. This is the default.NoData—Output values will be NoData if any NoData values are found in the input within the defined window.Fill NoData—NoData cell values will be replaced using the selected statistic on the values within the defined window. | String |
| Statistics Type(Optional) | Specifies the statistic type to be calculated.Mean—The mean (average value) of the cells in the defined window will be calculated. This is the default.Circular Mean—The mean for angles or other cyclic quantities—such as compass direction in degrees, daytimes, or fractional parts of real numbers—will be calculated. When this statistics type is selected, the Circular Wrap Value parameter becomes available. Use this parameter to designate a wrap value.Majority—The majority (value that occurs most often) of the cells in the defined window will be identified.Maximum—The maximum (largest value) of the cells in the defined window will be identified.Median—The median of the cells in the defined window will be identified.Minimum—The minimum (smallest value) of the cells in the defined window will be identified.Percentile—A percentile of the cells in the defined window will be calculated. The 90th percentile is calculated by default. When this statistics type is selected, the Percentile Value and Percentile Interpolation Type parameters become available. Use these new parameters to designate the percentile to calculate and choose the interpolation type to use, respectively. | String |
| Percentile Value(Optional) | The percentile value that will be calculated. The default is 90, for the 90th percentile.The value can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to the maximum statistic. A value of 50 will produce essentially the same result as the median statistic.This parameter is only supported if the Statistics Type parameter is set to Percentile. | Double |
| Percentile Interpolation Type(Optional) | Specifies the method of interpolation that will be used when the percentile value falls between two cell values.This parameter is only supported if the Statistics Type parameter is set to Median or Percentile.Auto-detect—If the input raster is of integer pixel type, the Nearest method will be used. If the input raster is of float pixel type, the Linear method will be used.Nearest—The nearest available value to the percentile will be used. In this case, the output pixel type will be the same as that of the input raster.Linear—The weighted average of the two surrounding values from the percentile will be used. In this case, the output pixel type will be floating point. | String |
| Circular Wrap Value(Optional) | The value that will be used to convert a linear value to the range of a given circular mean. Its value must be positive. The default value is 360 degrees. This parameter is only supported if the Statistics Type parameter is set to Circular Mean. | Double |
| in_raster | The input raster can only be a multidimensional raster in Cloud Raster Format (.crf file). | Raster Layer |
| dimension(Optional) | The name of the dimension along which the window will move.The default value is the first dimension other than x,y found in the input multidimensional raster. | String |
| backward_window(Optional) | The value of how many slices before or above to be included in the defined window. The value must be a positive integer from 1 to 100. The default value is 1.The unit of this parameter is slice. | Long |
| forward_window(Optional) | The value of how many slices after or below to be included in the defined window. The value must be a positive integer from 1 to 100. The default value is 1.The unit of this parameter is slice. | Long |
| nodata_handling(Optional) | Specifies how NoData values will be handled by the statistic calculation.DATA—NoData values in the value input will be ignored in the results of the defined window that they fall within. This is the default.NODATA—Output values will be NoData if any NoData values are found in the input within the defined window.FILL_NODATA—NoData cell values will be replaced using the selected statistic on the values within the defined window. | String |
| statistics_type(Optional) | Specifies the statistic type to be calculated.MEAN—The mean (average value) of the cells in the defined window will be calculated. This is the default.CIRCULAR_MEAN—The mean for angles or other cyclic quantities—such as compass direction in degrees, daytimes, or fractional parts of real numbers—will be calculated. When this statistics type is selected, use the circular_wrap_value parameter to designate a wrap value.MAJORITY—The majority (value that occurs most often) of the cells in the defined window will be identified.MAXIMUM—The maximum (largest value) of the cells in the defined window will be identified.MEDIAN—The median of the cells in the defined window will be identified.MINIMUM—The minimum (smallest value) of the cells in the defined window will be identified.PERCENTILE—A percentile of the cells in the defined window will be calculated. The 90th percentile is calculated by default. When this statistics type is selected, use the percentile_value and percentile_interpolation_type parameters to designate the percentile to calculate and choose the interpolation type to use, respectively. | String |
| percentile_value(Optional) | The percentile value that will be calculated. The default is 90, for the 90th percentile.The value can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to the maximum statistic. A value of 50 will produce essentially the same result as the median statistic.This parameter is only supported if the statistics_type parameter is set to PERCENTILE. If any other statistic type is specified, this parameter will be ignored. | Double |
| percentile_interpolation_type(Optional) | Specifies the method of interpolation that will be used when the percentile value falls between two cell values.This parameter is only supported if the statistics_type parameter is set to MEDIAN or PERCENTILE. If any other statistic type is specified, this parameter will be ignored.AUTO_DETECT—If the input raster is of integer pixel type, the NEAREST method will be used. If the input raster is of float pixel type, the LINEAR method will be used.NEAREST—The nearest available value to the percentile will be used. In this case, the output pixel type will be the same as that of the input raster.LINEAR—The weighted average of the two surrounding values from the percentile will be used. In this case, the output pixel type will be floating point. | String |
| circular_wrap_value(Optional) | The value that will be used to convert a linear value to the range of a given circular mean. Its value must be positive. The default value is 360 degrees. This parameter is only supported if the statistics_type parameter is set to CIRCULAR_MEAN. If any other statistic type is specified, this parameter will be ignored. | Double |

## Code Samples

### Example 1

```python
DimensionalMovingStatistics(in_raster, {dimension}, {backward_window}, {forward_window}, {nodata_handling}, {statistics_type}, {percentile_value}, {percentile_interpolation_type}, {circular_wrap_value})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
out_dimstats = DimensionalMovingStatistics("md_raster.crf", "StdTime", 
                                           1, 1, "NODATA", "MEAN")
out_dimstats.save("C:/sapyexamples/output/DMS01.crf")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
out_dimstats = DimensionalMovingStatistics("md_raster.crf", "StdTime", 
                                           1, 1, "NODATA", "MEAN")
out_dimstats.save("C:/sapyexamples/output/DMS01.crf")
```

### Example 4

```python
# Name: DimensionalMovingStatistics_standalone.py
# Description: Calculates majority on a multidimensional raster 
#                along its time dimension.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environment
env.workspace = "C:/sapyexamples/data"

# Set local variables
in_raster = "mining_location.crf"
dimension = "StdTime"
backward_window = 2
forward_window = 2
nodata_handling = "FILL_NODATA"
statistics_type = "MAJORITY"

# Execute DimensionalMovingStatistics
out_dimstats = DimensionalMovingStatistics(in_raster, dimension, 
                 backward_window, forward_window, nodata_handling, 
                 statistics_type)

# Save the output
out_dimstats.save("C:/sapyexamples/output/mining_location_out.crf")
```

### Example 5

```python
# Name: DimensionalMovingStatistics_standalone.py
# Description: Calculates majority on a multidimensional raster 
#                along its time dimension.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environment
env.workspace = "C:/sapyexamples/data"

# Set local variables
in_raster = "mining_location.crf"
dimension = "StdTime"
backward_window = 2
forward_window = 2
nodata_handling = "FILL_NODATA"
statistics_type = "MAJORITY"

# Execute DimensionalMovingStatistics
out_dimstats = DimensionalMovingStatistics(in_raster, dimension, 
                 backward_window, forward_window, nodata_handling, 
                 statistics_type)

# Save the output
out_dimstats.save("C:/sapyexamples/output/mining_location_out.crf")
```

---

## Distance Accumulation (Spatial Analyst)

## Summary

Calculates accumulated distance for each cell to sources, allowing for straight-line distance, cost distance, and true surface distance, as well as vertical and horizontal cost factors.

## Usage

- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted internally to a raster before performing the analysis. The resolution of the raster can be controlled with the Cell Size environment. By default, if no other rasters are specified in the tool, the resolution will be determined by the shorter of the width or height of the extent of the input feature, in the input spatial reference, divided by 250.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- Barriers are obstacles that must be routed around. They can be defined in two ways.For the Input Raster or Feature Barrier parameter, barriers can be represented either by cells that have a valid value or by feature data that is converted to a raster. Where barriers are connected only by diagonal cells, the barriers will be thickened to make them impermeable.Barriers are also defined by locations where NoData cells exist in the following inputs: Input Cost Raster, Input Surface Raster, Input Vertical Raster, and Input Horizontal Raster. Where NoData is connected only by diagonal cells, it will be thickened with additional NoData cells to make it an impermeable barrier.
- If the Input Surface Raster value has a vertical coordinate system (VCS), the values of the surface raster are considered to be in the units of the VCS. If the Input Surface Raster value does not have a VCS and the data is projected, the surface values are considered to be in the linear units of the spatial reference. If the Input Surface Raster value does not have a VCS and the data is not projected, the surface values are considered to be in meters. The final distance accumulation result is in cost per linear unit, or in linear units if no cost is introduced.
- Cost raster values that are negative or zero are invalid but will be treated as small positive values. The accumulative cost algorithm is a multiplicative process, and it cannot calculate accumulative cost correctly if cost values are negative or zero.If the cost raster contains those values, and those locations represent areas that are to be excluded from the analysis, turn those cells into NoData before running the tool. You can do this using the Set Null tool. The NoData value is treated as a barrier in this analysis, so any locations that are NoData in the input will be NoData in the result.
- If a source falls on NoData in any of the corresponding input rasters, it will be ignored in the analysis and no distance from that source will be calculated.
- The default values for the Vertical factor modifiers are the following:Keyword Zero Low High Slope Power Cos Sec factor cut cut power power angle angle ------------------------ ------ ----- ----- ----- ----- ----- ----- Binary 1.0 -30 30 ~ ~ ~ ~ Linear 1.0 -90 90 1/90 ~ ~ ~ Symmetric linear 1.0 -90 90 1/90 ~ ~ ~ Inverse linear 1.0 -45 45 -1/45 ~ ~ ~ Symmetric inverse linear 1.0 -45 45 -1/45 ~ ~ ~ Cos ~ -90 90 ~ 1.0 ~ ~ Sec ~ -90 90 ~ 1.0 ~ ~ Cos_sec ~ -90 90 ~ ~ 1.0 1.0 Sec_cos ~ -90 90 ~ ~ 1.0 1.0 Hiking time ~ -70 70 ~ ~ ~ ~ Bidirectional hiking time ~ -70 70 ~ ~ ~ ~
- The output of the Aspect tool can be used as input for the Input Horizontal Raster parameter.
- The default values for the Horizontal factor modifiers are the following:Keywords Zero factor Cut angle Slope Side value -------------- ----------- ----------- ----- --------- Binary 1.0 45 ~ ~ Forward 0.5 45 (fixed) ~ 1.0 Linear 0.5 181 1/90 ~ Inverse linear 2.0 180 -1/90 ~
- The characteristics of the source, or the movers from or to a source, can be controlled by the following parameters: Initial Accumulation sets the initial cost before the movement begins.Maximum Accumulation specifies how much cost a source can accumulate before reaching its limit.Cost Multiplier specifies the mode of travel or magnitude at the source.Travel Direction identifies whether the mover is starting at a source and moving to nonsource locations or starting at nonsource locations and moving back to a source.
- Initial Accumulation sets the initial cost before the movement begins.
- Maximum Accumulation specifies how much cost a source can accumulate before reaching its limit.
- Cost Multiplier specifies the mode of travel or magnitude at the source.
- Travel Direction identifies whether the mover is starting at a source and moving to nonsource locations or starting at nonsource locations and moving back to a source.
- If any of the source characteristic parameters are specified using a field, the source characteristic will be applied on a source-by-source basis, according to the information in the specified field for the source data. When a keyword or a constant value is provided, it will be applied to all sources.
- If the Initial Accumulation parameter value is specified, the source locations on the output cost distance surface will be set to that value; otherwise, the source locations on the output cost distance surface will be set to zero.
- To properly handle the edge of the projection at a global extent when performing distance analysis at a global scale, ensure that either a cylindrical projection or a geographic output coordinate system is used in conjunction with the Geodesic option for the Distance Method parameter.
- When no Extent environment setting is specified, the processing extent is determined in the following way:If only the Input Raster or Feature Sources and Input Raster or Feature Barriers values are specified, the union of the inputs, expanded by two cell widths on each side, will be used as the processing extent. The reason the output raster is expanded by two rows and columns is so the outputs can be used in the Optimal Path As Line and Optimal Path As Raster tools, and the generated paths can move around the barriers. To use the extent as an implicit barrier, you must explicitly set the Extent value in the environment settings.The processing extent will be the intersection of the Input Surface Raster, Input Cost Raster, Input Vertical Raster, or Input Horizontal Raster parameter value if specified.
- The analysis Mask environment can be set to a feature or a raster dataset. If the mask is a feature, it will be converted to a raster. The cells that have a value define the locations that are within the mask area. NoData cells define the locations that are outside the mask area and will be treated as a barrier.
- When the Cell Size or Snap Raster environment settings are not specified and there are multiple rasters specified as inputs, the Cell Size and Snap Raster environments are set based on this order of precedence: Input Cost Raster, Input Surface Raster, Input Vertical Raster, Input Horizontal Raster, Input Raster or Feature Sources, and Input Raster or Feature Barriers.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Sources | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| Input Raster or Feature Barriers(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature.For a raster barrier, the barrier must have a valid value, including zero, and the areas that are not barriers must be NoData. | Raster Layer; Feature Layer |
| Input Surface Raster(Optional) | A raster defining the elevation values at each cell location.The values are used to calculate the actual surface distance covered when passing between cells. | Raster Layer |
| Input Cost Raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point. Cost raster values that are negative or zero are invalid but will be treated as small positive cost values. | Raster Layer |
| Input Vertical Raster(Optional) | A raster defining the z-values for each cell location.The values are used for calculating the slope used to identify the vertical factor incurred when moving from one cell to another. | Raster Layer |
| Vertical Factor(Optional) | Specifies the relationship between the vertical cost factor and the vertical relative moving angle (VRMA).There are several factors with modifiers that identify a defined vertical factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the vertical factor used in calculating the total cost for moving into a neighboring cell.In the option descriptions below, two acronyms are used: VF stands for vertical factor, which defines the vertical difficulty encountered in moving from one cell to the next; VRMA stands for vertical relative moving angle, which identifies the slope angle between the FROM or processing cell and the TO cell.The options are as follows: Binary—If the VRMA is greater than the low-cut angle and less than the high-cut angle, the VF is set to the value associated with the zero factor; otherwise, it is infinity. Linear—The VF is a linear function of the VRMA. Symmetric Linear—The VF is a linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis. Inverse Linear—The VF is an inverse linear function of the VRMA. Symmetric Inverse Linear—The VF is an inverse linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis. Cos—The VF is the cosine-based function of the VRMA. Sec—The VF is the secant-based function of the VRMA. Cos-Sec—The VF is the cosine-based function of the VRMA when the VRMA is negative and is the secant-based function of the VRMA when the VRMA is not negative. Sec-Cos—The VF is the secant-based function of the VRMA when the VRMA is negative and is the cosine-based function of the VRMA when the VRMA is not negative. Hiking Time—The VF is the hiking time function of the VRMA.Bidirectional Hiking Time—The VF is a bidirectional modified hiking time function of the VRMA.Table—A table file will be used to define the vertical-factor graph that is used to determine the VFs.The modifiers to the vertical keywords are the following: Zero factor—The vertical factor used when the VRMA is zero. This factor positions the y-intercept of the specified function. By definition, the zero factor is not applicable to any of the trigonometric vertical functions (COS, SEC, COS-SEC, or SEC-COS). The y-intercept is defined by these functions. Low Cut angle—The VRMA angle below which the VF will be set to infinity. High Cut angle—The VRMA angle above which the VF will be set to infinity. Slope—The slope of the straight line used with the Linear and Inverse Linear vertical factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). Table name—The name of the table defining the VF. | Vertical Factor |
| Input Horizontal Raster(Optional) | A raster defining the horizontal direction at each cell.The values on the raster must be integers ranging from 0 to 360, with 0 degrees being north, or toward the top of the screen, and increasing clockwise. Flat areas should be given a value of -1. The values at each location will be used in conjunction with the Horizontal Factor parameter to determine the horizontal cost incurred when moving from a cell to its neighbors. | Raster Layer |
| Horizontal Factor(Optional) | Specifies the relationship between the horizontal cost factor and the horizontal relative moving angle (HRMA).There are several factors with modifiers that identify a defined horizontal factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the horizontal factor used in calculating the total cost of moving into a neighboring cell.In the option descriptions below, two acronyms are used: HF stands for horizontal factor, which defines the horizontal difficulty encountered when moving from one cell to the next; HRMA stands for horizontal relative moving angle, which identifies the angle between the horizontal direction from a cell and the moving direction.The options are as follows: Binary—If the HRMA is less than the cut angle, the HF is set to the value associated with the zero factor; otherwise, it is infinity. Forward—Only forward movement is allowed. The HRMA must be greater than or equal to 0 and less than 90 degrees (0 <= HRMA < 90). If the HRMA is greater than 0 and less than 45 degrees, the HF for the cell is set to the value associated with the zero factor. If the HRMA is greater than or equal to 45 degrees, the side value modifier value is used. The HF for any HRMA equal to or greater than 90 degrees is set to infinity. Linear—The HF is a linear function of the HRMA. Inverse Linear—The HF is an inverse linear function of the HRMA. Table—A table file will be used to define the horizontal factor graph used to determine the HFs.The modifiers to the horizontal factors are the following: Zero factor—The horizontal factor to be used when the HRMA is zero. This factor positions the y-intercept for any of the horizontal factor functions. Cut angle—The HRMA angle beyond which the HF will be set to infinity. Slope—The slope of the straight line used with the Linear and Inverse Linear horizontal factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). Side value—The HF when the HRMA is greater than or equal to 45 degrees and less than 90 degrees when the Forward horizontal factor keyword is specified. Table name—The name of the table defining the HF. | Horizontal Factor |
| Output Back Direction Raster(Optional) | The back direction raster contains the calculated direction in degrees. The direction identifies the next cell along the shortest path back to the closest source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| Output Source Direction Raster(Optional) | The source direction raster identifies the direction of the least accumulated cost source cell as an azimuth in degrees.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| Output Source Location Raster(Optional) | The source location raster is a multiband output. The first band contains a row index, and the second band contains a column index. These indexes identify the location of the source cell that is the least accumulated cost distance away. | Raster Dataset |
| Initial Accumulation(Optional) | The initial accumulative cost that will be used to begin the cost calculation.Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value.The values must be zero or greater. The default is 0. | Double; Field |
| Maximum Accumulation(Optional) | The maximum accumulation for the traveler for a source.The cost calculations continue for each source until the specified accumulation is reached.The values must be greater than zero. The default accumulation is to the edge of the output raster. | Double; Field |
| Costs Multiplier(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| Travel Direction(Optional) | Specifies the direction of the traveler when applying horizontal and vertical factors.If you select the String option, you can choose between from and to options, which will be applied to all sources.If you select the Field option, you can select the field from the source data that determines the direction to use for each source. The field must contain the text string FROM_SOURCE or TO_SOURCE.Travel from source—The horizontal factor and vertical factor will be applied beginning at the input source and travel out to the nonsource cells. This is the default.Travel to source—The horizontal factor and vertical factor will be applied beginning at each nonsource cell and travel back to the input source. | String; Field |
| Distance Method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.Planar—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.Geodesic—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| in_source_data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| in_barrier_data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature.For a raster barrier, the barrier must have a valid value, including zero, and the areas that are not barriers must be NoData. | Raster Layer; Feature Layer |
| in_surface_raster(Optional) | A raster defining the elevation values at each cell location.The values are used to calculate the actual surface distance covered when passing between cells. | Raster Layer |
| in_cost_raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point. Cost raster values that are negative or zero are invalid but will be treated as small positive cost values. | Raster Layer |
| in_vertical_raster(Optional) | A raster defining the z-values for each cell location.The values are used for calculating the slope used to identify the vertical factor incurred when moving from one cell to another. | Raster Layer |
| vertical_factor(Optional) | The Vertical factor object defines the relationship between the vertical cost factor and the vertical relative moving angle (VRMA).There are several factors with modifiers that identify a defined vertical factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the vertical factor used in calculating the total cost for moving into a neighboring cell.In the descriptions below, two acronyms are used: VF stands for vertical factor, which defines the vertical difficulty encountered in moving from one cell to the next; VRMA stands for vertical relative moving angle, which identifies the slope angle between the FROM or processing cell and the TO cell.The object comes in the following forms: VfBinary, VfLinear, VfInverseLinear, VfSymLinear, VfSymInverseLinear, VfCos, VfSec, VfSec, VfCosSec, VfSecCos, VfHikingTime, VfBidirHikingTime, VfTable.The definitions and parameters of these are the following:VfBinary({zeroFactor}, {lowCutAngle}, {highCutAngle}) If the VRMA is greater than the low-cut angle and less than the high-cut angle, the VF is set to the value associated with the zero factor; otherwise, it is infinity.VfLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is a linear function of the VRMA.VfInverseLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is an inverse linear function of the VRMA.VfSymLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is a linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis.VfSymInverseLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is an inverse linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis.VfCos({lowCutAngle}, {highCutAngle}, {cosPower}) The VF is the cosine-based function of the VRMA.VfSec({lowCutAngle}, {highCutAngle}, {secPower}) The VF is the secant-based function of the VRMA.VfCosSec({lowCutAngle}, {highCutAngle}, {cosPower}, {secPower}) The VF is the cosine-based function of the VRMA when the VRMA is negative and is the secant-based function of the VRMA when the VRMA is not negative.VfSecCos({lowCutAngle}, {highCutAngle}, {secPower}, {cos_power}) The VF is the secant-based function of the VRMA when the VRMA is negative and is the cosine-based function of the VRMA when the VRMA is not negative.VfHikingTime({lowCutAngle}, {highCutAngle}) The VF is the hiking time function of the VRMA.VfBidirHikingTime({lowCutAngle}, {highCutAngle}) The VF is a bidirectional modified hiking time function of the VRMA.VfTable(inTable) A table file will be used to define the vertical factor graph used to determine the VFs. The modifiers to the vertical parameters are the following: zeroFactor—The vertical factor used when the VRMA is zero. This factor positions the y-intercept of the specified function. By definition, the zero factor is not applicable to any of the trigonometric vertical functions (Cos, Sec, Cos-Sec, or Sec-Cos). The y-intercept is defined by these functions. lowCutAngle—The VRMA angle below which the VF will be set to infinity. highCutAngle—The VRMA angle above which the VF will be set to infinity. slope—The slope of the straight line used with the VfLinear and VfInverseLinear parameters. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). inTable—The name of the table defining the VF. | Vertical Factor |
| in_horizontal_raster(Optional) | A raster defining the horizontal direction at each cell.The values on the raster must be integers ranging from 0 to 360, with 0 degrees being north, or toward the top of the screen, and increasing clockwise. Flat areas should be given a value of -1. The values at each location will be used in conjunction with the horizontal_factor parameter to determine the horizontal cost incurred when moving from a cell to its neighbors. | Raster Layer |
| horizontal_factor(Optional) | The Horizontal Factor object defines the relationship between the horizontal cost factor and the horizontal relative moving angle.There are several factors with modifiers that identify a defined horizontal factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the horizontal factor used in calculating the total cost of moving into a neighboring cell.In the descriptions below, two acronyms are used: HF stands for horizontal factor, which defines the horizontal difficulty encountered when moving from one cell to the next; HRMA stands for horizontal relative moving angle, which identifies the angle between the horizontal direction from a cell and the moving direction.The object comes in the following forms: HfBinary, HfForward, HfLinear, HfInverseLinear, and HfTable. The definitions and parameters of these are the following: HfBinary({zeroFactor}, {cutAngle}) If the HRMA is less than the cut angle, the HF is set to the value associated with the zero factor; otherwise, it is infinity. HfForward({zeroFactor}, {sideValue}) Only forward movement is allowed. The HRMA must be greater than or equal to 0 and less than 90 degrees (0 <= HRMA < 90). If the HRMA is greater than 0 and less than 45 degrees, the HF for the cell is set to the value associated with the zero factor. If the HRMA is greater than or equal to 45 degrees, the side value modifier value is used. The HF for any HRMA equal to or greater than 90 degrees is set to infinity. HfLinear({zeroFactor}, {cutAngle}, {slope}) The HF is a linear function of the HRMA. HfInverseLinear({zeroFactor}, {cutAngle}, {slope}) The HF is an inverse linear function of the HRMA. HfTable(inTable) A table file will be used to define the horizontal factor graph used to determine the HFs.The modifiers to the horizontal keywords are the following: zeroFactor—The horizontal factor to be used when the HRMA is 0. This factor positions the y-intercept for any of the horizontal factor functions. cutAngle—The HRMA angle beyond which the HF will be set to infinity. slope—The slope of the straight line used with the HfLinear and HfInverseLinear horizontal factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). sideValue—The HF when the HRMA is greater than or equal to 45 degrees and less than 90 degrees when the HfForward horizontal factor keyword is specified. inTable—The name of the table defining the HF. | Horizontal Factor |
| out_back_direction_raster(Optional) | The back direction raster contains the calculated direction in degrees. The direction identifies the next cell along the shortest path back to the closest source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| out_source_direction_raster(Optional) | The source direction raster identifies the direction of the least accumulated cost source cell as an azimuth in degrees.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| out_source_location_raster(Optional) | The source location raster is a multiband output. The first band contains a row index, and the second band contains a column index. These indexes identify the location of the source cell that is the least accumulated cost distance away. | Raster Dataset |
| source_initial_accumulation(Optional) | The initial accumulative cost that will be used to begin the cost calculation.Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value.The values must be zero or greater. The default is 0. | Double; Field |
| source_maximum_accumulation(Optional) | The maximum accumulation for the traveler for a source.The cost calculations continue for each source until the specified accumulation is reached.The values must be greater than zero. The default accumulation is to the edge of the output raster. | Double; Field |
| source_cost_multiplier(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| source_direction(Optional) | Specifies the direction of the traveler when applying horizontal and vertical factors.FROM_SOURCE—The horizontal factor and vertical factor will be applied beginning at the input source and travel out to the nonsource cells. This is the default.TO_SOURCE—The horizontal factor and vertical factor will be applied beginning at each nonsource cell and travel back to the input source. Specify the FROM_SOURCE or TO_SOURCE keyword, which will be applied to all sources, or specify a field in the source data that contains the keywords to identify the direction of travel for each source. That field must contain the string FROM_SOURCE or TO_SOURCE. | String; Field |
| distance_method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.PLANAR—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.GEODESIC—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |

## Code Samples

### Example 1

```python
Keyword                   Zero    Low    High   Slope  Power  Cos    Sec
                          factor  cut    cut                  power  power
                                  angle  angle                             
------------------------  ------  -----  -----  -----  -----  -----  -----
Binary                    1.0     -30    30     ~      ~      ~      ~
Linear                    1.0     -90    90      1/90  ~      ~      ~
Symmetric linear          1.0     -90    90      1/90  ~      ~      ~
Inverse linear            1.0     -45    45     -1/45  ~      ~      ~
Symmetric inverse linear  1.0     -45    45     -1/45  ~      ~      ~
Cos                       ~       -90    90     ~      1.0    ~      ~
Sec                       ~       -90    90     ~      1.0    ~      ~
Cos_sec                   ~       -90    90     ~      ~      1.0    1.0
Sec_cos                   ~       -90    90     ~      ~      1.0    1.0
Hiking time               ~       -70    70     ~      ~      ~      ~
Bidirectional hiking time ~       -70    70     ~      ~      ~      ~
```

### Example 2

```python
Keywords         Zero factor   Cut angle     Slope   Side value
--------------   -----------   -----------   -----   ---------
Binary           1.0            45           ~       ~
Forward          0.5            45 (fixed)   ~       1.0
Linear           0.5           181            1/90   ~
Inverse linear   2.0           180           -1/90   ~
```

### Example 3

```python
DistanceAccumulation(in_source_data, {in_barrier_data}, {in_surface_raster}, {in_cost_raster}, {in_vertical_raster}, {vertical_factor}, {in_horizontal_raster}, {horizontal_factor}, {out_back_direction_raster}, {out_source_direction_raster}, {out_source_location_raster}, {source_initial_accumulation}, {source_maximum_accumulation}, {source_cost_multiplier}, {source_direction}, {distance_method})
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDistAcc = DistanceAccumulation("insources.shp", "barriers.tif")
outDistAcc.save("c:/sapyexamples/output/distacc.tif")
```

### Example 5

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDistAcc = DistanceAccumulation("insources.shp", "barriers.tif")
outDistAcc.save("c:/sapyexamples/output/distacc.tif")
```

### Example 6

```python
# Name: DistanceAccumulation_Ex_02.py
# Description: Calculates the distance accumulation.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSources = "insources.shp"
inBarrier = "barriers.tif"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute EucDirections
outDistAcc = DistanceAccumulation(inSources, inBarrier)

# Save the output 
outDistAcc.save("c:/sapyexamples/output/distacc2.tif")
```

### Example 7

```python
# Name: DistanceAccumulation_Ex_02.py
# Description: Calculates the distance accumulation.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSources = "insources.shp"
inBarrier = "barriers.tif"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute EucDirections
outDistAcc = DistanceAccumulation(inSources, inBarrier)

# Save the output 
outDistAcc.save("c:/sapyexamples/output/distacc2.tif")
```

---

## Distance Allocation (Spatial Analyst)

## Summary

Calculates distance allocation for each cell to the provided sources based on straight-line distance, cost distance, and true surface distance, as well as vertical and horizontal cost factors.

## Usage

- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted internally to a raster before performing the analysis. The resolution of the raster can be controlled with the Cell Size environment. By default, if no other rasters are specified in the tool, the resolution will be determined by the shorter of the width or height of the extent of the input feature, in the input spatial reference, divided by 250.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- Barriers are obstacles that must be routed around. They can be defined in two ways.For the Input Raster or Feature Barrier parameter, barriers can be represented either by cells that have a valid value or by feature data that is converted to a raster. Where barriers are connected only by diagonal cells, the barriers will be thickened to make them impermeable.Barriers are also defined by locations where NoData cells exist in the following inputs: Input Cost Raster, Input Surface Raster, Input Vertical Raster, and Input Horizontal Raster. Where NoData is connected only by diagonal cells, it will be thickened with additional NoData cells to make it an impermeable barrier.
- If the Input Surface Raster value has a vertical coordinate system (VCS), the values of the surface raster are considered to be in the units of the VCS. If the Input Surface Raster value does not have a VCS and the data is projected, the surface values are considered to be in the linear units of the spatial reference. If the Input Surface Raster value does not have a VCS and the data is not projected, the surface values are considered to be in meters. The final distance accumulation result is in cost per linear unit, or in linear units if no cost is introduced.
- Cost raster values that are negative or zero are invalid but will be treated as small positive values. The accumulative cost algorithm is a multiplicative process, and it cannot calculate accumulative cost correctly if cost values are negative or zero.If the cost raster contains those values, and those locations represent areas that are to be excluded from the analysis, turn those cells into NoData before running the tool. You can do this using the Set Null tool. The NoData value is treated as a barrier in this analysis, so any locations that are NoData in the input will be NoData in the result.
- If a source falls on NoData in any of the corresponding input rasters, it will be ignored in the analysis and no distance from that source will be calculated.
- The default values for the Vertical factor modifiers are the following:Keyword Zero Low High Slope Power Cos Sec factor cut cut power power angle angle ------------------------ ------ ----- ----- ----- ----- ----- ----- Binary 1.0 -30 30 ~ ~ ~ ~ Linear 1.0 -90 90 1/90 ~ ~ ~ Symmetric linear 1.0 -90 90 1/90 ~ ~ ~ Inverse linear 1.0 -45 45 -1/45 ~ ~ ~ Symmetric inverse linear 1.0 -45 45 -1/45 ~ ~ ~ Cos ~ -90 90 ~ 1.0 ~ ~ Sec ~ -90 90 ~ 1.0 ~ ~ Cos_sec ~ -90 90 ~ ~ 1.0 1.0 Sec_cos ~ -90 90 ~ ~ 1.0 1.0 Hiking time ~ -70 70 ~ ~ ~ ~ Bidirectional hiking time ~ -70 70 ~ ~ ~ ~
- The output of the Aspect tool can be used as input for the Input Horizontal Raster parameter.
- The default values for the Horizontal factor modifiers are the following:Keywords Zero factor Cut angle Slope Side value -------------- ----------- ----------- ----- --------- Binary 1.0 45 ~ ~ Forward 0.5 45 (fixed) ~ 1.0 Linear 0.5 181 1/90 ~ Inverse linear 2.0 180 -1/90 ~
- The characteristics of the source, or the movers from or to a source, can be controlled by the following parameters: Initial Accumulation sets the initial cost before the movement begins.Maximum Accumulation specifies how much cost a source can accumulate before reaching its limit.Cost Multiplier specifies the mode of travel or magnitude at the source.Travel Direction identifies whether the mover is starting at a source and moving to nonsource locations or starting at nonsource locations and moving back to a source.
- Initial Accumulation sets the initial cost before the movement begins.
- Maximum Accumulation specifies how much cost a source can accumulate before reaching its limit.
- Cost Multiplier specifies the mode of travel or magnitude at the source.
- Travel Direction identifies whether the mover is starting at a source and moving to nonsource locations or starting at nonsource locations and moving back to a source.
- If any of the source characteristic parameters are specified using a field, the source characteristic will be applied on a source-by-source basis, according to the information in the specified field for the source data. When a keyword or a constant value is provided, it will be applied to all sources.
- If the Initial Accumulation parameter value is specified, the source locations on the output cost distance surface will be set to that value; otherwise, the source locations on the output cost distance surface will be set to zero.
- To properly handle the edge of the projection at a global extent when performing distance analysis at a global scale, ensure that either a cylindrical projection or a geographic output coordinate system is used in conjunction with the Geodesic option for the Distance Method parameter.
- When no Extent environment setting is specified, the processing extent is determined in the following way:If only the Input Raster or Feature Sources and Input Raster or Feature Barriers values are specified, the union of the inputs, expanded by two cell widths on each side, will be used as the processing extent. The reason the output raster is expanded by two rows and columns is so the outputs can be used in the Optimal Path As Line and Optimal Path As Raster tools, and the generated paths can move around the barriers. To use the extent as an implicit barrier, you must explicitly set the Extent value in the environment settings.The processing extent will be the intersection of the Input Surface Raster, Input Cost Raster, Input Vertical Raster, or Input Horizontal Raster parameter value if specified.
- The analysis Mask environment can be set to a feature or a raster dataset. If the mask is a feature, it will be converted to a raster. The cells that have a value define the locations that are within the mask area. NoData cells define the locations that are outside the mask area and will be treated as a barrier.
- When the Cell Size or Snap Raster environment settings are not specified and there are multiple rasters specified as inputs, the Cell Size and Snap Raster environments are set based on this order of precedence: Input Cost Raster, Input Surface Raster, Input Vertical Raster, Input Horizontal Raster, Input Raster or Feature Sources, and Input Raster or Feature Barriers.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Sources | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| Input Raster or Feature Barriers(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature.For a raster barrier, the barrier must have a valid value, including zero, and the areas that are not barriers must be NoData. | Raster Layer; Feature Layer |
| Input Surface Raster(Optional) | A raster defining the elevation values at each cell location.The values are used to calculate the actual surface distance covered when passing between cells. | Raster Layer |
| Input Cost Raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point. Cost raster values that are negative or zero are invalid but will be treated as small positive cost values. | Raster Layer |
| Input Vertical Raster(Optional) | A raster defining the z-values for each cell location.The values are used for calculating the slope used to identify the vertical factor incurred when moving from one cell to another. | Raster Layer |
| Vertical Factor(Optional) | Specifies the relationship between the vertical cost factor and the vertical relative moving angle (VRMA).There are several factors with modifiers that identify a defined vertical factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the vertical factor used in calculating the total cost for moving into a neighboring cell.In the option descriptions below, two acronyms are used: VF stands for vertical factor, which defines the vertical difficulty encountered in moving from one cell to the next; VRMA stands for vertical relative moving angle, which identifies the slope angle between the FROM or processing cell and the TO cell.The options are as follows: Binary—If the VRMA is greater than the low-cut angle and less than the high-cut angle, the VF is set to the value associated with the zero factor; otherwise, it is infinity. Linear—The VF is a linear function of the VRMA. Symmetric Linear—The VF is a linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis. Inverse Linear—The VF is an inverse linear function of the VRMA. Symmetric Inverse Linear—The VF is an inverse linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis. Cos—The VF is the cosine-based function of the VRMA. Sec—The VF is the secant-based function of the VRMA. Cos-Sec—The VF is the cosine-based function of the VRMA when the VRMA is negative and is the secant-based function of the VRMA when the VRMA is not negative. Sec-Cos—The VF is the secant-based function of the VRMA when the VRMA is negative and is the cosine-based function of the VRMA when the VRMA is not negative. Hiking Time—The VF is the hiking time function of the VRMA.Bidirectional Hiking Time—The VF is a bidirectional modified hiking time function of the VRMA.Table—A table file will be used to define the vertical-factor graph that is used to determine the VFs.The modifiers to the vertical keywords are the following: Zero factor—The vertical factor used when the VRMA is zero. This factor positions the y-intercept of the specified function. By definition, the zero factor is not applicable to any of the trigonometric vertical functions (COS, SEC, COS-SEC, or SEC-COS). The y-intercept is defined by these functions. Low Cut angle—The VRMA angle below which the VF will be set to infinity. High Cut angle—The VRMA angle above which the VF will be set to infinity. Slope—The slope of the straight line used with the Linear and Inverse Linear vertical factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). Table name—The name of the table defining the VF. | Vertical Factor |
| Input Horizontal Raster(Optional) | A raster defining the horizontal direction at each cell.The values on the raster must be integers ranging from 0 to 360, with 0 degrees being north, or toward the top of the screen, and increasing clockwise. Flat areas should be given a value of -1. The values at each location will be used in conjunction with the Horizontal Factor parameter to determine the horizontal cost incurred when moving from a cell to its neighbors. | Raster Layer |
| Horizontal Factor(Optional) | Specifies the relationship between the horizontal cost factor and the horizontal relative moving angle (HRMA).There are several factors with modifiers that identify a defined horizontal factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the horizontal factor used in calculating the total cost of moving into a neighboring cell.In the option descriptions below, two acronyms are used: HF stands for horizontal factor, which defines the horizontal difficulty encountered when moving from one cell to the next; HRMA stands for horizontal relative moving angle, which identifies the angle between the horizontal direction from a cell and the moving direction.The options are as follows: Binary—If the HRMA is less than the cut angle, the HF is set to the value associated with the zero factor; otherwise, it is infinity. Forward—Only forward movement is allowed. The HRMA must be greater than or equal to 0 and less than 90 degrees (0 <= HRMA < 90). If the HRMA is greater than 0 and less than 45 degrees, the HF for the cell is set to the value associated with the zero factor. If the HRMA is greater than or equal to 45 degrees, the side value modifier value is used. The HF for any HRMA equal to or greater than 90 degrees is set to infinity. Linear—The HF is a linear function of the HRMA. Inverse Linear—The HF is an inverse linear function of the HRMA. Table—A table file will be used to define the horizontal factor graph used to determine the HFs.The modifiers to the horizontal factors are the following: Zero factor—The horizontal factor to be used when the HRMA is zero. This factor positions the y-intercept for any of the horizontal factor functions. Cut angle—The HRMA angle beyond which the HF will be set to infinity. Slope—The slope of the straight line used with the Linear and Inverse Linear horizontal factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). Side value—The HF when the HRMA is greater than or equal to 45 degrees and less than 90 degrees when the Forward horizontal factor keyword is specified. Table name—The name of the table defining the HF. | Horizontal Factor |
| Output Distance Accumulation Raster(Optional) | The output distance raster. The distance accumulation raster contains the accumulative distance for each cell from, or to, the least-cost source. | Raster Dataset |
| Output Back Direction Raster(Optional) | The back direction raster contains the calculated direction in degrees. The direction identifies the next cell along the shortest path back to the closest source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| Output Source Direction Raster(Optional) | The source direction raster identifies the direction of the least accumulated cost source cell as an azimuth in degrees. The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| Output Source Location Raster(Optional) | The source location raster is a multiband output. The first band contains a row index, and the second band contains a column index. These indexes identify the location of the source cell that is the least accumulated cost distance away. | Raster Dataset |
| Source Field(Optional) | The field used to assign values to the source locations. It must be of integer type. | Field |
| Initial Accumulation (Optional) | The initial accumulative cost that will be used to begin the cost calculation.Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value.The values must be zero or greater. The default is 0. | Double; Field |
| Maximum Accumulation(Optional) | The maximum accumulation for the traveler for a source.The cost calculations continue for each source until the specified accumulation is reached.The values must be greater than zero. The default accumulation is to the edge of the output raster. | Double; Field |
| Multiplier to Apply to Costs(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| Travel Direction(Optional) | Specifies the direction of the traveler when applying horizontal and vertical factors.If you select the String option, you can choose between from and to options, which will be applied to all sources.If you select the Field option, you can select the field from the source data that determines the direction to use for each source. The field must contain the text string FROM_SOURCE or TO_SOURCE.Travel from source—The horizontal factor and vertical factor will be applied beginning at the input source and travel out to the nonsource cells. This is the default.Travel to source—The horizontal factor and vertical factor will be applied beginning at each nonsource cell and travel back to the input source. | String; Field |
| Distance Method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.Planar—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.Geodesic—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| in_source_data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| in_barrier_data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature.For a raster barrier, the barrier must have a valid value, including zero, and the areas that are not barriers must be NoData. | Raster Layer; Feature Layer |
| in_surface_raster(Optional) | A raster defining the elevation values at each cell location.The values are used to calculate the actual surface distance covered when passing between cells. | Raster Layer |
| in_cost_raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point. Cost raster values that are negative or zero are invalid but will be treated as small positive cost values. | Raster Layer |
| in_vertical_raster(Optional) | A raster defining the z-values for each cell location.The values are used for calculating the slope used to identify the vertical factor incurred when moving from one cell to another. | Raster Layer |
| vertical_factor(Optional) | The Vertical factor object defines the relationship between the vertical cost factor and the vertical relative moving angle (VRMA).There are several factors with modifiers that identify a defined vertical factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the vertical factor used in calculating the total cost for moving into a neighboring cell.In the descriptions below, two acronyms are used: VF stands for vertical factor, which defines the vertical difficulty encountered in moving from one cell to the next; VRMA stands for vertical relative moving angle, which identifies the slope angle between the FROM or processing cell and the TO cell.The object comes in the following forms: VfBinary, VfLinear, VfInverseLinear, VfSymLinear, VfSymInverseLinear, VfCos, VfSec, VfSec, VfCosSec, VfSecCos, VfHikingTime, VfBidirHikingTime, VfTable.The definitions and parameters of these are the following:VfBinary({zeroFactor}, {lowCutAngle}, {highCutAngle}) If the VRMA is greater than the low-cut angle and less than the high-cut angle, the VF is set to the value associated with the zero factor; otherwise, it is infinity.VfLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is a linear function of the VRMA.VfInverseLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is an inverse linear function of the VRMA.VfSymLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is a linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis.VfSymInverseLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is an inverse linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis.VfCos({lowCutAngle}, {highCutAngle}, {cosPower}) The VF is the cosine-based function of the VRMA.VfSec({lowCutAngle}, {highCutAngle}, {secPower}) The VF is the secant-based function of the VRMA.VfCosSec({lowCutAngle}, {highCutAngle}, {cosPower}, {secPower}) The VF is the cosine-based function of the VRMA when the VRMA is negative and is the secant-based function of the VRMA when the VRMA is not negative.VfSecCos({lowCutAngle}, {highCutAngle}, {secPower}, {cos_power}) The VF is the secant-based function of the VRMA when the VRMA is negative and is the cosine-based function of the VRMA when the VRMA is not negative.VfHikingTime({lowCutAngle}, {highCutAngle}) The VF is the hiking time function of the VRMA.VfBidirHikingTime({lowCutAngle}, {highCutAngle}) The VF is a bidirectional modified hiking time function of the VRMA.VfTable(inTable) A table file will be used to define the vertical factor graph used to determine the VFs. The modifiers to the vertical parameters are the following: zeroFactor—The vertical factor used when the VRMA is zero. This factor positions the y-intercept of the specified function. By definition, the zero factor is not applicable to any of the trigonometric vertical functions (Cos, Sec, Cos-Sec, or Sec-Cos). The y-intercept is defined by these functions. lowCutAngle—The VRMA angle below which the VF will be set to infinity. highCutAngle—The VRMA angle above which the VF will be set to infinity. slope—The slope of the straight line used with the VfLinear and VfInverseLinear parameters. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). inTable—The name of the table defining the VF. | Vertical Factor |
| in_horizontal_raster(Optional) | A raster defining the horizontal direction at each cell.The values on the raster must be integers ranging from 0 to 360, with 0 degrees being north, or toward the top of the screen, and increasing clockwise. Flat areas should be given a value of -1. The values at each location will be used in conjunction with the horizontal_factor parameter to determine the horizontal cost incurred when moving from a cell to its neighbors. | Raster Layer |
| horizontal_factor(Optional) | The Horizontal Factor object defines the relationship between the horizontal cost factor and the horizontal relative moving angle.There are several factors with modifiers that identify a defined horizontal factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the horizontal factor used in calculating the total cost of moving into a neighboring cell.In the descriptions below, two acronyms are used: HF stands for horizontal factor, which defines the horizontal difficulty encountered when moving from one cell to the next; HRMA stands for horizontal relative moving angle, which identifies the angle between the horizontal direction from a cell and the moving direction.The object comes in the following forms: HfBinary, HfForward, HfLinear, HfInverseLinear, and HfTable. The definitions and parameters of these are the following: HfBinary({zeroFactor}, {cutAngle}) If the HRMA is less than the cut angle, the HF is set to the value associated with the zero factor; otherwise, it is infinity. HfForward({zeroFactor}, {sideValue}) Only forward movement is allowed. The HRMA must be greater than or equal to 0 and less than 90 degrees (0 <= HRMA < 90). If the HRMA is greater than 0 and less than 45 degrees, the HF for the cell is set to the value associated with the zero factor. If the HRMA is greater than or equal to 45 degrees, the side value modifier value is used. The HF for any HRMA equal to or greater than 90 degrees is set to infinity. HfLinear({zeroFactor}, {cutAngle}, {slope}) The HF is a linear function of the HRMA. HfInverseLinear({zeroFactor}, {cutAngle}, {slope}) The HF is an inverse linear function of the HRMA. HfTable(inTable) A table file will be used to define the horizontal factor graph used to determine the HFs.The modifiers to the horizontal keywords are the following: zeroFactor—The horizontal factor to be used when the HRMA is 0. This factor positions the y-intercept for any of the horizontal factor functions. cutAngle—The HRMA angle beyond which the HF will be set to infinity. slope—The slope of the straight line used with the HfLinear and HfInverseLinear horizontal factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). sideValue—The HF when the HRMA is greater than or equal to 45 degrees and less than 90 degrees when the HfForward horizontal factor keyword is specified. inTable—The name of the table defining the HF. | Horizontal Factor |
| out_distance_accumulation_raster(Optional) | The output distance raster. The distance accumulation raster contains the accumulative distance for each cell from, or to, the least-cost source. | Raster Dataset |
| out_back_direction_raster(Optional) | The back direction raster contains the calculated direction in degrees. The direction identifies the next cell along the shortest path back to the closest source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| out_source_direction_raster(Optional) | The source direction raster identifies the direction of the least accumulated cost source cell as an azimuth in degrees. The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| out_source_location_raster(Optional) | The source location raster is a multiband output. The first band contains a row index, and the second band contains a column index. These indexes identify the location of the source cell that is the least accumulated cost distance away. | Raster Dataset |
| source_field(Optional) | The field used to assign values to the source locations. It must be of integer type. | Field |
| source_initial_accumulation(Optional) | The initial accumulative cost that will be used to begin the cost calculation.Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value.The values must be zero or greater. The default is 0. | Double; Field |
| source_maximum_accumulation(Optional) | The maximum accumulation for the traveler for a source.The cost calculations continue for each source until the specified accumulation is reached.The values must be greater than zero. The default accumulation is to the edge of the output raster. | Double; Field |
| source_cost_multiplier(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| source_direction(Optional) | Specifies the direction of the traveler when applying horizontal and vertical factors.FROM_SOURCE—The horizontal factor and vertical factor will be applied beginning at the input source and travel out to the nonsource cells. This is the default.TO_SOURCE—The horizontal factor and vertical factor will be applied beginning at each nonsource cell and travel back to the input source. Specify the FROM_SOURCE or TO_SOURCE keyword, which will be applied to all sources, or specify a field in the source data that contains the keywords to identify the direction of travel for each source. That field must contain the string FROM_SOURCE or TO_SOURCE. | String; Field |
| distance_method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.PLANAR—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.GEODESIC—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |

## Code Samples

### Example 1

```python
Keyword                   Zero    Low    High   Slope  Power  Cos    Sec
                          factor  cut    cut                  power  power
                                  angle  angle                             
------------------------  ------  -----  -----  -----  -----  -----  -----
Binary                    1.0     -30    30     ~      ~      ~      ~
Linear                    1.0     -90    90      1/90  ~      ~      ~
Symmetric linear          1.0     -90    90      1/90  ~      ~      ~
Inverse linear            1.0     -45    45     -1/45  ~      ~      ~
Symmetric inverse linear  1.0     -45    45     -1/45  ~      ~      ~
Cos                       ~       -90    90     ~      1.0    ~      ~
Sec                       ~       -90    90     ~      1.0    ~      ~
Cos_sec                   ~       -90    90     ~      ~      1.0    1.0
Sec_cos                   ~       -90    90     ~      ~      1.0    1.0
Hiking time               ~       -70    70     ~      ~      ~      ~
Bidirectional hiking time ~       -70    70     ~      ~      ~      ~
```

### Example 2

```python
Keywords         Zero factor   Cut angle     Slope   Side value
--------------   -----------   -----------   -----   ---------
Binary           1.0            45           ~       ~
Forward          0.5            45 (fixed)   ~       1.0
Linear           0.5           181            1/90   ~
Inverse linear   2.0           180           -1/90   ~
```

### Example 3

```python
DistanceAllocation(in_source_data, {in_barrier_data}, {in_surface_raster}, {in_cost_raster}, {in_vertical_raster}, {vertical_factor}, {in_horizontal_raster}, {horizontal_factor}, {out_distance_accumulation_raster}, {out_back_direction_raster}, {out_source_direction_raster}, {out_source_location_raster}, {source_field}, {source_initial_accumulation}, {source_maximum_accumulation}, {source_cost_multiplier}, {source_direction}, {distance_method})
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDistAlloc = DistanceAllocation("insources.shp", "barriers.tif")
outDistAlloc.save("c:/sapyexamples/output/distalloc.tif")
```

### Example 5

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDistAlloc = DistanceAllocation("insources.shp", "barriers.tif")
outDistAlloc.save("c:/sapyexamples/output/distalloc.tif")
```

### Example 6

```python
# Name: DistanceAllocation_Ex_02.py
# Description: Calculates the distance allocation.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSources = "insources.shp"
inBarrier = "barriers.tif"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute EucDirections
outDistAlloc = DistanceAllocation(inSources, inBarrier)

# Save the output 
outDistAlloc.save("c:/sapyexamples/output/distAllo2.tif")
```

### Example 7

```python
# Name: DistanceAllocation_Ex_02.py
# Description: Calculates the distance allocation.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSources = "insources.shp"
inBarrier = "barriers.tif"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute EucDirections
outDistAlloc = DistanceAllocation(inSources, inBarrier)

# Save the output 
outDistAlloc.save("c:/sapyexamples/output/distAllo2.tif")
```

---

## Divide (Spatial Analyst)

## Summary

Divides the values of two rasters on a cell-by-cell basis.

## Usage

- The order of inputs is relevant for this tool.
- When a number is divided by zero, the output result is NoData.
- The data types of the inputs to determine the data type of the output: If both inputs are integers, an integer division is performed, and the output result is an integer. For example, if 3 is divided by 2, the output is 1.If either input is floating-point, a floating-point division is performed, and the output result is a floating-point value. For example, if 3 is divided by 2.0, the output is 1.5.
- If both inputs are integers, an integer division is performed, and the output result is an integer. For example, if 3 is divided by 2, the output is 1.
- If either input is floating-point, a floating-point division is performed, and the output result is a floating-point value. For example, if 3 is divided by 2.0, the output is 1.5.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "/" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input whose values will be divided by the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input whose values the first input are to be divided by.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input whose values will be divided by the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input whose values the first input are to be divided by.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Divide(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDivide = Divide("degs", "negs")
outDivide.save("C:/sapyexamples/output/outdivide2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outDivide = Divide("degs", "negs")
outDivide.save("C:/sapyexamples/output/outdivide2")
```

### Example 4

```python
# Name: Divide_Ex_02.py
# Description: Divides the values of two rasters on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster01 = "elevation"
inRaster02 = "landuse"

# Execute Divide
outDivide = Divide(inRaster01, inRaster02)

# Save the output 
outDivide.save("C:/sapyexamples/output/outdivide")
```

### Example 5

```python
# Name: Divide_Ex_02.py
# Description: Divides the values of two rasters on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster01 = "elevation"
inRaster02 = "landuse"

# Execute Divide
outDivide = Divide(inRaster01, inRaster02)

# Save the output 
outDivide.save("C:/sapyexamples/output/outdivide")
```

---

## Edit Signatures (Spatial Analyst)

## Summary

Edits and updates a signature file by merging, renumbering, and deleting class signatures.

## Usage

- The Edit Signatures tool allows the modification of an existing signature file by all or any of the following operations:Merging signatures of a set of classesRenumbering a signature class IDDeleting unwanted signatures
- Merging signatures of a set of classes
- Renumbering a signature class ID
- Deleting unwanted signatures
- When a multiband raster is specified as one of the Input raster bands (in_raster_bands in Python), all the bands will be used.To process a selection of bands from a multiband raster, you can first create a new raster dataset composed of those particular bands with the Composite Bands tool, and use the result in the list of the Input raster bands (in_raster_bands in Python).
- The input signature file must be an ASCII signature file. The file can be the output of any Multivariate tool that produces the file containing the required statistical information—for example, Iso Cluster and Create Signatures. The file must have a minimum of two classes. Such a file can be recognized by its .gsg extension.
- The input signature remap file is an ASCII file consisting of two columns of values per line, separated by a colon. The first column is the value of the original class ID. The second column contains the new class IDs for updating in the signature file. All of the entries in the file must be sorted in ascending order based on the first columnIn certain cases, some of your desired classes may be statistically too similar to each other, therefore, assignment of cells to the unique classes may not be reliable. For example, you may have wanted a wetland class and a separate class for forest wetland. However, these two classes cannot be easily distinguished from one another. In this case, you may want to merge the forest wetland class into the more general wetland class. Alternatively, if there is no statistical difference between the classes, you can remove one of them altogether since they both essentially represent the same class.To merge a set of classes, put the same new class ID for the second value for each class ID of that set. Only classes that need to be edited have to be placed in the signature remap file; any class not present in the remap file will remain unchanged. To delete a class signature, use -9999 as the value for the second column of that class. A class ID can also be renumbered to a value that does not exist in the input signature file.The following is an example of an input signature remap file:2 : 3 4 : 11 5 : -9999 9 : 3This example will merge classes 2 and 9 with 3, merge class 4 with 11, and delete class 5.
- If the input signature file carries names for the class signatures and if the signatures in the input signature remap file are to be merged, the name associated with the value in which to merge will be transferred to the output signature file.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster bands | The input raster bands for which to edit the signatures.They can be integer or floating point type. | Raster Layer |
| Input signature file | Input signature file whose class signatures are to be edited.A .gsg extension is required. | File |
| Input signature remap file | Input ASCII remap table containing the class IDs to be merged, renumbered, or deleted.The extension can be .rmp, .asc or .txt. The default is .rmp. | File |
| Output signature file | The output signature file.A .gsg extension must be specified. | File |
| Sample interval(Optional) | The interval to be used for sampling.The default is 10. | Long |
| in_raster_bands[in_raster_band,...] | The input raster bands for which to edit the signatures.They can be integer or floating point type. | Raster Layer |
| in_signature_file | Input signature file whose class signatures are to be edited.A .gsg extension is required. | File |
| in_signature_remap_file | Input ASCII remap table containing the class IDs to be merged, renumbered, or deleted.The extension can be .rmp, .asc or .txt. The default is .rmp. | File |
| out_signature_file | The output signature file.A .gsg extension must be specified. | File |
| sample_interval(Optional) | The interval to be used for sampling.The default is 10. | Long |

## Code Samples

### Example 1

```python
2 : 3
4 : 11
5 : -9999
9 : 3
```

### Example 2

```python
EditSignatures(in_raster_bands, in_signature_file, in_signature_remap_file, out_signature_file, {sample_interval})
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
EditSignatures("redl123", "c:/sapyexamples/data/zsamp12.gsg", 
               "c:/sapyexamples/data/zsamp7.rmp", 
               "c:/sapyexamples/output/redlremap.gsg", "")
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
EditSignatures("redl123", "c:/sapyexamples/data/zsamp12.gsg", 
               "c:/sapyexamples/data/zsamp7.rmp", 
               "c:/sapyexamples/output/redlremap.gsg", "")
```

### Example 5

```python
# Name: EditSignatures_Ex_02.py
# Description: Edits and updates a signature file by merging, renumbering, 
#    and deleting class signatures.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "redl123"
oldSig = "c:/sapyexamples/data/zsamp12.gsg"
sigRemap = "c:/sapyexamples/data/zsamp7.rmp"
outNewSig = "c:/sapyexamples/output/redlsig.gsg"
interval = ""

# Execute EditSignatures
EditSignatures(inRaster, oldSig, sigRemap, outNewSig, interval)
```

### Example 6

```python
# Name: EditSignatures_Ex_02.py
# Description: Edits and updates a signature file by merging, renumbering, 
#    and deleting class signatures.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "redl123"
oldSig = "c:/sapyexamples/data/zsamp12.gsg"
sigRemap = "c:/sapyexamples/data/zsamp7.rmp"
outNewSig = "c:/sapyexamples/output/redlsig.gsg"
interval = ""

# Execute EditSignatures
EditSignatures(inRaster, oldSig, sigRemap, outNewSig, interval)
```

---

## Equal To Frequency (Spatial Analyst)

## Summary

Evaluates on a cell-by-cell basis the number of times the values in a set of rasters are equal to another raster.

## Usage

- An arbitrary number of rasters can be specified in the input rasters list.
- If a cell location contains NoData on any of the input rasters, that location will be assigned NoData on the output.
- The output raster is always of integer type.
- If all inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process, otherwise an error will occur.If all of the inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before performing the operation.If one or more of the inputs are multidimensional rasters and the other inputs are constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input value raster | For each cell location in the input value raster, the number of occurrences (frequency) where a raster in the input list has an equal value is counted. | Raster Layer |
| Input rasters | The list of rasters that will be compared to the value raster. | Raster Layer |
| Process as multiband(Optional) | Specifies how the input multiband raster bands will be processed.Unchecked—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.Checked—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |
| in_value_raster | For each cell location in the input value raster, the number of occurrences (frequency) where a raster in the input list has an equal value is counted. | Raster Layer |
| in_rasters[in_raster,...] | The list of rasters that will be compared to the value raster. | Raster Layer |
| process_as_multiband(Optional) | Specifies how the input multiband raster bands will be processed.SINGLE_BAND—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.MULTI_BAND—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |

## Code Samples

### Example 1

```python
EqualToFrequency(in_value_raster, in_rasters, {process_as_multiband})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outETF = EqualToFrequency("cost", ["degs", "negs", "fourgrd"])
outETF.save("C:/sapyexamples/output/outetf.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outETF = EqualToFrequency("cost", ["degs", "negs", "fourgrd"])
outETF.save("C:/sapyexamples/output/outetf.tif")
```

### Example 4

```python
# Name: EqualToFrequency_Ex_02.py
# Description: Evaluates the number of times a set of rasters is
#              equal to another raster on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inValueRaster = "cost"
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute EqualToFrequency
outETF = EqualToFrequency(inValueRaster, [inRaster01, inRaster02, inRaster03])

# Save the output 
outETF.save("C:/sapyexamples/output/outETF")
```

### Example 5

```python
# Name: EqualToFrequency_Ex_02.py
# Description: Evaluates the number of times a set of rasters is
#              equal to another raster on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inValueRaster = "cost"
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute EqualToFrequency
outETF = EqualToFrequency(inValueRaster, [inRaster01, inRaster02, inRaster03])

# Save the output 
outETF.save("C:/sapyexamples/output/outETF")
```

---

## Equal To (Spatial Analyst)

## Summary

Performs a Relational equal-to operation on two inputs on a cell-by-cell basis.

## Usage

- Two inputs are necessary for this relational evaluation to take place.
- The order of inputs is irrelevant for this tool.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "==" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input that will be compared to for equality by the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input that will be compared from for equality by the first input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input that will be compared to for equality by the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input that will be compared from for equality by the first input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
EqualTo(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outEqualTo = EqualTo("degs", "negs")
outEqualTo.save("C:/sapyexamples/output/outequalto.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outEqualTo = EqualTo("degs", "negs")
outEqualTo.save("C:/sapyexamples/output/outequalto.tif")
```

### Example 4

```python
# Name: EqualTo_Ex_02.py
# Description: Performs a relational equal-to operation on two inputs
#              on a cell-by-cell basis within the Analysis window
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute EqualTo
outEqualTo = EqualTo(inRaster1, inRaster2)

# Save the output 
outEqualTo.save("C:/sapyexamples/output/outequalto")
```

### Example 5

```python
# Name: EqualTo_Ex_02.py
# Description: Performs a relational equal-to operation on two inputs
#              on a cell-by-cell basis within the Analysis window
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute EqualTo
outEqualTo = EqualTo(inRaster1, inRaster2)

# Save the output 
outEqualTo.save("C:/sapyexamples/output/outequalto")
```

---

## Euclidean Allocation (Spatial Analyst)

## Summary

Calculates, for each cell, the nearest source based on Euclidean distance.

## Usage

- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted to a raster internally before performing the analysis.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- The Maximum Distance value is specified in the same map units as the input source data.
- The input value raster is useful if the input raster or feature source data is a raster derived from a function that results in either one or zero. These functions lose their original zone values associated with the source cell locations. The input value raster can either restore these values or allow analysis on additional combinations of zone values within the source cells.
- If an input value raster is used, it may change the configuration and results of the Euclidean allocation output. It will not affect the optional Euclidean distance or direction results.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, the default output cell size is determined based on the type of input dataset as follows:If the input dataset is a raster, the cell size of the dataset is used.If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the input dataset is a raster, the cell size of the dataset is used.
- If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- The default processing extent for this tool is the Union of Inputs value. The combined extent of both input datasets will be processed.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature source data | The input source locations.This is a raster or feature identifying the cells or locations that will be used to calculate the Euclidean distance for each output cell location.For rasters, the input type can be integer or floating point. If the input source raster is floating point, the Input value raster parameter must be set, and it must be integer. The value raster will take precedence over the Source field parameter setting. | Raster Layer; Feature Layer |
| Maximum distance(Optional) | The threshold that the accumulative distance values cannot exceed.If an accumulative Euclidean distance value exceeds this value, the output value for the cell location will be NoData.The default distance is to the edge of the output raster. | Double |
| Input value raster(Optional) | The input integer raster that identifies the zone values that will be used for each input source location.For each source location (cell or feature), this value will be assigned to all cells allocated to the source location for the computation. The value raster will take precedence over the Source field parameter setting. | Raster Layer |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Source field(Optional) | The field used to assign values to the source locations. It must be of integer type.If the Input value raster parameter has been set, the values in that input will have precedence over this parameter setting. | Field |
| Output distance raster(Optional) | The output Euclidean distance raster.The distance raster identifies, for each cell, the Euclidean distance to the closest source cell, set of source cells, or source location.The output raster is of floating-point type. | Raster Dataset |
| Output direction raster(Optional) | The output Euclidean direction raster.The direction raster contains the calculated direction, in degrees, that each cell center is from the closest source cell center.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of integer type. | Raster Dataset |
| Distance Method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.Planar—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.Geodesic—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| Input raster or feature barrier data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| Out back direction raster(Optional) | The output Euclidean back direction raster.The back direction raster contains the calculated direction in degrees. The direction identifies the next cell along the shortest path back to the closest source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| in_source_data | The input source locations.This is a raster or feature identifying the cells or locations that will be used to calculate the Euclidean distance for each output cell location.For rasters, the input type can be integer or floating point. If the input source raster is floating point, the in_value_raster parameter must be set, and it must integer. The value raster will take precedence over the source_field parameter setting. | Raster Layer; Feature Layer |
| maximum_distance(Optional) | The threshold that the accumulative distance values cannot exceed.If an accumulative Euclidean distance value exceeds this value, the output value for the cell location will be NoData.The default distance is to the edge of the output raster. | Double |
| in_value_raster(Optional) | The input integer raster that identifies the zone values that will be used for each input source location.For each source location (cell or feature), this value will be assigned to all cells allocated to the source location for the computation. The value raster will take precedence over the source_field parameter setting. | Raster Layer |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| source_field(Optional) | The field used to assign values to the source locations. It must be of integer type.If the in_value_raster parameter has been set, the values in that input will have precedence over this parameter setting. | Field |
| out_distance_raster(Optional) | The output Euclidean distance raster.The distance raster identifies, for each cell, the Euclidean distance to the closest source cell, set of source cells, or source location.The output raster is of floating-point type. | Raster Dataset |
| out_direction_raster(Optional) | The output Euclidean direction raster.The direction raster contains the calculated direction, in degrees, that each cell center is from the closest source cell center.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of integer type. | Raster Dataset |
| distance_method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.PLANAR—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.GEODESIC—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| in_barrier_data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| out_back_direction_raster(Optional) | The output Euclidean back direction raster.The back direction raster contains the calculated direction in degrees. The direction identifies the next cell along the shortest path back to the closest source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |

## Code Samples

### Example 1

```python
EucAllocation(in_source_data, {maximum_distance}, {in_value_raster}, {cell_size}, {source_field}, {out_distance_raster}, {out_direction_raster}, {distance_method}, {in_barrier_data}, {out_back_direction_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
eucAllocate = EucAllocation("observers", 50000, "elevation", 25, "FID", 
                            "c:/sapyexamples/output/outeucdist", 
                            "c:/sapyexamples/output/outeucdir")
eucAllocate.save("c:/sapyexamples/output/eucalloc")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
eucAllocate = EucAllocation("observers", 50000, "elevation", 25, "FID", 
                            "c:/sapyexamples/output/outeucdist", 
                            "c:/sapyexamples/output/outeucdir")
eucAllocate.save("c:/sapyexamples/output/eucalloc")
```

### Example 4

```python
# Name: EucAllocation_Ex_02.py
# Description: Calculates, for each cell, the zone of the closest 
#              source location in Euclidean distance.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
maxDist = 50000
valRaster = "elevation"
cellSize = 25
sourceField = "FID"
optOutDist = "c:/sapyexamples/output/outeucdist02"
optOutDir = "c:/sapyexamples/output/outeucdir02"

# Execute EucAllocation
eucAllocate = EucAllocation(inSource, maxDist, valRaster, cellSize,
                             sourceField, optOutDist, optOutDir)

# Save the output 
eucAllocate.save("c:/sapyexamples/output/eucalloc02")
```

### Example 5

```python
# Name: EucAllocation_Ex_02.py
# Description: Calculates, for each cell, the zone of the closest 
#              source location in Euclidean distance.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
maxDist = 50000
valRaster = "elevation"
cellSize = 25
sourceField = "FID"
optOutDist = "c:/sapyexamples/output/outeucdist02"
optOutDir = "c:/sapyexamples/output/outeucdir02"

# Execute EucAllocation
eucAllocate = EucAllocation(inSource, maxDist, valRaster, cellSize,
                             sourceField, optOutDist, optOutDir)

# Save the output 
eucAllocate.save("c:/sapyexamples/output/eucalloc02")
```

---

## Euclidean Back Direction (Spatial Analyst)

## Summary

Calculates, for each cell, the direction, in degrees, to the neighboring cell along the shortest path back to the closest source while avoiding barriers.

## Usage

- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- The output values are based on compass directions (90 to the east, 180 to the south, 270 to the west, and 360 to the north), with 0 reserved for the source cells.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted to a raster internally before performing the analysis.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- The Maximum Distance value is specified in the same map units as the input source data.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, the default output cell size is determined based on the type of input dataset as follows:If the input dataset is a raster, the cell size of the dataset is used.If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the input dataset is a raster, the cell size of the dataset is used.
- If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- The default processing extent for this tool is the Union of Inputs value. The combined extent of both input datasets will be processed.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature source data | The input source locations.This is a raster or feature dataset that identifies the cells or locations to which the Euclidean back direction for every output cell location is calculated.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| Input raster or feature barrier data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| Maximum distance(Optional) | The threshold that the accumulative distance values cannot exceed.If an accumulative Euclidean distance value exceeds this value, the output value for the cell location will be NoData.The default distance is to the edge of the output raster. | Double |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Distance Method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.Planar—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.Geodesic—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| in_source_data | The input source locations.This is a raster or feature dataset that identifies the cells or locations to which the Euclidean back direction for every output cell location is calculated.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| in_barrier_data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| maximum_distance(Optional) | The threshold that the accumulative distance values cannot exceed.If an accumulative Euclidean distance value exceeds this value, the output value for the cell location will be NoData.The default distance is to the edge of the output raster. | Double |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| distance_method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.PLANAR—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.GEODESIC—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |

## Code Samples

### Example 1

```python
EucBackDirection(in_source_data, {in_barrier_data}, {maximum_distance}, {cell_size}, {distance_method})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outEucBackDir = EucBackDirection("observers", "in_barriers", 35000, 50, 
                            "GEODESIC")
outEucBackDir.save("c:/sapyexamples/output/eucoutbackdir.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outEucBackDir = EucBackDirection("observers", "in_barriers", 35000, 50, 
                            "GEODESIC")
outEucBackDir.save("c:/sapyexamples/output/eucoutbackdir.tif")
```

### Example 4

```python
# Name: EucBackDirection_Ex_02.py
# Description: Calculates, for each cell, the direction,
#              in degrees, to the neighboring cell along
#              the shortest path back to the closest
#              source while avoiding barriers.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
inBarriers = "rivers.tif"
maxDist = 35000
cellSize = 50
distMethod = "GEODESIC"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute EucDirections
outEucBackDir = EucBackDirection(inSource, inBarriers, maxDist,
                            cellSize, distMethod)

# Save the output 
outEucBackDir.save("c:/sapyexamples/output/eucoutbackdir02.tif")
```

### Example 5

```python
# Name: EucBackDirection_Ex_02.py
# Description: Calculates, for each cell, the direction,
#              in degrees, to the neighboring cell along
#              the shortest path back to the closest
#              source while avoiding barriers.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
inBarriers = "rivers.tif"
maxDist = 35000
cellSize = 50
distMethod = "GEODESIC"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute EucDirections
outEucBackDir = EucBackDirection(inSource, inBarriers, maxDist,
                            cellSize, distMethod)

# Save the output 
outEucBackDir.save("c:/sapyexamples/output/eucoutbackdir02.tif")
```

---

## Euclidean Direction (Spatial Analyst)

## Summary

Calculates, for each cell, the direction, in degrees, to the nearest source.

## Usage

- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- The output values are based on compass directions (90 to the east, 180 to the south, 270 to the west, and 360 to the north), with 0 reserved for the source cells.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted to a raster internally before performing the analysis.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- The Maximum Distance value is specified in the same map units as the input source data.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, the default output cell size is determined based on the type of input dataset as follows:If the input dataset is a raster, the cell size of the dataset is used.If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the input dataset is a raster, the cell size of the dataset is used.
- If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- The default processing extent for this tool is the Union of Inputs value. The combined extent of both input datasets will be processed.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature source data | The input source locations.This is a raster or feature identifying the cells or locations that will be used to calculate the Euclidean distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| Maximum distance(Optional) | The threshold that the accumulative distance values cannot exceed.If an accumulative Euclidean distance value exceeds this value, the output value for the cell location will be NoData.The default distance is to the edge of the output raster. | Double |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Output distance raster(Optional) | The output Euclidean distance raster.The distance raster identifies, for each cell, the Euclidean distance to the closest source cell, set of source cells, or source location.The output raster is of floating-point type. | Raster Dataset |
| Distance Method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.Planar—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.Geodesic—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| Input raster or feature barrier data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| Out back direction raster(Optional) | The output Euclidean back direction raster.The back direction raster contains the calculated direction in degrees. The direction identifies the next cell along the shortest path back to the closest source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| in_source_data | The input source locations.This is a raster or feature identifying the cells or locations that will be used to calculate the Euclidean distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| maximum_distance(Optional) | The threshold that the accumulative distance values cannot exceed.If an accumulative Euclidean distance value exceeds this value, the output value for the cell location will be NoData.The default distance is to the edge of the output raster. | Double |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| out_distance_raster(Optional) | The output Euclidean distance raster.The distance raster identifies, for each cell, the Euclidean distance to the closest source cell, set of source cells, or source location.The output raster is of floating-point type. | Raster Dataset |
| distance_method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.PLANAR—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.GEODESIC—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| in_barrier_data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| out_back_direction_raster(Optional) | The output Euclidean back direction raster.The back direction raster contains the calculated direction in degrees. The direction identifies the next cell along the shortest path back to the closest source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |

## Code Samples

### Example 1

```python
EucDirection(in_source_data, {maximum_distance}, {cell_size}, {out_distance_raster}, {distance_method}, {in_barrier_data}, {out_back_direction_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outEucDirect = EucDirection("observers", 35000, 50, 
                            "c:/sapyexamples/output/optoutdist")
outEucDirect.save("c:/sapyexamples/output/eucoutdir")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outEucDirect = EucDirection("observers", 35000, 50, 
                            "c:/sapyexamples/output/optoutdist")
outEucDirect.save("c:/sapyexamples/output/eucoutdir")
```

### Example 4

```python
# Name: EucDirection_Ex_02.py
# Description: Calculates the direction in degrees that each 
#              cell center is from the cell center of the 
#              closest source.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
maxDist = 35000
cellSize = 50
optOutDistance = "c:/sapyexamples/output/optdistout"

# Execute EucDirections
outEucDirect = EucDirection(inSource, maxDist, cellSize, 
                            optOutDistance)

# Save the output 
outEucDirect.save("c:/sapyexamples/output/eucoutdir02")
```

### Example 5

```python
# Name: EucDirection_Ex_02.py
# Description: Calculates the direction in degrees that each 
#              cell center is from the cell center of the 
#              closest source.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
maxDist = 35000
cellSize = 50
optOutDistance = "c:/sapyexamples/output/optdistout"

# Execute EucDirections
outEucDirect = EucDirection(inSource, maxDist, cellSize, 
                            optOutDistance)

# Save the output 
outEucDirect.save("c:/sapyexamples/output/eucoutdir02")
```

---

## Euclidean Distance (Spatial Analyst)

## Summary

Calculates, for each cell, the Euclidean distance to the nearest source.

## Usage

- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted to a raster internally before performing the analysis.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- The Maximum Distance value is specified in the same map units as the input source data.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, the default output cell size is determined based on the type of input dataset as follows:If the input dataset is a raster, the cell size of the dataset is used.If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the input dataset is a raster, the cell size of the dataset is used.
- If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- The default processing extent for this tool is the Union of Inputs value. The combined extent of both input datasets will be processed.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature source data | The input source locations.This is a raster or feature identifying the cells or locations that will be used to calculate the Euclidean distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| Maximum distance(Optional) | The threshold that the accumulative distance values cannot exceed.If an accumulative Euclidean distance value exceeds this value, the output value for the cell location will be NoData.The default distance is to the edge of the output raster. | Double |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Output direction raster(Optional) | The output Euclidean direction raster.The direction raster contains the calculated direction, in degrees, that each cell center is from the closest source cell center.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of integer type. | Raster Dataset |
| Distance Method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.Planar—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.Geodesic—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| Input raster or feature barrier data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| Out back direction raster(Optional) | The output Euclidean back direction raster.The back direction raster contains the calculated direction in degrees. The direction identifies the next cell along the shortest path back to the closest source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |
| in_source_data | The input source locations.This is a raster or feature identifying the cells or locations that will be used to calculate the Euclidean distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| maximum_distance(Optional) | The threshold that the accumulative distance values cannot exceed.If an accumulative Euclidean distance value exceeds this value, the output value for the cell location will be NoData.The default distance is to the edge of the output raster. | Double |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| out_direction_raster(Optional) | The output Euclidean direction raster.The direction raster contains the calculated direction, in degrees, that each cell center is from the closest source cell center.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of integer type. | Raster Dataset |
| distance_method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.PLANAR—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.GEODESIC—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| in_barrier_data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| out_back_direction_raster(Optional) | The output Euclidean back direction raster.The back direction raster contains the calculated direction in degrees. The direction identifies the next cell along the shortest path back to the closest source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north).The output raster is of type float. | Raster Dataset |

## Code Samples

### Example 1

```python
EucDistance(in_source_data, {maximum_distance}, {cell_size}, {out_direction_raster}, {distance_method}, {in_barrier_data}, {out_back_direction_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outEucDistance = EucDistance("rec_sites.shp", 5000, 5, 
                             "c:/sapyexamples/output/EucDirOut")
outEucDistance.save("C:/sapyexamples/output/eucdist")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outEucDistance = EucDistance("rec_sites.shp", 5000, 5, 
                             "c:/sapyexamples/output/EucDirOut")
outEucDistance.save("C:/sapyexamples/output/eucdist")
```

### Example 4

```python
# Name: EucDistance_Ex_02.py
# Description: Calculates for each cell the Euclidean distance to the nearest source.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSourceData = "rec_sites.shp"
maxDistance = 4000
cellSize = 4
outDirectionRaster = "C:/sapyexamples/output/eucdirect"

# Execute EucDistance
outEucDistance = EucDistance(inSourceData, maxDistance, cellSize, outDirectionRaster)

# Save the output 
outEucDistance.save("C:/sapyexamples/output/eucdist")
```

### Example 5

```python
# Name: EucDistance_Ex_02.py
# Description: Calculates for each cell the Euclidean distance to the nearest source.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSourceData = "rec_sites.shp"
maxDistance = 4000
cellSize = 4
outDirectionRaster = "C:/sapyexamples/output/eucdirect"

# Execute EucDistance
outEucDistance = EucDistance(inSourceData, maxDistance, cellSize, outDirectionRaster)

# Save the output 
outEucDistance.save("C:/sapyexamples/output/eucdist")
```

---

## Exp (Spatial Analyst)

## Summary

Calculates the base e exponential of the cells in a raster.

## Usage

- Input values can be integer or float as well as negative or positive.You can review some results for both positive and negative floating-point input values in the examples of output values from the Exponential tools.
- The base e exponential is the most commonly used exponential function.
- Input values less than or equal to -745 will be set to NoData in the output, because these values cannot be accurately represented by 32-bit floating-point numbers.
- The output raster from this tool is always floating-point type, regardless of the input value type.
- Output values from this tool are always positive.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input values for which to find the base e exponential.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input values for which to find the base e exponential.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Exp(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExp = Exp("landuse")
outExp.save("C:/sapyexamples/output/outexp.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExp = Exp("landuse")
outExp.save("C:/sapyexamples/output/outexp.tif")
```

### Example 4

```python
# Name: Exp_Ex_02.py
# Description: Calculates the base e exponential of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "landuse"

# Execute Exp
outExp = Exp(inRaster)

# Save the output 
outExp.save("C:/sapyexamples/output/outexp")
```

### Example 5

```python
# Name: Exp_Ex_02.py
# Description: Calculates the base e exponential of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "landuse"

# Execute Exp
outExp = Exp(inRaster)

# Save the output 
outExp.save("C:/sapyexamples/output/outexp")
```

---

## Exp10 (Spatial Analyst)

## Summary

Calculates the base 10 exponential of the cells in a raster.

## Usage

- Input values can be integer or float as well as negative or positive.You can review some results for both positive and negative floating-point input values in the examples of output values from the Exponential tools.
- Input values less than or equal to -324 will be set to NoData in the output, because these values cannot be accurately represented by 32-bit floating-point numbers.
- The output raster from this tool is always floating-point type, regardless of the input value type.
- Output values from this tool are always positive.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input values for which to find the base 10 exponential.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input values for which to find the base 10 exponential.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Exp10(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExp10 = Exp10("degs")
outExp10.save("C:/sapyexamples/output/outexp10")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExp10 = Exp10("degs")
outExp10.save("C:/sapyexamples/output/outexp10")
```

### Example 4

```python
# Name: Exp10_Ex_02.py
# Description: Calculates the base 10 exponential of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "cost"

# Execute Exp10
outExp10 = Exp10(inRaster)

# Save the output 
outExp10.save("C:/sapyexamples/output/outexp10.img")
```

### Example 5

```python
# Name: Exp10_Ex_02.py
# Description: Calculates the base 10 exponential of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "cost"

# Execute Exp10
outExp10 = Exp10(inRaster)

# Save the output 
outExp10.save("C:/sapyexamples/output/outexp10.img")
```

---

## Exp2 (Spatial Analyst)

## Summary

Calculates the base 2 exponential of the cells in a raster.

## Usage

- Input values can be integer or float as well as negative or positive.You can review some results for both positive and negative floating-point input values in the examples of output values from the Exponential tools.
- Input values less than or equal to -1,075 will be set to NoData in the output, because these values cannot be accurately represented by 32-bit floating-point numbers.
- The output raster from this tool is always floating-point type, regardless of the input value type.
- Output values from this tool are always positive.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input values for which to find the base 2 exponential.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input values for which to find the base 2 exponential.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Exp2(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExp2 = Exp2("degs")
outExp2.save("C:/sapyexamples/output/outexp2.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExp2 = Exp2("degs")
outExp2.save("C:/sapyexamples/output/outexp2.img")
```

### Example 4

```python
# Name: Exp2_Ex_02.py
# Description: Calculates the base 2 exponential of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Exp2
outExp2 = Exp2(inRaster)

# Save the output 
outExp2.save("C:/sapyexamples/output/outexp2")
```

### Example 5

```python
# Name: Exp2_Ex_02.py
# Description: Calculates the base 2 exponential of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Exp2
outExp2 = Exp2(inRaster)

# Save the output 
outExp2.save("C:/sapyexamples/output/outexp2")
```

---

## Expand (Spatial Analyst)

## Summary

Expands specified zones of a raster by a specified number of cells.

## Usage

- The specified zone values are considered to be foreground zones, while the remaining zone values are considered to be background zones. With this tool the foreground zones are allowed to expand into the background zones.
- When two foreground zones compete to expand into the same background zone, the conflict is resolved based on the value of the majority of surrounding cells.
- NoData cells are always considered background cells; therefore, neighboring cells of any value can expand into NoData cells. NoData cells will never expand into their neighbors.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster for which the identified zones are to be expandedIt must be of integer type. | Raster Layer |
| Number of cells | The number of cells to expand each specified zone by.The value must be an integer greater than 1. | Long |
| Zone values | The list of zone values to expand.The zone values must be integers. They can be in any order. | Long |
| Expand method(Optional) | The method used to expand the selected zones.The Distance option supports parallelization, and can be controlled with the Parallel Processing Factor environment setting.Morphological—Uses a mathematical morphology method to expand the zones. This is the default.Distance—Uses a distance-based method to expand the zones. | String |
| in_raster | The input raster for which the identified zones are to be expandedIt must be of integer type. | Raster Layer |
| number_cells | The number of cells to expand each specified zone by.The value must be an integer greater than 1. | Long |
| zone_values[zone_value,...] | The list of zone values to expand.The zone values must be integers. They can be in any order. | Long |
| expand_method(Optional) | The method used to expand the selected zones.MORPHOLOGICAL—Uses a mathematical morphology method to expand the zones. This is the default.DISTANCE—Uses a distance-based method to expand the zones.The DISTANCE option supports parallelization, and can be controlled with the parallelProcessingFactor environment setting. | String |

## Code Samples

### Example 1

```python
Expand(in_raster, number_cells, zone_values, {expand_method})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExpand = Expand("filter", 2, [0, 6, -3])
outExpand.save("C:/sapyexamples/output/outexpand.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExpand = Expand("filter", 2, [0, 6, -3])
outExpand.save("C:/sapyexamples/output/outexpand.img")
```

### Example 4

```python
# Name: Expand_Ex_02.py
# Description: Expands specified zones of a raster 
#              by a specified number of cells.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "filter"
numberCells = 2
zoneValues = [0, 6, -3]

# Execute Expand
outExpand = Expand(inRaster, numberCells, zoneValues)

# Save the output 
outExpand.save("C:/sapyexamples/output/outexpand")
```

### Example 5

```python
# Name: Expand_Ex_02.py
# Description: Expands specified zones of a raster 
#              by a specified number of cells.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "filter"
numberCells = 2
zoneValues = [0, 6, -3]

# Execute Expand
outExpand = Expand(inRaster, numberCells, zoneValues)

# Save the output 
outExpand.save("C:/sapyexamples/output/outexpand")
```

---

## Export Training Data For Deep Learning (Spatial Analyst)

## Summary

Converts labeled vector or raster data into deep learning training datasets using a remote sensing image. The output will be a folder of image chips and a folder of metadata files in the specified format.

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The input source imagery, typically multispectral imagery.Examples of the types of input source imagery include multispectral satellite, drone, aerial, and National Agriculture Imagery Program (NAIP). The input can be a folder of images. | Raster Dataset; Raster Layer; Mosaic Layer; Image Service; Map Server; Map Server Layer; Internet Tiled Layer; Folder |
| Output Folder | The folder where the output image chips and metadata will be stored.The folder can also be a folder URL that uses a cloud storage connection file (*.acs). | Folder |
| Input Feature Class Or Classified Raster Or Table | The training sample data in either vector or raster form. Vector inputs should follow the training sample format generated using the Training Samples Manager pane. Raster inputs should follow a classified raster format generated by the Classify Raster tool. The raster input can also be from a folder of classified rasters. Classified raster inputs require a corresponding raster attribute table. Input tables should follow a training sample format generated by the Label Objects for Deep Learning button in the Training Samples Manager pane. Following the proper training sample format will produce optimal results with the statistical information; however, the input can also be a point feature class without a class value field or an integer raster without class information. | Feature Class; Feature Layer; Raster Dataset; Raster Layer; Mosaic Layer; Image Service; Table; Folder |
| Image Format | Specifies the raster format that will be used for the image chip outputs.The PNG and JPEG formats support up to three bands.TIFF format—TIFF format will be used.PNG format—PNG format will be used.JPEG format—JPEG format will be used.MRF (Meta Raster Format)—Meta Raster Format (MRF) will be used. | String |
| Tile Size X(Optional) | The size of the image chips for the x dimension. | Long |
| Tile Size Y(Optional) | The size of the image chips for the y dimension. | Long |
| Stride X(Optional) | The distance to move in the x direction when creating the next image chips.When stride is equal to tile size, there will be no overlap. When stride is equal to half the tile size, there will be 50 percent overlap. | Long |
| Stride Y(Optional) | The distance to move in the y direction when creating the next image chips.When stride is equal to tile size, there will be no overlap. When stride is equal to half the tile size, there will be 50 percent overlap. | Long |
| Output No Feature Tiles(Optional) | Specifies whether image chips that do not capture training samples will be exported.Checked—All image chips, including those that do not capture training samples, will be exported.Unchecked—Only image chips that capture training samples will be exported. This is the default.If checked, image chips that do not capture labeled data will also be exported; if not checked, they will not be exported. | Boolean |
| Metadata Format(Optional) | Specifies the format that will be used for the output metadata labels. If the input training sample data is a feature class layer, such as a building layer or a standard classification training sample file, use the KITTI Labels or PASCAL Visual Object Classes option (KITTI_rectangles or PASCAL_VOC_rectangles in Python). The output metadata is a .txt file or an .xml file containing the training sample data contained in the minimum bounding rectangle. The name of the metadata file matches the input source image name. If the input training sample data is a class map, use the Classified Tiles option (Classified_Tiles in Python) as the output metadata format.For the KITTI metadata format, 15 columns are created, but only 5 of them are used in the tool. The first column is the class value. The next 3 columns are skipped. Columns 5 through 8 define the minimum bounding rectangle, which is composed of four image coordinate locations: left, top, right, and bottom pixels. The minimum bounding rectangle encompasses the training chip used in the deep learning classifier. The remaining columns are not used.KITTI Labels—The metadata will follow the same format as the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) Object Detection Evaluation dataset. The KITTI dataset is a vision benchmark suite. The label files are plain text files. All values, both numerical and strings, are separated by spaces, and each row corresponds to one object.This format is used for object detection.PASCAL Visual Object Classes—The metadata will follow the same format as the Pattern Analysis, Statistical Modeling and Computational Learning, Visual Object Classes (PASCAL_VOC) dataset. The PASCAL VOC dataset is a standardized image dataset for object class recognition. The label files are in XML format and contain information about image name, class value, and bounding boxes. This format is used for object detection. This is the default.Classified Tiles—The output will be one classified image chip per input image chip. No other metadata for each image chip is used. Only the statistics output has more information about the classes, such as class names, class values, and output statistics. This format is primarily used for pixel classification. This format is also used for change detection when the output is one classified image chip from two image chips.RCNN Masks—The output will be image chips that have a mask on the areas where the sample exists. The model generates bounding boxes and segmentation masks for each instance of an object in the image. This format is based on Feature Pyramid Network (FPN) and a ResNet101 backbone in the deep learning framework model. This format is used for object detection; however, it can also be used for object tracking when the Siam Mask model type is used during training, as well as time series pixel classification when the PSETAE architecture is used.Labeled Tiles—Each output tile will be labeled with a specific class. This format is used for object classification.Multi-labeled Tiles—Each output tile will be labeled with one or more classes. For example, a tile may be labeled agriculture and also cloudy. This format is used for object classification.Export Tiles—The output will be image chips with no label. This format is used for image translation techniques, such as Pix2Pix and Super Resolution.CycleGAN—The output will be image chips with no label. This format is used for image translation technique CycleGAN, which is used to train images that do not overlap.Imagenet—Each output tile will be labeled with a specific class. This format is used for object classification; however, it can also be used for object tracking when the Deep Sort model type is used during training.Panoptic Segmentation—The output will be one classified image chip and one instance per input image chip. The output will also have image chips that mask the areas where the sample exists; these image chips will be stored in a different folder.This format is used for both pixel classification and instance segmentation, so two output labels folders will be produced. | String |
| Start Index(Optional) | Legacy:This parameter has been deprecated. | Long |
| Class Value Field (Optional) | The field that contains the class values. If no field is specified, the system searches for a value or classvalue field. The field should be numeric, usually an integer. If the feature does not contain a class field, the system determines that all records belong to one class. | Field |
| Buffer Radius(Optional) | The radius of a buffer around each training sample that will be used to delineate a training sample area. This allows you to create circular polygon training samples from points. The linear unit of the Input Feature Class Or Classified Raster Or Table parameter value's spatial reference is used. | Double |
| Input Mask Polygons(Optional) | A polygon feature class that delineates the area where image chips will be created.Only image chips that fall completely within the polygons will be created. | Feature Layer |
| Rotation Angle(Optional) | The rotation angle that will be used to generate image chips. An image chip will first be generated with no rotation. It will then be rotated at the specified angle to create additional image chips. The image will be rotated and have a chip created, until it has been fully rotated. For example, if you specify a rotation angle of 45 degrees, the tool will create eight image chips. The eight image chips will be created at the following angles: 0, 45, 90, 135, 180, 25, 270, and 315.The default rotation angle is 0, which creates one default image chip. | Double |
| Reference System(Optional) | Specifies the type of reference system that will be used to interpret the input image. The reference system specified must match the reference system used to train the deep learning model.Map space—A map-based coordinate system will be used. This is the default.Pixel space—Image space will be used, with no rotation and no distortion. | String |
| Processing Mode(Optional) | Specifies how all raster items in a mosaic dataset or an image service will be processed. This parameter is applied when the input raster is a mosaic dataset or an image service.Process as mosaicked image—All raster items in the mosaic dataset or image service will be mosaicked together and processed. This is the default.Process all raster items separately—All raster items in the mosaic dataset or image service will be processed as separate images. | String |
| Blacken Around Feature(Optional) | Specifies whether the pixels around each object or feature in each image tile will be masked out.This parameter only applies when the Metadata Format parameter is set to Labeled Tiles and an input feature class or classified raster has been specified.Unchecked—Pixels surrounding objects or features will not be masked out. This is the default.Checked—Pixels surrounding objects or features will be masked out. | Boolean |
| Crop Mode(Optional) | Specifies whether the exported tiles will be cropped so that they are all the same size.This parameter only applies when the Metadata Format parameter is set to either Labeled Tiles or Imagenet, and an input feature class or classified raster has been specified.Fixed size—Exported tiles will be cropped to the same size and will center on the feature. This is the default.Bounding box—Exported tiles will be cropped so that the bounding geometry surrounds only the feature in the tile. | String |
| Additional Input Raster(Optional) | An additional input imagery source that will be used for image translation methods.This parameter is valid when the Metadata Format parameter is set to Classified Tiles, Export Tiles, or CycleGAN. | Raster Dataset; Raster Layer; Mosaic Layer; Image Service; Map Server; Map Server Layer; Internet Tiled Layer; Folder |
| Instance Feature Class (Optional) | The training sample data collected that contains classes for instance segmentation. The input can also be a point feature class without a class value field or an integer raster without class information.This parameter is only valid when the Metadata Format parameter is set to Panoptic Segmentation. | Feature Class; Feature Layer; Raster Dataset; Raster Layer; Mosaic Layer; Image Service; Table; Folder |
| Instance Class Value Field (Optional) | The field that contains the class values for instance segmentation. If no field is specified, the tool will use a value or class value field if one is present. If the feature does not contain a class field, the tool will determine that all records belong to one class.This parameter is only valid when the Metadata Format parameter is set to Panoptic Segmentation. | Field |
| Minimum Polygon Overlap Ratio (Optional) | The minimum overlap percentage for a feature to be included in the training data. If the percentage overlap is less than the value specified, the feature will be excluded from the training chip, and will not be added to the label file. The percent value is expressed as a decimal. For example, to specify an overlap of 20 percent, use a value of 0.2. The default value is 0, which means that all features will be included. This parameter improves the performance of the tool and also improves inferencing. The speed is improved since less training chips are created. The inferencing is improved since the model is trained to only detect large patches of objects and ignores small corners of features. This means less false positives will be detected, and less false positives will be removed by the Non Maximum Suppression tool.This parameter is active when the Input Feature Class Or Classified Raster Or Table parameter value is a feature class. | Double |
| in_raster | The input source imagery, typically multispectral imagery.Examples of the types of input source imagery include multispectral satellite, drone, aerial, and National Agriculture Imagery Program (NAIP). The input can be a folder of images. | Raster Dataset; Raster Layer; Mosaic Layer; Image Service; Map Server; Map Server Layer; Internet Tiled Layer; Folder |
| out_folder | The folder where the output image chips and metadata will be stored.The folder can also be a folder URL that uses a cloud storage connection file (*.acs). | Folder |
| in_class_data | The training sample data in either vector or raster form. Vector inputs should follow the training sample format generated using the Training Samples Manager pane. Raster inputs should follow a classified raster format generated by the Classify Raster tool. The raster input can also be from a folder of classified rasters. Classified raster inputs require a corresponding raster attribute table. Input tables should follow a training sample format generated by the Label Objects for Deep Learning button in the Training Samples Manager pane. Following the proper training sample format will produce optimal results with the statistical information; however, the input can also be a point feature class without a class value field or an integer raster without class information. | Feature Class; Feature Layer; Raster Dataset; Raster Layer; Mosaic Layer; Image Service; Table; Folder |
| image_chip_format | Specifies the raster format that will be used for the image chip outputs.The PNG and JPEG formats support up to three bands.TIFF—TIFF format will be used.PNG—PNG format will be used.JPEG—JPEG format will be used.MRF—Meta Raster Format (MRF) will be used. | String |
| tile_size_x(Optional) | The size of the image chips for the x dimension. | Long |
| tile_size_y(Optional) | The size of the image chips for the y dimension. | Long |
| stride_x(Optional) | The distance to move in the x direction when creating the next image chips.When stride is equal to tile size, there will be no overlap. When stride is equal to half the tile size, there will be 50 percent overlap. | Long |
| stride_y(Optional) | The distance to move in the y direction when creating the next image chips.When stride is equal to tile size, there will be no overlap. When stride is equal to half the tile size, there will be 50 percent overlap. | Long |
| output_nofeature_tiles(Optional) | Specifies whether image chips that do not capture training samples will be exported.ALL_TILES—All image chips, including those that do not capture training samples, will be exported.ONLY_TILES_WITH_FEATURES—Only image chips that capture training samples will be exported. This is the default. | Boolean |
| metadata_format(Optional) | Specifies the format that will be used for the output metadata labels. If the input training sample data is a feature class layer, such as a building layer or a standard classification training sample file, use the KITTI Labels or PASCAL Visual Object Classes option (KITTI_rectangles or PASCAL_VOC_rectangles in Python). The output metadata is a .txt file or an .xml file containing the training sample data contained in the minimum bounding rectangle. The name of the metadata file matches the input source image name. If the input training sample data is a class map, use the Classified Tiles option (Classified_Tiles in Python) as the output metadata format.KITTI_rectangles—The metadata will follow the same format as the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) Object Detection Evaluation dataset. The KITTI dataset is a vision benchmark suite. The label files are plain text files. All values, both numerical and strings, are separated by spaces, and each row corresponds to one object.This format is used for object detection.PASCAL_VOC_rectangles—The metadata will follow the same format as the Pattern Analysis, Statistical Modeling and Computational Learning, Visual Object Classes (PASCAL_VOC) dataset. The PASCAL VOC dataset is a standardized image dataset for object class recognition. The label files are in XML format and contain information about image name, class value, and bounding boxes. This format is used for object detection. This is the default.Classified_Tiles—The output will be one classified image chip per input image chip. No other metadata for each image chip is used. Only the statistics output has more information about the classes, such as class names, class values, and output statistics. This format is primarily used for pixel classification. This format is also used for change detection when the output is one classified image chip from two image chips.RCNN_Masks—The output will be image chips that have a mask on the areas where the sample exists. The model generates bounding boxes and segmentation masks for each instance of an object in the image. This format is based on Feature Pyramid Network (FPN) and a ResNet101 backbone in the deep learning framework model. This format is used for object detection; however, it can also be used for object tracking when the Siam Mask model type is used during training, as well as time series pixel classification when the PSETAE architecture is used.Labeled_Tiles—Each output tile will be labeled with a specific class. This format is used for object classification.MultiLabeled_Tiles—Each output tile will be labeled with one or more classes. For example, a tile may be labeled agriculture and also cloudy. This format is used for object classification.Export_Tiles—The output will be image chips with no label. This format is used for image translation techniques, such as Pix2Pix and Super Resolution.CycleGAN—The output will be image chips with no label. This format is used for image translation technique CycleGAN, which is used to train images that do not overlap.Imagenet—Each output tile will be labeled with a specific class. This format is used for object classification; however, it can also be used for object tracking when the Deep Sort model type is used during training.Panoptic_Segmentation—The output will be one classified image chip and one instance per input image chip. The output will also have image chips that mask the areas where the sample exists; these image chips will be stored in a different folder.This format is used for both pixel classification and instance segmentation, so two output labels folders will be produced. For the KITTI metadata format, 15 columns are created, but only 5 of them are used in the tool. The first column is the class value. The next 3 columns are skipped. Columns 5 through 8 define the minimum bounding rectangle, which is composed of four image coordinate locations: left, top, right, and bottom pixels. The minimum bounding rectangle encompasses the training chip used in the deep learning classifier. The remaining columns are not used. The following is an example of the PASCAL_VOC_rectangles option: <?xml version=”1.0”?> - <layout> <image>000000000</image> <object>1</object> - <part> <class>1</class> - <bndbox> <xmin>31.85</xmin> <ymin>101.52</ymin> <xmax>256.00</xmax> <ymax>256.00</ymax> </bndbox> </part> </layout>For more information, see the Microsoft PASCAL Visual Object Classes (VOC) Challenge paper. | String |
| start_index(Optional) | Legacy:This parameter has been deprecated. Use a value of 0 or # in Python. | Long |
| class_value_field(Optional) | The field that contains the class values. If no field is specified, the system searches for a value or classvalue field. The field should be numeric, usually an integer. If the feature does not contain a class field, the system determines that all records belong to one class. | Field |
| buffer_radius(Optional) | The radius of a buffer around each training sample that will be used to delineate a training sample area. This allows you to create circular polygon training samples from points. The linear unit of the in_class_data parameter value's spatial reference is used. | Double |
| in_mask_polygons(Optional) | A polygon feature class that delineates the area where image chips will be created.Only image chips that fall completely within the polygons will be created. | Feature Layer |
| rotation_angle(Optional) | The rotation angle that will be used to generate image chips. An image chip will first be generated with no rotation. It will then be rotated at the specified angle to create additional image chips. The image will be rotated and have a chip created, until it has been fully rotated. For example, if you specify a rotation angle of 45 degrees, the tool will create eight image chips. The eight image chips will be created at the following angles: 0, 45, 90, 135, 180, 25, 270, and 315.The default rotation angle is 0, which creates one default image chip. | Double |
| reference_system(Optional) | Specifies the type of reference system that will be used to interpret the input image. The reference system specified must match the reference system used to train the deep learning model.MAP_SPACE—A map-based coordinate system will be used. This is the default.PIXEL_SPACE—Image space will be used, with no rotation and no distortion. | String |
| processing_mode(Optional) | Specifies how all raster items in a mosaic dataset or an image service will be processed. This parameter is applied when the input raster is a mosaic dataset or an image service.PROCESS_AS_MOSAICKED_IMAGE—All raster items in the mosaic dataset or image service will be mosaicked together and processed. This is the default.PROCESS_ITEMS_SEPARATELY—All raster items in the mosaic dataset or image service will be processed as separate images. | String |
| blacken_around_feature(Optional) | Specifies whether the pixels around each object or feature in each image tile will be masked out.This parameter only applies when the metadata_format parameter is set to Labeled_Tiles and an input feature class or classified raster has been specified.NO_BLACKEN—Pixels surrounding objects or features will not be masked out. This is the default.BLACKEN_AROUND_FEATURE—Pixels surrounding objects or features will be masked out. | Boolean |
| crop_mode(Optional) | Specifies whether the exported tiles will be cropped so that they are all the same size.This parameter only applies when the metadata_format parameter is set to either Labeled_Tiles or Imagenet, and an input feature class or classified raster has been specified.FIXED_SIZE—Exported tiles will be cropped to the same size and will center on the feature. This is the default.BOUNDING_BOX—Exported tiles will be cropped so that the bounding geometry surrounds only the feature in the tile. | String |
| in_raster2(Optional) | An additional input imagery source that will be used for image translation methods.This parameter is valid when the metadata_format parameter is set to Classified_Tiles, Export_Tiles, or CycleGAN. | Raster Dataset; Raster Layer; Mosaic Layer; Image Service; Map Server; Map Server Layer; Internet Tiled Layer; Folder |
| in_instance_data(Optional) | The training sample data collected that contains classes for instance segmentation. The input can also be a point feature class without a class value field or an integer raster without class information.This parameter is only valid when the metadata_format parameter is set to Panoptic_Segmentation. | Feature Class; Feature Layer; Raster Dataset; Raster Layer; Mosaic Layer; Image Service; Table; Folder |
| instance_class_value_field(Optional) | The field that contains the class values for instance segmentation. If no field is specified, the tool will use a value or class value field if one is present. If the feature does not contain a class field, the tool will determine that all records belong to one class.This parameter is only valid when the metadata_format parameter is set to Panoptic_Segmentation. | Field |
| min_polygon_overlap_ratio(Optional) | The minimum overlap percentage for a feature to be included in the training data. If the percentage overlap is less than the value specified, the feature will be excluded from the training chip, and will not be added to the label file. The percent value is expressed as a decimal. For example, to specify an overlap of 20 percent, use a value of 0.2. The default value is 0, which means that all features will be included. This parameter improves the performance of the tool and also improves inferencing. The speed is improved since less training chips are created. The inferencing is improved since the model is trained to only detect large patches of objects and ignores small corners of features. This means less false positives will be detected, and less false positives will be removed by the Non Maximum Suppression tool.This parameter is enabled when the in_class_data parameter value is a feature class. | Double |

## Code Samples

### Example 1

```python
ExportTrainingDataForDeepLearning(in_raster, out_folder, in_class_data, image_chip_format, {tile_size_x}, {tile_size_y}, {stride_x}, {stride_y}, {output_nofeature_tiles}, {metadata_format}, {start_index}, {class_value_field}, {buffer_radius}, {in_mask_polygons}, {rotation_angle}, {reference_system}, {processing_mode}, {blacken_around_feature}, {crop_mode}, {in_raster2}, {in_instance_data}, {instance_class_value_field}, {min_polygon_overlap_ratio})
```

### Example 2

```python
<?xml version=”1.0”?>
- <layout>
      <image>000000000</image>
      <object>1</object>
    - <part>
         <class>1</class>
       - <bndbox>
            <xmin>31.85</xmin>
            <ymin>101.52</ymin>
            <xmax>256.00</xmax>
            <ymax>256.00</ymax>
         </bndbox>
      </part>
  </layout>
```

### Example 3

```python
<?xml version=”1.0”?>
- <layout>
      <image>000000000</image>
      <object>1</object>
    - <part>
         <class>1</class>
       - <bndbox>
            <xmin>31.85</xmin>
            <ymin>101.52</ymin>
            <xmax>256.00</xmax>
            <ymax>256.00</ymax>
         </bndbox>
      </part>
  </layout>
```

### Example 4

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Image Analyst extension license
arcpy.CheckOutExtension("spatialAnalyst")

ExportTrainingDataForDeepLearning("c:/test/image.tif", "c:/test/outfolder",
             "c:/test/training.shp", "TIFF", "256", "256", "128", "128", 
             "ONLY_TILES_WITH_FEATURES", "Labeled_Tiles", 0, "Classvalue", 0, 
			 None, 0,  "MAP_SPACE", "PROCESS_AS_MOSAICKED_IMAGE", "NO_BLACKEN", 
			 "FIXED_SIZE")
```

### Example 5

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Image Analyst extension license
arcpy.CheckOutExtension("spatialAnalyst")

ExportTrainingDataForDeepLearning("c:/test/image.tif", "c:/test/outfolder",
             "c:/test/training.shp", "TIFF", "256", "256", "128", "128", 
             "ONLY_TILES_WITH_FEATURES", "Labeled_Tiles", 0, "Classvalue", 0, 
			 None, 0,  "MAP_SPACE", "PROCESS_AS_MOSAICKED_IMAGE", "NO_BLACKEN", 
			 "FIXED_SIZE")
```

### Example 6

```python
# Import system modules and check out ArcGIS Image Analyst extension license
import arcpy
arcpy.CheckOutExtension("SpatialAnalyst")
from arcpy.sa import *

# Set local variables
inRaster = "C:/test/InputRaster.tif"
out_folder = "c:/test/OutputFolder"
in_training = "c:/test/TrainingData.shp"
image_chip_format = "TIFF"
tile_size_x = "256"
tile_size_y = "256"
stride_x="128"
stride_y="128"
output_nofeature_tiles="ONLY_TILES_WITH_FEATURES"
metadata_format="Labeled_Tiles"
start_index = 0
classvalue_field = "Classvalue"
buffer_radius = 0
in_mask_polygons = "MaskPolygon"
rotation_angle = 0
reference_system = "MAP_SPACE"
processing_mode = "PROCESS_AS_MOSAICKED_IMAGE"
blacken_around_feature = "NO_BLACKEN"
crop_mode = "FIXED_SIZE"

# Execute 
ExportTrainingDataForDeepLearning(inRaster, out_folder, in_training, 
             image_chip_format,tile_size_x, tile_size_y, stride_x, 
             stride_y,output_nofeature_tiles, metadata_format, start_index, 
			 classvalue_field, buffer_radius, in_mask_polygons, rotation_angle, 
			 reference_system, processing_mode, blacken_around_feature, crop_mode)
```

### Example 7

```python
# Import system modules and check out ArcGIS Image Analyst extension license
import arcpy
arcpy.CheckOutExtension("SpatialAnalyst")
from arcpy.sa import *

# Set local variables
inRaster = "C:/test/InputRaster.tif"
out_folder = "c:/test/OutputFolder"
in_training = "c:/test/TrainingData.shp"
image_chip_format = "TIFF"
tile_size_x = "256"
tile_size_y = "256"
stride_x="128"
stride_y="128"
output_nofeature_tiles="ONLY_TILES_WITH_FEATURES"
metadata_format="Labeled_Tiles"
start_index = 0
classvalue_field = "Classvalue"
buffer_radius = 0
in_mask_polygons = "MaskPolygon"
rotation_angle = 0
reference_system = "MAP_SPACE"
processing_mode = "PROCESS_AS_MOSAICKED_IMAGE"
blacken_around_feature = "NO_BLACKEN"
crop_mode = "FIXED_SIZE"

# Execute 
ExportTrainingDataForDeepLearning(inRaster, out_folder, in_training, 
             image_chip_format,tile_size_x, tile_size_y, stride_x, 
             stride_y,output_nofeature_tiles, metadata_format, start_index, 
			 classvalue_field, buffer_radius, in_mask_polygons, rotation_angle, 
			 reference_system, processing_mode, blacken_around_feature, crop_mode)
```

---

## Extract by Attributes (Spatial Analyst)

## Summary

Extracts the cells of a raster based on a logical query.

## Usage

- Additional attributes from the input raster, if any, will be carried over as-is to the output raster attribute table. Depending on the property being recorded, some of the attribute values may need to be recalculated.
- When a multiband raster is specified as the Input Raster (in_raster in Python) value, all bands will be used.To process a selection of bands from a multiband raster, first create a raster dataset composed of those particular bands using the Composite Bands tool. Then use the result as the Input Raster (in_raster in Python) value.The default output format is a geodatabase raster. If an Esri Grid stack is specified as the output format, the name of the stack cannot start with a number, use spaces, or be more than nine characters in length.
- If the Where clause evaluates to true, the original input value is returned for the cell location. If it evaluates to false, the cell location is assigned NoData.
- The Where clause uses an SQL query. See the following topics for more details on creating queries: Build an SQL querySQL reference for query expressions used in ArcGIS
- Build an SQL query
- SQL reference for query expressions used in ArcGIS
- In order to use a {where_clause} in Python, it should be enclosed in quotes. For example, "Value > 5000".You can consult the help for more information on specifying a query in Python.
- If an item other than Value of input raster is specified in the query, the original input value is returned for the cell location.
- If the input raster is integer, the output raster will be integer. If the input is floating point, the output will be floating point.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster from which cells will be extracted. | Raster Layer |
| Where clause | A logical expression that selects a subset of raster cells.The Where clause follows the general form of an SQL expression. It can be entered directly, for example, VALUE > 100, if you click the Edit SQL mode button . If in the Edit Clause Mode , you can begin constructing the expression by clicking on the Add Clause Mode button. | SQL Expression |
| in_raster | The input raster from which cells will be extracted. | Raster Layer |
| where_clause | A logical expression that selects a subset of raster cells.The expression follows the general form of an SQL expression. An example of a where_clause is "VALUE > 100". | SQL Expression |

## Code Samples

### Example 1

```python
ExtractByAttributes(in_raster, where_clause)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
attExtract = ExtractByAttributes("elevation", "VALUE > 1000") 
attExtract.save("c:/sapyexamples/output/attextract")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
attExtract = ExtractByAttributes("elevation", "VALUE > 1000") 
attExtract.save("c:/sapyexamples/output/attextract")
```

### Example 4

```python
# Name: ExtractByAttributes_Ex_02.py
# Description: Extracts the cells of a raster based on a logical query. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inSQLClause = "VALUE > 1000"

# Execute ExtractByAttributes
attExtract = ExtractByAttributes(inRaster, inSQLClause) 

# Save the output 
attExtract.save("c:/sapyexamples/output/attextract02")
```

### Example 5

```python
# Name: ExtractByAttributes_Ex_02.py
# Description: Extracts the cells of a raster based on a logical query. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inSQLClause = "VALUE > 1000"

# Execute ExtractByAttributes
attExtract = ExtractByAttributes(inRaster, inSQLClause) 

# Save the output 
attExtract.save("c:/sapyexamples/output/attextract02")
```

---

## Extract by Circle (Spatial Analyst)

## Summary

Extracts the cells of a raster based on a circle by specifying the circle's center and radius.

## Usage

- Additional attributes from the input raster, if any, will be carried over as-is to the output raster attribute table. Depending on the property being recorded, some of the attribute values may need to be recalculated.
- When a multiband raster is specified as the Input Raster (in_raster in Python) value, all bands will be used.To process a selection of bands from a multiband raster, first create a raster dataset composed of those particular bands using the Composite Bands tool. Then use the result as the Input Raster (in_raster in Python) value.The default output format is a geodatabase raster. If an Esri Grid stack is specified as the output format, the name of the stack cannot start with a number, use spaces, or be more than nine characters in length.
- The center of the cell is used to determine whether a cell is inside or outside a circle. If the center is within the arc of the circle, the cell is considered fully inside even if portions of the cell are outside the circle.
- Cell locations that are not selected are assigned a value of NoData.
- If the input raster is integer, the output raster will be integer. If the input is floating point, the output will be floating point.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster from which cells will be extracted. | Raster Layer |
| Center point | The center coordinate (x,y) of the circle defining the area to be extracted.The coordinates are specified in the same map units as the input raster. | Point |
| Radius | The radius of the circle defining the area to be extracted.The radius is specified in map units and is in the same units as the input raster. | Double |
| Extraction area(Optional) | Specifies whether cells inside or outside the input circle will be selected and written to the output raster.Inside—Cells inside the input circle will be selected and written to the output raster. All cells outside the circle will receive NoData values on the output raster.Outside—Cells outside the input circle will be selected and written to the output raster. All cells inside the circle will receive NoData values on the output raster. | String |
| in_raster | The input raster from which cells will be extracted. | Raster Layer |
| center_point | The Point class determines the center coordinate (x,y) of the circle defining the area to be extracted.The form of the class is the following: Point (x, y)The coordinates are specified in the same map units as the input raster. | Point |
| radius | The radius of the circle defining the area to be extracted.The radius is specified in map units and is in the same units as the input raster. | Double |
| extraction_area(Optional) | Specifies whether cells inside or outside the input circle will be selected and written to the output raster.INSIDE—Cells inside the input circle will be selected and written to the output raster. All cells outside the circle will receive NoData values on the output raster.OUTSIDE—Cells outside the input circle will be selected and written to the output raster. All cells inside the circle will receive NoData values on the output raster. | String |

## Code Samples

### Example 1

```python
ExtractByCircle(in_raster, center_point, radius, {extraction_area})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExtCircle = ExtractByCircle("elevation", arcpy.Point(482838.823, 222128.982),
                                500, "INSIDE")
outExtCircle.save("c:/sapyexamples/output/extcircle")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExtCircle = ExtractByCircle("elevation", arcpy.Point(482838.823, 222128.982),
                                500, "INSIDE")
outExtCircle.save("c:/sapyexamples/output/extcircle")
```

### Example 4

```python
# Name: ExtractByCircle_Ex_02.py
# Description: Extracts the cells of a raster based on a circle.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = ("elevation")
centerPoint = arcpy.Point(482838.823, 222128.982)
circRadius = 1000
extractType = "INSIDE"

# Execute ExtractByCircle
outExtCircle = ExtractByCircle(inRaster, centerPoint, circRadius, 
                               extractType)

# Save the output 
outExtCircle.save("c:/sapyexamples/output/extcircle02")
```

### Example 5

```python
# Name: ExtractByCircle_Ex_02.py
# Description: Extracts the cells of a raster based on a circle.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = ("elevation")
centerPoint = arcpy.Point(482838.823, 222128.982)
circRadius = 1000
extractType = "INSIDE"

# Execute ExtractByCircle
outExtCircle = ExtractByCircle(inRaster, centerPoint, circRadius, 
                               extractType)

# Save the output 
outExtCircle.save("c:/sapyexamples/output/extcircle02")
```

---

## Extract by Mask (Spatial Analyst)

## Summary

Extracts the cells of a raster that correspond to the areas defined by a mask.

## Usage

- Additional attributes from the input raster, if any, will be carried over as-is to the output raster attribute table. Depending on the property being recorded, some of the attribute values may need to be recalculated.
- When a multiband raster is specified as the Input Raster (in_raster in Python) value, all bands will be used.To process a selection of bands from a multiband raster, first create a raster dataset composed of those particular bands using the Composite Bands tool. Then use the result as the Input Raster (in_raster in Python) value.The default output format is a geodatabase raster. If an Esri Grid stack is specified as the output format, the name of the stack cannot start with a number, use spaces, or be more than nine characters in length.
- When a multiband raster is specified for the input raster mask, only the first band will be used in the operation.
- When the Input raster (in_raster in Python) value and the Input raster or feature mask data raster data (in_mask_data in Python) are of the same cell size and the cells are aligned, they will be used directly in the tool. They will not be resampled internally during tool operation.If the cell size is different, the output cell size will be the maximum of the inputs, and the Input raster value will be used as the snap raster internally. If the cell size is the same but the cells are not aligned, the Input raster value will be used as the snap raster internally. Either of these cases will trigger an internal resampling before the extraction operation is performed.More information is available in the Cell Size and Snap Raster environment topics.
- If the mask input is a feature, it will be converted to a raster internally, using the cell size and cell alignment (snap raster) from the Input raster value by default.
- If Mask is specified in the environment setting while running the Extract by Mask tool, the output raster will have cell values only for the area that lies within the intersection of the environment mask and the input mask data.
- You can use the Analysis Extent (analysis_extent in Python) parameter to specify the output analysis area explicitly for a stand-alone tool operation or to override the environment setting as part of a workflow. You can specify the extent by typing values, choosing the display extent, selecting a layer, or browsing for an input dataset.
- The default Analysis Extent value is calculated from the intersection of the Input raster value and the Input raster or feature mask data value.
- If the analysis extent is not explicitly specified as the parameter value, it will be derived from the analysis environment settings.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster from which cells will be extracted. | Raster Layer |
| Input raster or feature mask data | The input mask data defining the cell locations to extract.It can be a raster or a feature dataset.When the input mask data is a raster, NoData cells on the mask will be assigned NoData values on the output raster.When the input mask is feature data, cells in the input raster whose center falls within the specified shape of the feature will be included in the output, while cells whose center falls outside will receive NoData. | Raster Layer; Feature Layer |
| Extraction Area(Optional) | Specifies whether cells inside or outside the locations defined by the input mask will be selected and written to the output raster.Inside—Cells within the input mask will be selected and written to the output raster. All cells outside the mask will receive NoData on the output raster. This is default.Outside—Cells outside the input mask will be selected and written to the output raster. All cells covered by the mask will receive NoData. | String |
| Analysis Extent(Optional) | The extent that defines the area to be extracted.By default, the extent is calculated as the intersection of the Input raster value and the Input raster or feature mask data value. Processing will occur out to the x and y limits, and cells outside that extent will be NoData.The coordinates are specified in the same map units as the input raster if not explicitly set by the analysis environment.Current Display Extent —The extent will be based on the active map or scene.Draw Extent —The extent will be based on a rectangle drawn on the map or scene.Extent of a Layer —The extent will be based on an active map layer. Choose an available layer or use the Extent of data in all layers option. Each map layer has the following options:All Features —The extent of all features.Selected Features —The extent of the selected features.Visible Features —The extent of visible features.Browse —The extent will be based on a dataset.Clipboard —The extent can be copied to and from the clipboard. Copy Extent —Copies the extent and coordinate system to the clipboard.Paste Extent —Pastes the extent and coordinate system from the clipboard. If the clipboard does not include a coordinate system, the extent will use the map’s coordinate system.Reset Extent —The extent will be reset to the default value.When coordinates are manually provided, the coordinates must be numeric values and in the active map's coordinate system. The map may use different display units than the provided coordinates. Use a negative value sign for south and west coordinates. | Extent |
| in_raster | The input raster from which cells will be extracted. | Raster Layer |
| in_mask_data | The input mask data defining the cell locations to extract.It can be a raster or a feature dataset.When the input mask data is a raster, NoData cells on the mask will be assigned NoData values on the output raster.When the input mask is feature data, cells in the input raster whose center falls within the specified shape of the feature will be included in the output, while cells whose center falls outside will receive NoData. | Raster Layer; Feature Layer |
| extraction_area(Optional) | Specifies whether cells inside or outside the locations defined by the input mask will be selected and written to the output raster.INSIDE—Cells within the input mask will be selected and written to the output raster. All cells outside the mask will receive NoData on the output raster. This is default.OUTSIDE—Cells outside the input mask will be selected and written to the output raster. All cells covered by the mask will receive NoData. | String |
| analysis_extent(Optional) | The extent that defines the area to be extracted.If not specified, the default extent is the intersection of the in_raster value and the in_mask_data value.The coordinates are specified in the same map units as the input raster if not explicitly set by the analysis environment.MAXOF—The maximum extent of all inputs will be used.MINOF—The minimum area common to all inputs will be used.DISPLAY—The extent is equal to the visible display.Layer name—The extent of the specified layer will be used.Extent object—The extent of the specified object will be used. Space delimited string of coordinates—The extent of the specified string will be used. Coordinates are expressed in the order of x-min, y-min, x-max, y-max. | Extent |

## Code Samples

### Example 1

```python
ExtractByMask(in_raster, in_mask_data, {extraction_area}, {analysis_extent})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExtractByMask = ExtractByMask("elevation", "mask.shp", "INSIDE")
outExtractByMask.save("C:/sapyexamples/output/maskextract")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outExtractByMask = ExtractByMask("elevation", "mask.shp", "INSIDE")
outExtractByMask.save("C:/sapyexamples/output/maskextract")
```

### Example 4

```python
# Name: ExtractByMask_Ex_02.py
# Description: Extracts the cells of a elevation raster for all areas outside of the mask features.
#     Keeping the output extent of the input elevation raster. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inMaskData = "mask.shp"
extraction_area = "OUTSIDE"
analysis_extent = "elevation"


# Execute ExtractByMask
outExtractByMask = ExtractByMask(inRaster, inMaskData, extraction_area, analysis_extent)

# Save the output 
outExtractByMask.save("C:/sapyexamples/output/extractmask")
```

### Example 5

```python
# Name: ExtractByMask_Ex_02.py
# Description: Extracts the cells of a elevation raster for all areas outside of the mask features.
#     Keeping the output extent of the input elevation raster. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inMaskData = "mask.shp"
extraction_area = "OUTSIDE"
analysis_extent = "elevation"


# Execute ExtractByMask
outExtractByMask = ExtractByMask(inRaster, inMaskData, extraction_area, analysis_extent)

# Save the output 
outExtractByMask.save("C:/sapyexamples/output/extractmask")
```

---

## Extract by Points (Spatial Analyst)

## Summary

Extracts the cells of a raster based on a set of coordinate points.

## Usage

- Additional attributes from the input raster, if any, will be carried over as-is to the output raster attribute table. Depending on the property being recorded, some of the attribute values may need to be recalculated.
- When a multiband raster is specified as the Input Raster (in_raster in Python) value, all bands will be used.To process a selection of bands from a multiband raster, first create a raster dataset composed of those particular bands using the Composite Bands tool. Then use the result as the Input Raster (in_raster in Python) value.The default output format is a geodatabase raster. If an Esri Grid stack is specified as the output format, the name of the stack cannot start with a number, use spaces, or be more than nine characters in length.
- Cell locations that are not selected are assigned a value of NoData.
- If the input raster is integer, the output raster will be integer. If the input is floating point, the output will be floating point.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster from which cells will be extracted. | Raster Layer |
| Input points | The points where values will be extracted from the raster.The points are specified as x,y coordinate pairs in the same map units as the input raster. | Point |
| Extraction area(Optional) | Identifies whether to extract cells based on the specified point locations (inside) or outside the point locations (outside) .Inside—The cell in which the selected point falls will be written to the output raster. All cells outside the box will receive NoData on the output raster.Outside—The cells outside the input points should be selected and written to the output raster. | String |
| in_raster | The input raster from which cells will be extracted. | Raster Layer |
| points[point,...] | A Python list of Point class objects denote the locations where values will be extracted from the raster.The point objects are specified in a list of x,y coordinate pairs in the same map units as the input raster. The form of the object is:[point(x1,y1), point(x2,y2),...] | Point |
| extraction_area(Optional) | Identifies whether to extract cells based on the specified point locations (inside) or outside the point locations (outside) .INSIDE—The cell in which the selected point falls will be written to the output raster. All cells outside the box will receive NoData on the output raster.OUTSIDE—The cells outside the input points should be selected and written to the output raster. | String |

## Code Samples

### Example 1

```python
ExtractByPoints(in_raster, points, {extraction_area})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
pointList = [arcpy.Point(743050, 4321275), arcpy.Point(743100, 4321200),
             arcpy.Point(734500,4322000)]
outPointExtract = ExtractByPoints("soil", pointList,"INSIDE")
outPointExtract.save("c:/sapyexamples/output/pntextract")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
pointList = [arcpy.Point(743050, 4321275), arcpy.Point(743100, 4321200),
             arcpy.Point(734500,4322000)]
outPointExtract = ExtractByPoints("soil", pointList,"INSIDE")
outPointExtract.save("c:/sapyexamples/output/pntextract")
```

### Example 4

```python
# Name: ExtractByPoints_Ex_02.py
# Description: Extracts the cells of a raster based on a set of points.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "soil"
pointList = [arcpy.Point(743050, 4321275), 
             arcpy.Point(743100, 4321200), 
             arcpy.Point(743500, 4322000),
             arcpy.Point(742900, 4321800)]

# Execute ExtractByPoints
outPointExtract = ExtractByPoints("soil", pointList,"INSIDE")

# Save the output 
outPointExtract.save("c:/sapyexamples/output/pntext")
```

### Example 5

```python
# Name: ExtractByPoints_Ex_02.py
# Description: Extracts the cells of a raster based on a set of points.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "soil"
pointList = [arcpy.Point(743050, 4321275), 
             arcpy.Point(743100, 4321200), 
             arcpy.Point(743500, 4322000),
             arcpy.Point(742900, 4321800)]

# Execute ExtractByPoints
outPointExtract = ExtractByPoints("soil", pointList,"INSIDE")

# Save the output 
outPointExtract.save("c:/sapyexamples/output/pntext")
```

---

## Extract by Polygon (Spatial Analyst)

## Summary

Extracts the cells of a raster based on a polygon by specifying the polygon's vertices.

## Usage

- Additional attributes from the input raster, if any, will be carried over as-is to the output raster attribute table. Depending on the property being recorded, some of the attribute values may need to be recalculated.
- When a multiband raster is specified as the Input Raster (in_raster in Python) value, all bands will be used.To process a selection of bands from a multiband raster, first create a raster dataset composed of those particular bands using the Composite Bands tool. Then use the result as the Input Raster (in_raster in Python) value.The default output format is a geodatabase raster. If an Esri Grid stack is specified as the output format, the name of the stack cannot start with a number, use spaces, or be more than nine characters in length.
- To extract based on a polygon in a feature class instead of providing a series of x,y pairs, you can use the Extract By Mask tool.
- The polygon object may consist of just one part, or many parts as a polygon class. In the later case, all polygon parts must be contiguous, such that they could be outlined by one polygon. To extract based on a polygon feature that contains multiple disconnected parts, use the Extract By Mask tool.
- The center of the cell is used to determine whether a cell is inside or outside a polygon. If the center is within the arcs of the polygon, the cell is considered fully inside, even if portions of the cell fall outside the polygon.
- The polygon has a limit of 1,000 vertices. Polygon vertices must be entered in a clockwise order. The first and last vertex should be the same to close the polygon. This is especially important if multiple polygons are to be used. In that case, if the last point for each individual polygon is not identical to its starting vertex, polygons may be closed automatically by directly connecting to the first vertex. However, this may produce a result different from what you may have expected, so take care if employing this technique.The arcs of the polygon can cross one another, but convoluted polygons are not recommended.
- Cell locations that are not selected are assigned a value of NoData.
- If the input raster is integer, the output raster will be integer. If the input is floating point, the output will be floating point.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster from which cells will be extracted. | Raster Layer |
| Polygon | A polygon (or polygons) defined by a series of vertices (x,y point coordinates) that identify the area of the input raster to be extracted. The last coordinate of a polygon part should be the same as the first in order to close a polygon.When specifying multiple polygons, they must be contiguous. Enter the series of coordinates polygon by polygon. Be sure to close each part by defining the last coordinate the same as the first one. The points are in the same map units as the input raster. | Point |
| Extraction area(Optional) | Identifies whether to extract cells inside or outside the input polygon.Inside—The cells inside the input polygon should be selected and written to the output raster. All cells outside the polygon will receive NoData values on the output raster.Outside—The cells outside the input polygon should be selected and written to the output raster. All cells inside the polygon will receive NoData. | String |
| in_raster | The input raster from which cells will be extracted. | Raster Layer |
| polygon[point,...] | A polygon (or polygons) that defines the area of the input raster to be extracted.Each polygon part is a list of vertices defined by Point classes. The points are specified as x,y coordinate pairs in the same map units as the input raster.The form of the object for a single polygon is as follows:[point(x1,y1), point(x2,y2), ..., point(xn,yn), point(x1,y1]Optionally, a group of multiple polygons can be specified by using a Polygon class to define a list of polygon parts. Note that in order to do this, all parts must be contiguous, and thus be encompassed by one single perimeter shape. The form of the object in this case would be in a contiguous list as follows:[point(x1,y1), point(x2,y2), ..., point(xn,yn), point(x1,y1), point(x'1,y'1), point(x'2,y'2), ..., point(x'n,y'n), point(x'1,y'1), ...]In all cases, the last coordinate for each polygon part should be the same as the first in order to close it. | Point |
| extraction_area(Optional) | Identifies whether to extract cells inside or outside the input polygon.INSIDE—The cells inside the input polygon should be selected and written to the output raster. All cells outside the polygon will receive NoData values on the output raster.OUTSIDE—The cells outside the input polygon should be selected and written to the output raster. All cells inside the polygon will receive NoData. | String |

## Code Samples

### Example 1

```python
ExtractByPolygon(in_raster, polygon, {extraction_area})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
polyPoints = [arcpy.Point(743050, 4321275), arcpy.Point(743100, 4321200), 
             arcpy.Point(743500, 4322000),arcpy.Point(742900, 4321800)]
env.workspace = "C:/sapyexamples/data"
extPolygonOut = ExtractByPolygon("soil", polyPoints, "INSIDE")
extPolygonOut.save("c:/sapyexamples/output/extpoly")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
polyPoints = [arcpy.Point(743050, 4321275), arcpy.Point(743100, 4321200), 
             arcpy.Point(743500, 4322000),arcpy.Point(742900, 4321800)]
env.workspace = "C:/sapyexamples/data"
extPolygonOut = ExtractByPolygon("soil", polyPoints, "INSIDE")
extPolygonOut.save("c:/sapyexamples/output/extpoly")
```

### Example 4

```python
# Name: ExtractByPolgyon_Ex_02.py
# Description: Extracts the cells of a raster based on a polygon.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "soil"
polyPoints = [arcpy.Point(743050, 4321275), arcpy.Point(743100, 4321200), 
             arcpy.Point(743500, 4322000),arcpy.Point(742900, 4321800)]

# Execute ExtractByPolygon
extPolygonOut = ExtractByPolygon(inRaster, polyPoints, "INSIDE")

# Save the output 
extPolygonOut.save("c:/sapyexamples/output/extpoly02")
```

### Example 5

```python
# Name: ExtractByPolgyon_Ex_02.py
# Description: Extracts the cells of a raster based on a polygon.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "soil"
polyPoints = [arcpy.Point(743050, 4321275), arcpy.Point(743100, 4321200), 
             arcpy.Point(743500, 4322000),arcpy.Point(742900, 4321800)]

# Execute ExtractByPolygon
extPolygonOut = ExtractByPolygon(inRaster, polyPoints, "INSIDE")

# Save the output 
extPolygonOut.save("c:/sapyexamples/output/extpoly02")
```

---

## Extract by Rectangle (Spatial Analyst)

## Summary

Extracts the cells of a raster based on a rectangle by specifying the rectangle's extent.

## Usage

- Additional attributes from the input raster, if any, will be carried over as-is to the output raster attribute table. Depending on the property being recorded, some of the attribute values may need to be recalculated.
- When a multiband raster is specified as the Input Raster (in_raster in Python) value, all bands will be used.To process a selection of bands from a multiband raster, first create a raster dataset composed of those particular bands using the Composite Bands tool. Then use the result as the Input Raster (in_raster in Python) value.The default output format is a geodatabase raster. If an Esri Grid stack is specified as the output format, the name of the stack cannot start with a number, use spaces, or be more than nine characters in length.
- The center of the cell is used to determine whether a cell is inside or outside a rectangle. If the center is within the outline of a rectangle, the cell is considered fully inside even if portions of the cell are outside the rectangle.
- Cell locations that are not selected are assigned a value of NoData.
- If the input raster is integer, the output raster will be integer. If the input is floating point, the output will be floating point.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster from which cells will be extracted. | Raster Layer |
| Extent | A rectangle that defines the area to be extracted.Current Display Extent —The extent will be based on the active map or scene.Draw Extent —The extent will be based on a rectangle drawn on the map or scene.Extent of a Layer —The extent will be based on an active map layer. Choose an available layer or use the Extent of data in all layers option. Each map layer has the following options:All Features —The extent of all features.Selected Features —The extent of the selected features.Visible Features —The extent of visible features.Browse —The extent will be based on a dataset.Clipboard —The extent can be copied to and from the clipboard. Copy Extent —Copies the extent and coordinate system to the clipboard.Paste Extent —Pastes the extent and coordinate system from the clipboard. If the clipboard does not include a coordinate system, the extent will use the map’s coordinate system.Reset Extent —The extent will be reset to the default value.When coordinates are manually provided, the coordinates must be numeric values and in the active map's coordinate system. The map may use different display units than the provided coordinates. Use a negative value sign for south and west coordinates.The coordinates are specified in the same map units as the input raster. | Extent |
| Extraction area(Optional) | Specifies whether cells inside or outside the input rectangle will be selected and written to the output raster.Inside—Cells inside the input rectangle will be selected and written to the output raster. All cells outside the rectangle will receive NoData values on the output raster.Outside—Cells outside the input rectangle will be selected and written to the output raster. All cells inside the rectangle will receive NoData values on the output raster. | String |
| in_raster | The input raster from which cells will be extracted. | Raster Layer |
| rectangleextent | A rectangle that defines the area to be extracted.MAXOF—The maximum extent of all inputs will be used.MINOF—The minimum area common to all inputs will be used.DISPLAY—The extent is equal to the visible display.Layer name—The extent of the specified layer will be used.Extent object—The extent of the specified object will be used. Space delimited string of coordinates—The extent of the specified string will be used. Coordinates are expressed in the order of x-min, y-min, x-max, y-max.The coordinates are specified in the same map units as the input raster. | Extent |
| extraction_area(Optional) | Specifies whether cells inside or outside the input rectangle will be selected and written to the output raster.INSIDE—Cells inside the input rectangle will be selected and written to the output raster. All cells outside the rectangle will receive NoData values on the output raster.OUTSIDE—Cells outside the input rectangle will be selected and written to the output raster. All cells inside the rectangle will receive NoData values on the output raster. | String |

## Code Samples

### Example 1

```python
ExtractByRectangle(in_raster, rectangle, {extraction_area})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
rectExtract = ExtractByRectangle("elevation", 
                                 Extent(477625, 213900, 486400, 224200), 
                                 "OUTSIDE")
rectExtract.save("c:/sapyexamples/output/extrect")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
rectExtract = ExtractByRectangle("elevation", 
                                 Extent(477625, 213900, 486400, 224200), 
                                 "OUTSIDE")
rectExtract.save("c:/sapyexamples/output/extrect")
```

### Example 4

```python
# Name: ExtractByRectangle_Ex_02.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inRectangle = Extent(477625, 213900, 486400, 224200)

# Execute ExtractByRectangle
rectExtract = ExtractByRectangle(inRaster, inRectangle, "INSIDE")

# Save the output 
rectExtract.save("c:/sapyexamples/output/extrect02")
```

### Example 5

```python
# Name: ExtractByRectangle_Ex_02.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inRectangle = Extent(477625, 213900, 486400, 224200)

# Execute ExtractByRectangle
rectExtract = ExtractByRectangle(inRaster, inRectangle, "INSIDE")

# Save the output 
rectExtract.save("c:/sapyexamples/output/extrect02")
```

---

## Extract Multi Values to Points (Spatial Analyst)

## Summary

Extracts cell values at locations specified in a point feature class from one or more rasters and records the values to the attribute table of the point feature class.

## Usage

- This tool modifies the input point features and may change its internal feature ID, which may be named ObjectID, FID, or OID. It is recommended that you include a unique ID field in the attribute table before performing the analysis.
- Cell values will be extracted from all input rasters at each location. A new field containing the cell values for each input raster will be appended to the input point feature class.
- Additional attributes from the input raster table, if any, will not be appended to the input point features.
- The input rasters will not be resampled honoring the analysis environment. Instead, the cell values will be extracted from all input rasters in their original resolution and spatial reference by projecting the input locations to the raster's spatial reference from which values are extracted.However, the analysis environment is applied to the input locations.
- Locations that extract values from NoData cells in the input raster will be given a <null> value in the output table. For shapefiles, because null fields are not supported, NoData cells are instead represented in the table with a value of -9999.
- The shapefile format has limitations on the maximum length of a field name; it is 10 characters. As a result, any fields that are appended to the attribute table of an input shapefile will have their names truncated and made unique by default. This may make it difficult to distinguish between the fields, particularly if the names are long or very similar. In this case, it is recommended that you copy the input shapefile to a file geodatabase and use the feature class for the analysis.
- If the Input point features (in_point_features in Python) values are defined using an XY event layer, the underlying event table is directly updated. The tool will fail if the underlying table is read-only.
- If the Input point features value is a point feature class with no spatial index, a warning will be issued. To improve tool performance for an input with a large number of points, create a spatial index. See the Add Spatial Index tool for more information.
- The tool will fail to execute with multipoint features. To perform analysis with multipoint features, convert them to single point features before using them in the extraction tool. See processing multipoint data for more information.
- Any combination of rasters (single band or multiband) can be specified for the Input rasters (in_rasters in Python) parameter.
- When a multiband raster is specified as one of the Input Rasters (in_rasters in Python) values, all of the bands in that input will be used.To process a selection of bands from an input multiband raster, first create a raster dataset composed of those particular bands using the Composite Bands tool. Then use the result in the list of input rasters.
- When the input is a multiband raster, a field will be added for all bands with a b1_, b2_, …bn prefix added to the name of the output field denoting the band number.
- Output field names are created from the name of the input raster by default; otherwise, you can specify a unique name for each field to store raster values.
- The Bilinear interpolation of values at point locations (bilinear_interpolate_values in Python) parameter specifies whether interpolation will be used to obtain the values from the raster. The default option is to extract the exact cell value at the input locations. To extract interpolated values using the bilinear method, check this parameter (bilinear_interpolate_values = "BILINEAR" in Python).
- If a feature is specified in the Mask environment, an internal raster is created using the minimum cell size of the input rasters. During extraction, the internal mask raster is again resampled to the cell size of each input raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point features | The input point features to which raster values will be added. | Feature Layer |
| Input rasters | The input raster (or rasters) values that will be extracted based on the input point feature location.Optionally, you can supply the name for the field to store the raster value. By default, a unique field name will be created based on the input raster dataset name. | Extract Values |
| Bilinear interpolation of values at point locations(Optional) | Specifies whether interpolation will be used.Unchecked—No interpolation will be applied; the value of the cell center will be used. This is the default.Checked—The value of the cell will be calculated from the adjacent cells with valid values using bilinear interpolation. NoData values will be ignored in the interpolation unless all adjacent cells are NoData. | Boolean |
| in_point_features | The input point features to which raster values will be added. | Feature Layer |
| in_rasters[Raster, {Output Field Name}] | The input raster (or rasters) values that will be extracted based on the input point feature location.Optionally, you can supply the name for the field to store the raster value. By default, a unique field name will be created based on the input raster dataset name. | Extract Values |
| bilinear_interpolate_values(Optional) | Specifies whether interpolation will be used.NONE—No interpolation will be applied; the value of the cell center will be used. This is the default.BILINEAR—The value of the cell will be calculated from the adjacent cells with valid values using bilinear interpolation. NoData values will be ignored in the interpolation unless all adjacent cells are NoData. | Boolean |

## Code Samples

### Example 1

```python
ExtractMultiValuesToPoints(in_point_features, in_rasters, {bilinear_interpolate_values})
```

### Example 2

```python
import arcpy
from arcpy.sa import *
from arcpy import env 
env.workspace = "c:/sapyexamples/data"
ExtractMultiValuesToPoints("observers.shp", [["elevation", "ELEV"], 
                           ["costraster", "COST"], ["flowdir", "DIR"]], "NONE")
```

### Example 3

```python
import arcpy
from arcpy.sa import *
from arcpy import env 
env.workspace = "c:/sapyexamples/data"
ExtractMultiValuesToPoints("observers.shp", [["elevation", "ELEV"], 
                           ["costraster", "COST"], ["flowdir", "DIR"]], "NONE")
```

### Example 4

```python
# Name: ExtractMultiValuesToPoints_Ex_02.py
# Description: Extracts the cells of multiple rasters as attributes in
#    an output point feature class.  This example takes a multiband IMG
#    and two GRID files as input.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "poi.shp"
inRasterList = [["doqq.img", "doqqval"], ["redstd", "focalstd"], 
                ["redmin", "focalmin"]]

# Execute ExtractValuesToPoints
ExtractMultiValuesToPoints(inPointFeatures, inRasterList, "BILINEAR")
```

### Example 5

```python
# Name: ExtractMultiValuesToPoints_Ex_02.py
# Description: Extracts the cells of multiple rasters as attributes in
#    an output point feature class.  This example takes a multiband IMG
#    and two GRID files as input.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "poi.shp"
inRasterList = [["doqq.img", "doqqval"], ["redstd", "focalstd"], 
                ["redmin", "focalmin"]]

# Execute ExtractValuesToPoints
ExtractMultiValuesToPoints(inPointFeatures, inRasterList, "BILINEAR")
```

---

## Extract Values to Points (Spatial Analyst)

## Summary

Extracts the cell values of a raster based on a set of point features and records the values in the attribute table of an output feature class.

## Usage

- All fields from the input point feature class will be carried over to the output point feature class.
- A new field named RASTERVALU is added to the output to store the extracted values. If a field with this name already exists in the attribute table of the input features, the tool will fail to execute.
- The input raster will not be resampled honoring the analysis environment. Instead, the cell values are extracted from the input raster in its original resolution and spatial reference by projecting the input locations to the raster's spatial reference from which values are extracted.However, the analysis environment is applied to the input locations.
- Locations that extract values from NoData cells in the input raster will be given a <null> value in the output table. For shapefiles, because null fields are not supported, NoData cells are instead represented in the table with a value of -9999.
- The shapefile format has a limitation on the maximum length of a field name of 10 characters. As a result, any fields that are appended to the attribute table of an output shapefile will have their names truncated and made unique by default. This may make it difficult to distinguish between the fields, particularly if the names are long or very similar. In this case, it is suggested to output to a file geodatabase instead.
- The tool will fail to execute with multipoint features. To perform analysis with multipoint features, convert them to single point features before using them in the extraction tool. See processing multipoint data for more information.
- When a multiband raster is specified as the Input Raster (in_raster in Python) value, only the first band will be used.To process a different band, specify the band to use.To extract values from multiple rasters or a multiband raster dataset, use the Extract Multi Values To Points tool.
- The interpolation option determines how the values will be obtained from the raster. The default option is to extract the exact cell value at the input locations. To extract interpolated value using a bilinear method, check the Interpolate values at the point locations (interpolate_values in Python) option.
- To add all the attributes from the input raster table, check the Append all the input raster attributes to the output point features option (ALL for the add_attributes parameter in Python). The attributes will be carried over as-is to the output point features, keeping the same values. Note that, depending on the nature of the property being recorded, some of the attribute values may need to be recalculated.
- If the Output Coordinate System environment hasn’t been explicitly specified, the spatial reference of the output feature class is derived from the input point features. However, if the output is written to a feature dataset, with or without Output Coordinate System environment specified, the output spatial reference will be same as the feature dataset.
- If a feature is specified in the Mask environment, it will be converted to a raster internally, using the cell size and cell alignment from the input raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point features | The input point features defining the locations from which you want to extract the raster cell values. | Feature Layer |
| Input raster | The raster dataset whose values will be extracted.It can be an integer or floating-point type raster. | Raster Layer |
| Output point features | The output point feature dataset containing the extracted raster values. | Feature Class |
| Interpolate values at the point locations(Optional) | Specifies whether interpolation will be used.Unchecked—No interpolation will be applied; the value of the cell center will be used. This is the default.Checked—The value of the cell will be calculated from the adjacent cells with valid values using bilinear interpolation. NoData values will be ignored in the interpolation unless all adjacent cells are NoData. | Boolean |
| Append all the input raster attributes to the output point features(Optional) | Determines if the raster attributes are written to the output point feature dataset.Unchecked—Only the value of the input raster is added to the point attributes. This is the default.Checked—All the fields from the input raster (except Count) will be added to the point attributes. | Boolean |
| in_point_features | The input point features defining the locations from which you want to extract the raster cell values. | Feature Layer |
| in_raster | The raster dataset whose values will be extracted.It can be an integer or floating-point type raster. | Raster Layer |
| out_point_features | The output point feature dataset containing the extracted raster values. | Feature Class |
| interpolate_values(Optional) | Specifies whether interpolation will be used.NONE—No interpolation will be applied; the value of the cell center will be used. This is the default.INTERPOLATE—The value of the cell will be calculated from the adjacent cells with valid values using bilinear interpolation. NoData values will be ignored in the interpolation unless all adjacent cells are NoData. | Boolean |
| add_attributes(Optional) | Determines if the raster attributes are written to the output point feature dataset.VALUE_ONLY—Only the value of the input raster is added to the point attributes. This is the default.ALL—All the fields from the input raster (except Count) will be added to the point attributes. | Boolean |

## Code Samples

### Example 1

```python
ExtractValuesToPoints(in_point_features, in_raster, out_point_features, {interpolate_values}, {add_attributes})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
ExtractValuesToPoints("rec_sites.shp", "elevation",
                      "C:/sapyexamples/output/outValPnts","INTERPOLATE",
                      "VALUE_ONLY")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
ExtractValuesToPoints("rec_sites.shp", "elevation",
                      "C:/sapyexamples/output/outValPnts","INTERPOLATE",
                      "VALUE_ONLY")
```

### Example 4

```python
# Name: ExtractValuesToPoints_Ex_02.py
# Description: Extracts the cells of a raster based on a set of points.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "rec_sites.shp"
inRaster = "elevation"
outPointFeatures = "C:/sapyexamples/output/extractvaluespts.shp"

# Execute ExtractValuesToPoints
ExtractValuesToPoints(inPointFeatures, inRaster, outPointFeatures,
                      "INTERPOLATE", "VALUE_ONLY")
```

### Example 5

```python
# Name: ExtractValuesToPoints_Ex_02.py
# Description: Extracts the cells of a raster based on a set of points.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "rec_sites.shp"
inRaster = "elevation"
outPointFeatures = "C:/sapyexamples/output/extractvaluespts.shp"

# Execute ExtractValuesToPoints
ExtractValuesToPoints(inPointFeatures, inRaster, outPointFeatures,
                      "INTERPOLATE", "VALUE_ONLY")
```

---

## Feature Preserving Smoothing (Spatial Analyst)

## Summary

Smooths a surface raster by removing noise while preserving features.

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Surface Raster | The input surface raster. | Raster Layer |
| Distance Units(Optional) | Specifies the distance unit that will be used for the Neighborhood Distance parameter. The default is Cells.Cells—The distance unit will be cells.Meters—The distance unit will be meters.Centimeters—The distance unit will be centimeters.Kilometers—The distance unit will be kilometers.Inches—The distance unit will be inches.Feet—The distance unit will be feet.Yard—The distance unit will be yards.Miles—The distance unit will be miles. | String |
| Neighborhood Distance(Optional) | The distance away from the target cell that defines the size of the processing neighborhood.The value must be a positive number. The default value is 5 cells. | Double |
| Normal Difference Threshold(Optional) | The maximum normal difference for a neighboring cell to be included in computing a new cell value for the current processing cell. A normal difference is an angle formed by the normal vector of a neighboring cell and the normal vector of the current processing cell.The value can be any number from –180 degrees to 180 degrees. The default value is 15 degrees. | Double |
| Number of Iterations(Optional) | The number of times that the smoothing process will be repeated.The value must be a positive integer. The default value is 3. | Long |
| Maximum Elevation Change(Optional) | The allowed maximum height change of any cell in one iteration.When a new value is calculated for a cell location, it is compared to the original value at that cell location. If the difference is less than or equal to this parameter setting, the new cell value will be used. Otherwise, the original value will remain unchanged.The value must be a positive number. The default value is 0.5 meters. | Linear Unit |
| Z Unit(Optional) | Specifies the linear unit that will be used for vertical z-values.It is defined by a vertical coordinate system if it exists. If no vertical coordinate system exists, define the z-unit using the unit list to ensure correct geodesic computation. The default is meter.Inch—The linear unit will be inches.Foot—The linear unit will be feet.Yard—The linear unit will be yards.Mile US—The linear unit will be miles.Nautical mile—The linear unit will be nautical miles.Millimeter—The linear unit will be millimeters.Centimeter—The linear unit will be centimeters.Meter—The linear unit will be meters.Kilometer—The linear unit will be kilometers.Decimeter—The linear unit will be decimeters. | String |
| Target Device for Analysis(Optional) | Specifies the device that will be used to perform the calculation.GPU then CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU only—The calculation will only be performed on the CPU.GPU only—The calculation will only be performed on the GPU. | String |
| in_raster | The input surface raster. | Raster Layer |
| distance_units(Optional) | Specifies the distance unit that will be used for the Neighborhood Distance parameter. The default is CELLS. CELLS—The distance unit will be cells.METERS—The distance unit will be meters.CENTIMETERS—The distance unit will be centimeters.KILOMETERS—The distance unit will be kilometers.INCHES—The distance unit will be inches.FEET—The distance unit will be feet.YARDS—The distance unit will be yards.MILES—The distance unit will be miles. | String |
| neighborhood_distance(Optional) | The distance away from the target cell that defines the size of the processing neighborhood.The value must be a positive number. The default value is 5 cells. | Double |
| normal_difference_threshold(Optional) | The maximum normal difference for a neighboring cell to be included in computing a new cell value for the current processing cell. A normal difference is an angle formed by the normal vector of a neighboring cell and the normal vector of the current processing cell.The value can be any number from –180 degrees to 180 degrees. The default value is 15 degrees. | Double |
| number_iterations(Optional) | The number of times that the smoothing process will be repeated.The value must be a positive integer. The default value is 3. | Long |
| maximum_elevation_change(Optional) | The allowed maximum height change of any cell in one iteration.When a new value is calculated for a cell location, it is compared to the original value at that cell location. If the difference is less than or equal to this parameter setting, the new cell value will be used. Otherwise, the original value will remain unchanged.The value must be a positive number. The default value is 0.5 meters. | Linear Unit |
| z_unit(Optional) | Specifies the linear unit that will be used for vertical z-values.It is defined by a vertical coordinate system if it exists. If no vertical coordinate system exists, define the z-unit using the unit list to ensure correct geodesic computation. The default is meter.INCH—The linear unit will be inches.FOOT—The linear unit will be feet.YARD—The linear unit will be yards.MILE_US—The linear unit will be miles.NAUTICAL_MILE—The linear unit will be nautical miles.MILLIMETER—The linear unit will be millimeters.CENTIMETER—The linear unit will be centimeters.METER—The linear unit will be meters.KILOMETER—The linear unit will be kilometers.DECIMETER—The linear unit will be decimeters. | String |
| analysis_target_device(Optional) | Specifies the device that will be used to perform the calculation.GPU_THEN_CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU_ONLY—The calculation will only be performed on the CPU.GPU_ONLY—The calculation will only be performed on the GPU. | String |

## Code Samples

### Example 1

```python
FeaturePreservingSmoothing(in_raster, {distance_units}, {neighborhood_distance}, {normal_difference_threshold}, {number_iterations}, {maximum_elevation_change}, {z_unit}, {analysis_target_device})
```

### Example 2

```python
from arcpy.sa import *
outFPS01 = FeaturePreservingSmoothing("elevation_1m.tif", "CELLS", 5, 15, 3, 
                                      "0.5 Meters", "METER", "GPU_THEN_CPU")
outFPS01.save("C:/sapyexamples/output/outsmoothraster01.tif")
```

### Example 3

```python
from arcpy.sa import *
outFPS01 = FeaturePreservingSmoothing("elevation_1m.tif", "CELLS", 5, 15, 3, 
                                      "0.5 Meters", "METER", "GPU_THEN_CPU")
outFPS01.save("C:/sapyexamples/output/outsmoothraster01.tif")
```

### Example 4

```python
# Name: FeaturePreservingSmoothing_Ex_02.py
# Description: Smooths a 1m resolution elevation raster  
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation_1m.tif"
distUnits = "METERS"
nbrDistance = 5
normDiffThreshold = 10
iterations = 1
maxElevChange = "1.5 Meters"
zUnit = ""
analysisDevice = ""

# Execute the tool
outFPS02 = FeaturePreservingSmoothing(inRaster, distUnits, nbrDistance,
                                    normDiffThreshold, iterations, maxElevChange,
                                    zUnit, analysisDevice)

# Save the output 
outFPS02.save("C:/sapyexamples/output/outsmoothraster02.tif")
```

### Example 5

```python
# Name: FeaturePreservingSmoothing_Ex_02.py
# Description: Smooths a 1m resolution elevation raster  
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation_1m.tif"
distUnits = "METERS"
nbrDistance = 5
normDiffThreshold = 10
iterations = 1
maxElevChange = "1.5 Meters"
zUnit = ""
analysisDevice = ""

# Execute the tool
outFPS02 = FeaturePreservingSmoothing(inRaster, distUnits, nbrDistance,
                                    normDiffThreshold, iterations, maxElevChange,
                                    zUnit, analysisDevice)

# Save the output 
outFPS02.save("C:/sapyexamples/output/outsmoothraster02.tif")
```

---

## Feature Solar Radiation (Spatial Analyst)

## Summary

Calculates the incoming solar insolation for input points or polygon features relative to the surface (ground) on Earth or the Moon.

## Usage

- The defined spatial reference of the Input surface raster parameter specifies whether the analysis will be for Earth or the Moon.
- The solar radiation computation requires the Output Coordinate System environment value to be in a projected coordinate system (PCS). It is recommended that the data be in a PCS with units of meters. If you run the analysis with a spherical coordinate system, you must set the Output Coordinate System environment to a valid PCS.
- The input features must be point or polygon feature data. Analysis on 3D or multipatch are not supported.You can include additional details to represent engineered surfaces using the input feature parameters by specifying direction, tilt, area, and offset for all or individual features, for example, to represent a set of points as solar panel arrays on the ground or building rooftop.
- It is recommended that you specify the output table format as geodatabase. This allows for increased performance and greater functionality. Tables in dBase file format (.dbf) have known limitations in precision, field name lengths, and date and time formatting.
- The calculated solar insolation values for total, direct, diffuse, and direct duration are added as attributes to the output table. These include values for total insolation (across the entire area) and average insolation (per unit area) of each feature. The units are kilowatt hours (kWh) and kilowatt hours per meter squared (kwh/m2), respectively. Duration units are hours.
- The total insolation is calculated by analyzing each cell location of the input surface raster that intersects the feature (or part thereof) and multiplying it by that feature's area. It is not calculated for a single central location of the feature.
- If you are running an analysis for large extents with few or highly dispersed polygon features, the process may take additional time due to the resolution required for rasterization.
- The Feature Slope, Feature Aspect, Feature Area, and Feature Offset parameters can be used to provide additional details to represent engineered surfaces that may intercept the incoming solar radiation, such as direction, tilt, area, and offset. These may be static or changing position and orientation in time. For example, a set of points that represent solar panel arrays on the ground or building rooftop, or a panel on a moving vehicle.If the feature parameters are not specified, the values are calculated from the input surface raster or the individual features by default. Points have an area of zero unless otherwise specified.If you provide a value for any of these parameters, it will be applied to all input features. Alternatively, you can provide an input field attribute from the input features to analyze each feature individually. If a field is specified and a value is missing (Null), the value will be set as zero.
- Daylight saving time is supported for Earth only. For the Moon, times must be specified in UTC.
- The End date and time parameter value must be equal to or greater than the start date. The total span of time must not be greater than one year. The start and end date times can cross the calendar year.
- Output radiation values will be calculated for each respective time interval. If no solar radiation was received for a time interval, the result for that location will have a value of zero.If the total time specified between the start and end times is not equally divisible by the time interval, the total duration will be extended internally to provide the required number of time slices. For example, if the Time Interval parameter is set to cover three days but the difference between the specified start and end times covers eight days, the time interval will be extended to nine days. No partial results for times will be returned.
- The minimum time interval for Earth data is 30 minutes and must be proportional to 30. The minimum time interval for Moon data is two hours and must be proportional to 2.
- The Neighborhood Distance (neighborhood_distance in Python) parameter determines the neighborhood size and calculates the surface parameter over this distance from the target cell center. The value cannot be less than the input raster cell size.A small neighborhood distance captures more local variability in the landscape, such as characteristics of smaller landscape features. With high-resolution elevation data, larger distances may be more appropriate.
- If the Use adaptive neighborhood parameter is checked (use_adaptive_neighborhood = "ADAPTIVE_NEIGHBORHOOD" in Python), the neighborhood distance will change with variability in the terrain. The neighborhood distance will shrink if there is too much variability in the calculation window.
- Earth's Moon does not have an atmosphere; the radiation parameters diffuse proportion and transmittivity are not relevant during analysis. As a result, the incoming diffuse solar radiation is zero and the total radiation is equal to direct solar radiation.
- The diffuse proportion is the fraction of global normal radiation flux that is diffuse. Values range from 0 to 1. Set this value according to atmospheric conditions. Typical values are 0.2 for very clear sky conditions and 0.3 for generally clear sky conditions.
- Transmittivity is the ratio of the energy reaching Earth's surface to that which is received at the upper limit of the atmosphere. Values range from 0 (no transmission) to 1 (complete transmission). Typically observed values are 0.6 or 0.7 for very clear sky conditions and 0.5 for a generally clear sky.
- Transmittivity has an inverse relationship with the diffuse proportion parameter. Altering these values may affect the model result. Identifying the best values for the area of interest depends on several variables (such as location and time). You can change these values to compare how they affect the result.
- The Sun Map Grid Level parameter controls the speed and accuracy of the computation. It adjusts the resolution of the hexagonal grid cells that will be used for the internal calculations, based on the H3 geospatial indexing system.A lower grid level creates fewer larger sun map areas and decreases tool run time. A higher grid level creates more smaller sun maps, improving the accuracy of the result.Valid values of the sun map grid level for Earth range from 5 to 7. For the Moon, the valid value range is from 4 to 6.The default level is determined by the input surface raster. When analyzing surface data on Earth, if the analysis cell size is less than or equal to 4 meters, the default grid level is 6. If the cell size is greater than 4 meters, the default grid level is 5. For analyzing surface data on the Moon, the default level is 6.The following table shows the average area of the hexagon grid cells for each sun map level, in units of square kilometers:LevelEarthMoon4Not applicable131.65252.9 (default > 4m)18.8636.1 (default < 4m)2.69 (default)75.16Not applicable
- This tool can be GPU accelerated, which means that if a compatible graphics processing unit (GPU) is available on your system, it will be used to enhance the performance of the tool. Use the Target device for analysis (analysis_target_device in Python) parameter to control whether the GPU or CPU will be used to run the tool.See GPU processing with Spatial Analyst for details on compatible GPUs, configuring and working with GPU devices, as well as troubleshooting tips.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- Additional resources: Acton, Charles A. 1996. "Ancillary data services of NASA's Navigation and Ancillary Information Facility." Planetary and Space Science Volume 44, Issue 1, January 1996, pp. 65–70. https://doi.org/10.1016/0032-0633(95)00107-7Acton, Charles, Nathaniel Bachman, Boris Semenov, and Edward Wright. 2018. "A look towards the future in the handling of space science mission geometry." Planetary and Space Science Volume 150, January 2018, pp. 9–12. https://doi.org/10.1016/j.pss.2017.02.013Brodsky, Isaac. 2018. "Uber’s Hexagonal Hierarchical Spatial Index H3." Engineering (blog), June 27, 2018. https://www.uber.com/blog/h3/

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Surface Raster | The input elevation surface raster. | Raster Layer |
| Input Point or Polygon Features | The input features (point or polygon) that represent a location or engineered surface to calculate the amount of solar radiation received. | Feature Layer |
| Unique ID Field | The field that contains the values that define each feature.It can be an integer or a string field of the input features. | Field |
| Output table | The output table that will contain the summary of the amount of solar radiation received by the input featuresThe format of the table is determined by the output location and path. By default, the output will be a geodatabase table if in a geodatabase workspace, or a dBASE table if in a file workspace. | Table |
| Start Date and Time | The start date and time for the analysis. | Date |
| End Date and Time | The end date and time for the analysis. | Date |
| Time Zone(Optional) | The time zone that will be used for the start and end time. The default is coordinated universal time (UTC).UTC—The time zone will be UTC.Dateline Standard Time—The time zone will be Dateline Standard Time (UTC-12:00).UTC-11—The time zone will be UTC-11 (UTC-11:00).Aleutian Standard Time—The time zone will be Aleutian Standard Time (UTC-10:00).Hawaiian Standard Time—The time zone will be Hawaiian Standard Time (UTC-10:00).Marquesas Standard Time—The time zone will be Marquesas Standard Time (UTC-09:30).Alaskan Standard Time—The time zone will be Alaskan Standard Time (UTC-09:00).UTC-09—The time zone will be UTC-09 (UTC-09:00).Pacific Standard Time (Mexico)—The time zone will be Pacific Standard Time (Mexico) (UTC-08:00).UTC-08—The time zone will be UTC-08 (UTC-08:00).Pacific Standard Time—The time zone will be Pacific Standard Time (UTC-08:00).US Mountain Standard Time—The time zone will be US Mountain Standard Time (UTC-07:00).Mountain Standard Time (Mexico)—The time zone will be Mountain Standard Time (Mexico) (UTC-07:00).Mountain Standard Time—The time zone will be Mountain Standard Time (UTC-07:00).Yukon Standard Time—The time zone will be Yukon Standard Time (UTC-07:00).Central America Standard Time—The time zone will be Central America Standard Time (UTC-06:00).Central Standard Time—The time zone will be Central Standard Time (UTC-06:00).Easter Island Standard Time—The time zone will be Easter Island Standard Time (UTC-06:00).Central Standard Time (Mexico)—The time zone will be Central Standard Time (Mexico) (UTC-06:00).Canada Central Standard Time—The time zone will be Canada Central Standard Time (UTC-06:00).SA Pacific Standard Time—The time zone will be SA Pacific Standard Time (UTC-05:00).Eastern Standard Time (Mexico)—The time zone will be Eastern Standard Time (Mexico) (UTC-05:00).Eastern Standard Time—The time zone will be Eastern Standard Time (UTC-05:00).Haiti Standard Time—The time zone will be Haiti Standard Time (UTC-05:00).Cuba Standard Time—The time zone will be Cuba Standard Time (UTC-05:00).US Eastern Standard Time—The time zone will be US Eastern Standard Time (UTC-05:00).Turks And Caicos Standard Time—The time zone will be Turks And Caicos Standard Time (UTC-04:00).Paraguay Standard Time—The time zone will be Paraguay Standard Time (UTC-04:00).Atlantic Standard Time—The time zone will be Atlantic Standard Time (UTC-04:00).Venezuela Standard Time—The time zone will be Venezuela Standard Time (UTC-04:00).Central Brazilian Standard Time—The time zone will be Central Brazilian Standard Time (UTC-04:00).SA Western Standard Time—The time zone will be SA Western Standard Time (UTC-04:00).Pacific SA Standard Time—The time zone will be Pacific SA Standard Time (UTC-04:00).Newfoundland Standard Time—The time zone will be Newfoundland Standard Time (UTC-03:30).Tocantins Standard Time—The time zone will be Tocantins Standard Time (UTC-03:00).E. South America Standard Time—The time zone will be E. South America Standard Time (UTC-03:00).SA Eastern Standard Time—The time zone will be SA Eastern Standard Time (UTC-03:00).Argentina Standard Time—The time zone will be Argentina Standard Time (UTC-03:00).Greenland Standard Time—The time zone will be Greenland Standard Time (UTC-03:00).Montevideo Standard Time—The time zone will be Montevideo Standard Time (UTC-03:00).Magallanes Standard Time—The time zone will be Magallanes Standard Time (UTC-03:00).Saint Pierre Standard Time—The time zone will be Saint Pierre Standard Time (UTC-03:00).Bahia Standard Time—The time zone will be Bahia Standard Time (UTC-03:00).UTC-02—The time zone will be UTC-02 (UTC-02:00).Mid-Atlantic Standard Time—The time zone will be Mid-Atlantic Standard Time (UTC-02:00).Azores Standard Time—The time zone will be Azores Standard Time (UTC-01:00).Cape Verde Standard Time—The time zone will be Cape Verde Standard Time (UTC-01:00).GMT Standard Time—The time zone will be GMT Standard Time (UTC+00:00).Greenwich Standard Time—The time zone will be Greenwich Standard Time (UTC+00:00).Sao Tome Standard Time—The time zone will be Sao Tome Standard Time (UTC+00:00).Morocco Standard Time—The time zone will be Morocco Standard Time (UTC+00:00).W. Europe Standard Time—The time zone will be W. Europe Standard Time (UTC+01:00).Central Europe Standard Time—The time zone will be Central Europe Standard Time (UTC+01:00).Romance Standard Time—The time zone will be Romance Standard Time (UTC+01:00).Central European Standard Time—The time zone will be Central European Standard Time (UTC+01:00).W. Central Africa Standard Time—The time zone will be W. Central Africa Standard Time (UTC+01:00).Jordan Standard Time—The time zone will be Jordan Standard Time (UTC+02:00).GTB Standard Time—The time zone will be GTB Standard Time (UTC+02:00).Middle East Standard Time—The time zone will be Middle East Standard Time (UTC+02:00).Egypt Standard Time—The time zone will be Egypt Standard Time (UTC+02:00).E. Europe Standard Time—The time zone will be E. Europe Standard Time (UTC+02:00).Syria Standard Time—The time zone will be Syria Standard Time (UTC+02:00).West Bank Standard Time—The time zone will be West Bank Standard Time (UTC+02:00).South Africa Standard Time—The time zone will be South Africa Standard Time (UTC+02:00).FLE Standard Time—The time zone will be FLE Standard Time (UTC+02:00).Israel Standard Time—The time zone will be Israel Standard (UTC+02:00).South Sudan Standard Time—The time zone will be South Sudan Standard Time (UTC+02:00).Kaliningrad Standard Time—The time zone will be Kaliningrad Standard Time (UTC+02:00).Sudan Standard Time—The time zone will be Sudan Standard Time (UTC+02:00).Libya Standard Time—The time zone will be Libya Standard Time (UTC+02:00).Namibia Standard Time—The time zone will be Namibia Standard Time (UTC+02:00).Arabic Standard Time—The time zone will be Arabic Standard Time (UTC+03:00).Turkey Standard Time—The time zone will be Turkey Standard Time (UTC+03:00).Arab Standard Time—The time zone will be Arab Standard Time (UTC+03:00).Belarus Standard Time—The time zone will be Belarus Standard Time (UTC+03:00).Russian Standard Time—The time zone will be Russian Standard Time (UTC+03:00).E. Africa Standard Time—The time zone will be E. Africa Standard Time (UTC+03:00).Volgograd Standard Time—The time zone will be Volgograd Standard Time (UTC+03:00).Iran Standard Time—The time zone will be Iran Standard Time (UTC+03:30).Arabian Standard Time—The time zone will be Arabian Standard Time (UTC+04:00).Astrakhan Standard Time—The time zone will be Astrakhan Standard Time (UTC+04:00).Azerbaijan Standard Time—The time zone will be Azerbaijan Standard Time (UTC+04:00).Russia Time Zone 3—The time zone will be Russia Time Zone 3 (UTC+04:00).Mauritius Standard Time—The time zone will be Mauritius Standard Time (UTC+04:00).Saratov Standard Time—The time zone will be Saratov Standard Time (UTC+04:00).Georgian Standard Time—The time zone will be Georgian Standard Time (UTC+04:00).Caucasus Standard Time—The time zone will be Caucasus Standard Time (UTC+04:00).Afghanistan Standard Time—The time zone will be Afghanistan Standard Time (UTC+04:30).West Asia Standard Time—The time zone will be West Asia Standard Time (UTC+05:00).Ekaterinburg Standard Time—The time zone will be Ekaterinburg Standard Time (UTC+05:00).Pakistan Standard Time—The time zone will be Pakistan Standard Time (UTC+05:00).Qyzylorda Standard Time—The time zone will be Qyzylorda Standard Time (UTC+05:00).India Standard Time—The time zone will be India Standard Time (UTC+05:30).Sri Lanka Standard Time—The time zone will be Sri Lanka Standard Time (UTC+05:30).Nepal Standard Time—The time zone will be Nepal Standard Time (UTC+05:45).Central Asia Standard Time—The time zone will be Central Asia Standard Time (UTC+06:00).Bangladesh Standard Time—The time zone will be Bangladesh Standard Time (UTC+06:00).Omsk Standard Time—The time zone will be Omsk Standard Time (UTC+06:00).Myanmar Standard Time—The time zone will be Myanmar Standard Time (UTC+06:30).SE Asia Standard Time—The time zone will be SE Asia Standard Time (UTC+07:00).Altai Standard Time—The time zone will be Altai Standard Time (UTC+07:00).W. Mongolia Standard Time—The time zone will be W. Mongolia Standard Time (UTC+07:00).North Asia Standard Time—The time zone will be North Asia Standard Time (UTC+07:00).N. Central Asia Standard Time—The time zone will be N. Central Asia Standard Time (UTC+07:00).Tomsk Standard Time—The time zone will be Tomsk Standard Time (UTC+07:00).China Standard Time—The time zone will be China Standard Time (UTC+08:00).North Asia East Standard Time—The time zone will be North Asia East Standard Time (UTC+08:00).Singapore Standard Time—The time zone will be Singapore Standard Time (UTC+08:00).W. Australia Standard Time—The time zone will be W. Australia Standard Time (UTC+08:00).Taipei Standard Time—The time zone will be Taipei Standard Time (UTC+08:00).Ulaanbaatar Standard Time—The time zone will be Ulaanbaatar Standard Time (UTC+08:00).Aus Central W. Standard Time—The time zone will be Aus Central W. Standard Time (UTC+08:45).Transbaikal Standard Time—The time zone will be Transbaikal Standard Time (UTC+09:00).Tokyo Standard Time—The time zone will be Tokyo Standard Time (UTC+09:00).North Korea Standard Time—The time zone will be North Korea Standard Time (UTC+09:00).Korea Standard Time—The time zone will be Korea Standard Time (UTC+09:00).Yakutsk Standard Time—The time zone will be Yakutsk Standard Time (UTC+09:00).Cen. Australia Standard Time—The time zone will be Cen. Australia Standard Time (UTC+09:30).AUS Central Standard Time—The time zone will be AUS Central Standard Time (UTC+09:30).E. Australia Standard Time—The time zone will be E. Australia Standard Time (UTC+10:00).AUS Eastern Standard Time—The time zone will be AUS Eastern Standard Time (UTC+10:00).West Pacific Standard Time—The time zone will be West Pacific Standard Time (UTC+10:00).Tasmania Standard Time—The time zone will be Tasmania Standard Time (UTC+10:00).Vladivostok Standard Time—The time zone will be Vladivostok Standard Time (UTC+10:00).Lord Howe Standard Time—The time zone will be Lord Howe Standard Time (UTC+10:30).Bougainville Standard Time—The time zone will be Bougainville Standard Time (UTC+11:00).Russia Time Zone 10—The time zone will be Russia Time Zone 10 (UTC+11:00).Magadan Standard Time—The time zone will be Magadan Standard Time (UTC+11:00).Norfolk Standard Time—The time zone will be Norfolk Standard Time (UTC+11:00).Sakhalin Standard Time—The time zone will be Sakhalin Standard Time (UTC+11:00).Central Pacific Standard Time—The time zone will be Central Pacific Standard Time (UTC+11:00).Russia Time Zone 11—The time zone will be Russia Time Zone 11 (UTC+11:00).New Zealand Standard Time—The time zone will be New Zealand Standard Time (UTC+12:00).UTC+12—The time zone will be UTC+12 (UTC+12:00).Fiji Standard Time—The time zone will be Fiji Standard Time (UTC+12:00).Kamchatka Standard Time—The time zone will be Kamchatka Standard Time (UTC+12:00).Chatham Islands Standard Time—The time zone will be Chatham Islands Standard Time (UTC+12:45).UTC+13—The time zone will be UTC+13 (UTC+13:00).Tonga Standard Time—The time zone will be Tonga Standard Time (UTC+13:00).Samoa Standard Time—The time zone will be Samoa Standard Time (UTC+13:00).Line Islands Standard Time—The time zone will be Line Islands Standard Time (UTC+14:00). | String |
| Adjust times for daylight saving time (Optional) | Specifies whether the input time configuration will be adjusted for daylight saving time.This parameter is not applicable for analysis on the Moon.Unchecked—The input time values will not be adjusted for daylight saving time. This is the default.Checked—The input time values will be adjusted for daylight saving time. | Boolean |
| Calculate insolation for time intervals(Optional) | Specifies whether a single total insolation value will be calculated for the entire time configuration or multiple radiation values will be calculated for the specified interval.Unchecked—A single total radiation value will be calculated for the entire time configuration. This is the default.Checked—Multiple radiation values will be calculated for each time interval over the entire time configuration. The number of outputs depends on the interval value. For example, for a whole year with monthly intervals, the result will contain 12 output radiation values for each location. | Boolean |
| Time Interval Unit(Optional) | Specifies the time unit that will be used for calculating solar radiation values over the entire time configuration.This parameter is only available when the Calculate insolation for time intervals parameter is checked.Minute—The interval unit will be minutes. This option is only available for Earth-based data.Hour—The interval unit will be hours.Day—The interval unit will be days. This is the defaultWeek—The interval unit will be weeks. | String |
| Time Interval(Optional) | The value of the duration or time between intervals.The default value is dependent on the interval unit specified. The default value for each of the available units are listed below. Minute—60Hour—4Day—14 Week—2 | Long |
| Feature Offset(Optional) | A vertical distance that will be added to the raster surface for analysis. It must be a positive integer or floating-point value.You can select a field from the input features dataset, or you can provide a numerical value.For example, if the object is a panel, provide the height of the panel.If a value is provided for this parameter, that value will be used by all features. To specify different values for each individual feature, select a field from the input features dataset.The default value is 0. | Double; Field |
| Feature Area(Optional) | The area associated with the input features. It must be a positive integer or floating-point value.You can select a field from the input features dataset, or you can provide a numerical value.For example, if the object is a panel, provide the area of the panel.If a value is provided for this parameter, that value will be used by all features. To specify different values for each individual feature, select a field from the input features dataset.By default, the area is obtained from the input features. For point features, the default area is 0. | Double; Field |
| Feature Slope(Optional) | The relative slope or incline associated with the input features. It must be a positive integer or floating-point value.You can select a field from the input features dataset, or you can provide a numerical value.For example, if the object is a panel, provide the incline of the panel.If a value is provided for this parameter, that value will be used by all features. To specify different values for each individual feature, select a field from the input features dataset.Slope is expressed in degrees from 0 to 90. The default values for analysis are calculated from the underlying values of the input surface raster. | Double; Field |
| Feature Aspect(Optional) | The relative aspect or direction associated with the input features. It must be a positive integer or floating-point value.You can select a field from the input features dataset, or you can provide a numerical value.For example, if the object is a panel, provide the direction of the panel face.If a value is provided for this parameter, that value will be used by all features. To specify different values for each individual feature, select a field from the input features dataset.Aspect is expressed in degrees from 0 to 360. The default values for analysis area calculated from the underlying values of the input surface raster. | Double; Field |
| Neighborhood Distance(Optional) | The distance from the target cell center for which the output insolation value will be calculated. It determines the size of the neighborhood.The default value is the input surface raster cell size, resulting in a 3 by 3 neighborhood. | Linear Unit |
| Use Adaptive Neighborhood(Optional) | Specifies whether neighborhood distance will vary with landscape changes (adaptive). The maximum distance is determined by the neighborhood distance. The minimum distance is the input raster cell size. Unchecked—A single (fixed) neighborhood distance will be used at all locations. This is the default.Checked—An adaptive neighborhood distance will be used at all locations. | Boolean |
| Diffuse Model Type(Optional) | Specifies the type of diffuse radiation model that will be used.Uniform sky—The uniform diffuse model will be used. The incoming diffuse radiation is the same from all sky directions. This is the default.Standard overcast sky—The standard overcast diffuse model will be used. The incoming diffuse radiation flux varies with the zenith angle. | String |
| Diffuse Proportion(Optional) | The proportion of global normal radiation flux that is diffuse. Values range from 0 to 1.Set this value according to atmospheric conditions. The default value is 0.3 for generally clear sky conditions. | Double |
| Transmittivity(Optional) | The fraction of radiation that passes through the atmosphere (averaged overall wavelengths). Values range from 0 (no transmission) to 1 (all transmission).The default is 0.5 for a generally clear sky. | Double |
| Target Device for Analysis(Optional) | Specifies the device that will be used to perform the calculation.GPU then CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU only—The calculation will only be performed on the CPU.GPU only—The calculation will only be performed on the GPU. | String |
| Output Join Layer(Optional) | The output layer that will be created by joining the output table to the input feature class. This is an optional output. | Feature Layer |
| Sun Map Grid Level(Optional) | The resolution that will be used to generate the H3 hexagonal grid cells used for internal calculations. A lower grid level value creates fewer, larger sun map areas and decreases tool run time. A higher grid level creates more smaller sun maps improving the accuracy of the result.Valid values of the sun map grid level for Earth range from 5 to 7. For the Moon, the valid value range is from 4 to 6.By default, the grid level is determined by the input surface raster. When analyzing surface data on Earth, if the analysis cell size is less than or equal to 4 meters, the default grid level is 6. If the analysis cell size is greater than 4 meters, the default grid level is 5. For analyzing surface data on the Moon, the default grid level is 6. | Long |
| in_surface_raster | The input elevation surface raster. | Raster Layer |
| in_features | The input features (point or polygon) that represent a location or engineered surface to calculate the amount of solar radiation received. | Feature Layer |
| unique_id_field | The field that contains the values that define each feature.It can be an integer or a string field of the input features. | Field |
| out_table | The output table that will contain the summary of the amount of solar radiation received by the input featuresThe format of the table is determined by the output location and path. By default, the output will be a geodatabase table if in a geodatabase workspace, or a dBASE table if in a file workspace. | Table |
| start_date_time | The start date and time for the analysis. | Date |
| end_date_time | The end date and time for the analysis. | Date |
| time_zone(Optional) | The time zone that will be used for the start and end time. The default is coordinated universal time (UTC).UTC—The time zone will be UTC.Dateline_Standard_Time—The time zone will be Dateline Standard Time (UTC-12:00).UTC-11—The time zone will be UTC-11 (UTC-11:00).Aleutian_Standard_Time—The time zone will be Aleutian Standard Time (UTC-10:00).Hawaiian_Standard_Time—The time zone will be Hawaiian Standard Time (UTC-10:00).Marquesas_Standard_Time—The time zone will be Marquesas Standard Time (UTC-09:30).Alaskan_Standard_Time—The time zone will be Alaskan Standard Time (UTC-09:00).UTC-09—The time zone will be UTC-09 (UTC-09:00).Pacific_Standard_Time_(Mexico)—The time zone will be Pacific Standard Time (Mexico) (UTC-08:00).UTC-08—The time zone will be UTC-08 (UTC-08:00).Pacific_Standard_Time—The time zone will be Pacific Standard Time (UTC-08:00).US_Mountain_Standard_Time—The time zone will be US Mountain Standard Time (UTC-07:00).Mountain_Standard_Time_(Mexico)—The time zone will be Mountain Standard Time (Mexico) (UTC-07:00).Mountain_Standard_Time—The time zone will be Mountain Standard Time (UTC-07:00).Yukon_Standard_Time—The time zone will be Yukon Standard Time (UTC-07:00).Central_America_Standard_Time—The time zone will be Central America Standard Time (UTC-06:00).Central_Standard_Time—The time zone will be Central Standard Time (UTC-06:00).Easter_Island_Standard_Time—The time zone will be Easter Island Standard Time (UTC-06:00).Central_Standard_Time_(Mexico)—The time zone will be Central Standard Time (Mexico) (UTC-06:00).Canada_Central_Standard_Time—The time zone will be Canada Central Standard Time (UTC-06:00).SA_Pacific_Standard_Time—The time zone will be SA Pacific Standard Time (UTC-05:00).Eastern_Standard_Time_(Mexico)—The time zone will be Eastern Standard Time (Mexico) (UTC-05:00).Eastern_Standard_Time—The time zone will be Eastern Standard Time (UTC-05:00).Haiti_Standard_Time—The time zone will be Haiti Standard Time (UTC-05:00).Cuba_Standard_Time—The time zone will be Cuba Standard Time (UTC-05:00).US_Eastern_Standard_Time—The time zone will be US Eastern Standard Time (UTC-05:00).Turks_And_Caicos_Standard_Time—The time zone will be Turks And Caicos Standard Time (UTC-04:00).Paraguay_Standard_Time—The time zone will be Paraguay Standard Time (UTC-04:00).Atlantic_Standard_Time—The time zone will be Atlantic Standard Time (UTC-04:00).Venezuela_Standard_Time—The time zone will be Venezuela Standard Time (UTC-04:00).Central_Brazilian_Standard_Time—The time zone will be Central Brazilian Standard Time (UTC-04:00).SA_Western_Standard_Time—The time zone will be SA Western Standard Time (UTC-04:00).Pacific_SA_Standard_Time—The time zone will be Pacific SA Standard Time (UTC-04:00).Newfoundland_Standard_Time—The time zone will be Newfoundland Standard Time (UTC-03:30).Tocantins_Standard_Time—The time zone will be Tocantins Standard Time (UTC-03:00).E._South_America_Standard_Time—The time zone will be E. South America Standard Time (UTC-03:00).SA_Eastern_Standard_Time—The time zone will be SA Eastern Standard Time (UTC-03:00).Argentina_Standard_Time—The time zone will be Argentina Standard Time (UTC-03:00).Greenland_Standard_Time—The time zone will be Greenland Standard Time (UTC-03:00).Montevideo_Standard_Time—The time zone will be Montevideo Standard Time (UTC-03:00).Magallanes_Standard_Time—The time zone will be Magallanes Standard Time (UTC-03:00).Saint_Pierre_Standard_Time—The time zone will be Saint Pierre Standard Time (UTC-03:00).Bahia_Standard_Time—The time zone will be Bahia Standard Time (UTC-03:00).UTC-02—The time zone will be UTC-02 (UTC-02:00).Mid-Atlantic_Standard_Time—The time zone will be Mid-Atlantic Standard Time (UTC-02:00).Azores_Standard_Time—The time zone will be Azores Standard Time (UTC-01:00).Cape_Verde_Standard_Time—The time zone will be Cape Verde Standard Time (UTC-01:00).GMT_Standard_Time—The time zone will be GMT Standard Time (UTC+00:00).Greenwich_Standard_Time—The time zone will be Greenwich Standard Time (UTC+00:00).Sao_Tome_Standard_Time—The time zone will be Sao Tome Standard Time (UTC+00:00).Morocco_Standard_Time—The time zone will be Morocco Standard Time (UTC+00:00).W._Europe_Standard_Time—The time zone will be W. Europe Standard Time (UTC+01:00).Central_Europe_Standard_Time—The time zone will be Central Europe Standard Time (UTC+01:00).Romance_Standard_Time—The time zone will be Romance Standard Time (UTC+01:00).Central_European_Standard_Time—The time zone will be Central European Standard Time (UTC+01:00).W._Central_Africa_Standard_Time—The time zone will be W. Central Africa Standard Time (UTC+01:00).Jordan_Standard_Time—The time zone will be Jordan Standard Time (UTC+02:00).GTB_Standard_Time—The time zone will be GTB Standard Time (UTC+02:00).Middle_East_Standard_Time—The time zone will be Middle East Standard Time (UTC+02:00).Egypt_Standard_Time—The time zone will be Egypt Standard Time (UTC+02:00).E._Europe_Standard_Time—The time zone will be E. Europe Standard Time (UTC+02:00).Syria_Standard_Time—The time zone will be Syria Standard Time (UTC+02:00).West_Bank_Standard_Time—The time zone will be West Bank Standard Time (UTC+02:00).South_Africa_Standard_Time—The time zone will be South Africa Standard Time (UTC+02:00).FLE_Standard_Time—The time zone will be FLE Standard Time (UTC+02:00).Israel_Standard_Time—The time zone will be Israel Standard (UTC+02:00).South_Sudan_Standard_Time—The time zone will be South Sudan Standard Time (UTC+02:00).Kaliningrad_Standard_Time—The time zone will be Kaliningrad Standard Time (UTC+02:00).Sudan_Standard_Time—The time zone will be Sudan Standard Time (UTC+02:00).Libya_Standard_Time—The time zone will be Libya Standard Time (UTC+02:00).Namibia_Standard_Time—The time zone will be Namibia Standard Time (UTC+02:00).Arabic_Standard_Time—The time zone will be Arabic Standard Time (UTC+03:00).Turkey_Standard_Time—The time zone will be Turkey Standard Time (UTC+03:00).Arab_Standard_Time—The time zone will be Arab Standard Time (UTC+03:00).Belarus_Standard_Time—The time zone will be Belarus Standard Time (UTC+03:00).Russian_Standard_Time—The time zone will be Russian Standard Time (UTC+03:00).E._Africa_Standard_Time—The time zone will be E. Africa Standard Time (UTC+03:00).Volgograd_Standard_Time—The time zone will be Volgograd Standard Time (UTC+03:00).Iran_Standard_Time—The time zone will be Iran Standard Time (UTC+03:30).Arabian_Standard_Time—The time zone will be Arabian Standard Time (UTC+04:00).Astrakhan_Standard_Time—The time zone will be Astrakhan Standard Time (UTC+04:00).Azerbaijan_Standard_Time—The time zone will be Azerbaijan Standard Time (UTC+04:00).Russia_Time_Zone_3—The time zone will be Russia Time Zone 3 (UTC+04:00).Mauritius_Standard_Time—The time zone will be Mauritius Standard Time (UTC+04:00).Saratov_Standard_Time—The time zone will be Saratov Standard Time (UTC+04:00).Georgian_Standard_Time—The time zone will be Georgian Standard Time (UTC+04:00).Caucasus_Standard_Time—The time zone will be Caucasus Standard Time (UTC+04:00).Afghanistan_Standard_Time—The time zone will be Afghanistan Standard Time (UTC+04:30).West_Asia_Standard_Time—The time zone will be West Asia Standard Time (UTC+05:00).Ekaterinburg_Standard_Time—The time zone will be Ekaterinburg Standard Time (UTC+05:00).Pakistan_Standard_Time—The time zone will be Pakistan Standard Time (UTC+05:00).Qyzylorda_Standard_Time—The time zone will be Qyzylorda Standard Time (UTC+05:00).India_Standard_Time—The time zone will be India Standard Time (UTC+05:30).Sri_Lanka_Standard_Time—The time zone will be Sri Lanka Standard Time (UTC+05:30).Nepal_Standard_Time—The time zone will be Nepal Standard Time (UTC+05:45).Central_Asia_Standard_Time—The time zone will be Central Asia Standard Time (UTC+06:00).Bangladesh_Standard_Time—The time zone will be Bangladesh Standard Time (UTC+06:00).Omsk_Standard_Time—The time zone will be Omsk Standard Time (UTC+06:00).Myanmar_Standard_Time—The time zone will be Myanmar Standard Time (UTC+06:30).SE_Asia_Standard_Time—The time zone will be SE Asia Standard Time (UTC+07:00).Altai_Standard_Time—The time zone will be Altai Standard Time (UTC+07:00).W._Mongolia_Standard_Time—The time zone will be W. Mongolia Standard Time (UTC+07:00).North_Asia_Standard_Time—The time zone will be North Asia Standard Time (UTC+07:00).N._Central_Asia_Standard_Time—The time zone will be N. Central Asia Standard Time (UTC+07:00).Tomsk_Standard_Time—The time zone will be Tomsk Standard Time (UTC+07:00).China_Standard_Time—The time zone will be China Standard Time (UTC+08:00).North_Asia_East_Standard_Time—The time zone will be North Asia East Standard Time (UTC+08:00).Singapore_Standard_Time—The time zone will be Singapore Standard Time (UTC+08:00).W._Australia_Standard_Time—The time zone will be W. Australia Standard Time (UTC+08:00).Taipei_Standard_Time—The time zone will be Taipei Standard Time (UTC+08:00).Ulaanbaatar_Standard_Time—The time zone will be Ulaanbaatar Standard Time (UTC+08:00).Aus_Central_W._Standard_Time—The time zone will be Aus Central W. Standard Time (UTC+08:45).Transbaikal_Standard_Time—The time zone will be Transbaikal Standard Time (UTC+09:00).Tokyo_Standard_Time—The time zone will be Tokyo Standard Time (UTC+09:00).North_Korea_Standard_Time—The time zone will be North Korea Standard Time (UTC+09:00).Korea_Standard_Time—The time zone will be Korea Standard Time (UTC+09:00).Yakutsk_Standard_Time—The time zone will be Yakutsk Standard Time (UTC+09:00).Cen._Australia_Standard_Time—The time zone will be Cen. Australia Standard Time (UTC+09:30).AUS_Central_Standard_Time—The time zone will be AUS Central Standard Time (UTC+09:30).E._Australia_Standard_Time—The time zone will be E. Australia Standard Time (UTC+10:00).AUS_Eastern_Standard_Time—The time zone will be AUS Eastern Standard Time (UTC+10:00).West_Pacific_Standard_Time—The time zone will be West Pacific Standard Time (UTC+10:00).Tasmania_Standard_Time—The time zone will be Tasmania Standard Time (UTC+10:00).Vladivostok_Standard_Time—The time zone will be Vladivostok Standard Time (UTC+10:00).Lord_Howe_Standard_Time—The time zone will be Lord Howe Standard Time (UTC+10:30).Bougainville_Standard_Time—The time zone will be Bougainville Standard Time (UTC+11:00).Russia_Time_Zone_10—The time zone will be Russia Time Zone 10 (UTC+11:00).Magadan_Standard_Time—The time zone will be Magadan Standard Time (UTC+11:00).Norfolk_Standard_Time—The time zone will be Norfolk Standard Time (UTC+11:00).Sakhalin_Standard_Time—The time zone will be Sakhalin Standard Time (UTC+11:00).Central_Pacific_Standard_Time—The time zone will be Central Pacific Standard Time (UTC+11:00).Russia_Time_Zone_11—The time zone will be Russia Time Zone 11 (UTC+11:00).New_Zealand_Standard_Time—The time zone will be New Zealand Standard Time (UTC+12:00).UTC+12—The time zone will be UTC+12 (UTC+12:00).Fiji_Standard_Time—The time zone will be Fiji Standard Time (UTC+12:00).Kamchatka_Standard_Time—The time zone will be Kamchatka Standard Time (UTC+12:00).Chatham_Islands_Standard_Time—The time zone will be Chatham Islands Standard Time (UTC+12:45).UTC+13—The time zone will be UTC+13 (UTC+13:00).Tonga_Standard_Time—The time zone will be Tonga Standard Time (UTC+13:00).Samoa_Standard_Time—The time zone will be Samoa Standard Time (UTC+13:00).Line_Islands_Standard_Time—The time zone will be Line Islands Standard Time (UTC+14:00). | String |
| adjust_DST(Optional) | Specifies whether the input time configuration will be adjusted for daylight saving time.This parameter is not applicable for analysis on the Moon.NOT_ADJUSTED_FOR_DST—The input time values will not be adjusted for daylight saving time. This is the default.ADJUSTED_FOR_DST—The input time values will be adjusted for daylight saving time. | Boolean |
| use_time_interval(Optional) | Specifies whether a single total insolation value will be calculated for the entire time configuration or multiple radiation values will be calculated for the specified interval.NO_INTERVAL—A single radiation value will be calculated for the entire time configuration. This is default.INTERVAL—Multiple radiation values will be calculated for each time interval over the entire time configuration. | Boolean |
| interval_unit(Optional) | Specifies the time unit that will be used for calculating solar radiation values over the entire time configuration.This parameter is only supported when the use_time_interval parameter is set to INTERVAL.MINUTE—The interval unit will be minutes. This option is only available for Earth-based data.HOUR—The interval unit will be hours.DAY—The interval unit will be days. This is the defaultWEEK—The interval unit will be weeks. | String |
| interval(Optional) | The value of the duration or time between intervals.The default value is dependent on the interval unit specified. The default value for each of the available units are listed below. MINUTE—60HOUR—4DAY—14 WEEK—2 | Long |
| feature_offset(Optional) | A vertical distance that will be added to the raster surface for analysis. It must be a positive integer or floating-point value.You can select a field from the input features dataset, or you can provide a numerical value.For example, if the object is a panel, provide the height of the panel.If a value is provided for this parameter, that value will be used by all features. To specify different values for each individual feature, select a field from the input features dataset.The default value is 0. | Double; Field |
| feature_area(Optional) | The area associated with the input features. It must be a positive integer or floating-point value.You can select a field from the input features dataset, or you can provide a numerical value.For example, if the object is a panel, provide the area of the panel.If a value is provided for this parameter, that value will be used by all features. To specify different values for each individual feature, select a field from the input features dataset.By default, the area is obtained from the input features. For point features, the default area is 0. | Double; Field |
| feature_slope(Optional) | The relative slope or incline associated with the input features. It must be a positive integer or floating-point value.You can select a field from the input features dataset, or you can provide a numerical value.For example, if the object is a panel, provide the incline of the panel.If a value is provided for this parameter, that value will be used by all features. To specify different values for each individual feature, select a field from the input features dataset.Slope is expressed in degrees from 0 to 90. The default values for analysis are calculated from the underlying values of the input surface raster. | Double; Field |
| feature_aspect(Optional) | The relative aspect or direction associated with the input features. It must be a positive integer or floating-point value.You can select a field from the input features dataset, or you can provide a numerical value.For example, if the object is a panel, provide the direction of the panel face.If a value is provided for this parameter, that value will be used by all features. To specify different values for each individual feature, select a field from the input features dataset.Aspect is expressed in degrees from 0 to 360. The default values for analysis area calculated from the underlying values of the input surface raster. | Double; Field |
| neighborhood_distance(Optional) | The distance from the target cell center for which the output insolation value will be calculated. It determines the size of the neighborhood.The default value is the input surface raster cell size, resulting in a 3 by 3 neighborhood. | Linear Unit |
| use_adaptive_neighborhood(Optional) | Specifies whether neighborhood distance will vary with landscape changes (adaptive). The maximum distance is determined by the neighborhood distance. The minimum distance is the input raster cell size. FIXED_NEIGHBORHOOD—A single (fixed) neighborhood distance will be used at all locations. This is the default.ADAPTIVE_NEIGHBORHOOD—An adaptive neighborhood distance will be used at all locations. | Boolean |
| diffuse_model_type(Optional) | Specifies the type of diffuse radiation model that will be used.UNIFORM_SKY—The uniform diffuse model will be used. The incoming diffuse radiation is the same from all sky directions. This is the default.STANDARD_OVERCAST_SKY—The standard overcast diffuse model will be used. The incoming diffuse radiation flux varies with the zenith angle. | String |
| diffuse_proportion(Optional) | The proportion of global normal radiation flux that is diffuse. Values range from 0 to 1.Set this value according to atmospheric conditions. The default value is 0.3 for generally clear sky conditions. | Double |
| transmittivity(Optional) | The fraction of radiation that passes through the atmosphere (averaged overall wavelengths). Values range from 0 (no transmission) to 1 (all transmission).The default is 0.5 for a generally clear sky. | Double |
| analysis_target_device(Optional) | Specifies the device that will be used to perform the calculation.GPU_THEN_CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU_ONLY—The calculation will only be performed on the CPU.GPU_ONLY—The calculation will only be performed on the GPU. | String |
| out_join_layer(Optional) | The output layer that will be created by joining the output table to the input feature class. This is an optional output. | Feature Layer |
| sunmap_grid_level(Optional) | The resolution that will be used to generate the H3 hexagonal grid cells used for internal calculations. A lower grid level value creates fewer, larger sun map areas and decreases tool run time. A higher grid level creates more smaller sun maps improving the accuracy of the result.Valid values of the sun map grid level for Earth range from 5 to 7. For the Moon, the valid value range is from 4 to 6.By default, the grid level is determined by the input surface raster. When analyzing surface data on Earth, if the analysis cell size is less than or equal to 4 meters, the default grid level is 6. If the analysis cell size is greater than 4 meters, the default grid level is 5. For analyzing surface data on the Moon, the default grid level is 6. | Long |

## Code Samples

### Example 1

```python
FeatureSolarRadiation(in_surface_raster, in_features, unique_id_field, out_table, start_date_time, end_date_time, {time_zone}, {adjust_DST}, {use_time_interval}, {interval_unit}, {interval}, {feature_offset}, {feature_area}, {feature_slope}, {feature_aspect}, {neighborhood_distance}, {use_adaptive_neighborhood}, {diffuse_model_type}, {diffuse_proportion}, {transmittivity}, {analysis_target_device}, {out_join_layer}, {sunmap_grid_level})
```

### Example 2

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "C:/sapyexamples/solardata.gdb"
env.scratchWorkspace = "C:/sapyexamples/outfile.gdb"
#Run FeatureSolarRadiation
arcpy.sa.FeatureSolarRadiation("dem30m.tif","solar_pnts","pntID","SolarPnts_radiation_092023",
                               "9/1/2023 06:30:00 AM","10/1/2023 6:30:00 PM","Pacific_Standard_Time")
```

### Example 3

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "C:/sapyexamples/solardata.gdb"
env.scratchWorkspace = "C:/sapyexamples/outfile.gdb"
#Run FeatureSolarRadiation
arcpy.sa.FeatureSolarRadiation("dem30m.tif","solar_pnts","pntID","SolarPnts_radiation_092023",
                               "9/1/2023 06:30:00 AM","10/1/2023 6:30:00 PM","Pacific_Standard_Time")
```

### Example 4

```python
# Name: FeatureSolarRadiation_standalone.py
# Description: Calculate the solar insolation for the whole year 2023 at one week 
#               intervals for engineered features represented by point features.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/solardata.gdb"
arcpy.env.scratchWorkspace = "C:/sapyexamples/outfile.gdb"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Run FeatureSolarRadiation
arcpy.sa.FeatureSolarRadiation(
    in_surface_raster="dem30m.tif",
    in_features="solar_pnts",
    unique_id_field="pntID",
    out_table=r"SolarPnts_radiation_092023",
    start_date_time="1/1/2023",
    end_date_time="12/31/2023",
    time_zone="Mountain_Standard_Time",
    adjust_DST="ADJUSTED_FOR_DST",
    use_time_interval="NO_INTERVAL",
    interval_unit="WEEK",
    interval=1,
    feature_offset=2.5,
    feature_area="Area_FLD",
    feature_slope="Slope_FLD",
    feature_aspect="Aspect_FLD",
    neighborhood_distance="",
    use_adaptive_neighborhood="",
    diffuse_model_type="UNIFORM_SKY",
    diffuse_proportion=0.3,
    transmittivity=0.5,
    analysis_target_device="GPU_THEN_CPU",
    out_join_layer=None
)
```

### Example 5

```python
# Name: FeatureSolarRadiation_standalone.py
# Description: Calculate the solar insolation for the whole year 2023 at one week 
#               intervals for engineered features represented by point features.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/solardata.gdb"
arcpy.env.scratchWorkspace = "C:/sapyexamples/outfile.gdb"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Run FeatureSolarRadiation
arcpy.sa.FeatureSolarRadiation(
    in_surface_raster="dem30m.tif",
    in_features="solar_pnts",
    unique_id_field="pntID",
    out_table=r"SolarPnts_radiation_092023",
    start_date_time="1/1/2023",
    end_date_time="12/31/2023",
    time_zone="Mountain_Standard_Time",
    adjust_DST="ADJUSTED_FOR_DST",
    use_time_interval="NO_INTERVAL",
    interval_unit="WEEK",
    interval=1,
    feature_offset=2.5,
    feature_area="Area_FLD",
    feature_slope="Slope_FLD",
    feature_aspect="Aspect_FLD",
    neighborhood_distance="",
    use_adaptive_neighborhood="",
    diffuse_model_type="UNIFORM_SKY",
    diffuse_proportion=0.3,
    transmittivity=0.5,
    analysis_target_device="GPU_THEN_CPU",
    out_join_layer=None
)
```

---

## Fill (Spatial Analyst)

## Summary

Fills sinks in a surface raster to remove small imperfections in the data.

## Usage

- A sink is a cell with an undefined drainage direction; no cells surrounding it are lower. The pour point is the boundary cell with the lowest elevation for the contributing area of a sink. If the sink were filled with water, this is the point where water would pour out.
- The z-limit specifies the maximum difference allowed between the depth of a sink and the pour point and determines which sinks will be filled and which will remain untouched. The z-limit is not the maximum depth to which a sink will be filled.For example, consider a sink area where the pour point is 210 feet in elevation, and the deepest point within the sink is 204 feet (a difference of 6 feet). If the z-limit is set to 8, this particular sink will be filled. However, if the z-limit is set to 4, this sink will not be filled since the depth of this sink exceeds this difference and would be considered a valid sink.
- All sinks that are less than the z-limit, and lower than their lowest adjacent neighbor, will be filled to the height of their pour points.
- Running the Fill tool can be memory, CPU, and disk intensive. It can require up to four times the disk space of the input raster.
- The number of sinks found with the z-limit will determine the length of processing time. The more sinks there are, the longer the processing time will be.
- The Sink tool can be used in advance of using the Fill tool to find the number of sinks and help identify their depth. Knowing the depth of the sinks can help in determining an appropriate z-limit.
- Fill can also be used to remove peaks. A peak is a cell where no adjacent cells are higher. To remove peaks, the input surface raster must be inverted. This can be performed with the Minus tool. Specify the highest value of the surface raster as the first input to Minus and surface raster as the second input. Perform a Fill. Invert the results to obtain a surface that has original surface raster values with the peaks removed. The z-limit can be applied to this process as well. If nothing is specified for z-limit, then all peaks will be removed. If it is specified, where the difference in z-value between a peak and its highest adjacent neighbor is greater than the z-limit, that peak will not be removed.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. The Parallel processing with Spatial Analyst help topic includes details about this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrator privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input surface raster | The input raster representing a continuous surface. | Raster Layer |
| Z limit(Optional) | Maximum elevation difference between a sink and its pour point to be filled.If the difference in z-values between a sink and its pour point is greater than the z_limit, that sink will not be filled.The value for z-limit must be greater than zero.Unless a value is specified for this parameter, all sinks will be filled, regardless of depth. | Double |
| in_surface_raster | The input raster representing a continuous surface. | Raster Layer |
| z_limit(Optional) | Maximum elevation difference between a sink and its pour point to be filled.If the difference in z-values between a sink and its pour point is greater than the z_limit, that sink will not be filled.The value for z-limit must be greater than zero.Unless a value is specified for this parameter, all sinks will be filled, regardless of depth. | Double |

## Code Samples

### Example 1

```python
Fill(in_surface_raster, {z_limit})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFill = Fill("elevation")
outFill.save("C:/sapyexamples/output/outfill01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFill = Fill("elevation")
outFill.save("C:/sapyexamples/output/outfill01")
```

### Example 4

```python
# Name: Fill_Ex_02.py
# Description: Fills sinks in a surface raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSurfaceRaster = "elevation"
zLimit = 3.28

# Execute FlowDirection
outFill = Fill(inSurfaceRaster, zLimit)

# Save the output 
outFill.save("C:/sapyexamples/output/outfill02")
```

### Example 5

```python
# Name: Fill_Ex_02.py
# Description: Fills sinks in a surface raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSurfaceRaster = "elevation"
zLimit = 3.28

# Execute FlowDirection
outFill = Fill(inSurfaceRaster, zLimit)

# Save the output 
outFill.save("C:/sapyexamples/output/outfill02")
```

---

## Filter (Spatial Analyst)

## Summary

Performs either a smoothing (Low pass) or edge-enhancing (High pass) filter on a raster.

## Usage

- The Low pass filter option (LOW in Python) is an averaging (smoothing) filter. The High pass filter option (HIGH in Python) is an edge-enhancement filter.
- Input NoData cells may receive a value in the output if the Ignore NoData in calculations option is checked (ignore_nodata set to NODATA in Python), provided at least one cell within the filter neighborhood has a valid value.
- You can use the Focal Statistics tool to create custom filters to your specification.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster on which to perform the filter operation. | Raster Layer |
| Filter type(Optional) | The type of filter operation to perform.Low pass—Traverses a low pass 3-by-3 filter over the raster. This option smooths the entire input raster and reduces the significance of anomalous cells. This is the default.High pass—Traverses a high pass 3-by-3 filter over the raster. This option enhances the edges of subdued features in a raster. | String |
| Ignore NoData in calculations(Optional) | Denotes whether NoData values are ignored by the filter calculation.Checked—If a NoData value exists within the filter, the NoData value will be ignored. Only cells within the filter that have data values will be used in determining the output. This is the default.Unchecked—If a NoData value exists within the filter, the output for the processing cell will be NoData. With this option, the presence of a NoData value implies that there is insufficient information to determine the statistic value for the neighborhood. | Boolean |
| in_raster | The input raster on which to perform the filter operation. | Raster Layer |
| filter_type(Optional) | The type of filter operation to perform.LOW—Traverses a low pass 3-by-3 filter over the raster. This option smooths the entire input raster and reduces the significance of anomalous cells. This is the default.HIGH—Traverses a high pass 3-by-3 filter over the raster. This option enhances the edges of subdued features in a raster. | String |
| ignore_nodata(Optional) | Denotes whether NoData values are ignored by the filter calculation.DATA—If a NoData value exists within the filter, the NoData value will be ignored. Only cells within the filter that have data values will be used in determining the output. This is the default.NODATA—If a NoData value exists within the filter, the output for the processing cell will be NoData. With this option, the presence of a NoData value implies that there is insufficient information to determine the statistic value for the neighborhood. | Boolean |

## Code Samples

### Example 1

```python
Filter(in_raster, {filter_type}, {ignore_nodata})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
filterOut =  Filter("elevation", "HIGH", "DATA") 
filterOut.save("C:/sapyexamples/output/filtered")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
filterOut =  Filter("elevation", "HIGH", "DATA") 
filterOut.save("C:/sapyexamples/output/filtered")
```

### Example 4

```python
# Name: Filter_Ex_02.py
# Description: Performs a preset focal filter on a raster. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation" 

# Execute Filter
filterOut =  Filter(inRaster, "LOW", "") 

# Save the output 
filterOut.save("C:/sapyexamples/output/filterout")
```

### Example 5

```python
# Name: Filter_Ex_02.py
# Description: Performs a preset focal filter on a raster. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation" 

# Execute Filter
filterOut =  Filter(inRaster, "LOW", "") 

# Save the output 
filterOut.save("C:/sapyexamples/output/filterout")
```

---

## Float (Spatial Analyst)

## Summary

Converts each cell value of a raster into a floating-point representation.

## Usage

- The input values can be positive or negative.
- If you execute Float on an input that is already floating point, the output values will remain the same as the input values.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input raster to be converted to floating point.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input raster to be converted to floating point.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Float(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFloat = Float("landuse")
outFloat.save("C:/sapyexamples/output/outfloat2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFloat = Float("landuse")
outFloat.save("C:/sapyexamples/output/outfloat2")
```

### Example 4

```python
# Name: Float_Ex_02.py
# Description: Converts each cell value of a raster into a floating-point representation
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "landuse"

# Execute Float
outFloat = Float(inRaster)

# Save the output 
outFloat.save("C:/sapyexamples/output/outfloat")
```

### Example 5

```python
# Name: Float_Ex_02.py
# Description: Converts each cell value of a raster into a floating-point representation
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "landuse"

# Execute Float
outFloat = Float(inRaster)

# Save the output 
outFloat.save("C:/sapyexamples/output/outfloat")
```

---

## Flow Accumulation (Spatial Analyst)

## Summary

Creates a raster of accumulated flow into each cell. A weight factor can optionally be applied.

## Usage

- The result of Flow Accumulation is a raster of accumulated flow to each cell, as determined by accumulating the weight for all cells that flow into each downslope cell.
- The Flow Accumulation tool supports three flow modeling algorithms while computing accumulated flow. These are D8, Multiple Flow Direction (MFD) and D-Infinity (DINF) flow methods.
- If the input flow direction raster is not created with the Flow Direction tool, there is a chance that the defined flow could loop. If the flow direction contains a loop, Flow Accumulation will go into an endless cycle and never finish.Input flow direction can be created using the D8, Multiple Flow Direction (MFD) or D-Infinity (DINF) methods. The type of input flow direction raster between these three influences how the Flow Accumulation tool partitions and accumulates flow in each cell. Use the Input flow direction type to specify which method was used when the flow direction raster was created.
- Cells of undefined flow direction will only receive flow; they will not contribute to any downstream flow.For an input D8 flow direction raster, a cell is considered to have an undefined flow direction if its value in the flow direction raster is anything other than 1, 2, 4, 8, 16, 32, 64, or 128.For an input D-Infinity flow direction raster, a cell is considered to have an undefined flow direction if its value in the flow direction raster is -1.
- The accumulated flow is based on the number of total or a fraction of cells flowing into each cell in the output raster. The current processing cell is not considered in this accumulation.
- Output cells with a high flow accumulation are areas of concentrated flow and can be used to identify stream channels.
- Output cells with a flow accumulation of zero are local topographic highs and can be used to identify ridges.
- The Flow Accumulation tool does not honour the Compression environment setting. The output raster will always be uncompressed.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. The Parallel processing with Spatial Analyst help topic includes details about this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrator privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input flow direction raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool. The flow direction raster can be created using the D8, Multiple Flow Direction (MFD), or D-Infinity method. Use the Input flow direction type parameter to specify the method used when the flow direction raster was created. | Raster Layer |
| Input weight raster(Optional) | An optional input raster for applying a weight to each cell.If no weight raster is specified, a default weight of 1 will be applied to each cell. For each cell in the output raster, the result will be the number of cells that flow into it. | Raster Layer |
| Output data type(Optional) | The output accumulation raster can be integer, floating point, or double type.Float—The output raster will be floating point type. This is the default.Integer—The output raster will be integer type.Double—The output raster will be double type. | String |
| Input flow direction type(Optional) | Specifies the input flow direction raster type.D8—The input flow direction raster is of type D8. This is the default.MFD—The input flow direction raster is of type Multi Flow Direction (MFD).DINF—The input flow direction raster is of type D-Infinity (DINF). | String |
| in_flow_direction_raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool. The flow direction raster can be created using the D8, Multiple Flow Direction (MFD), or D-Infinity method. Use the flow_direction_type parameter to specify the method used when the flow direction raster was created. | Raster Layer |
| in_weight_raster(Optional) | An optional input raster for applying a weight to each cell.If no weight raster is specified, a default weight of 1 will be applied to each cell. For each cell in the output raster, the result will be the number of cells that flow into it. | Raster Layer |
| data_type(Optional) | The output accumulation raster can be integer, floating point, or double type.FLOAT—The output raster will be floating point type. This is the default.INTEGER—The output raster will be integer type.DOUBLE—The output raster will be double type. | String |
| flow_direction_type(Optional) | Specifies the input flow direction raster type.D8—The input flow direction raster is of type D8. This is the default.MFD—The input flow direction raster is of type Multi Flow Direction (MFD).DINF—The input flow direction raster is of type D-Infinity (DINF). | String |

## Code Samples

### Example 1

```python
FlowAccumulation(in_flow_direction_raster, {in_weight_raster}, {data_type}, {flow_direction_type})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFlowAccumulation = FlowAccumulation("flowdir")
outFlowAccumulation.save("C:/sapyexamples/output/outflowacc01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFlowAccumulation = FlowAccumulation("flowdir")
outFlowAccumulation.save("C:/sapyexamples/output/outflowacc01")
```

### Example 4

```python
# Name: FlowAccumulation_Ex_02.py
# Description: Creates a raster of accumulated flow to each cell.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFlowDirRaster = "flowdir"
inWeightRaster = ""
dataType = "INTEGER"

# Execute FlowDirection
outFlowAccumulation = FlowAccumulation(inFlowDirRaster, inWeightRaster, dataType)

# Save the output 
outFlowAccumulation.save("C:/sapyexamples/output/outflowacc02.img")
```

### Example 5

```python
# Name: FlowAccumulation_Ex_02.py
# Description: Creates a raster of accumulated flow to each cell.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFlowDirRaster = "flowdir"
inWeightRaster = ""
dataType = "INTEGER"

# Execute FlowDirection
outFlowAccumulation = FlowAccumulation(inFlowDirRaster, inWeightRaster, dataType)

# Save the output 
outFlowAccumulation.save("C:/sapyexamples/output/outflowacc02.img")
```

---

## Flow Direction (Spatial Analyst)

## Summary

Creates a raster of flow direction from each cell to its downslope neighbor, or neighbors, using the D8, Multiple Flow Direction (MFD), or D-Infinity (DINF) method.

## Usage

- The Flow Direction tool supports three flow modeling algorithm: D8, Multiple Flow Direction (MFD), and D-Infinity (DINF).
- The D8 flow method models flow direction from each cell to its steepest downslope neighbor.The output of the Flow Direction tool using the D8 flow direction type is an integer raster whose values range from 1 to 255. The values for each direction from the center are the following:For example, if the direction of steepest drop is to the left of the current processing cell, its flow direction value is 16.If a cell is lower than its eight neighbors, that cell is given the value of its lowest neighbor, and flow is defined toward this cell. If multiple neighbors have the lowest value, the cell is still given this value, but flow is defined with one of the two methods described below. This is used to filter out one-cell sinks, which are considered noise.If a cell has the same change in z-value in multiple directions and that cell is part of a sink, the flow direction is referred to as undefined. In this case, the value for that cell in the output flow direction raster will be the sum of those directions. For example, if the change in z-value is the same both to the right (flow direction = 1) and down (flow direction = 4), the flow direction for that cell is 1 + 4 = 5. Cells with undefined flow direction can be flagged as sinks using the Sink tool.If a cell has the same change in z-value in multiple directions and is not part of a sink, the flow direction is assigned with a lookup table defining the most likely direction. See Greenlee (1987).The output D8 drop raster is calculated as the difference in z-value divided by the path length between the cell centers, expressed in percentages. For adjacent cells, this is analogous to the percent slope between cells. Across a flat area, the distance becomes the distance to the nearest cell of lower elevation. The result is a map of percent rise in the path of steepest descent from each cell.
- If a cell is lower than its eight neighbors, that cell is given the value of its lowest neighbor, and flow is defined toward this cell. If multiple neighbors have the lowest value, the cell is still given this value, but flow is defined with one of the two methods described below. This is used to filter out one-cell sinks, which are considered noise.
- If a cell has the same change in z-value in multiple directions and that cell is part of a sink, the flow direction is referred to as undefined. In this case, the value for that cell in the output flow direction raster will be the sum of those directions. For example, if the change in z-value is the same both to the right (flow direction = 1) and down (flow direction = 4), the flow direction for that cell is 1 + 4 = 5. Cells with undefined flow direction can be flagged as sinks using the Sink tool.
- If a cell has the same change in z-value in multiple directions and is not part of a sink, the flow direction is assigned with a lookup table defining the most likely direction. See Greenlee (1987).
- The output D8 drop raster is calculated as the difference in z-value divided by the path length between the cell centers, expressed in percentages. For adjacent cells, this is analogous to the percent slope between cells. Across a flat area, the distance becomes the distance to the nearest cell of lower elevation. The result is a map of percent rise in the path of steepest descent from each cell.
- The MFD algorithm, described by Qin et al. (2007), partitions flow from a cell to all downslope neighbors. A flow-partition exponent is created from an adaptive approach based on local terrain conditions and is used to determine fraction of flow draining to all downslope neighbors.Note:The MFD flow direction type only supports the creation of an output flow direction raster in Cloud Raster Format (CRF), such as flowdir1.crf, in a folder workspace.The MFD flow direction output when added to a map only displays the D8 flow directions. As MFD flow directions have potentially multiple values related to each cell (each value corresponds to the proportion of flow to each downslope neighbor), it is not easily visualized. However, an MFD flow direction output raster is an input recognized by the Flow Accumulation tool that will use the MFD flow directions to proportion and accumulate flow from each cell to all downslope neighbors.
- The DINF flow method, described by Tarboton (1997), determines flow direction as the steepest downward slope on eight triangular facets formed in a 3 by 3 cell window centered on the cell of interest. Flow direction output is a floating point raster represented as a single angle in degrees counterclockwise from 0 (due east) to 360 (again due east).
- With the Force all edge cells to flow outward parameter unchecked (force_flow = "NORMAL" in Python), the default setting, a cell at the edge of the surface raster will flow toward the inner cell with the steepest drop in z-value. If the drop is less than or equal to zero, the cell will flow out of the surface raster.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. The Parallel processing with Spatial Analyst help topic includes details about this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrator privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- References:Greenlee, D. D. 1987. "Raster and Vector Processing for Scanned Linework." Photogrammetric Engineering and Remote Sensing 53 (10): 1383–1387.Qin, C., Zhu, A. X., Pei, T., Li, B., Zhou, C., & Yang, L. 2007. "An adaptive approach to selecting a flow partition exponent for a multiple flow direction algorithm." International Journal of Geographical Information Science 21(4): 443-458.Tarboton, D. G. 1997. "A new method for the determination of flow directions and upslope areas in grid digital elevation models." Water Resources Research 33(2): 309-319.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input surface raster | The input raster representing a continuous surface. | Raster Layer |
| Force all edge cells to flow outward(Optional) | Specifies whether edge cells will always flow outward or follow normal flow rules.Unchecked—If the maximum drop on the inside of an edge cell is greater than zero, the flow direction will be determined as usual; otherwise, the flow direction will be toward the edge. Cells that should flow from the edge of the surface raster inward will do so. This is the default.Checked—All cells at the edge of the surface raster will flow outward from the surface raster. | Boolean |
| Output drop raster(Optional) | An optional output drop raster.The drop raster returns the ratio of the maximum change in elevation from each cell along the direction of flow to the path length between centers of cells, expressed in percentages.This output is of floating-point type. | Raster Dataset |
| Flow direction type(Optional) | Specifies the type of flow method that will be used when computing flow directions.D8—Flow direction will be determined by the D8 method. This method assigns flow direction to the steepest downslope neighbor. This is the default.MFD—Flow direction will be based on the MFD flow method. Flow direction will be partitioned across downslope neighbors according to an adaptive partition exponent.DINF—Flow direction will be based on the DINF flow method. This method assigns flow direction to the steepest slope of a triangular facet. | String |
| in_surface_raster | The input raster representing a continuous surface. | Raster Layer |
| force_flow(Optional) | Specifies whether edge cells will always flow outward or follow normal flow rules. NORMAL—If the maximum drop on the inside of an edge cell is greater than zero, the flow direction will be determined as usual; otherwise, the flow direction will be toward the edge. Cells that should flow from the edge of the surface raster inward will do so. This is the default.FORCE—All cells at the edge of the surface raster will flow outward from the surface raster. | Boolean |
| out_drop_raster(Optional) | An optional output drop raster.The drop raster returns the ratio of the maximum change in elevation from each cell along the direction of flow to the path length between centers of cells, expressed in percentages.This output is of floating-point type. | Raster Dataset |
| flow_direction_type(Optional) | Specifies the type of flow method that will be used when computing flow directions.D8—Flow direction will be determined by the D8 method. This method assigns flow direction to the steepest downslope neighbor. This is the default.MFD—Flow direction will be based on the MFD flow method. Flow direction will be partitioned across downslope neighbors according to an adaptive partition exponent.DINF—Flow direction will be based on the DINF flow method. This method assigns flow direction to the steepest slope of a triangular facet. | String |

## Code Samples

### Example 1

```python
FlowDirection(in_surface_raster, {force_flow}, {out_drop_raster}, {flow_direction_type})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFlowDirection = FlowDirection("elevation", "NORMAL")
outFlowDirection.save("C:/sapyexamples/output/outflowdir01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFlowDirection = FlowDirection("elevation", "NORMAL")
outFlowDirection.save("C:/sapyexamples/output/outflowdir01")
```

### Example 4

```python
# Name: FlowDirection_Example.py
# Description: Creates a raster of flow direction from each cell to its
#    steepest downslope neighbor.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSurfaceRaster = "elevation"
outDropRaster = "C:/sapyexamples/output/dropraster"

# Execute FlowDirection
outFlowDirection = FlowDirection(inSurfaceRaster, "FORCE", outDropRaster)

# Save the output 
outFlowDirection.save("C:/sapyexamples/output/outflowdir02")
```

### Example 5

```python
# Name: FlowDirection_Example.py
# Description: Creates a raster of flow direction from each cell to its
#    steepest downslope neighbor.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSurfaceRaster = "elevation"
outDropRaster = "C:/sapyexamples/output/dropraster"

# Execute FlowDirection
outFlowDirection = FlowDirection(inSurfaceRaster, "FORCE", outDropRaster)

# Save the output 
outFlowDirection.save("C:/sapyexamples/output/outflowdir02")
```

---

## Flow Distance (Spatial Analyst)

## Summary

Computes, for each cell, the horizontal or vertical component of downslope distance, following the flow paths, to cells on a stream into which they flow. In case of multiple flow paths, minimum, weighted mean, or maximum flow distance can be computed.

## Usage

- To limit downslope directions along which flow distance is measured, provide an optional input flow direction raster that can be derived using the Flow Direction tool. Choose from D8, D-Infinity (DINF) and multi flow direction (MFD) flow models while generating an optional input flow direction raster. Use the Input flow direction type to specify which method was used when the flow direction raster was created.
- If an optional input flow direction raster is provided, it is recommended that this raster be created using the Flow Direction tool using the same input surface raster that you'll provide to the Flow Distance tool.If this input surface raster is void of sinks, the distance measurements would be to stream cells represented by the input stream raster.If this input surface raster has sinks present, some flow paths can get terminated short by them flowing into sinks before reaching streams. In such cases, flow distance measurements for these cells are calculated only up to the sink cells into which they flow.
- When the tool is run without providing an optional flow direction raster, flow distance is assessed considering all possible downslope flow paths from each cell to cell(s) on the stream into which they flow.When the tool is run with an optional D8 flow direction raster, there is only one possible downslope flow path from every cell to a cell on the stream and flow distance is measured along this single flow path.
- When multiple flow paths exist from each cell to cells on the stream into which they flow, use the Statistics type to compute minimum, weighted mean, or maximum flow distance.If there is only a single flow path from each cell to a cell on the stream, all statistics types produce the same result.
- It is recommended to create the input stream raster using the same input surface raster that is provided as input to the tool. You can create stream rasters from an input surface raster using the Flow Direction, Flow Accumulation, and Con tools, respectively. If you want to use streams from other data sources, for best results, you would have to burn them into the input surface raster first and then run the Flow Distance tool on the result.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. The Parallel processing with Spatial Analyst help topic includes details about this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrator privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input stream raster | An input stream raster that represents a linear stream network. | Raster Layer |
| Input surface raster | The input raster representing a continuous surface. | Raster Layer |
| Input flow direction raster(Optional) | The input raster that shows the direction of flow out of each cell.When a flow direction raster is provided, the down slope direction(s) will be limited to those defined by the input flow directions.The flow direction raster can be created using the Flow Direction tool. The flow direction raster can be created using the D8, Multiple Flow Direction (MFD), or D-Infinity method. Use the Input flow direction type parameter to specify the method used when the flow direction raster was created. | Raster Layer |
| Distance type(Optional) | Determines if the vertical or horizontal component of flow distance is calculated.Vertical—The flow distance calculations represent the vertical component of flow distance, following the flow path, from each cell in the domain to cell(s) on the stream into which they flow. This is the default.Horizontal—The flow distance calculations represent the horizontal component of flow distance, following the flow path, from each cell in the domain to cell(s) on the stream into which they flow. | String |
| Input flow direction type(Optional) | Specifies the input flow direction raster type.D8—The input flow direction raster is of type D8. This is the default.MFD—The input flow direction raster is of type Multi Flow Direction (MFD).DINF—The input flow direction raster is of type D-Infinity (DINF). | String |
| Statistics type(Optional) | Determines the statistics type used to compute flow distance over multiple flow paths. If there is only a single flow path from each cell to a cell on the stream, all statistics types produce the same result.Minimum—Where multiple flow paths exist, minimum flow distance in computed. This is the default.Weighted Mean—Where multiple flow paths exist, a weighted mean of flow distance is computed. Flow proportion from a cell to its downstream neighboring cells are used as weights for computing weighted mean.Maximum—When multiple flow paths exist, maximum flow distance is computed. | String |
| in_stream_raster | An input stream raster that represents a linear stream network. | Raster Layer |
| in_surface_raster | The input raster representing a continuous surface. | Raster Layer |
| in_flow_direction_raster(Optional) | The input raster that shows the direction of flow out of each cell.When a flow direction raster is provided, the down slope direction(s) will be limited to those defined by the input flow directions.The flow direction raster can be created using the Flow Direction tool. The flow direction raster can be created using the D8, Multiple Flow Direction (MFD), or D-Infinity method. Use the flow_direction_type parameter to specify the method used when the flow direction raster was created. | Raster Layer |
| distance_type(Optional) | Determines if the vertical or horizontal component of flow distance is calculated.VERTICAL—The flow distance calculations represent the vertical component of flow distance, following the flow path, from each cell in the domain to cell(s) on the stream into which they flow. This is the default.HORIZONTAL—The flow distance calculations represent the horizontal component of flow distance, following the flow path, from each cell in the domain to cell(s) on the stream into which they flow. | String |
| flow_direction_type(Optional) | Specifies the input flow direction raster type.D8—The input flow direction raster is of type D8. This is the default.MFD—The input flow direction raster is of type Multi Flow Direction (MFD).DINF—The input flow direction raster is of type D-Infinity (DINF). | String |
| statistics_type(Optional) | Determines the statistics type used to compute flow distance over multiple flow paths. If there is only a single flow path from each cell to a cell on the stream, all statistics types produce the same result.MINIMUM—Where multiple flow paths exist, minimum flow distance in computed. This is the default.WEIGHTED_MEAN—Where multiple flow paths exist, a weighted mean of flow distance is computed. Flow proportion from a cell to its downstream neighboring cells are used as weights for computing weighted mean.MAXIMUM—When multiple flow paths exist, maximum flow distance is computed. | String |

## Code Samples

### Example 1

```python
FlowDistance(in_stream_raster, in_surface_raster, {in_flow_direction_raster}, {distance_type}, {flow_direction_type}, {statistics_type})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFlowDistance = FlowDistance("streams", "elevation", "", "VERTICAL")
outFlowDistance.save("C:/sapyexamples/output/outflowdist01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFlowDistance = FlowDistance("streams", "elevation", "", "VERTICAL")
outFlowDistance.save("C:/sapyexamples/output/outflowdist01")
```

### Example 4

```python
# Name: FlowDistance_Example.py
# Description: Creates a raster of horizontal flow distance from each cell to a cell 
# on the stream into which it drains.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inStreamRaster = "streams"
inSurfaceRaster = "elevation"
inFlowDirectionRaster = "flowdir"


# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute FlowDistance
outFlowDistance = FlowDistance(inStreamRaster, inSurfaceRaster, inFlowDirectionRaster, "HORIZONTAL")

# Save the output 
outFlowDistance.save("C:/sapyexamples/output/outflowdist02")
```

### Example 5

```python
# Name: FlowDistance_Example.py
# Description: Creates a raster of horizontal flow distance from each cell to a cell 
# on the stream into which it drains.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inStreamRaster = "streams"
inSurfaceRaster = "elevation"
inFlowDirectionRaster = "flowdir"


# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute FlowDistance
outFlowDistance = FlowDistance(inStreamRaster, inSurfaceRaster, inFlowDirectionRaster, "HORIZONTAL")

# Save the output 
outFlowDistance.save("C:/sapyexamples/output/outflowdist02")
```

---

## Flow Length (Spatial Analyst)

## Summary

Calculates the upstream or downstream distance, or weighted distance, along the flow path for each cell.

## Usage

- A primary use of the Flow Length tool is to calculate the length of the longest flow path within a given basin. This measure is often used to calculate the time of concentration of a basin. This would be done using the Upstream option.The tool can also be used to create distance-area diagrams of hypothetical rainfall and runoff events using the weight raster as an impedance to movement downslope.
- The value type for the Flow Length output raster is floating point.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input flow direction raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool. | Raster Layer |
| Direction of measurement(Optional) | The direction of measurement along the flow path.Downstream—Calculates the downslope distance along the flow path, from each cell to a sink or outlet on the edge of the raster.Upstream—Calculates the longest upslope distance along the flow path, from each cell to the top of the drainage divide. | String |
| Input weight raster(Optional) | An optional input raster for applying a weight to each cell.If no weight raster is specified, a default weight of 1 will be applied to each cell. For each cell in the output raster, the result will be the number of cells that flow into it. | Raster Layer |
| in_flow_direction_raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool. | Raster Layer |
| direction_measurement(Optional) | The direction of measurement along the flow path.DOWNSTREAM—Calculates the downslope distance along the flow path, from each cell to a sink or outlet on the edge of the raster.UPSTREAM—Calculates the longest upslope distance along the flow path, from each cell to the top of the drainage divide. | String |
| in_weight_raster(Optional) | An optional input raster for applying a weight to each cell.If no weight raster is specified, a default weight of 1 will be applied to each cell. For each cell in the output raster, the result will be the number of cells that flow into it. | Raster Layer |

## Code Samples

### Example 1

```python
FlowLength(in_flow_direction_raster, {direction_measurement}, {in_weight_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFlowLength = FlowLength("flowdir", "DOWNSTREAM", "")
outFlowLength.save("c:/sapyexamples/output/outflowlen01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFlowLength = FlowLength("flowdir", "DOWNSTREAM", "")
outFlowLength.save("c:/sapyexamples/output/outflowlen01")
```

### Example 4

```python
# Name: _Ex_02.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFlowDirectionRaster = "flowdir"
inWeightRaster = ""
directionType = "DOWNSTREAM"

# Execute 
outFlowLength = FlowLength(inFlowDirectionRaster, directionType, inWeightRaster)

# Save the output 
outFlowLength.save("c:/sapyexamples/output/outflowlen02.tif")
```

### Example 5

```python
# Name: _Ex_02.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFlowDirectionRaster = "flowdir"
inWeightRaster = ""
directionType = "DOWNSTREAM"

# Execute 
outFlowLength = FlowLength(inFlowDirectionRaster, directionType, inWeightRaster)

# Save the output 
outFlowLength.save("c:/sapyexamples/output/outflowlen02.tif")
```

---

## Focal Flow (Spatial Analyst)

## Summary

Determines the flow of the values in the input raster within each cell's immediate neighborhood.

## Usage

- Focal Flow evaluates the eight immediate neighbors of a cell to determine the flow.
- The resulting values from the tool measure flow into, not out of, a cell.
- The output values are derived from the binary representation of the results of the analysis.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input surface raster | The input surface raster for which to calculate the focal flow.The eight immediate neighbors of each cell are evaluated to determine the flow.The input raster can be integer or floating-point. | Raster Layer |
| Threshold value(Optional) | Defines a value that constitutes the threshold, which must be equaled or exceeded before flow can occur.The threshold value can be either an integer or floating-point value.If the difference between the value at a neighboring cell location and the value of the processing cell is less than or equal to the threshold value, the output will be 0 (or no flow). | Double |
| in_surface_raster | The input surface raster for which to calculate the focal flow.The eight immediate neighbors of each cell are evaluated to determine the flow.The input raster can be integer or floating-point. | Raster Layer |
| threshold_value(Optional) | Defines a value that constitutes the threshold, which must be equaled or exceeded before flow can occur.The threshold value can be either an integer or floating-point value.If the difference between the value at a neighboring cell location and the value of the processing cell is less than or equal to the threshold value, the output will be 0 (or no flow). | Double |

## Code Samples

### Example 1

```python
FocalFlow(in_surface_raster, {threshold_value})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
focalFlowOut = FocalFlow("elevation", 10)
focalFlowOut.save("C:/sapyexamples/output/flowout")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
focalFlowOut = FocalFlow("elevation", 10)
focalFlowOut.save("C:/sapyexamples/output/flowout")
```

### Example 4

```python
# Name: FocalFlow_Ex_02.py
# Description: Determines the flow of the values in the 
#    input raster within each cell's immediate neighborhood.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
threshold = 5 

# Execute FocalFlow
outFocalFlow = FocalFlow(inRaster, threshold)

# Save the output 
outFocalFlow.save("C:/sapyexamples/output/focalflow")
```

### Example 5

```python
# Name: FocalFlow_Ex_02.py
# Description: Determines the flow of the values in the 
#    input raster within each cell's immediate neighborhood.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
threshold = 5 

# Execute FocalFlow
outFocalFlow = FocalFlow(inRaster, threshold)

# Save the output 
outFocalFlow.save("C:/sapyexamples/output/focalflow")
```

---

## Focal Statistics (Spatial Analyst)

## Summary

Calculates for each input cell location a statistic of the values within a specified neighborhood around it.

## Usage

- There are several neighborhood shapes and statistics types to choose from. The available statistics depend on the type of the input raster.
- The available neighborhood shapes are annulus (a donut or ring), circle, rectangle, and wedge. A custom neighborhood shape can be defined using a kernel file.
- When a circular, an annulus-shaped, or a wedge-shaped neighborhood is specified, some of the outer diagonal cells may not be considered in the calculations because the center of the cell must be encompassed within the neighborhood.
- The irregular and weight Neighborhood types require that a Kernel file value be specified. A kernel file is an ASCII text file that specifies the values and shape of the neighborhood. The file can be created with any plain text editor. The file must have a .txt extension and no spaces in the file name.See the Irregular and Weight sections of How Focal Statistics works for information about creating and using kernel files.
- For integer input rasters, the valid statistics for Statistics type are majority, maximum, mean, median, minimum, minority, percentile, range, standard deviation, sum, and variety. For float input rasters, the valid statistics are maximum, mean, median, minimum, percentile, range, standard deviation, and sum. Majority, minority, and variety are not available for float input rasters.
- If the input raster is integer, the output raster will be integer for the majority, maximum, minimum, minority, range, sum, and variety statistic types. The output will be float for the mean, median, percentile, and standard deviation statistic types. If the input raster is of float type, the output will be float for all of the available statistic types.
- For median calculations, if the neighborhood has an odd number of cells, the values will be ranked and the middle value will be reported as the median. If the neighborhood has an even number of cells, the values will be ranked and the middle two values will be averaged.
- For majority and minority calculations, see the How Focal Statistics works topic for more information when there is a tie.
- The Neighborhood parameter can be set to Weight only for the Mean, Standard deviation, and Sum statistic types.
- Input NoData cells may receive a value in the output if the Ignore NoData in calculations parameter is checked, provided at least one cell within the neighborhood has a valid value.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The raster for which the focal statistics for each input cell will be calculated. | Raster Layer |
| Neighborhood(Optional) | The cells surrounding a processing cell that will be used in the statistic calculation. There are several predefined neighborhood types to choose from, or a custom kernel can be defined.Once the neighborhood type is selected, other parameters can be set to fully define the shape, size, and units of measure. The default neighborhood is a square rectangle with a width and height of three cells.The following are the forms of the available neighborhood types:Annulus, Inner radius, Outer radius, Units type A ring or donut-shaped neighborhood defined by an inner radius and an outer radius. The minimum value for radius is 1 cell, and the outer radius must be larger than the inner. The maximum inner radius is 2046 cells, and the maximum outer radius is 2047 cells. The default annulus is an inner radius of 1 cell and an outer radius of 3 cells.Circle, Radius, Units type A circular neighborhood with the given radius. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The default radius is 3 cells.Rectangle, Height, Width, Units type A rectangular neighborhood defined by width and height. The minimum value for width or height is 1 cell, and the maximum value is 4096 cells. The default is a square with a width and height of 3 cells.Wedge, Radius, Start angle, End angle, Units type A wedge-shaped neighborhood defined by a radius, a start angle, and an end angle. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The wedge extends counterclockwise from the starting angle to the ending angle. Angles are specified in degrees, with 0 or 360 representing east. Negative angles can be used. The default wedge is from 0 to 90 degrees, with a radius of 3 cells.Irregular, Kernel file A custom neighborhood with specifications set by the identified kernel text file, which can apply weights to the members of the neighborhood. The minimum value for width or height of the kernel is 1 cell, and the maximum value is 4096 cells.Weight, Kernel file A custom neighborhood with specifications set by the identified kernel text file, which can apply weights to the members of the neighborhood. The minimum value for width or height of the kernel is 1 cell, and the maximum value is 4096 cells.For the annulus, circle, rectangle and wedge neighborhood types, the distance units for the parameters can be specified in Cell units or Map units. Cell units is the default.For kernel neighborhoods, the first line in the kernel file defines the width and height of the neighborhood in numbers of cells. The subsequent lines indicate how the input value that corresponds to that location in the kernel will be processed. A value of 0 in the kernel file for either the irregular or the weight neighborhood type indicates the corresponding location will not be included in the calculation. For the irregular neighborhood, a value of 1 in the kernel file indicates that the corresponding input cell will be included in the operation. For the weight neighborhood, the value at each position indicates what the corresponding input cell value is to be multiplied by. Positive, negative, and decimal values can be used. | Neighborhood |
| Statistics type(Optional) | Specifies the statistic type to be calculated.The default statistic type is Mean.If the input raster is integer, all the statistics types will be available. If the input raster is floating point, only the Mean, Maximum, Median, Minimum, Percentile, Range, Standard deviation, and Sum statistic types will be available.Mean—The mean (average value) of the cells in the neighborhood will be calculated.Majority—The majority (value that occurs most often) of the cells in the neighborhood will be identified.Maximum—The maximum (largest value) of the cells in the neighborhood will be identified.Median—The median of the cells in the neighborhood will be calculated. Median is equivalent to the 50th percentile.Minimum—The minimum (smallest value) of the cells in the neighborhood will be identified.Minority—The minority (value that occurs least often) of the cells in the neighborhood will be identified.Percentile—A percentile of the cells in the neighborhood will be calculated. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the Percentile value parameter.Range—The range (difference between largest and smallest value) of the cells in the neighborhood will be calculated.Standard deviation—The standard deviation of the cells in the neighborhood will be calculated.Sum—The sum of the cells in the neighborhood will be calculated.Variety—The variety (the number of unique values) of the cells in the neighborhood will be calculated. | String |
| Ignore NoData in calculations(Optional) | Specifies whether NoData values will be ignored by the statistic calculation.Checked—If a NoData value exists within a neighborhood, the NoData value will be ignored. Only cells within the neighborhood that have data values will be used in determining the output value. If the processing cell itself is NoData, the processing cell may receive a value in the output raster, provided at least one cell within the neighborhood has a valid value. This is the default.Unchecked—If any cell in a neighborhood has a value of NoData, including the processing cell, the output for the processing cell will be NoData. The presence of a NoData value implies that there is insufficient information to determine the statistic value for the neighborhood. | Boolean |
| Percentile value(Optional) | The percentile value that will be calculated. The default is 90, for the 90th percentile.The value can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to the maximum statistic. A value of 50 will produce essentially the same result as the median statistic.This option is only supported if the Statistics type parameter is set to Percentile. If any other statistic type is specified, this parameter will be ignored. | Double |
| in_raster | The raster for which the focal statistics for each input cell will be calculated. | Raster Layer |
| neighborhood(Optional) | The cells surrounding a processing cell that will be used in the statistic calculation. There are several predefined neighborhood types to choose from, or a custom kernel can be defined.Once the neighborhood type is selected, other parameters can be set to fully define the shape, size, and units of measure. The default neighborhood is a square rectangle with a width and height of three cells.The shape of the neighborhoods are defined by the Neighborhood class. The available neighborhood types are NbrAnnulus, NbrCircle, NbrRectangle, NbrWedge, NbrIrregular, and NbrWeight.The following are the forms of the available neighborhood types:NbrAnnulus({innerRadius}, {outerRadius}, {units})A ring or donut-shaped neighborhood defined by an inner radius and an outer radius. The minimum value for radius is 1 cell, and the outer radius must be larger than the inner. The maximum inner radius is 2046 cells, and the maximum outer radius is 2047 cells. The default annulus is an inner radius of 1 cell and an outer radius of 3 cells.NbrCircle({radius}, {units}A circular neighborhood with the given radius. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The default radius is 3 cells.NbrRectangle({width}, {height}, {units})A rectangular neighborhood defined by width and height. The minimum value for width or height is 1 cell, and the maximum value is 4096 cells. The default is a square with a width and height of 3 cells.NbrWedge({radius}, {startAngle}, {endAngle}, {units})A wedge-shaped neighborhood defined by a radius, a start angle, and an end angle. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The wedge extends counterclockwise from the starting angle to the ending angle. Angles are specified in degrees, with 0 or 360 representing east. Negative angles can be used. The default wedge is from 0 to 90 degrees, with a radius of 3 cells.NbrIrregular(inKernelFile)A custom neighborhood with specifications set by the identified kernel text file. The minimum value for width or height of the kernel is 1 cell, and the maximum value is 4096 cells.NbrWeight(inKernelFile)A custom neighborhood with specifications set by the identified kernel text file, which can apply weights to the members of the neighborhood. The minimum value for width or height of the kernel is 1 cell, and the maximum value is 4096 cells.For the NbrAnnulus, Nbrcircle, NbrRectangle and NbrWedge neighborhoods, the distance units for the parameters can be specified in CELL units or MAP units. Cell units is the default.For kernel neighborhoods, the first line in the kernel file defines the width and height of the neighborhood in numbers of cells. The subsequent lines indicate how the input value that corresponds to that location in the kernel will be processed. A value of 0 in the kernel file for either the irregular or the weight neighborhood type indicates the corresponding location will not be included in the calculation. For the irregular neighborhood, a value of 1 in the kernel file indicates that the corresponding input cell will be included in the operation. For the weight neighborhood, the value at each position indicates what the corresponding input cell value is to be multiplied by. Positive, negative, and decimal values can be used. | Neighborhood |
| statistics_type(Optional) | Specifies the statistic type to be calculated.MEAN—The mean (average value) of the cells in the neighborhood will be calculated.MAJORITY—The majority (value that occurs most often) of the cells in the neighborhood will be identified.MAXIMUM—The maximum (largest value) of the cells in the neighborhood will be identified.MEDIAN—The median of the cells in the neighborhood will be calculated. Median is equivalent to the 50th percentile.MINIMUM—The minimum (smallest value) of the cells in the neighborhood will be identified.MINORITY—The minority (value that occurs least often) of the cells in the neighborhood will be identified.PERCENTILE—A percentile of the cells in the neighborhood will be calculated. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the percentile_value parameter.RANGE—The range (difference between largest and smallest value) of the cells in the neighborhood will be calculated.STD—The standard deviation of the cells in the neighborhood will be calculated.SUM—The sum of the cells in the neighborhood will be calculated.VARIETY—The variety (the number of unique values) of the cells in the neighborhood will be calculated.The default statistic type is MEAN.If the input raster is integer, all the statistics types will be available. If the input raster is floating point, only the MEAN, MAXIMUM, MEDIAN, MINIMUM, PERCENTILE, RANGE, STD, and SUM statistic types will be available. | String |
| ignore_nodata(Optional) | Specifies whether NoData values will be ignored by the statistic calculation.DATA—If a NoData value exists within a neighborhood, the NoData value will be ignored. Only cells within the neighborhood that have data values will be used in determining the output value. If the processing cell itself is NoData, the processing cell may receive a value in the output raster, provided at least one cell within the neighborhood has a valid value. This is the default.NODATA—If any cell in a neighborhood has a value of NoData, including the processing cell, the output for the processing cell will be NoData. The presence of a NoData value implies that there is insufficient information to determine the statistic value for the neighborhood. | Boolean |
| percentile_value(Optional) | The percentile value that will be calculated. The default is 90, for the 90th percentile.The value can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to the maximum statistic. A value of 50 will produce essentially the same result as the median statistic.This option is only supported if the statistics_type parameter is set to PERCENTILE. If any other statistic type is specified, this parameter will be ignored. | Double |

## Code Samples

### Example 1

```python
FocalStatistics(in_raster, {neighborhood}, {statistics_type}, {ignore_nodata}, {percentile_value})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFocalStat = FocalStatistics("elevation", NbrAnnulus(5, 10, "CELL"), 
                               "MINORITY", "NODATA")
outFocalStat.save("C:/sapyexamples/output/focalstat01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outFocalStat = FocalStatistics("elevation", NbrAnnulus(5, 10, "CELL"), 
                               "MINORITY", "NODATA")
outFocalStat.save("C:/sapyexamples/output/focalstat01")
```

### Example 4

```python
# Name: FocalStatistics_Ex_02.py
# Description: Calculates a statistic on a raster over a specified
#    neighborhood.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
neighborhood = NbrRectangle(10, 10, "CELL")

# Execute FocalStatistics
outFocalStatistics = FocalStatistics(inRaster, neighborhood, "MINORITY",
                                     "")

# Save the output 
outFocalStatistics.save("C:/sapyexamples/output/focalstatout")
```

### Example 5

```python
# Name: FocalStatistics_Ex_02.py
# Description: Calculates a statistic on a raster over a specified
#    neighborhood.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
neighborhood = NbrRectangle(10, 10, "CELL")

# Execute FocalStatistics
outFocalStatistics = FocalStatistics(inRaster, neighborhood, "MINORITY",
                                     "")

# Save the output 
outFocalStatistics.save("C:/sapyexamples/output/focalstatout")
```

---

## Formulas for the transformation functions

## Code Samples

### Example 1

```python
ScaledY = fromScale + (Y - min(Y)) * r
```

### Example 2

```python
ScaledY = fromScale + (Y - min(Y)) * r
```

### Example 3

```python
Exp((In – inShift) * baseFactor)
```

### Example 4

```python
Exp((In – inShift) * baseFactor)
```

### Example 5

```python
inShift = Con(toScale > fromScale, A, B)
```

### Example 6

```python
inShift = Con(toScale > fromScale, A, B)
```

### Example 7

```python
baseFactor = Con(toScale > fromScale, C, D)
```

### Example 8

```python
baseFactor = Con(toScale > fromScale, C, D)
```

### Example 9

```python
Exp(-Spread * Square(In - MidPoint))
```

### Example 10

```python
Exp(-Spread * Square(In - MidPoint))
```

### Example 11

```python
Spread = Ln(10) * 4 / Pow(MidPoint - minIn, 2)
```

### Example 12

```python
Spread = Ln(10) * 4 / Pow(MidPoint - minIn, 2)
```

### Example 13

```python
MidPoint = (maxIn + minIn) / 2
```

### Example 14

```python
MidPoint = (maxIn + minIn) / 2
```

### Example 15

```python
1.0 / (1.0 + Pow(In / MidPoint, - Spread))
```

### Example 16

```python
1.0 / (1.0 + Pow(In / MidPoint, - Spread))
```

### Example 17

```python
MidPoint = (maxIn + minIn) / 2
```

### Example 18

```python
MidPoint = (maxIn + minIn) / 2
```

### Example 19

```python
Con(In < Min, 0, Con(In > Max, 1, (In - Min) / Diff))
```

### Example 20

```python
Con(In < Min, 0, Con(In > Max, 1, (In - Min) / Diff))
```

### Example 21

```python
Con(In > Min, 0, Con(In < Max, 1, (In - Min) / Diff))
```

### Example 22

```python
Con(In > Min, 0, Con(In < Max, 1, (In - Min) / Diff))
```

### Example 23

```python
Min = minIn
```

### Example 24

```python
Min = minIn
```

### Example 25

```python
Max = maxIn
```

### Example 26

```python
Max = maxIn
```

### Example 27

```python
Ln((In – inShift) * baseFactor)
```

### Example 28

```python
Ln((In – inShift) * baseFactor)
```

### Example 29

```python
inShift = Con(toScale > fromScale, A, B)
```

### Example 30

```python
inShift = Con(toScale > fromScale, A, B)
```

### Example 31

```python
baseFactor = Con(toScale > fromScale, C, D)
```

### Example 32

```python
baseFactor = Con(toScale > fromScale, C, D)
```

### Example 33

```python
C / (1 + A * Exp((In – Min) * B))
```

### Example 34

```python
C / (1 + A * Exp((In – Min) * B))
```

### Example 35

```python
C / (1 + A * Exp( - (In – Min) * B))
```

### Example 36

```python
C / (1 + A * Exp( - (In – Min) * B))
```

### Example 37

```python
A = C / yInterceptPercent - 1
```

### Example 38

```python
A = C / yInterceptPercent - 1
```

### Example 39

```python
B = Ln(A) / (0.5 * (Max + Min) - Min)
```

### Example 40

```python
B = Ln(A) / (0.5 * (Max + Min) - Min)
```

### Example 41

```python
Con(In > nMeans, 1 - (nStdv / (In - nMeans + nStdv)), 0)
```

### Example 42

```python
Con(In > nMeans, 1 - (nStdv / (In - nMeans + nStdv)), 0)
```

### Example 43

```python
Con(In > nMeans, nStdv / (In - nMeans + nStdv), 1)
```

### Example 44

```python
Con(In > nMeans, nStdv / (In - nMeans + nStdv), 1)
```

### Example 45

```python
1.0 / (1.0 + Spread * Pow(In - MidPoint, 2))
```

### Example 46

```python
1.0 / (1.0 + Spread * Pow(In - MidPoint, 2))
```

### Example 47

```python
Spread = 36 / Pow(MidPoint - minIn, 2)
```

### Example 48

```python
Spread = 36 / Pow(MidPoint - minIn, 2)
```

### Example 49

```python
MidPoint = (maxIn + minIn) / 2
```

### Example 50

```python
MidPoint = (maxIn + minIn) / 2
```

### Example 51

```python
Pow(In – inShift, Exponent)
```

### Example 52

```python
Pow(In – inShift, Exponent)
```

### Example 53

```python
inShift = Con(toScale > fromScale, A, B)
```

### Example 54

```python
inShift = Con(toScale > fromScale, A, B)
```

### Example 55

```python
Exponent = Con(toScale > fromScale, C, D)
```

### Example 56

```python
Exponent = Con(toScale > fromScale, C, D)
```

### Example 57

```python
1.0 / (1.0 + Pow(In / MidPoint, Spread))
```

### Example 58

```python
1.0 / (1.0 + Pow(In / MidPoint, Spread))
```

### Example 59

```python
MidPoint = (maxIn + minIn) / 2
```

### Example 60

```python
MidPoint = (maxIn + minIn) / 2
```

### Example 61

```python
Con(In < Min , 0, Con(In < MidP, (In - Min) / HDiff, Con(In > Max, 0, (Max - In) / HDiff)))
```

### Example 62

```python
Con(In < Min , 0, Con(In < MidP, (In - Min) / HDiff, Con(In > Max, 0, (Max - In) / HDiff)))
```

### Example 63

```python
Con(In < Max, 1, Con(In < MidP, (In - MidP) / HDiff, Con(In > Min, 1, (MidP - In) / HDiff)))
```

### Example 64

```python
Con(In < Max, 1, Con(In < MidP, (In - MidP) / HDiff, Con(In > Min, 1, (MidP - In) / HDiff)))
```

### Example 65

```python
Min = minIn
```

### Example 66

```python
Min = minIn
```

### Example 67

```python
Max = maxIn
```

### Example 68

```python
Max = maxIn
```

---

## Fuzzy Membership (Spatial Analyst)

## Summary

Transforms the input raster into a 0 to 1 scale, indicating the strength of a membership in a set, based on a specified fuzzification algorithm.

## Usage

- This tool does not scale categorical data. To include categorical data into fuzzy overlay analysis, a preprocessing step is necessary. You can create a model or run the following geoprocessing tools. First, use the Reclassify tool to provide a new range of values (for example, 1 to 100). Then Divide the result by a factor (for example, by 100) to normalize the output values to be between 0.0 and 1.0.
- Spread determines how rapidly the fuzzy membership values decrease from 1 to 0. The larger the value, the steeper the fuzzification around the midpoint. Said another way, as the spread gets smaller, the fuzzy memberships approach 0 more slowly. The selection of the appropriate spread value is a subjective process that is dependent on the range of the crisp values. For Gaussian and Near, the default value of 0.1 is a good starting point. Typically, the values vary within the ranges of [0.01–1] or [0.001-1], respectively. For Small and Large, the default value of 5 is a good starting point where, typically, the values vary between 1 and 10.Affect of spread on a Gaussian fuzzy membership.
- You may have a case where none of the input values have a 100 percent possibility of being a member of the specified set. In other words, no input value has a fuzzy membership of 1. In this situation, you may want to rescale the fuzzy membership values to reflect the new scale. For example, if the highest membership for the input values is .75, you can establish the new scale by multiplying each of the fuzzy membership values by 0.75.
- The hedges implemented are Very and Somewhat. Very is also known as concentration and is defined as the fuzzy membership function squared. Somewhat is known as dilation, or More or Less, and is the square root of the fuzzification membership function. The Very and Somewhat hedges decrease and increase, respectively, the fuzzy membership functions.
- Negative values are not accepted in the Small and Large membership functions.
- For the Linear membership function, the input raster must be ordered data. The minimum can be less than the maximum to create a positive slope or greater than the maximum to create a negative slope for the transformation.If the minimum is less than the maximum, a positive-sloped function is used for the transformation; if the minimum is less than the maximum, a negative-sloped function is used.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster whose values will be scaled from 0 to 1.It can be an integer or a floating-point raster. | Raster Layer |
| Membership type(Optional) | Specifies the algorithm used in fuzzification of the input raster.Certain settings for Membership type employ a Spread parameter to determine how rapidly the fuzzy membership values decrease from 1 to 0. The default values for the spread are detailed in the table below.Gaussian—Assigns a membership value of 1 at the midpoint.The membership decreases to 0 for values that deviate from the midpoint according to a normal curve. Gaussian is similar to the Near function but has a more narrow spread. Midpoint — Default is the midpoint of the range of values of the input raster.Spread — Default is 0.1. Typically, the values vary between [0.01–1].Small—Used to indicate that small values of the input raster have high membership in the fuzzy set.Assigns a membership value of 0.5 at the midpoint. Midpoint — Default is the midpoint of the range of values of the input raster.Spread — Default is 5.Large—Used to indicate that large values of the input raster have high membership in the fuzzy set.Assigns a membership value of 0.5 at the midpoint. Midpoint — Default is the midpoint of the range of values of the input raster.Spread — Default is 5.Near—Calculates memberships for values near some intermediate value.Assigns a membership value of 1 at the midpoint. The membership decreases to 0 for values that deviate from the midpoint. Midpoint — Default is the midpoint of the range of values of the input raster.Spread — Default is 0.1. Typically, the values vary within the range of [0.001–1].MSLarge—Calculates membership based on the mean and standard deviation of the input data where large values have high membership.The result can be similar to the Large function, depending on how the multipliers of the mean and standard deviation are defined. Mean multiplier — Default is 1.Standard deviation multiplier — Default is 2.MSSmall—Calculates membership based on the mean and standard deviation of the input data where small values have high membership. This is the default membership type.The result can be similar to the Small function, depending on how the multipliers of the mean and standard deviation are defined. Mean multiplier — Default is 1. Standard deviation multiplier — Default is 2. Linear—Calculates membership based on the linear transformation of the input raster.Assigns a membership value of 0 at the minimum and a membership of 1 at the maximum. Minimum — Default is 1.Maximum — Default is 2. | Fuzzy function |
| Hedge(Optional) | Defining a hedge increases or decreases the fuzzy membership values which modify the meaning of a fuzzy set. Hedges are useful to help in controlling the criteria or important attributes.None—No hedge is applied. This is the default.Somewhat—Known as dilation, defined as the square root of the fuzzy membership function. This hedge increases the fuzzy membership functions.Very—Also known as concentration, defined as the fuzzy membership function squared. This hedge decreases the fuzzy membership functions. | String |
| in_raster | The input raster whose values will be scaled from 0 to 1.It can be an integer or a floating-point raster. | Raster Layer |
| fuzzy_function(Optional) | Specifies the algorithm used in fuzzification of the input raster.The fuzzy classes are used to specify the type of membership.The types of membership classes are: FuzzyGaussian, FuzzyLarge, FuzzyLinear, FuzzyMSLarge, FuzzyMSSmall, FuzzyNear, and FuzzySmall.The following are the forms of the membership classes: FuzzyGaussian({midpoint},{spread}) FuzzyLarge({midpoint},{spread}) FuzzyLinear({minimum},{maximum}) FuzzyMSLarge({meanMultiplier},{STDMultiplier}) FuzzyMSSmall({meanMultiplier},{STDMultiplier}) FuzzyNear({midpoint},{spread}) FuzzySmall({midpoint},{spread}) | Fuzzy function |
| hedge(Optional) | Defining a hedge increases or decreases the fuzzy membership values which modify the meaning of a fuzzy set. Hedges are useful to help in controlling the criteria or important attributes.NONE—No hedge is applied. This is the default.SOMEWHAT—Known as dilation, defined as the square root of the fuzzy membership function. This hedge increases the fuzzy membership functions.VERY—Also known as concentration, defined as the fuzzy membership function squared. This hedge decreases the fuzzy membership functions. | String |

## Code Samples

### Example 1

```python
FuzzyMembership(in_raster, {fuzzy_function}, {hedge})
```

### Example 2

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "c:/sapyexamples/data"
outFzyMember = FuzzyMembership("elevation", FuzzyGaussian(1200, 0.06))
outFzyMember.save("c:/sapyexamples/fzymemb")
```

### Example 3

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "c:/sapyexamples/data"
outFzyMember = FuzzyMembership("elevation", FuzzyGaussian(1200, 0.06))
outFzyMember.save("c:/sapyexamples/fzymemb")
```

### Example 4

```python
# Name: FuzzyMembership_Ex_02.py
# Description: Scales input raster data into values ranging from zero to one
#     indicating the strength of a membership in a set. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"

# Create the FuzzyGaussian algorithm object
midpoint = 1000
spread = 0.4
myFuzzyAlgorithm = FuzzyGaussian(midpoint, spread)

# Execute FuzzyMembership
outFuzzyMember = FuzzyMembership(inRaster, myFuzzyAlgorithm)

# Save the output
outFuzzyMember.save("c:/sapyexamples/fzymemb2")
```

### Example 5

```python
# Name: FuzzyMembership_Ex_02.py
# Description: Scales input raster data into values ranging from zero to one
#     indicating the strength of a membership in a set. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"

# Create the FuzzyGaussian algorithm object
midpoint = 1000
spread = 0.4
myFuzzyAlgorithm = FuzzyGaussian(midpoint, spread)

# Execute FuzzyMembership
outFuzzyMember = FuzzyMembership(inRaster, myFuzzyAlgorithm)

# Save the output
outFuzzyMember.save("c:/sapyexamples/fzymemb2")
```

---

## Fuzzy Overlay (Spatial Analyst)

## Summary

Combine fuzzy membership rasters data together, based on selected overlay type.

## Usage

- This tool is recommended for the use with the result of the fuzzy membership tool. It is meant to be applied to rasters with values that range between 0 and 1.
- The following lists the appropriate Overlay type to use for certain conditions. Use Or to get the maximum value from all of the input evidence rasters. In this case, if any of the input have a high value, the final output will be high.Use And to get the minimum value from all of the input evidence rasters. Here, all inputs must have a high value in order for the output to be a high value.Use Product when the combined evidence is less important than any single evidence.Use Sum when the combined evidence is more important than any single evidence.The Gamma type is typically used to combine more basic data. When gamma is 1, the result is the same as fuzzy sum. When it is 0, the result is the same as fuzzy Product. Values between 0 and 1 allow you to combine evidence to produce results between the two extremes established by fuzzy And or fuzzy Or.
- Use Or to get the maximum value from all of the input evidence rasters. In this case, if any of the input have a high value, the final output will be high.
- Use And to get the minimum value from all of the input evidence rasters. Here, all inputs must have a high value in order for the output to be a high value.
- Use Product when the combined evidence is less important than any single evidence.
- Use Sum when the combined evidence is more important than any single evidence.
- The Gamma type is typically used to combine more basic data. When gamma is 1, the result is the same as fuzzy sum. When it is 0, the result is the same as fuzzy Product. Values between 0 and 1 allow you to combine evidence to produce results between the two extremes established by fuzzy And or fuzzy Or.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input rasters | A list of input membership rasters to be combined in the overlay. | Raster Layer |
| Overlay type(Optional) | Specifies the method used to combine two or more membership data.And—The minimum of the fuzzy memberships from the input fuzzy rasters.Or—The maximum of the fuzzy memberships from the input rasters.Product—A decreasive function. Use this when the combination of multiple evidence is less important or smaller than any of the inputs alone.Sum—An increasive function. Use this when the combination of multiple evidence is more important or larger than any of the inputs alone.Gamma—The algebraic product of the fuzzy Sum and fuzzy Product, both raised to the power of gamma. | String |
| Gamma(Optional) | The gamma value to be used. This is only available when the Overlay type is set to Gamma.Default value is 0.9. | Double |
| in_rasters[in_raster,...] | A list of input membership rasters to be combined in the overlay. | Raster Layer |
| overlay_type(Optional) | Specifies the method used to combine two or more membership data.AND—The minimum of the fuzzy memberships from the input fuzzy rasters.OR—The maximum of the fuzzy memberships from the input rasters.PRODUCT—A decreasive function. Use this when the combination of multiple evidence is less important or smaller than any of the inputs alone.SUM—An increasive function. Use this when the combination of multiple evidence is more important or larger than any of the inputs alone.GAMMA—The algebraic product of the fuzzy Sum and fuzzy Product, both raised to the power of gamma. | String |
| gamma(Optional) | The gamma value to be used. This is only available when the Overlay type is set to Gamma.Default value is 0.9. | Double |

## Code Samples

### Example 1

```python
FuzzyOverlay(in_rasters, {overlay_type}, {gamma})
```

### Example 2

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "c:/sapyexamples/data"
outFzyOverlay = FuzzyOverlay(["fzymembout1", "fzymembout2"], "AND")
outFzyOverlay.save("c:/sapexamples/output/fuzzover.tif")
```

### Example 3

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "c:/sapyexamples/data"
outFzyOverlay = FuzzyOverlay(["fzymembout1", "fzymembout2"], "AND")
outFzyOverlay.save("c:/sapexamples/output/fuzzover.tif")
```

### Example 4

```python
# Name: FuzzyOverlay_Ex_02.py
# Description: Combine fuzzy membership rasters data together based on 
#    selected overlay type ("GAMMA" in this case). 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasterList = ["fzymembout1", "fzymembout2"]

# Execute FuzzyMembership
outFzyOverlay = FuzzyOverlay(inRasterList, "GAMMA", 0.9)

# Save the output
outFzyOverlay.save("c:/sapexamples/output/fuzzoverlay")
```

### Example 5

```python
# Name: FuzzyOverlay_Ex_02.py
# Description: Combine fuzzy membership rasters data together based on 
#    selected overlay type ("GAMMA" in this case). 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasterList = ["fzymembout1", "fzymembout2"]

# Execute FuzzyMembership
outFzyOverlay = FuzzyOverlay(inRasterList, "GAMMA", 0.9)

# Save the output
outFzyOverlay.save("c:/sapexamples/output/fuzzoverlay")
```

---

## Generate Multidimensional Anomaly (Spatial Analyst)

## Summary

Computes the anomaly for each slice in an existing multidimensional raster to generate a new multidimensional raster.

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Multidimensional Raster | The input multidimensional raster dataset. | Raster Dataset; Raster Layer; Mosaic Dataset; Mosaic Layer; Image Service; File |
| Variables [Dimension Info] (Description)(Optional) | The variable or variables for which anomalies will be calculated. If no variable is specified, all variables with a time dimension will be analyzed. | String |
| Anomaly Calculation Method(Optional) | Specifies the method that will be used to calculate the anomaly.Difference From Mean—The difference between a pixel's value and the mean of that pixel's values across slices defined by the interval will be calculated. This is the default.Percent Difference From Mean—The percent difference between a pixel's value and the mean of that pixel's values across slices defined by the interval will be calculated.Percent Of Mean—The percent of the mean will be calculated.Z-score—The z-score for each pixel will be calculated. A z-score of 0 indicates the pixel's value is identical to the mean. A z-score of 1 indicates the pixel's value is 1 standard deviation from the mean. If a z-score is 2, the pixel's value is 2 standard deviations from the mean, and so on.Difference From Median—The difference between a pixel's value and the mathematical median of that pixel's values across slices defined by the interval will be calculated.Percent Difference From Median—The percent difference between a pixel's value and the mathematical median of that pixel's values across slices defined by the interval will be calculated.Percent Of Median—The percent of the mathematical median will be calculated. | String |
| Mean Calculation Interval(Optional) | Specifies the temporal interval that will be used to calculate the mean.All—The mean is calculated across all slices for each pixel.Yearly—The yearly mean is calculated for each pixel.Recurring monthly—The monthly mean is calculated for each pixel.Recurring weekly—The weekly mean is calculated for each pixel.Recurring daily—The daily mean is calculated for each pixel.Hourly—The hourly mean is calculated for each pixel.External raster—An existing raster dataset that contains the mean or median value for each pixel is referenced. | String |
| Ignore NoData(Optional) | Specifies whether NoData values will be ignored in the analysis.Checked—The analysis will include all valid pixels along a given dimension and ignore NoData pixels. This is the default.Unchecked—The analysis will result in NoData if there are NoData values for the pixels along the given dimension. | Boolean |
| Input External Raster(Optional) | The reference raster dataset that contains a previously calculated mean for each pixel. The anomalies will be calculated in comparison to this mean. | Raster Layer; Raster Dataset; Mosaic Layer; Mosaic Dataset |
| in_multidimensional_raster | The input multidimensional raster dataset. | Raster Dataset; Raster Layer; Mosaic Dataset; Mosaic Layer; Image Service; File |
| variables[variables,...](Optional) | The variable or variables for which anomalies will be calculated. If no variable is specified, all variables with a time dimension will be analyzed. | String |
| method(Optional) | Specifies the method that will be used to calculate the anomaly. DIFFERENCE_FROM_MEAN—The difference between a pixel's value and the mean of that pixel's values across slices defined by the interval will be calculated. This is the default.PERCENT_DIFFERENCE_FROM_MEAN—The percent difference between a pixel's value and the mean of that pixel's values across slices defined by the interval will be calculated.PERCENT_OF_MEAN—The percent of the mean will be calculated.Z_SCORE—The z-score for each pixel will be calculated. A z-score of 0 indicates the pixel's value is identical to the mean. A z-score of 1 indicates the pixel's value is 1 standard deviation from the mean. If a z-score is 2, the pixel's value is 2 standard deviations from the mean, and so on.DIFFERENCE_FROM_MEDIAN—The difference between a pixel's value and the mathematical median of that pixel's values across slices defined by the interval will be calculated.PERCENT_DIFFERENCE_FROM_MEDIAN—The percent difference between a pixel's value and the mathematical median of that pixel's values across slices defined by the interval will be calculated.PERCENT_OF_MEDIAN—The percent of the mathematical median will be calculated. | String |
| calculation_interval(Optional) | Specifies the temporal interval that will be used to calculate the mean.ALL—The mean is calculated across all slices for each pixel.YEARLY—The yearly mean is calculated for each pixel.RECURRING_MONTHLY—The monthly mean is calculated for each pixel.RECURRING_WEEKLY—The weekly mean is calculated for each pixel.RECURRING_DAILY—The daily mean is calculated for each pixel.HOURLY—The hourly mean is calculated for each pixel.EXTERNAL_RASTER—An existing raster dataset that contains the mean or median value for each pixel is referenced. | String |
| ignore_nodata(Optional) | Specifies whether NoData values will be ignored in the analysis.DATA—The analysis will include all valid pixels along a given dimension and ignore NoData pixels. This is the default.NODATA—The analysis will result in NoData if there are NoData values for the pixels along the given dimension. | Boolean |
| reference_mean_raster(Optional) | The reference raster dataset that contains a previously calculated mean for each pixel. The anomalies will be calculated in comparison to this mean. | Raster Layer; Raster Dataset; Mosaic Layer; Mosaic Dataset |

## Code Samples

### Example 1

```python
GenerateMultidimensionalAnomaly(in_multidimensional_raster, {variables}, {method}, {calculation_interval}, {ignore_nodata}, {reference_mean_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
arcpy.CheckOutExtension("Spatial")
outTempAnomaly = GenerateMultidimensionalAnomaly(
	"C:/sapyexamples/data/climateData.nc", "temperature", "DIFFERENCE_FROM_MEAN",
        "ALL", "DATA")
outTempAnomaly.save("C:/sapyexamples/output/TempAnomaly.crf")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
arcpy.CheckOutExtension("Spatial")
outTempAnomaly = GenerateMultidimensionalAnomaly(
	"C:/sapyexamples/data/climateData.nc", "temperature", "DIFFERENCE_FROM_MEAN",
        "ALL", "DATA")
outTempAnomaly.save("C:/sapyexamples/output/TempAnomaly.crf")
```

### Example 4

```python
# Name: GenerateMultidimensionalAnomaly_Ex_02.py
# Description: Generates an anomaly multidimensional raster for
#           ocean temperature data, comparing pixel values with the yearly mean
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

""""
Usage: out_multidimensional_raster = GenerateMultidimensionalAnomaly(in_multidimensional_raster,
                                     {variables}, {method}, {temporal_interval})
"""

# Define input parameters
inputFile = "C:/sapyexamples/data/climateData.crf"
variable = "oceantemp"
averageMethod = "PERCENT_DIFFERENCE_FROM_MEAN"
averageInterval = "YEARLY"
ignoreNoData = "DATA"

# Execute GenerateMultidimensionalAnomaly
outYearlyAnomaly = GenerateMultidimensionalAnomaly(inputFile, variable, 
	averageMethod, averageInterval, ignoreNoData)

# Save the output
outYearlyAnomaly.save("C:/sapyexamples/output/TempAnomaly.crf")
```

### Example 5

```python
# Name: GenerateMultidimensionalAnomaly_Ex_02.py
# Description: Generates an anomaly multidimensional raster for
#           ocean temperature data, comparing pixel values with the yearly mean
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

""""
Usage: out_multidimensional_raster = GenerateMultidimensionalAnomaly(in_multidimensional_raster,
                                     {variables}, {method}, {temporal_interval})
"""

# Define input parameters
inputFile = "C:/sapyexamples/data/climateData.crf"
variable = "oceantemp"
averageMethod = "PERCENT_DIFFERENCE_FROM_MEAN"
averageInterval = "YEARLY"
ignoreNoData = "DATA"

# Execute GenerateMultidimensionalAnomaly
outYearlyAnomaly = GenerateMultidimensionalAnomaly(inputFile, variable, 
	averageMethod, averageInterval, ignoreNoData)

# Save the output
outYearlyAnomaly.save("C:/sapyexamples/output/TempAnomaly.crf")
```

---

## Generate Training Samples From Seed Points (Spatial Analyst)

## Summary

Generates training samples from seed points, such as accuracy assessment points or training sample points. A typical use case is generating training samples from an existing source, such as a thematic raster or a feature class.

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Class Data | The data source that labels the training samples. | Mosaic Layer; Raster Layer; Feature Layer; Image Service; String |
| Input Seed Points | A point shapefile or feature class to provide the centers of training sample polygons. | Feature Layer |
| Output Training Sample Feature Class | The output training sample feature class in the format that can be used in training tools, including shapefiles. The output feature class can be either a polygon feature class or a point feature class. | Feature Class |
| Min Sample Area(Optional) | The minimum area needed for each training sample, in square meters. The minimum value must be greater than or equal to 0. | Double |
| Max Sample Radius(Optional) | The longest distance (in meters) from any point within the training sample to its center seed point. If set to 0, the output training sample will be points instead of polygons. The minimum value must be greater than or equal to 0. | Double |
| in_class_data | The data source that labels the training samples. | Mosaic Layer; Raster Layer; Feature Layer; Image Service; String |
| in_seed_points | A point shapefile or feature class to provide the centers of training sample polygons. | Feature Layer |
| out_training_feature_class | The output training sample feature class in the format that can be used in training tools, including shapefiles. The output feature class can be either a polygon feature class or a point feature class. | Feature Class |
| min_sample_area(Optional) | The minimum area needed for each training sample, in square meters. The minimum value must be greater than or equal to 0. | Double |
| max_sample_radius(Optional) | The longest distance (in meters) from any point within the training sample to its center seed point. If set to 0, the output training sample will be points instead of polygons. The minimum value must be greater than or equal to 0. | Double |

## Code Samples

### Example 1

```python
GenerateTrainingSamplesFromSeedPoints(in_class_data, in_seed_points, out_training_feature_class, {min_sample_area}, {max_sample_radius})
```

### Example 2

```python
### GenerateTrainingSamplesFromSeedPoints example 1 (Python window)
import arcpy
from arcpy.sa import *

cls_img = "C:/Data/svm.tif"
seed_pnts = "C:/Data/seeds.shp"
trn_samples = "C:/out/ts.shp"

GenerateTrainingSamplesFromSeedPoints(cls_img, seed_pnts, trn_samples, "30", "50")
```

### Example 3

```python
### GenerateTrainingSamplesFromSeedPoints example 1 (Python window)
import arcpy
from arcpy.sa import *

cls_img = "C:/Data/svm.tif"
seed_pnts = "C:/Data/seeds.shp"
trn_samples = "C:/out/ts.shp"

GenerateTrainingSamplesFromSeedPoints(cls_img, seed_pnts, trn_samples, "30", "50")
```

### Example 4

```python
### GenerateTrainingSamplesFromSeedPoints example 2 (stand-alone script)
import arcpy
from arcpy.sa import *

GenerateTrainingSamplesFromSeedPoints("C:/Data/svm.tif", 
                                      "C:/Data/seeds.shp", 
                                      "C:/out/ts.shp", 
                                      "30", "50")
```

### Example 5

```python
### GenerateTrainingSamplesFromSeedPoints example 2 (stand-alone script)
import arcpy
from arcpy.sa import *

GenerateTrainingSamplesFromSeedPoints("C:/Data/svm.tif", 
                                      "C:/Data/seeds.shp", 
                                      "C:/out/ts.shp", 
                                      "30", "50")
```

---

## Geomorphon Landforms (Spatial Analyst)

## Summary

Calculates the geomorphon pattern of each cell of an input surface raster and classifies calculated geomorphons into common landform types.

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input surface raster | The input surface raster. | Raster Layer |
| Output geomorphons raster(Optional) | Each geomorphon pattern will be assigned a unique identifier, which is stored for each cell in the output geomorphons raster.The output is of integer type. | Raster Dataset |
| Flat terrain angle threshold(Optional) | The angle threshold (in degrees) below which the target cell will be classified as flat.The default value is 1 degree. Specifying a larger value than the default is recommended for low resolution DEMs. | Double |
| Distance units(Optional) | Specifies the distance unit that will be used for the Search distance and Skip distance parameters.Distance will be measured in the specified unit or number of cells. The default is Cells.Cells—The distance unit will be cells.Meters—The distance unit will be meters.Centimeters—The distance unit will be centimeters.Kilometers—The distance unit will be kilometers.Inches—The distance unit will be inches.Feet—The distance unit will be feet.Yard—The distance unit will be yards.Miles—The distance unit will be miles. | String |
| Search distance(Optional) | The distance away from the target cell that defines the radius of the area that will be used to identify the geomorphon pattern.The default value is 10. Use a search distance value that matches the type and size of the landforms that you want to classify. | Double |
| Skip distance(Optional) | The distance away from the target cell where the analysis area starts. Neighboring cells that fall within this distance will be skipped and won't contribute to identification of the geomorphon pattern.The classification of each individual cell is determined by assessing the neighboring cells within the skip distance from the target cell center. | Double |
| Z unit(Optional) | Specifies the linear unit that will be used for vertical z-values.It is defined by a vertical coordinate system if it exists. If no vertical coordinate system exists, define the z-unit using the unit list to ensure correct geodesic computation. The default is meter.Inch—The linear unit will be inches.Foot—The linear unit will be feet.Yard—The linear unit will be yards.Mile US—The linear unit will be miles.Nautical mile—The linear unit will be nautical miles.Millimeter—The linear unit will be millimeters.Centimeter—The linear unit will be centimeters.Meter—The linear unit will be meters.Kilometer—The linear unit will be kilometers.Decimeter—The linear unit will be decimeters. | String |
| in_surface_raster | The input surface raster. | Raster Layer |
| out_geomorphons_raster(Optional) | Each geomorphon pattern will be assigned a unique identifier, which is stored for each cell in the output geomorphons raster.The output is of integer type. | Raster Dataset |
| angle_threshold(Optional) | The angle threshold (in degrees) below which the target cell will be classified as flat.The default value is 1 degree. Specifying a larger value than the default is recommended for low resolution DEMs. | Double |
| distance_units(Optional) | Specifies the distance unit that will be used for the Search distance and Skip distance parameters.Distance will be measured in the specified unit or number of cells. The default is Cells.Specifies the distance unit that will be used for the search_distance and skip_distance parameters.Distance will be measured in the specified unit or number of cells. The default is CELLS.CELLS—The distance unit will be cells.METERS—The distance unit will be meters.CENTIMETERS—The distance unit will be centimeters.KILOMETERS—The distance unit will be kilometers.INCHES—The distance unit will be inches.FEET—The distance unit will be feet.YARDS—The distance unit will be yards.MILES—The distance unit will be miles. | String |
| search_distance(Optional) | The distance away from the target cell that defines the radius of the area that will be used to identify the geomorphon pattern.The default value is 10. Use a search distance value that matches the type and size of the landforms that you want to classify. | Double |
| skip_distance(Optional) | The distance away from the target cell where the analysis area starts. Neighboring cells that fall within this distance will be skipped and won't contribute to identification of the geomorphon pattern.The classification of each individual cell is determined by assessing the neighboring cells within the skip distance from the target cell center. | Double |
| z_unit(Optional) | Specifies the linear unit that will be used for vertical z-values.It is defined by a vertical coordinate system if it exists. If no vertical coordinate system exists, define the z-unit using the unit list to ensure correct geodesic computation. The default is meter.INCH—The linear unit will be inches.FOOT—The linear unit will be feet.YARD—The linear unit will be yards.MILE_US—The linear unit will be miles.NAUTICAL_MILE—The linear unit will be nautical miles.MILLIMETER—The linear unit will be millimeters.CENTIMETER—The linear unit will be centimeters.METER—The linear unit will be meters.KILOMETER—The linear unit will be kilometers.DECIMETER—The linear unit will be decimeters. | String |

## Code Samples

### Example 1

```python
GeomorphonLandforms(in_surface_raster, {out_geomorphons_raster}, {angle_threshold}, {distance_units}, {search_distance}, {skip_distance}, {z_unit})
```

### Example 2

```python
from arcpy.sa import *
outGeomorphonLandforms = GeomorphonLandforms("elevation_1m.tif", "", "", "", "", "", "")
outGeomorphonLandforms.save("C:/sapyexamples/output/outgeorphonlandforms01.tif")
```

### Example 3

```python
from arcpy.sa import *
outGeomorphonLandforms = GeomorphonLandforms("elevation_1m.tif", "", "", "", "", "", "")
outGeomorphonLandforms.save("C:/sapyexamples/output/outgeorphonlandforms01.tif")
```

### Example 4

```python
# Name: GeomorphonLandforms_standalone.py
# Description: Calculates geomorphons over a search distance of 50 meters, skipping cells within 2 meters
# of the target cell. Terrain is considered flat if the difference between elevation angles is less or equal to 2 degrees.
# The calculated geomorphons are classified into landforms and saved as a raster. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation_1m.tif"
inAngleThreshold = 2
inDistanceUnits = "METERS"
inSearchDistance = 50
inSkipDistance = 2
inZunit = "METER"

# Execute the tool
outGeomorphonLandforms = GeomorphonLandforms(inRaster, "", inAngleThreshold, inDistanceUnits,
                                         inSearchDistance, inSkipDistance, inZunit)

# Save the output 
outGeomorphonLandforms.save("C:/sapyexamples/output/outgeomorphonlandforms02.tif")
```

### Example 5

```python
# Name: GeomorphonLandforms_standalone.py
# Description: Calculates geomorphons over a search distance of 50 meters, skipping cells within 2 meters
# of the target cell. Terrain is considered flat if the difference between elevation angles is less or equal to 2 degrees.
# The calculated geomorphons are classified into landforms and saved as a raster. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation_1m.tif"
inAngleThreshold = 2
inDistanceUnits = "METERS"
inSearchDistance = 50
inSkipDistance = 2
inZunit = "METER"

# Execute the tool
outGeomorphonLandforms = GeomorphonLandforms(inRaster, "", inAngleThreshold, inDistanceUnits,
                                         inSearchDistance, inSkipDistance, inZunit)

# Save the output 
outGeomorphonLandforms.save("C:/sapyexamples/output/outgeomorphonlandforms02.tif")
```

---

## Greater Than Equal (Spatial Analyst)

## Summary

Performs a Relational greater-than-or-equal-to operation on two inputs on a cell-by-cell basis.

## Usage

- Two inputs are necessary for this relational evaluation to take place.
- The order of inputs is relevant for this tool.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is ">=" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input being tested to determine if it is greater than or equal to the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input against which the first input is tested to be greater than or equal to.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input being tested to determine if it is greater than or equal to the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input against which the first input is tested to be greater than or equal to.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
GreaterThanEqual(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outGTE = GreaterThanEqual("degs", "negs")
outGTE.save("C:/sapyexamples/output/outgte.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outGTE = GreaterThanEqual("degs", "negs")
outGTE.save("C:/sapyexamples/output/outgte.tif")
```

### Example 4

```python
# Name: GreaterThanEqual_Ex_02.py
# Description: Performs a relational greater-than-equal operation on
#              two inputs on a cell-by-cell basis within the Analysis
#              window
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute GreaterThanEqual
outGTE = GreaterThanEqual(inRaster1, inRaster2)

# Save the output 
outGTE.save("C:/sapyexamples/output/outgte")
```

### Example 5

```python
# Name: GreaterThanEqual_Ex_02.py
# Description: Performs a relational greater-than-equal operation on
#              two inputs on a cell-by-cell basis within the Analysis
#              window
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute GreaterThanEqual
outGTE = GreaterThanEqual(inRaster1, inRaster2)

# Save the output 
outGTE.save("C:/sapyexamples/output/outgte")
```

---

## Greater Than Frequency (Spatial Analyst)

## Summary

Evaluates on a cell-by-cell basis the number of times a set of rasters is greater than another raster.

## Usage

- An arbitrary number of rasters can be specified in the input rasters list.
- If a cell location contains NoData on any of the input rasters, that location will be assigned NoData on the output.
- The output raster is always of integer type.
- If all inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process, otherwise an error will occur.If all of the inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before performing the operation.If one or more of the inputs are multidimensional rasters and the other inputs are constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input value raster | For each cell location in the input value raster, the number of occurrences (frequency) where a raster in the input list has a greater value is counted. | Raster Layer |
| Input rasters | The list of rasters that will be compared to the value raster. | Raster Layer |
| Process as multiband(Optional) | Specifies how the input multiband raster bands will be processed. Unchecked—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.Checked—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |
| in_value_raster | For each cell location in the input value raster, the number of occurrences (frequency) where a raster in the input list has a greater value is counted. | Raster Layer |
| in_rasters[in_raster,...] | The list of rasters that will be compared to the value raster. | Raster Layer |
| process_as_multiband(Optional) | Specifies how the input multiband raster bands will be processed. SINGLE_BAND—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.MULTI_BAND—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |

## Code Samples

### Example 1

```python
GreaterThanFrequency(in_value_raster, in_rasters, {process_as_multiband})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outGTF = GreaterThanFrequency("cost", ["degs", "negs", "fourgrd"])
outGTF.save("C:/sapyexamples/output/outgtf.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outGTF = GreaterThanFrequency("cost", ["degs", "negs", "fourgrd"])
outGTF.save("C:/sapyexamples/output/outgtf.tif")
```

### Example 4

```python
# Name: GreaterThanFrequency_Ex_02.py
# Description: Evaluates the number of times a set of rasters is
#              greater than another raster on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inValueRaster = "cost"
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute GreaterThanFrequency
outGTF = GreaterThanFrequency(inValueRaster, [inRaster01, inRaster02, inRaster03])

# Save the output 
outGTF.save("C:/sapyexamples/output/outgtf")
```

### Example 5

```python
# Name: GreaterThanFrequency_Ex_02.py
# Description: Evaluates the number of times a set of rasters is
#              greater than another raster on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inValueRaster = "cost"
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute GreaterThanFrequency
outGTF = GreaterThanFrequency(inValueRaster, [inRaster01, inRaster02, inRaster03])

# Save the output 
outGTF.save("C:/sapyexamples/output/outgtf")
```

---

## Greater Than (Spatial Analyst)

## Summary

Performs a Relational greater-than operation on two inputs on a cell-by-cell basis.

## Usage

- Two inputs are necessary for this relational evaluation to take place.
- The order of inputs is relevant for this tool.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is ">" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input being tested to determine if it is greater than the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input against which the first input is tested to be greater than.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input being tested to determine if it is greater than the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input against which the first input is tested to be greater than.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
GreaterThan(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outGreaterThan = GreaterThan("degs", "negs")
outGreaterThan.save("C:/sapyexamples/output/outgt.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outGreaterThan = GreaterThan("degs", "negs")
outGreaterThan.save("C:/sapyexamples/output/outgt.img")
```

### Example 4

```python
# Name: GreaterThan_Ex_02.py
# Description: Performs a relational greater-than operation on two inputs
#              on a cell-by-cell basis within the Analysis window
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute GreaterThan
outGreaterThan = GreaterThan(inRaster1, inRaster2)

# Save the output 
outGreaterThan.save("C:/sapyexamples/output/outgt")
```

### Example 5

```python
# Name: GreaterThan_Ex_02.py
# Description: Performs a relational greater-than operation on two inputs
#              on a cell-by-cell basis within the Analysis window
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute GreaterThan
outGreaterThan = GreaterThan(inRaster1, inRaster2)

# Save the output 
outGreaterThan.save("C:/sapyexamples/output/outgt")
```

---

## How the Boolean math tools work

## Code Samples

### Example 1

```python
Input1 ≠ 0 and Input2 ≠ 0, Output = 1
Input1 ≠ 0 and Input2 = 0, Output = 0
Input1 = 0 and Input2 ≠ 0, Output = 0
Input1 = 0 and Input2 = 0, Output = 0
```

### Example 2

```python
Input1 ≠ 0 and Input2 ≠ 0, Output = 1
Input1 ≠ 0 and Input2 = 0, Output = 1
Input1 = 0 and Input2 ≠ 0, Output = 1
Input1 = 0 and Input2 = 0, Output = 0
```

### Example 3

```python
Input1 ≠ 0 and Input2 ≠ 0, Output = 0
Input1 ≠ 0 and Input2 = 0, Output = 1
Input1 = 0 and Input2 ≠ 0, Output = 1
Input1 = 0 and Input2 = 0, Output = 0
```

### Example 4

```python
Input1 ≠ 0, Output = 0
Input1 ≠ 0, Output = 1
```

---

## How the combinatorial math tools work

## Code Samples

### Example 1

```python
Input Values     =>   NoData Excluded   =>   Unique Combinations
==============        ===============        ======================
InRas1  InRas2        InRas1  InRas2         InRas1  InRas2   Count
------  ------        ------  ------         ------  ------   -----
  1       0             1       0              1        0     ( 2 )
  1       1             1       1              1        1     ( 2 )
  0       1             0       1              0        1     ( 1 )
  0       0             0       0              0        0     ( 3 )
nodata    3             1       3              1        3     ( 1 )
  1       3             2       1              2        1     ( 1 )
  2       1             2       2              2        2     ( 2 )
  2       2             0       0              4        3     ( 1 )
  4     nodata          0       0              0        2     ( 1 )
  0       0             2       2 
  0       0             4       3  
  2       2             0       2  
  4       3             1       1  
  0       2             1       0
  1       1          
  1       0
```

### Example 2

```python
Combinations     =>   True/False State  =>   Returned Value 
==============        ================       =============== 
InRas1  InRas2        And   Or    XOr        And   Or    XOr
------  ------        ---   ---   ---        ---   ---   ---
  1       0            F     T     T          0     1     1
  1       1            T     T     F          1     2     0
  0       1            F     T     T          0     3     2
  0       0            F     F     F          0     0     0
  1       3            T     T     F          2     4     0
  2       1            T     T     F          3     5     0
  2       2            T     T     F          4     6     0
  4       3            T     T     F          5     7     0
  0       2            F     T     T          0     8     3
```

---

## How Sample works

## Code Samples

### Example 1

```python
locationID-1 x-coord1 y-coord1 cellvalue1 cellvalue2 cellvalue3 ....
    locationID-2 x-coord2 y-coord2 cellvalue1 cellvalue2 cellvalue3 ....
```

### Example 2

```python
locationID-1 cellvalue dimensionAvalue1 dimensionBvalue1 ....
    locationID-1 cellvalue dimensionAvalue1 dimensionBvalue2 ....
    locationID-1 cellvalue dimensionAvalue2 dimensionBvalue1 ....
    locationID-1 cellvalue dimensionAvalue2 dimensionBvalue2 ....
    locationID-2 cellvalue dimensionAvalue1 dimensionBvalue1 ....
    locationID-2 cellvalue dimensionAvalue1 dimensionBvalue2 ....
    locationID-2 cellvalue dimensionAvalue2 dimensionBvalue1 ....
    locationID-2 cellvalue dimensionAvalue2 dimensionBvalue2 ....
```

---

## How the relational math tools work

## Code Samples

### Example 1

```python
Input1 = Input2, Output = 1
 Input1 ≠ Input2, Output = 0
```

### Example 2

```python
Input1 = Input2, Output = 0
 Input1 ≠ Input2, Output = 1
```

### Example 3

```python
Input1 > Input2, Output = 1
 Input1 = Input2, Output = 0
 Input1 < Input2, Output = 0
```

### Example 4

```python
Input1 > Input2, Output = 1
 Input1 = Input2, Output = 1
 Input1 < Input2, Output = 0
```

### Example 5

```python
Input1 > Input2, Output = 0
 Input1 = Input2, Output = 0
 Input1 < Input2, Output = 1
```

### Example 6

```python
Input1 > Input2, Output = 0
 Input1 = Input2, Output = 1
 Input1 < Input2, Output = 1
```

---

## Highest Position (Spatial Analyst)

## Summary

Determines on a cell-by-cell basis the position of the raster with the maximum value in a set of rasters.

## Usage

- An arbitrary number of rasters can be specified in the input rasters list.
- The order of the input rasters is relevant for this tool.
- When a multiband raster is specified as one of the Input rasters or constant values parameter values (in_rasters_or_constants in Python), all the bands will be used.To process a selection of bands from a multiband raster, first create a raster dataset composed of those particular bands using the Composite Bands tool; then use the result in the list in the Input rasters or constant values parameter (in_rasters_or_constants in Python).
- If a cell location contains NoData on any of the input rasters, that location will be assigned NoData on the output.
- The output raster is always of integer type.
- If two or more input rasters contain the maximum value for a particular cell location, the position of the first one is returned on the output raster.
- If all inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process, otherwise an error will occur.If all of the inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before performing the operation.If one or more of the inputs are multidimensional rasters and the other inputs are constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input rasters or constant values | The list of input rasters for which the position of the input with the highest value will be determined.A number can be used as an input; however, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_rasters_or_constants[in_raster_or_constant,...] | The list of input rasters for which the position of the input with the highest value will be determined.A number can be used as an input; however, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
HighestPosition(in_rasters_or_constants)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outHighestPosition = HighestPosition(["degs", "negs", "fourgrd"])
outHighestPosition.save("C:/sapyexamples/output/outhp.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outHighestPosition = HighestPosition(["degs", "negs", "fourgrd"])
outHighestPosition.save("C:/sapyexamples/output/outhp.img")
```

### Example 4

```python
# Name: HighestPosition_Ex_02.py
# Description: Determines the position of a raster with the maximum
#              value in a set of rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute HighestPosition
outHighestPosition = HighestPosition([inRaster01, inRaster02, inRaster03])

# Save the output 
outHighestPosition.save("C:/sapyexamples/output/outhp")
```

### Example 5

```python
# Name: HighestPosition_Ex_02.py
# Description: Determines the position of a raster with the maximum
#              value in a set of rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute HighestPosition
outHighestPosition = HighestPosition([inRaster01, inRaster02, inRaster03])

# Save the output 
outHighestPosition.save("C:/sapyexamples/output/outhp")
```

---

## Hillshade (Spatial Analyst)

## Summary

Creates a shaded relief from a surface raster by considering the illumination source angle and shadows.

## Usage

- The Hillshade tool creates a shaded relief raster from a raster. The illumination source is considered to be at infinity.
- The hillshade raster has an integer value range of 0 to 255.
- Two types of shaded relief rasters can be output. If the Model shadows option is disabled (unchecked), the output raster only considers local illumination angle. If it is enabled (checked), the output raster considers the effects of both local illumination angle and shadow.
- The analysis of shadows is done by considering the effects of the local horizon at each cell. Raster cells in shadow are assigned a value of zero.
- To create a raster of the shadow areas only, use the Con, Reclassify, or Extract by Attributes tool to separate the value zero from the other hillshade values. The Model shadows option must be enabled (checked) to create this result.
- If the input raster is in a spherical coordinate system, such as decimal degrees, the resulting hillshade may look peculiar. This is due to the difference in measure between the horizontal ground units and the elevation z units. Since the length of a degree of longitude changes with latitude, you will need to specify an appropriate z-factor for that latitude. If your x,y units are decimal degrees and your z units are meters, some appropriate z-factors for particular latitudes are: Latitude Z-factor 0 0.00000898 10 0.00000912 20 0.00000956 30 0.00001036 40 0.00001171 50 0.00001395 60 0.00001792 70 0.00002619 80 0.00005156
- When the input raster needs to be resampled, the bilinear technique will be used. An example of when an input raster may be resampled is when the output coordinate system, extent, or cell size is different from that of the input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input surface raster. | Raster Layer |
| Azimuth(Optional) | Azimuth angle of the light source.The azimuth is expressed in positive degrees from 0 to 360, measured clockwise from north.The default is 315 degrees. | Double |
| Altitude(Optional) | Altitude angle of the light source above the horizon.The altitude is expressed in positive degrees, with 0 degrees at the horizon and 90 degrees directly overhead.The default is 45 degrees. | Double |
| Model shadows(Optional) | Type of shaded relief to be generated.Unchecked—The output raster only considers local illumination angles; the effects of shadows are not considered. The output values can range from 0 to 255, with 0 representing the darkest areas, and 255 the brightest. This is the default.Checked—The output shaded raster considers both local illumination angles and shadows. The output values range from 0 to 255, with 0 representing the shadow areas, and 255 the brightest. | Boolean |
| Z factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| in_raster | The input surface raster. | Raster Layer |
| azimuth(Optional) | Azimuth angle of the light source.The azimuth is expressed in positive degrees from 0 to 360, measured clockwise from north.The default is 315 degrees. | Double |
| altitude(Optional) | Altitude angle of the light source above the horizon.The altitude is expressed in positive degrees, with 0 degrees at the horizon and 90 degrees directly overhead.The default is 45 degrees. | Double |
| model_shadows(Optional) | Type of shaded relief to be generated.NO_SHADOWS—The output raster only considers local illumination angles; the effects of shadows are not considered.The output values can range from 0 to 255, with 0 representing the darkest areas, and 255 the brightest. This is the default.SHADOWS—The output shaded raster considers both local illumination angles and shadows.The output values range from 0 to 255, with 0 representing the shadow areas, and 255 the brightest. | Boolean |
| z_factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |

## Code Samples

### Example 1

```python
Latitude     Z-factor
     0           0.00000898
    10           0.00000912
    20           0.00000956
    30           0.00001036
    40           0.00001171
    50           0.00001395
    60           0.00001792
    70           0.00002619
    80           0.00005156
```

### Example 2

```python
Hillshade(in_raster, {azimuth}, {altitude}, {model_shadows}, {z_factor})
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outHillshade = Hillshade("elevation", 180, 75, "SHADOWS", 1)
outHillshade.save("C:/sapyexamples/output/outhillshd01")
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outHillshade = Hillshade("elevation", 180, 75, "SHADOWS", 1)
outHillshade.save("C:/sapyexamples/output/outhillshd01")
```

### Example 5

```python
# Name: Hillshade_Ex_02.py
# Description: Computes hillshade values for a raster surface.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
azimuth = 180
altitude = 75
modelShadows = "SHADOWS"
zFactor = 0.348

# Execute HillShade
outHillShade = Hillshade(inRaster, azimuth, altitude, modelShadows, zFactor)

# Save the output 
outHillShade.save("C:/sapyexamples/output/outhillshd02")
```

### Example 6

```python
# Name: Hillshade_Ex_02.py
# Description: Computes hillshade values for a raster surface.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
azimuth = 180
altitude = 75
modelShadows = "SHADOWS"
zFactor = 0.348

# Execute HillShade
outHillShade = Hillshade(inRaster, azimuth, altitude, modelShadows, zFactor)

# Save the output 
outHillShade.save("C:/sapyexamples/output/outhillshd02")
```

---

## How Aspect works

## Code Samples

### Example 1

```python
[dz/dx] = ((c + 2f + i)*4/wght1 - (a + 2d + g)*4/wght2) / 8
```

### Example 2

```python
[dz/dx] = ((c + 2f + i)*4/wght1 - (a + 2d + g)*4/wght2) / 8
```

### Example 3

```python
[dz/dy] = ((g + 2h + i)*4/wght3 - (a + 2b + c)*4/wght4 ) / 8
```

### Example 4

```python
[dz/dy] = ((g + 2h + i)*4/wght3 - (a + 2b + c)*4/wght4 ) / 8
```

### Example 5

```python
aspect = 57.29578 * atan2 ([dz/dy], -[dz/dx])
```

### Example 6

```python
aspect = 57.29578 * atan2 ([dz/dy], -[dz/dx])
```

### Example 7

```python
if aspect < 0
    cell = 90.0 - aspect>
  else if aspect > 90.0
    cell = 360.0 - aspect + 90.0
  else
    cell = 90.0 - aspect
```

### Example 8

```python
if aspect < 0
    cell = 90.0 - aspect>
  else if aspect > 90.0
    cell = 360.0 - aspect + 90.0
  else
    cell = 90.0 - aspect
```

### Example 9

```python
[dz/dx] = ((c + 2f + i)*4/wght1 - (a + 2d + g)*4/wght2) / 8
          = ((85 + 170 + 84)*4/(1+2+1) - (101 + 202 + 101)*4/(1+2+1)) / 8
          = -8.125
```

### Example 10

```python
[dz/dx] = ((c + 2f + i)*4/wght1 - (a + 2d + g)*4/wght2) / 8
          = ((85 + 170 + 84)*4/(1+2+1) - (101 + 202 + 101)*4/(1+2+1)) / 8
          = -8.125
```

### Example 11

```python
[dz/dy] = ((g + 2h + i)*4/wght3 - (a + 2b + c)*4/wght4) / 8
          = ((101 + 182 + 84)*4/(1+2+1) - (101 + 184 + 85)*4/(1+2+1)) / 8
          = -0.375
```

### Example 12

```python
[dz/dy] = ((g + 2h + i)*4/wght3 - (a + 2b + c)*4/wght4) / 8
          = ((101 + 182 + 84)*4/(1+2+1) - (101 + 184 + 85)*4/(1+2+1)) / 8
          = -0.375
```

### Example 13

```python
aspect = 57.29578 * atan2 ([dz/dy], -[dz/dx])
         = 57.29578 * atan2 (-0.375, 8.125)
         = -2.64
```

### Example 14

```python
aspect = 57.29578 * atan2 ([dz/dy], -[dz/dx])
         = 57.29578 * atan2 (-0.375, 8.125)
         = -2.64
```

### Example 15

```python
cell = 90.0 - aspect
       = 90 - (-2.64)
       = 90 + 2.64
       = 92.64
```

### Example 16

```python
cell = 90.0 - aspect
       = 90 - (-2.64)
       = 90 + 2.64
       = 92.64
```

### Example 17

```python
X = (N(φ)+h)cosφcosλ
```

### Example 18

```python
X = (N(φ)+h)cosφcosλ
```

### Example 19

```python
Y = (N(φ)+h)cosφsinλ
```

### Example 20

```python
Y = (N(φ)+h)cosφsinλ
```

### Example 21

```python
Z = (b2/a2*N(φ)+h)sinφ
```

### Example 22

```python
Z = (b2/a2*N(φ)+h)sinφ
```

---

## How Band Collection Statistics works

## Code Samples

### Example 1

```python
#               STATISTICS of INDIVIDUAL LAYERS

#   Layer           MIN          MAX          MEAN         STD
# ---------------------------------------------------------------
       1            1.0000      21.0000       7.8410       4.1690
       2            1.0000     128.0000      25.5144      35.8494
       3          296.9573    4073.6306    1565.5359     763.9803
       4            0.3333     127.5000      51.5314      29.7958
# ===============================================================
```

### Example 2

```python
#               STATISTICS of INDIVIDUAL LAYERS

#   Layer           MIN          MAX          MEAN         STD
# ---------------------------------------------------------------
       1            1.0000      21.0000       7.8410       4.1690
       2            1.0000     128.0000      25.5144      35.8494
       3          296.9573    4073.6306    1565.5359     763.9803
       4            0.3333     127.5000      51.5314      29.7958
# ===============================================================



#                    COVARIANCE MATRIX

#   Layer            1            2            3            4
# ---------------------------------------------------------------
       1           17.3826      16.9320    3177.5947      87.9590
       2           16.9320    1285.3096    3117.1753      31.3420
       3         3177.5947    3117.1753  583723.0625   16137.9785
       4           87.9590      31.3420   16137.9785     887.8751
# ===============================================================


#                    CORRELATION MATRIX

#    Layer            1            2            3            4
# ---------------------------------------------------------------
       1            1.0000       0.1133       0.9976       0.7080
       2            0.1133       1.0000       0.1138       0.0293
       3            0.9976       0.1138       1.0000       0.7089
       4            0.7080       0.0293       0.7089       1.0000
# ===============================================================
```

---

## How Block Statistics works

## Code Samples

### Example 1

```python
4 6 7
6 7 8
4 5 6
```

### Example 2

```python
4 6 7
6 7 8
4 5 6
```

### Example 3

```python
3 3
0.0 0.5 0.0 
0.5 2.0 0.5 
0.0 0.5 0.0
```

### Example 4

```python
3 3
0.0 0.5 0.0 
0.5 2.0 0.5 
0.0 0.5 0.0
```

### Example 5

```python
= (w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + w6x6 + w7x7 + w8x8 + w9x9) /
  (w1 + w2 + w3 + w4 + w5 + w6 + w7 + w8 + w9)
= ((0*4)+(0.5*6)+(0*7)+(0.5*6)+(2.0*7)+(0.5*8)+(0*4)+(0.5*5)+(0*6)) /
  (0 + 0.5 + 0 + 0.5 + 2.0 + 0.5 + 0 + 0.5 + 0)
= (0 + 3.0 + 0 + 3.0 + 14.0 + 4.0 + 0 + 2.5 + 0) / 
  (0.5 + 0.5 + 2.0 + 0.5 + 0.5)
= (3.0 + 3.0 + 14.0 + 4.0 + 2.5) / 4.0
= 26.5 / 4.0
= 6.625
```

### Example 6

```python
= (w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + w6x6 + w7x7 + w8x8 + w9x9) /
  (w1 + w2 + w3 + w4 + w5 + w6 + w7 + w8 + w9)
= ((0*4)+(0.5*6)+(0*7)+(0.5*6)+(2.0*7)+(0.5*8)+(0*4)+(0.5*5)+(0*6)) /
  (0 + 0.5 + 0 + 0.5 + 2.0 + 0.5 + 0 + 0.5 + 0)
= (0 + 3.0 + 0 + 3.0 + 14.0 + 4.0 + 0 + 2.5 + 0) / 
  (0.5 + 0.5 + 2.0 + 0.5 + 0.5)
= (3.0 + 3.0 + 14.0 + 4.0 + 2.5) / 4.0
= 26.5 / 4.0
= 6.625
```

### Example 7

```python
4 6 7
6 7 8
4 5 6
```

### Example 8

```python
4 6 7
6 7 8
4 5 6
```

### Example 9

```python
3 3
0.0 0.5 0.0 
0.5 2.0 0.5 
0.0 0.5 0.0
```

### Example 10

```python
3 3
0.0 0.5 0.0 
0.5 2.0 0.5 
0.0 0.5 0.0
```

### Example 11

```python
4 6 7
6 7 8
4 5 6
```

### Example 12

```python
4 6 7
6 7 8
4 5 6
```

### Example 13

```python
3 3
-1 -2 -1
 0  0  0
 1  2  1
```

### Example 14

```python
3 3
-1 -2 -1
 0  0  0
 1  2  1
```

### Example 15

```python
= (w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + w6x6 + w7x7 + w8x8 + w9x9)
= ((-1*4) + (-2*6) + (-1*7) + (0*6) + (0*7) + (0*8) + (1*4) + (2*5) + (1*6))
= (-4) + (-12) + (-7) + 4 + 10 + 6
= -3
```

### Example 16

```python
= (w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + w6x6 + w7x7 + w8x8 + w9x9)
= ((-1*4) + (-2*6) + (-1*7) + (0*6) + (0*7) + (0*8) + (1*4) + (2*5) + (1*6))
= (-4) + (-12) + (-7) + 4 + 10 + 6
= -3
```

---

## How Contouring works

## Code Samples

### Example 1

```python
3 3
.005 .005 .005
.005 .960 .005
.005 .005 .005
```

---

## How Create Signatures works

## Code Samples

### Example 1

```python
# Signatures Produced by ClassSig from Zone-Grid redsamp5 and Stack redlands
# Number of selected grids
/*        3
# Layer-Number        Grid-name
/*        1            redlands3
/*        2            redlands1
/*        3            redlands2

# Type  Number of Classes  Number of Layers  Number of Parametric Layers
  1     5                  3                 3
#  ----------------------------------------------------------------------

# Class ID    Number of Cells    Class Name
  1           654                sand
# Layers   1           2           3
# Means 
         170.4908    155.7569    161.9419
# Covariance
1        292.6546    182.3661    186.2583
2        182.3661    127.8076    139.3009
3        186.2583    139.3009    196.3029
# ---------------------------------------------------------------

# Class ID    Number of Cells    Class Name
  2           585                urban
# Layers   1           2           3
# Means 
         104.5009     92.4410     92.0513
# Covariance
1        384.6580    552.1828    389.0496
2        552.1828   1378.6750    863.5595
3        389.0496    863.5595    772.2063
# ---------------------------------------------------------------

# Class ID    Number of Cells    Class Name
  3           783                forest
# Layers   1           2           3
# Means
          27.0026    174.3768     72.7931
# Covariance
1        241.0818    -14.6301    293.7806
2        -14.6301    764.2914    221.4054
3        293.7806    221.4054    527.0799
# ---------------------------------------------------------------

# Class ID    Number of Cells    Class Name
  4           951                water
# Layers   1           2           3
# Means
           1.1504      0.0515      0.0873
# Covariance
1          7.2753      3.9638      6.4848
2          3.9638      2.5247      4.0702
3          6.4848      4.0702      6.5724
# -----------------------------------------------------------------

# Class ID    Number of Cells     Class Name
  5           969                 agri_field
# Layers   1           2           3
# Means 
          32.4675    232.7781     85.4149
# Covariance
1        423.1004   -684.8693    324.1354
2       -684.8693   1271.6315   -509.0008
3        324.1354   -509.0008    366.1232
```

### Example 2

```python
Input raster bands : redlandsInput raster or feature sample data : redzone5Sample field : "Value"Output signature file : z5red.gsgCompute covariance matrices : off
```

### Example 3

```python
# Number of selected grids
/*        3
# Layer-Number        Grid-name
/*        1            redlands3
/*        2            redlands1
/*        3            redlands2

# Type  Number of Classes  Number of Layers  Number of Parametric Layers
  1     5                  3                 3
#  ----------------------------------------------------------------------

# Class ID    Number of Cells    Class Name
  1           654                sand
# Layers   1           2           3
# Means 
         170.4908    155.7569    161.9419
# ---------------------------------------------------------------

# Class ID    Number of Cells    Class Name
  2           585                urban
# Layers   1           2           3
# Means 
         104.5009     92.4410     92.0513
# ---------------------------------------------------------------

# Class ID    Number of Cells    Class Name
  3           783                forest
# Layers   1           2           3
# Means
          27.0026    174.3768     72.7931
# ---------------------------------------------------------------

# Class ID    Number of Cells    Class Name
  4           951                water
# Layers   1           2           3
# Means
           1.1504      0.0515      0.0873
# -----------------------------------------------------------------

# Class ID    Number of Cells     Class Name
  5           969                 agri_field
# Layers   1           2           3
# Means 
          32.4675    232.7781     85.4149
```

---

## How Curvature works

## Code Samples

### Example 1

```python
Z = Ax²y² + Bx²y + Cxy² + Dx² + Ey² + Fxy + Gx + Hy + I
```

### Example 2

```python
Z = Ax²y² + Bx²y + Cxy² + Dx² + Ey² + Fxy + Gx + Hy + I
```

### Example 3

```python
A = [(Z1 + Z3 + Z7 + Z9) / 4  - (Z2 + Z4 + Z6 + Z8) / 2 + Z5] / L4 
B = [(Z1 + Z3 - Z7 - Z9) /4 - (Z2 - Z8) /2] / L3 
C = [(-Z1 + Z3 - Z7 + Z9) /4 + (Z4 - Z6)] /2] / L3 
D = [(Z4 + Z6) /2 - Z5] / L2 
E = [(Z2 + Z8) /2 - Z5] / L2 
F = (-Z1 + Z3 + Z7 - Z9) / 4L2 
G = (-Z4 + Z6) / 2L 
H = (Z2 - Z8) / 2L 
I = Z5
```

### Example 4

```python
A = [(Z1 + Z3 + Z7 + Z9) / 4  - (Z2 + Z4 + Z6 + Z8) / 2 + Z5] / L4 
B = [(Z1 + Z3 - Z7 - Z9) /4 - (Z2 - Z8) /2] / L3 
C = [(-Z1 + Z3 - Z7 + Z9) /4 + (Z4 - Z6)] /2] / L3 
D = [(Z4 + Z6) /2 - Z5] / L2 
E = [(Z2 + Z8) /2 - Z5] / L2 
F = (-Z1 + Z3 + Z7 - Z9) / 4L2 
G = (-Z4 + Z6) / 2L 
H = (Z2 - Z8) / 2L 
I = Z5
```

### Example 5

```python
Standard Curvature = -100 * ([d2z/dx2] + [d2z/dy2])
```

### Example 6

```python
Standard Curvature = -100 * ([d2z/dx2] + [d2z/dy2])
```

### Example 7

```python
Profile Curvature = -2(D + E) * 100
```

### Example 8

```python
Profile Curvature = -2(D + E) * 100
```

---

## How Cut Fill works

## Code Samples

### Example 1

```python
Vol = (cell_area) * ΔZ
```

### Example 2

```python
Vol = (cell_area) * ΔZ
```

### Example 3

```python
ΔZ = ZBefore - ZAfter
```

### Example 4

```python
ΔZ = ZBefore - ZAfter
```

### Example 5

```python
Vol = (10m * 10m) * (235m - 232m)
      = 100m2 * 3m
      = 300m3
```

### Example 6

```python
Vol = (10m * 10m) * (235m - 232m)
      = 100m2 * 3m
      = 300m3
```

### Example 7

```python
ObjectID   Value   Count           Volume        Area
       0       1   55819            0.000   258107056
       1       2     707   -137415060.250     3269168
       2       3      65   -114913516.625      300560
       3       4     810   1235057106.000     3745440
```

---

## How Dendrogram works

## Code Samples

### Example 1

```python
Distances between pairs of combined classes (in the sequence of merging):

Remaining   Merged   Between-Class
Class      Class      Distance
----------------------------------
  3         5        3.442680
  4         6        3.608904
  7         9        3.899360
  2         7        3.795288
  3         4        4.883098
  2         8        6.073256
  1         3        6.257798
  1         2        9.350019
----------------------------------

Dendrogram of /discb/topdir/myspace/isoclust12.gsg

C       DISTANCE
L
A
S   0      1.0     2.1     3.1     4.1     5.2     6.2     7.2     8.3     9.3
S   |-------|-------|-------|-------|-------|-------|-------|-------|------
   
   5 -------------------------|
                              |----------|
   3 -------------------------|          |
                                         |----------|
   6 ---------------------------|        |          |
                                |--------|          |-------------------|
   4 ---------------------------|                   |                   |
                                                    |                   |
   1 -----------------------------------------------|                   |
                                                                        |-
   9 -----------------------------|                                     |
                                  |                                     |
   7 ---------------------------------------------|                     |
                                   |              |                     |
   2 ------------------------------|              |---------------------|
                                                  |
   8 ---------------------------------------------|
   
    |-------|-------|-------|-------|-------|-------|-------|-------|------
    0      1.0     2.1     3.1     4.1     5.2     6.2     7.2     8.3     9.3
```

---

## How Derive Continuous Flow works

## Code Samples

### Example 1

```python
maximum_drop = change_in_z-value/distance
```

### Example 2

```python
maximum_drop = change_in_z-value/distance
```

---

## How Edit Signatures works

## Code Samples

### Example 1

```python
8 : 3
 9 : 1
11 : -9999
14 : 4
15 : 7
21 : 3
23 : 6
```

### Example 2

```python
# Signatures Produced by ClassSig from Class-Grid zsamp12 and Stack redl123
#    Number of selected grids
/*           3
#    Layer-Number    Grid-name
/*           1       redlands1
/*           2       redlands2
/*           3       redlands3

# Type  Number of Classes  Number of Layers  Number of Parametric Layers
   1             14               3                3
# ===============================================================

#  Class ID     Number of Cells    Class Name
        1             4493         
# Layers         1            2            3
# Means    
             	 57.4801      55.1022      34.5615
# Covariance
1           	755.8841     389.1188     165.2408
2           	389.1188     451.9519     248.4967
3           	165.2408     248.4967     163.7970
# -------------------------------------------------------

#  Class ID     Number of Cells    Class Name
        2             1464         
# Layers        1            2            3
# Means    
            142.5451      48.3053      22.8818
# Covariance
1           301.2310      61.3188     -24.5077
2            61.3188     150.2574     102.7169
3           -24.5077     102.7169     103.9020
# ------------------------------------------------------

#  Class ID     Number of Cells    Class Name
        3            142         
# Layers        1            2            3
# Means    
            226.2817      94.4225      25.4789
# Covariance
1          1250.7286     448.2489     -11.1146
2           448.2489     302.1464      75.3991
3           -11.1146      75.3991      67.7407
# ------------------------------------------------------
#  Class ID     Number of Cells    Class Name
        4            399         
# Layers        1            2            3
# Means    
            161.6867     174.5113     177.4386
# Covariance
1            29.0699      23.6907      32.0523
2            23.6907      65.3359      38.7300
3            32.0523      38.7300      55.1061
# ------------------------------------------------------

#  Class ID     Number of Cells    Class Name
        5             1476         
# Layers        1            2            3
# Means    
              0.0589     0.0976     1.2026
# Covariance
1             3.1321     2.4268     3.5081
2             2.4268     2.8922     3.9924
3             3.5081     3.9924     6.7094
# ------------------------------------------------------
#  Class ID     Number of Cells    Class Name
        6               225         
# Layers        1            2            3
# Means    
            138.5378     140.1644     168.5600
# Covariance
1           151.4461     120.3978     142.3225
2           120.3978     142.5309     128.7914
3           142.3225     128.7914     149.9618
# ------------------------------------------------------

#  Class ID     Number of Cells    Class Name
        7               383         
# Layers        1            2            3
# Means    
            129.2950     146.6136      97.0836
# Covariance
1            72.6745      21.6483      74.7947
2            21.6483      20.2377      38.7392
3            74.7947      38.7392     164.1239
# ------------------------------------------------------

#  Class ID     Number of Cells    Class Name
        8                948         
# Layers        1            2            3
# Means    
            251.3091      76.7447      22.7795
# Covariance
1            49.3943       2.3736     -16.1440
2             2.3736      89.0773      13.2319
3           -16.1440      13.2319      12.8732
# -----------------------------------------------------
#  Class ID     Number of Cells    Class Name
        9               446         
# Layers        1            2            3
# Means    
            100.0022      61.6861      39.1323
# Covariance
1            50.9685       3.0816      -2.7846
2             3.0816      81.6765      57.7427
3            -2.7846      57.7427      57.0229
# ------------------------------------------------------

#  Class ID     Number of Cells    Class Name
       11              244         
# Layers        1            2            3
# Means    
            133.8402      85.3934      84.4672
# Covariance
1            78.2336      -1.2908     -20.0320
2            -1.2908      58.4454      29.1652
3           -20.0320      29.1652      77.5586
# -----------------------------------------------------

#  Class ID     Number of Cells    Class Name
       14             186         
# Layers        1            2            3
# Means    
            159.5753     212.3172     163.9677
# Covariance
1           112.8186     197.4165     155.3484
2           197.4165     432.0772     319.2643
3           155.3484     319.2643     265.5773
# ------------------------------------------------------

#  Class ID     Number of Cells    Class Name
       15             149         
# Layers        1            2             3
# Means    
            144.9262     154.2483     113.9262
# Covariance
1           191.0824      27.4239     137.5486
2            27.4239      81.4717      13.0252
3           137.5486      13.0252     114.0283
# -----------------------------------------------------

#  Class ID     Number of Cells    Class Name
       21             253         
# Layers        1            2            3
# Means    
            235.0514      98.1107      32.6324
# Covariance
1           278.8188      81.3633     -12.5802
2            81.3633     132.3131      36.1639
3           -12.5802      36.1639      38.6699
# ----------------------------------------------------
#  Class ID     Number of Cells    Class Name
       23             121         
# Layers        1            2             3
# Means    
            145.3223     143.9669     155.3058
# Covariance
1            21.4536      16.4524      24.5590
2            16.4524      43.2322      14.8685
3            24.5590      14.8685      79.9140
```

---

## How Feature Preserving Smoothing works

## Code Samples

### Example 1

```python
ax + by + cz + d = 0
```

### Example 2

```python
ax + by + cz + d = 0
```

---

## How Filter works

## Code Samples

### Example 1

```python
7 5 2
 4 8 3
 3 1 5
```

### Example 2

```python
7 5 2
 4 8 3
 3 1 5
```

### Example 3

```python
Value = ((7 + 5 + 2) + (4 + 8 + 3) + (3 + 1 + 5)) / 9 
       = 38 / 9
       = 4.222
```

### Example 4

```python
Value = ((7 + 5 + 2) + (4 + 8 + 3) + (3 + 1 + 5)) / 9 
       = 38 / 9
       = 4.222
```

### Example 5

```python
2.000   3.000   4.000   5.000   6.000
 2.000   3.000   4.000   NoData  6.000
 2.000   3.000   4.000   5.000   6.000
 2.000  30.000   4.000   5.000   NoData
 1.000   2.000   2.000   3.000   NoData
```

### Example 6

```python
2.000   3.000   4.000   5.000   6.000
 2.000   3.000   4.000   NoData  6.000
 2.000   3.000   4.000   5.000   6.000
 2.000  30.000   4.000   5.000   NoData
 1.000   2.000   2.000   3.000   NoData
```

### Example 7

```python
2.500   3.000   3.800   5.000   5.667
 2.500   3.000   3.875   5.000   5.600
 7.000   6.000   7.250   4.857   5.500
 6.667   5.556   6.444   4.143   4.750
 8.750   6.833   7.667   3.500   4.000
```

### Example 8

```python
2.500   3.000   3.800   5.000   5.667
 2.500   3.000   3.875   5.000   5.600
 7.000   6.000   7.250   4.857   5.500
 6.667   5.556   6.444   4.143   4.750
 8.750   6.833   7.667   3.500   4.000
```

### Example 9

```python
NoData  NoData  NoData  NoData  NoData
 NoData  3.000   NoData  NoData  NoData
 NoData  6.000   NoData  NoData  NoData
 NoData  5.556   6.444   NoData  NoData
 NoData  NoData  NoData  NoData  NoData
```

### Example 10

```python
NoData  NoData  NoData  NoData  NoData
 NoData  3.000   NoData  NoData  NoData
 NoData  6.000   NoData  NoData  NoData
 NoData  5.556   6.444   NoData  NoData
 NoData  NoData  NoData  NoData  NoData
```

### Example 11

```python
-0.7  -1.0  -0.7
 -1.0   6.8  -1.0
 -0.7  -1.0  -0.7
```

### Example 12

```python
-0.7  -1.0  -0.7
 -1.0   6.8  -1.0
 -0.7  -1.0  -0.7
```

### Example 13

```python
7 5 2
 4 8 3
 3 1 5
```

### Example 14

```python
7 5 2
 4 8 3
 3 1 5
```

### Example 15

```python
Value = ((7*-0.7) + (5*-1.0) + (2*-0.7) +
          (4*-1.0) + (8*6.8)  + (3*-1.0) + 
          (3*-0.7) + (1*-1.0) + (5*-0.7))
       = ((-4.9 + -5.0 + -1.4) +
          (-4.0 + 54.4 + -3.0) +
          (-2.1 + -1.0 + -3.5)
       = -11.3 + 47.4 + -6.6
       = 29.5
```

### Example 16

```python
Value = ((7*-0.7) + (5*-1.0) + (2*-0.7) +
          (4*-1.0) + (8*6.8)  + (3*-1.0) + 
          (3*-0.7) + (1*-1.0) + (5*-0.7))
       = ((-4.9 + -5.0 + -1.4) +
          (-4.0 + 54.4 + -3.0) +
          (-2.1 + -1.0 + -3.5)
       = -11.3 + 47.4 + -6.6
       = 29.5
```

---

## How Flow Direction works

## Code Samples

### Example 1

```python
maximum_drop = change_in_z-value/distance
```

### Example 2

```python
maximum_drop = change_in_z-value/distance
```

---

## How Focal Statistics works

## Code Samples

### Example 1

```python
x = (width of the neighborhood + 1)/2
y = (height of the neighborhood + 1)/2
```

### Example 2

```python
x = (width of the neighborhood + 1)/2
y = (height of the neighborhood + 1)/2
```

### Example 3

```python
x = (width + 1)/2
y = (height + 1)/2
```

### Example 4

```python
x = (width + 1)/2
y = (height + 1)/2
```

### Example 5

```python
x = (width + 1)/2
y = (height + 1)/2
```

### Example 6

```python
x = (width + 1)/2
y = (height + 1)/2
```

### Example 7

```python
pk = (k-1)/(n-1)
```

### Example 8

```python
pk = (k-1)/(n-1)
```

### Example 9

```python
4 6 7
6 7 8
4 5 6
```

### Example 10

```python
4 6 7
6 7 8
4 5 6
```

### Example 11

```python
3 3
0.0 0.5 0.0 
0.5 2.0 0.5 
0.0 0.5 0.0
```

### Example 12

```python
3 3
0.0 0.5 0.0 
0.5 2.0 0.5 
0.0 0.5 0.0
```

### Example 13

```python
= (w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + w6x6 + w7x7 + w8x8 + w9x9) /
  (w1 + w2 + w3 + w4 + w5 + w6 + w7 + w8 + w9)
= ((0*4)+(0.5*6)+(0*7)+(0.5*6)+(2.0*7)+(0.5*8)+(0*4)+(0.5*5)+(0*6)) /
  (0 + 0.5 + 0 + 0.5 + 2.0 + 0.5 + 0 + 0.5 + 0)
= (0 + 3.0 + 0 + 3.0 + 14.0 + 4.0 + 0 + 2.5 + 0) / 
  (0.5 + 0.5 + 2.0 + 0.5 + 0.5)
= (3.0 + 3.0 + 14.0 + 4.0 + 2.5) / 4.0
= 26.5 / 4.0
= 6.625
```

### Example 14

```python
= (w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + w6x6 + w7x7 + w8x8 + w9x9) /
  (w1 + w2 + w3 + w4 + w5 + w6 + w7 + w8 + w9)
= ((0*4)+(0.5*6)+(0*7)+(0.5*6)+(2.0*7)+(0.5*8)+(0*4)+(0.5*5)+(0*6)) /
  (0 + 0.5 + 0 + 0.5 + 2.0 + 0.5 + 0 + 0.5 + 0)
= (0 + 3.0 + 0 + 3.0 + 14.0 + 4.0 + 0 + 2.5 + 0) / 
  (0.5 + 0.5 + 2.0 + 0.5 + 0.5)
= (3.0 + 3.0 + 14.0 + 4.0 + 2.5) / 4.0
= 26.5 / 4.0
= 6.625
```

### Example 15

```python
4 6 7
6 7 8
4 5 6
```

### Example 16

```python
4 6 7
6 7 8
4 5 6
```

### Example 17

```python
3 3
0.0 0.5 0.0 
0.5 2.0 0.5 
0.0 0.5 0.0
```

### Example 18

```python
3 3
0.0 0.5 0.0 
0.5 2.0 0.5 
0.0 0.5 0.0
```

### Example 19

```python
4 6 7
6 7 8
4 5 6
```

### Example 20

```python
4 6 7
6 7 8
4 5 6
```

### Example 21

```python
3 3
-1 -2 -1
 0  0  0
 1  2  1
```

### Example 22

```python
3 3
-1 -2 -1
 0  0  0
 1  2  1
```

### Example 23

```python
= (w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + w6x6 + w7x7 + w8x8 + w9x9)
= ((-1*4) + (-2*6) + (-1*7) + (0*6) + (0*7) + (0*8) + (1*4) + (2*5) + (1*6))
= (-4) + (-12) + (-7) + 4 + 10 + 6
= -3
```

### Example 24

```python
= (w1x1 + w2x2 + w3x3 + w4x4 + w5x5 + w6x6 + w7x7 + w8x8 + w9x9)
= ((-1*4) + (-2*6) + (-1*7) + (0*6) + (0*7) + (0*8) + (1*4) + (2*5) + (1*6))
= (-4) + (-12) + (-7) + 4 + 10 + 6
= -3
```

---

## How Fuzzy Overlay works

## Code Samples

### Example 1

```python
fuzzyAndValue = min(arg1, ..., argn)
```

### Example 2

```python
fuzzyAndValue = min(arg1, ..., argn)
```

### Example 3

```python
fuzzyOrValue = max(arg1, ..., argn)
```

### Example 4

```python
fuzzyOrValue = max(arg1, ..., argn)
```

### Example 5

```python
fuzzyProductValue = product(arg1, ..., argn)
```

### Example 6

```python
fuzzyProductValue = product(arg1, ..., argn)
```

### Example 7

```python
fuzzySumValue = 1 - product(1 - arg1, ..., 1 - argn)
```

### Example 8

```python
fuzzySumValue = 1 - product(1 - arg1, ..., 1 - argn)
```

### Example 9

```python
µ(x) = (FuzzySum)γ * (FuzzyProduct)1-γ
```

### Example 10

```python
µ(x) = (FuzzySum)γ * (FuzzyProduct)1-γ
```

### Example 11

```python
fuzzyGammaValue = pow(1 - ((1 - arg1) * (1 - arg2) * ...), Gamma) * 
                    pow(arg1 * arg2 * ..., 1 - Gamma)
```

### Example 12

```python
fuzzyGammaValue = pow(1 - ((1 - arg1) * (1 - arg2) * ...), Gamma) * 
                    pow(arg1 * arg2 * ..., 1 - Gamma)
```

---

## How Hillshade works

## Code Samples

### Example 1

```python
(1)  Hillshade = 255.0 * ((cos(Zenith_rad) * cos(Slope_rad)) +
               (sin(Zenith_rad) * sin(Slope_rad) * cos(Azimuth_rad - Aspect_rad)))
```

### Example 2

```python
(1)  Hillshade = 255.0 * ((cos(Zenith_rad) * cos(Slope_rad)) +
               (sin(Zenith_rad) * sin(Slope_rad) * cos(Azimuth_rad - Aspect_rad)))
```

### Example 3

```python
(2)  Zenith_deg = 90.0 - Altitude
```

### Example 4

```python
(2)  Zenith_deg = 90.0 - Altitude
```

### Example 5

```python
(3)  Zenith_rad = Zenith_deg * pi / 180.0
```

### Example 6

```python
(3)  Zenith_rad = Zenith_deg * pi / 180.0
```

### Example 7

```python
(4)  Azimuth_math = 360.0 - Azimuth + 90.0
```

### Example 8

```python
(4)  Azimuth_math = 360.0 - Azimuth + 90.0
```

### Example 9

```python
(5)  Azimuth_math = Azimuth_math - 360.0
```

### Example 10

```python
(5)  Azimuth_math = Azimuth_math - 360.0
```

### Example 11

```python
(6)  Azimuth_rad = Azimuth_math * pi / 180.0
```

### Example 12

```python
(6)  Azimuth_rad = Azimuth_math * pi / 180.0
```

### Example 13

```python
(7)  [dz/dx] = ((c + 2f + i) - (a + 2d + g)) / (8 * cellsize)
```

### Example 14

```python
(7)  [dz/dx] = ((c + 2f + i) - (a + 2d + g)) / (8 * cellsize)
```

### Example 15

```python
(8)  [dz/dy] = ((g + 2h + i) - (a + 2b + c)) / (8 * cellsize)
```

### Example 16

```python
(8)  [dz/dy] = ((g + 2h + i) - (a + 2b + c)) / (8 * cellsize)
```

### Example 17

```python
(9)  Slope_rad = ATAN (z_factor * √ ([dz/dx]2 + [dz/dy]2))
```

### Example 18

```python
(9)  Slope_rad = ATAN (z_factor * √ ([dz/dx]2 + [dz/dy]2))
```

### Example 19

```python
(10)
  If [dz/dx] is non-zero:
    Aspect_rad = atan2 ([dz/dy], -[dz/dx])
      if Aspect_rad < 0 then
        Aspect_rad = 2 * pi + Aspect_rad
  If [dz/dx] is zero:
    if [dz/dy] > 0 then
      Aspect_rad = pi / 2
    else if [dz/dy] < 0 then
      Aspect_rad = 2 * pi - pi / 2
    else
      Aspect_rad = Aspect_rad
```

### Example 20

```python
(10)
  If [dz/dx] is non-zero:
    Aspect_rad = atan2 ([dz/dy], -[dz/dx])
      if Aspect_rad < 0 then
        Aspect_rad = 2 * pi + Aspect_rad
  If [dz/dx] is zero:
    if [dz/dy] > 0 then
      Aspect_rad = pi / 2
    else if [dz/dy] < 0 then
      Aspect_rad = 2 * pi - pi / 2
    else
      Aspect_rad = Aspect_rad
```

### Example 21

```python
(2)  Zenith_deg = 90.0 - Altitude 
              = 90.0 - 45.0
              = 45.0
```

### Example 22

```python
(2)  Zenith_deg = 90.0 - Altitude 
              = 90.0 - 45.0
              = 45.0
```

### Example 23

```python
(3)  Zenith_rad = Zenith_deg * pi / 180.0
              = 45.0 * 3.1415926536 / 180.0
              = 0.7853981634
```

### Example 24

```python
(3)  Zenith_rad = Zenith_deg * pi / 180.0
              = 45.0 * 3.1415926536 / 180.0
              = 0.7853981634
```

### Example 25

```python
(4)  Azimuth_math = 360.0 - Azimuth + 90.0
                = 360.0 - 315.0 + 90.0
                = 135.0
```

### Example 26

```python
(4)  Azimuth_math = 360.0 - Azimuth + 90.0
                = 360.0 - 315.0 + 90.0
                = 135.0
```

### Example 27

```python
(6)  Azimuth_rad = Azimuth_math * pi / 180.0
               = 135.0 * 3.1415926536 / 180
               = 2.3561944902
```

### Example 28

```python
(6)  Azimuth_rad = Azimuth_math * pi / 180.0
               = 135.0 * 3.1415926536 / 180
               = 2.3561944902
```

### Example 29

```python
(7)  [dz/dx] = ((c + 2f + i) - (a + 2d + g)) / (8 * cellsize)
             = ((2483 + 4966 + 2477) - (2450 + 4904 + 2447)) / (8 * 5)
             = (9926 - 9801) / 40
             = 3.125
```

### Example 30

```python
(7)  [dz/dx] = ((c + 2f + i) - (a + 2d + g)) / (8 * cellsize)
             = ((2483 + 4966 + 2477) - (2450 + 4904 + 2447)) / (8 * 5)
             = (9926 - 9801) / 40
             = 3.125
```

### Example 31

```python
(8)  [dz/dy] = ((g + 2h + i) - (a + 2b + c)) / (8 * cellsize)
             = (2447 + 4910 + 2477) - (2450 + 4922 + 2483) / (8 * 5)
             = (9834 - 9855) / 40
             = -0.525
```

### Example 32

```python
(8)  [dz/dy] = ((g + 2h + i) - (a + 2b + c)) / (8 * cellsize)
             = (2447 + 4910 + 2477) - (2450 + 4922 + 2483) / (8 * 5)
             = (9834 - 9855) / 40
             = -0.525
```

### Example 33

```python
(9)  Slope_rad = ATAN ( z_factor * √ ([dz/dx]2 + [dz/dy]2))
             = atan(1 * sqrt((3.125 * 3.125) + (-0.525 * -0.525)))
             = atan(1 * sqrt(10.04125 + 0.275625))
             = atan(1 * 3.1687931457)
             = 1.2651101670
```

### Example 34

```python
(9)  Slope_rad = ATAN ( z_factor * √ ([dz/dx]2 + [dz/dy]2))
             = atan(1 * sqrt((3.125 * 3.125) + (-0.525 * -0.525)))
             = atan(1 * sqrt(10.04125 + 0.275625))
             = atan(1 * 3.1687931457)
             = 1.2651101670
```

### Example 35

```python
Aspect_rad = atan2 ([dz/dy], -[dz/dx])
           = atan2(-0.525, -3.125)
           = -2.9751469600
```

### Example 36

```python
Aspect_rad = atan2 ([dz/dy], -[dz/dx])
           = atan2(-0.525, -3.125)
           = -2.9751469600
```

### Example 37

```python
Aspect_rad = 2 * pi + Aspect_rad
           = 2 * 3.1415926536 + -2.9751469600
           = 3.3080383471
```

### Example 38

```python
Aspect_rad = 2 * pi + Aspect_rad
           = 2 * 3.1415926536 + -2.9751469600
           = 3.3080383471
```

### Example 39

```python
Hillshade = 255.0 * ((cos(Zenith_rad) * cos(Slope_rad)) + 
             (sin(Zenith_rad) * sin(Slope_rad) * cos(Azimuth_rad - Aspect_rad)))
          = 255.0 * ((cos(0.7857142857) * cos(1.26511)) +
             (sin(0.7857142857) * sin(1.26511) * cos(2.3571428571 - 3.310567)))
          = 153.82
```

### Example 40

```python
Hillshade = 255.0 * ((cos(Zenith_rad) * cos(Slope_rad)) + 
             (sin(Zenith_rad) * sin(Slope_rad) * cos(Azimuth_rad - Aspect_rad)))
          = 255.0 * ((cos(0.7857142857) * cos(1.26511)) +
             (sin(0.7857142857) * sin(1.26511) * cos(2.3571428571 - 3.310567)))
          = 153.82
```

---

## How Iso Cluster works

## Code Samples

### Example 1

```python
# Signatures Produced by Clustering of 
#    Stack redlands
#    number_of_classes=6   max_iterations=20   min_class_size=20
#    sampling interval=10
#    Number of selected grids
/*           3
#    Layer-Number   Grid-name
/*           1      redlands1
/*           2      redlands2
/*           3      redlands3

# Type  Number of Classes   Number of Layers  Number of Parametric
                                                   Layers
   1             4                 3                 3
# ===============================================================

# Class ID     Number of Cells      Class Name
       1              1843 
# Layers   1             2             3
# Means 
        22.8817       60.7656       34.8893
# Covariance
1      169.3975      -69.7444      179.0808
2      -69.7444      714.7072       10.7889
3      179.0808       10.7889      284.0931
# ---------------------------------------------------------------

# Class ID     Number of Cells      Class Name
       2              2495 
# Layers   1             2             3
# Means 
         38.4894      132.9775       61.8104
# Covariance
1       414.9621      -19.0732      301.0267
2       -19.0732      510.8439      102.8931
3       301.0267      102.8931      376.5450
# ---------------------------------------------------------------
# Class ID     Number of Cells      Class Name
       3              2124 
# Layers   1             2             3
# Means 
         70.3983       82.9576       89.2472
# Covariance
1       264.2680      100.6966       39.3895
2       100.6966      523.9096       75.5573
3        39.3895       75.5573      279.7387
# ------------------------------------------------------------

# Class ID     Number of Cells      Class Name
       4              2438 
# Layers   1             2             3
# Means 105.8708      137.6645      130.0886
# Covariance
1       651.0465      175.1060      391.6028
2       175.1060      300.8853      143.2443
3       391.6028      143.2443      647.7345
```

---

## How Kriging works

## Code Samples

### Example 1

```python
Semivariogram(distanceh) = 0.5 * average((valuei – valuej)2)
```

### Example 2

```python
Semivariogram(distanceh) = 0.5 * average((valuei – valuej)2)
```

---

## How Line Density works

## Code Samples

### Example 1

```python
Density = ((L1 * V1) + (L2 * V2)) / (area_of_circle)
```

### Example 2

```python
Density = ((L1 * V1) + (L2 * V2)) / (area_of_circle)
```

---

## How the Locate Regions tool works

## Code Samples

### Example 1

```python
StepInterval = LargerDist/(N - 1)
```

### Example 2

```python
StepInterval = LargerDist/(N - 1)
```

---

## How Maximum Likelihood Classification works

## Code Samples

### Example 1

```python
RECORD    VALUE    COUNT
0             1       69
1             2      462
2             3     1834
3             4     1123
4             5     2044
5             6     9140
6             7    28443
7             8    46781
8             9    63234
9            10    46393
10           11    42157
11           12    54506
12           13    37937
13           14   744128
```

---

## How Multiscale Surface Percentile works

## Code Samples

### Example 1

```python
ni = no + [Δn × (i - no)]p
```

### Example 2

```python
ni = no + [Δn × (i - no)]p
```

### Example 3

```python
Percentile = counti ∈C(zi < z0) × (100/nC)
```

### Example 4

```python
Percentile = counti ∈C(zi < z0) × (100/nC)
```

### Example 5

```python
Percentile = (Count of cell values less than center cell value) 
              * 100 / (Count of cells in neighborhood)
           = 5 * 100 / 9
           = 55.5556
```

---

## How Particle Track works

## Code Samples

### Example 1

```python
ParticleTrack(dir1, mag1, ttrack.txt, 500, 650, 5, 100, track_feat.shp)
```

### Example 2

```python
ParticleTrack(dir1, mag1, ttrack.txt, 500, 650, 5, 100, track_feat.shp)
```

### Example 3

```python
out_vol = DarcyFlow(head, poros, thickn, transm, dir1, mag1)
ParticleTrack(dir1, mag1, ttrack.txt, 500, 650, "#", "#", track_feat.shp)
out_puff = PorousPuff(ttrack.txt, poros, thickn, 3.2e7, 50000, 6, 3, 1, 250)
```

### Example 4

```python
out_vol = DarcyFlow(head, poros, thickn, transm, dir1, mag1)
ParticleTrack(dir1, mag1, ttrack.txt, 500, 650, "#", "#", track_feat.shp)
out_puff = PorousPuff(ttrack.txt, poros, thickn, 3.2e7, 50000, 6, 3, 1, 250)
```

---

## How Point Density works

## Code Samples

### Example 1

```python
Desired output is density per:
  
                        | sq foot | sq meter |  acre  | hectare | 1,000 sq feet |
                 -------+---------+----------+--------+---------+---------------|
Input map units: feet   |  1      |    3.208 | 208.7  | 328.083 |     31.623    |
                 meters |  0.3048 |    1     |  63.6  | 100     |      9.639    |
```

---

## How Porous Puff works

## Code Samples

### Example 1

```python
outPPuff1 = PorousPuff(ttrack.txt, poros, thickn, 1000000, 0.01, 10, 1.5, 1.0, 500)
```

### Example 2

```python
outPPuff1 = PorousPuff(ttrack.txt, poros, thickn, 1000000, 0.01, 10, 1.5, 1.0, 500)
```

### Example 3

```python
out_vol = DarcyFlow(head, poros, thickn, transm, dir1, mag1)
ParticleTrack(dir1, mag1, ttrack.txt, 500, 650, "#", "#", track_feat.shp)
out_puff = PorousPuff(ttrack.txt, poros, thickn, 3.2e7, 50000, 6, 3, 1, 250)
```

### Example 4

```python
out_vol = DarcyFlow(head, poros, thickn, transm, dir1, mag1)
ParticleTrack(dir1, mag1, ttrack.txt, 500, 650, "#", "#", track_feat.shp)
out_puff = PorousPuff(ttrack.txt, poros, thickn, 3.2e7, 50000, 6, 3, 1, 250)
```

---

## How Principal Components works

## Code Samples

### Example 1

```python
COVARIANCE MATRIX
#    Layer            1            2            3
#  -----------------------------------------------------------
1           34.1763      31.2377      51.8100
2           31.2377     212.6159      99.9540
3           51.8100      99.9540     118.8057
#  ===========================================================

#                    CORRELATION MATRIX
#    Layer            1            2            3
#  -----------------------------------------------------------
1            1.0000       0.3665       0.8131
2            0.3665       1.0000       0.6289
3            0.8131       0.6289       1.0000
#  ===========================================================

#               EIGENVALUES AND EIGENVECTORS
# Number of Input Layers     Number of Principal Component Layers
3                                3
# PC Layer            1            2            3
#  -----------------------------------------------------------
# Eigen Values
287.8278      69.8781       7.8920
# Eigen Vectors
# Input Layer
1            0.2112       0.4718       0.8560
2            0.8116      -0.5727       0.1154
3            0.5447       0.6704      -0.5039
#  ===========================================================
```

---

## How Reclass by ASCII File works

## Code Samples

### Example 1

```python
in_value : out_value
```

### Example 2

```python
5 : 100
7 : 200
```

### Example 3

```python
in_min_value in_max_value : out_value
```

### Example 4

```python
1 3 : 4   (where  1 <= value <= 3, values remapped to 4)
3 5 : 6   (where  3 <  value <= 5, values remapped to 6)
5 7 : 8   (where  5 <  value <= 7, values remapped to 8)
```

---

## How Sink works

## Code Samples

### Example 1

```python
sinks = Sink(flowdir)
sink_areas = Watershed(flowdir, sinks)
sink_min = ZonalStatistics(sink_areas, "Value", elevation, "Minimum")
sink_max = ZonalFill(sink_areas, elevation)
sink_depth = Minus(sink_max, sink_min)
```

### Example 2

```python
sinks = Sink(flowdir)
sink_areas = Watershed(flowdir, sinks)
sink_min = ZonalStatistics(sink_areas, "Value", elevation, "Minimum")
sink_max = ZonalFill(sink_areas, elevation)
sink_depth = Minus(sink_max, sink_min)
```

---

## How Slope works

## Code Samples

### Example 1

```python
slope_radians = ATAN ( √ ([dz/dx]2 + [dz/dy]2) )
```

### Example 2

```python
slope_radians = ATAN ( √ ([dz/dx]2 + [dz/dy]2) )
```

### Example 3

```python
slope_degrees = ATAN ( √ ([dz/dx]2 + [dz/dy]2) ) * 57.29578
```

### Example 4

```python
slope_degrees = ATAN ( √ ([dz/dx]2 + [dz/dy]2) ) * 57.29578
```

### Example 5

```python
slope_degrees = ATAN (rise_run) * 57.29578
```

### Example 6

```python
slope_degrees = ATAN (rise_run) * 57.29578
```

### Example 7

```python
rise_run = √ ([dz/dx]2 + [dz/dy]2]
```

### Example 8

```python
rise_run = √ ([dz/dx]2 + [dz/dy]2]
```

### Example 9

```python
[dz/dx] = ((c + 2f + i)*4/wght1 - (a + 2d + g)*4/wght2) / (8 * x_cellsize)
```

### Example 10

```python
[dz/dx] = ((c + 2f + i)*4/wght1 - (a + 2d + g)*4/wght2) / (8 * x_cellsize)
```

### Example 11

```python
[dz/dy] = ((g + 2h + i)*4/wght3 - (a + 2b + c)*4/wght4) / (8 * y_cellsize)
```

### Example 12

```python
[dz/dy] = ((g + 2h + i)*4/wght3 - (a + 2b + c)*4/wght4) / (8 * y_cellsize)
```

### Example 13

```python
[dz/dx] = ((c + 2f + i)*4/wght1 - (a + 2d + g)*4/wght2) / (8 * x_cellsize)
          = ((50 + 60 + 10)*4/(1+2+1) - (50 + 60 + 8)*4/(1+2+1)) / (8 * 5)
          = (120 - 118) / 40
          = 0.05
```

### Example 14

```python
[dz/dx] = ((c + 2f + i)*4/wght1 - (a + 2d + g)*4/wght2) / (8 * x_cellsize)
          = ((50 + 60 + 10)*4/(1+2+1) - (50 + 60 + 8)*4/(1+2+1)) / (8 * 5)
          = (120 - 118) / 40
          = 0.05
```

### Example 15

```python
[dz/dy] = ((g + 2h + i)*4/wght3 - (a + 2b + c)*4/wght4) / (8 * y_cellsize)
          = ((8 + 20 + 10)*4/(1+2+1) - (50 + 90 + 50)*4/(1+2+1)) / (8 * 5)
          = (38 - 190 ) / 40
          = -3.8
```

### Example 16

```python
[dz/dy] = ((g + 2h + i)*4/wght3 - (a + 2b + c)*4/wght4) / (8 * y_cellsize)
          = ((8 + 20 + 10)*4/(1+2+1) - (50 + 90 + 50)*4/(1+2+1)) / (8 * 5)
          = (38 - 190 ) / 40
          = -3.8
```

### Example 17

```python
rise_run = √ ([dz/dx]2 + [dz/dy]2)
           = √ ((0.05)2 + (-3.8)2)
           = √ (0.0025 + 14.44)
           = 3.80032
```

### Example 18

```python
rise_run = √ ([dz/dx]2 + [dz/dy]2)
           = √ ((0.05)2 + (-3.8)2)
           = √ (0.0025 + 14.44)
           = 3.80032
```

### Example 19

```python
slope_degrees = ATAN (rise_run) * 57.29578
                = ATAN (3.80032) * 57.29578
                = 1.31349 * 57.29578
                = 75.25762
```

### Example 20

```python
slope_degrees = ATAN (rise_run) * 57.29578
                = ATAN (3.80032) * 57.29578
                = 1.31349 * 57.29578
                = 75.25762
```

### Example 21

```python
X = (N(φ)+h)cosφcosλ
```

### Example 22

```python
X = (N(φ)+h)cosφcosλ
```

### Example 23

```python
Y = (N(φ)+h)cosφsinλ
```

### Example 24

```python
Y = (N(φ)+h)cosφsinλ
```

### Example 25

```python
Z = (b2/a2*N(φ)+h)sinφ
```

### Example 26

```python
Z = (b2/a2*N(φ)+h)sinφ
```

### Example 27

```python
Slope_PercentRise = ATAN(β) * 100%
```

### Example 28

```python
Slope_PercentRise = ATAN(β) * 100%
```

---

## How solar radiation is calculated

## Code Samples

### Example 1

```python
Globaltot = Dirtot + Diftot
```

### Example 2

```python
Globaltot = Dirtot + Diftot
```

### Example 3

```python
Dirtot = Σ Dirθ,α    (1)
```

### Example 4

```python
Dirtot = Σ Dirθ,α    (1)
```

### Example 5

```python
Dirθ,α = SConst * βm(θ) * SunDurθ,α * SunGapθ,α * cos(AngInθ,α)    (2)
```

### Example 6

```python
Dirθ,α = SConst * βm(θ) * SunDurθ,α * SunGapθ,α * cos(AngInθ,α)    (2)
```

### Example 7

```python
m(θ) = EXP(-0.000118 * Elev - 1.638*10-9 * Elev2) / cos(θ)    (3)
```

### Example 8

```python
m(θ) = EXP(-0.000118 * Elev - 1.638*10-9 * Elev2) / cos(θ)    (3)
```

### Example 9

```python
AngInθ,α = acos( Cos(θ) * Cos(Gz) + Sin(θ) * Sin(Gz) * Cos(α-Ga) )    (4)
```

### Example 10

```python
AngInθ,α = acos( Cos(θ) * Cos(Gz) + Sin(θ) * Sin(Gz) * Cos(α-Ga) )    (4)
```

### Example 11

```python
Difθ,α = Rglb * Pdif * Dur * SkyGapθ,α * Weightθ,α * cos(AngInθ,α)    (5)
```

### Example 12

```python
Difθ,α = Rglb * Pdif * Dur * SkyGapθ,α * Weightθ,α * cos(AngInθ,α)    (5)
```

### Example 13

```python
Rglb = (SConst Σ(βm(θ))) / (1 - Pdif)    (6)
```

### Example 14

```python
Rglb = (SConst Σ(βm(θ))) / (1 - Pdif)    (6)
```

### Example 15

```python
Weightθ,α = (cosθ2- cosθ1) / Divazi    (7)
```

### Example 16

```python
Weightθ,α = (cosθ2- cosθ1) / Divazi    (7)
```

### Example 17

```python
Weightθ,α = (2cosθ2 + cos2θ2 - 2cosθ1 - cos2θ1) / 4 * Divazi    (8)
```

### Example 18

```python
Weightθ,α = (2cosθ2 + cos2θ2 - 2cosθ1 - cos2θ1) / 4 * Divazi    (8)
```

### Example 19

```python
Diftot = Σ Difθ,α    (9)
```

### Example 20

```python
Diftot = Σ Difθ,α    (9)
```

---

## How Spline works

## Code Samples

### Example 1

```python
T(x,y) = a1 + a2x + a3y
```

### Example 2

```python
T(x,y) = a1 + a2x + a3y
```

### Example 3

```python
T(x,y) = a1
```

### Example 4

```python
T(x,y) = a1
```

---

## How Surface Parameters works

## Code Samples

### Example 1

```python
X = (N(φ) + h) * cos(φ) * cos(λ)
```

### Example 2

```python
X = (N(φ) + h) * cos(φ) * cos(λ)
```

### Example 3

```python
Y = (N(φ) + h) * cos(φ) * sin(λ)
```

### Example 4

```python
Y = (N(φ) + h) * cos(φ) * sin(λ)
```

### Example 5

```python
Z = (b2 / a2 * N(φ) + h) * sin(φ)
```

### Example 6

```python
Z = (b2 / a2 * N(φ) + h) * sin(φ)
```

### Example 7

```python
N(φ) = a2 / √( a2 * cos(φ)2 + b2 * sin(φ)2)
```

### Example 8

```python
N(φ) = a2 / √( a2 * cos(φ)2 + b2 * sin(φ)2)
```

---

## How cost distance tools work

## Code Samples

### Example 1

```python
Cost = Cost of travel  *  Characteristics  *  Movement characteristics
       over surface       of the mover        on the surface
```

### Example 2

```python
Cost = Cost of travel  *  Characteristics  *  Movement characteristics
       over surface       of the mover        on the surface
```

### Example 3

```python
a1 = (cost1 + cost2) / 2
```

### Example 4

```python
a1 = (cost1 + cost2) / 2
```

### Example 5

```python
accum_cost = a1 + (cost2 + cost3) / 2
```

### Example 6

```python
accum_cost = a1 + (cost2 + cost3) / 2
```

### Example 7

```python
a1 = 1.414214 (cost3 + cost2) / 2
```

### Example 8

```python
a1 = 1.414214 (cost3 + cost2) / 2
```

### Example 9

```python
accum_cost = a1 + 1.414214(cost2 + cost3) / 2
```

### Example 10

```python
accum_cost = a1 + 1.414214(cost2 + cost3) / 2
```

---

## How the horizontal and vertical factors affect path distance

## Code Samples

### Example 1

```python
0    1.40
    10   2.43
    20   2.30
    30   3.44
    40   1.25
    50   1.02
    60   0.90
    70   0.86
    80   0.25
    90   0.78
    100  1.49
    110  2.35
    120  3.32
    130  2.39
    140  3.18
    150  2.13
    160  1.89
    170  1.20
    180  2.034
```

### Example 2

```python
-90  -1
    -80  -1
    -70   2.099409721
    -60   0.060064462
    -50   0.009064613
    -40   0.00263818
    -30   0.001055449
    -20   0.000500142
    -10   0.00025934
      0   0.000198541
     10   0.000368021
     20   0.000709735
     30   0.001497754
     40   0.003743755
     50   0.012863298
     60   0.085235529
     70   2.979204206
     80  -1
     90  -1
```

### Example 3

```python
VF = cos(VRMA)power
```

### Example 4

```python
VF = cos(VRMA)power
```

### Example 5

```python
VF = sec(VRMA)power
```

### Example 6

```python
VF = sec(VRMA)power
```

---

## How the path distance tools work

## Code Samples

### Example 1

```python
Cost = Cost of travel  *  Characteristics  *  Movement characteristics
       over surface       of the mover        on the surface
```

### Example 2

```python
Cost = Cost of travel  *  Characteristics  *  Movement characteristics
       over surface       of the mover        on the surface
```

### Example 3

```python
a1 = (cost1 + cost2) / 2
```

### Example 4

```python
a1 = (cost1 + cost2) / 2
```

### Example 5

```python
accum_cost = a1 + (cost2 + cost3) / 2
```

### Example 6

```python
accum_cost = a1 + (cost2 + cost3) / 2
```

### Example 7

```python
a1 = 1.414214(cost1 + cost2) / 2
```

### Example 8

```python
a1 = 1.414214(cost1 + cost2) / 2
```

### Example 9

```python
accum_cost = a1 + 1.414214(cost2 + cost3) / 2
```

### Example 10

```python
accum_cost = a1 + 1.414214(cost2 + cost3) / 2
```

### Example 11

```python
Cost_distance = (((Cost_surface(a) * HF(a)) + (Cost_surface(b) * HF(b)))/2)
                * Surface_distance(ab) * VF(ab)
```

### Example 12

```python
Cost_distance = (((Cost_surface(a) * HF(a)) + (Cost_surface(b) * HF(b)))/2)
                * Surface_distance(ab) * VF(ab)
```

### Example 13

```python
Cost_distance = (((Cost_surface(a) * HF(a)) + (Cost_surface(b) * HF(b)))/2)
                * 1.414214 * Surface_distance(ab) * VF(ab)
```

### Example 14

```python
Cost_distance = (((Cost_surface(a) * HF(a)) + (Cost_surface(b) * HF(b)))/2)
                * 1.414214 * Surface_distance(ab) * VF(ab)
```

### Example 15

```python
Accum_cost_distance = a1 + (((Cost_surface(b) * HF(b)) + (Cost_surface(c) * HF(c)))/2)
                      * Surface_distance(bc) * VF(bc)
```

### Example 16

```python
Accum_cost_distance = a1 + (((Cost_surface(b) * HF(b)) + (Cost_surface(c) * HF(c)))/2)
                      * Surface_distance(bc) * VF(bc)
```

---

## How the source characteristics affect cost distance analysis

## Code Samples

### Example 1

```python
accum_cost = a1 + (cost2 + cost3)/2
```

### Example 2

```python
accum_cost = a1 + (cost2 + cost3)/2
```

### Example 3

```python
accum_cost = a1 + (1.4142 * ((cost2 + cost3)/2))
```

### Example 4

```python
accum_cost = a1 + (1.4142 * ((cost2 + cost3)/2))
```

### Example 5

```python
accum_cost = a1 + ((((cost2 * HF(2)) + (cost3 * HF(3)))/2) * Surface_distance(23) * VF(23))
```

### Example 6

```python
accum_cost = a1 + ((((cost2 * HF(2)) + (cost3 * HF(3)))/2) * Surface_distance(23) * VF(23))
```

### Example 7

```python
accum_cost = a1 + ((((cost2 * HF(2)) + (cost3 * HF(3)))/2) * 1.414214 * Surface_distance(23) * VF(23))
```

### Example 8

```python
accum_cost = a1 + ((((cost2 * HF(2)) + (cost3 * HF(3)))/2) * 1.414214 * Surface_distance(23) * VF(23))
```

### Example 9

```python
accum_cost = (a1 * (1.0 + resistance_rate) + (((cost2 + cost3) / 2) * cost_multiplier))
```

### Example 10

```python
accum_cost = (a1 * (1.0 + resistance_rate) + (((cost2 + cost3) / 2) * cost_multiplier))
```

### Example 11

```python
accum_cost = (a1 * (1 + resistance_rate)) + ((((cost2 * HF(2)) + (cost3 * HF(3)))/2) 
              * Surface_distance(23) * VF(23) * cost_multiplier)
```

### Example 12

```python
accum_cost = (a1 * (1 + resistance_rate)) + ((((cost2 * HF(2)) + (cost3 * HF(3)))/2) 
              * Surface_distance(23) * VF(23) * cost_multiplier)
```

### Example 13

```python
a1 = (((cost1 + cost2) / 2) * cost_multiplier)
```

### Example 14

```python
a1 = (((cost1 + cost2) / 2) * cost_multiplier)
```

### Example 15

```python
a1 = starting_cost + (((cost1 + cost2) / 2) * cost_multiplier)
```

### Example 16

```python
a1 = starting_cost + (((cost1 + cost2) / 2) * cost_multiplier)
```

### Example 17

```python
a5 = c1 + c2 (1+r) + c3 (1+r)2 + c4(1+r)3 + c5(1+r)4
```

### Example 18

```python
a5 = c1 + c2 (1+r) + c3 (1+r)2 + c4(1+r)3 + c5(1+r)4
```

### Example 19

```python
a5 = c1 (1+r)4 + c2 (1+r)3 + c3 (1+r)2 + c4 (1+r) + c5
```

### Example 20

```python
a5 = c1 (1+r)4 + c2 (1+r)3 + c3 (1+r)2 + c4 (1+r) + c5
```

---

## How Trend works

## Code Samples

### Example 1

```python
coef #          coef
------ ----------------
     0 -1192066.7888371
     1 -1.78479492586755
     2 -0.195982103615487
     3 -8.87072249743903e-1
     4 -2.0538267625596e-1
     5 -3.85610088343239e-1
     6 -1.46420255709888e-2
     7 -5.31539027745154e-2
     8 -2.59261094879031e-3
     9 9.71651459136166e-4
------ ----------------
RMS Error  = 296.957857221845
Chi-Square  = 17019506.0103975
```

### Example 2

```python
Prediction(x,y) = c0 + 
                  x·c1 + y·c2 + 
                  x2·c3 + x·y·c4 + y2·c5 +
                  x3·c6 + x2·y·c7 + x·y2·c8 + y3·c9
```

---

## How zonal statistics tools work

## Code Samples

### Example 1

```python
Zonal Range = Zonal Maximum – Zonal Minimum
```

### Example 2

```python
Zonal Range = Zonal Maximum – Zonal Minimum
```

---

## IDW (Spatial Analyst)

## Summary

Interpolates a raster surface from points using an inverse distance weighted (IDW) technique.

## Usage

- The output value for a cell using inverse distance weighting (IDW) is limited to the range of the values used to interpolate. Because IDW is a weighted distance average, the average cannot be greater than the highest or less than the lowest input. Therefore, it cannot create ridges or valleys if these extremes have not already been sampled (Watson and Philip 1985).
- The best results from IDW are obtained when sampling is sufficiently dense with regard to the local variation you are attempting to simulate. If the sampling of input points is sparse or uneven, the results may not sufficiently represent the desired surface (Watson and Philip 1985).
- The influence of an input point on an interpolated value is isotropic. Since the influence of an input point on an interpolated value is distance related, IDW is not ridge preserving (Philip and Watson 1982).
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Some input datasets may have several points with the same x,y coordinates. If the values of the points at the common location are the same, they are considered duplicates and have no effect on the output. If the values are different, they are considered coincident points.The various interpolation tools may handle this data condition differently. For example, in some cases, the first coincident point encountered is used for the calculation; in other cases, the last point encountered is used. This may cause some locations in the output raster to have different values than what you might expect. The solution is to prepare your data by removing these coincident points. The Collect Events tool in the Spatial Statistics toolbox is useful for identifying any coincident points in your data.
- The barriers option is used to specify the location of linear features known to interrupt the surface continuity. These features do not have z-values. Cliffs, faults, and embankments are typical examples of barriers. Barriers limit the selected set of the input sample points used to interpolate output z-values to those samples on the same side of the barrier as the current processing cell. Separation by a barrier is determined by line-of-sight analysis between each pair of points. This means that topological separation is not required for two points to be excluded from each other's region of influence. Input sample points that lie exactly on the barrier line will be included in the selected sample set for both sides of the barrier.
- Barrier features are input as polyline features. IDW only uses the x,y coordinates for the linear feature; therefore, it is not necessary to provide z-values for the left and right sides of the barrier. Any z-values provided will be ignored.
- Using barriers will significantly extend the processing time.
- This tool has a limit of approximately 45 million input points. If your input feature class contains more than 45 million points, the tool may fail to create a result. You can avoid this limit by interpolating your study area in several pieces, making sure there is some overlap in the edges, then mosaicking the results to create a single large raster dataset. Alternatively, you can use a terrain dataset to store and visualize points and surfaces comprised of billions of measurement points.If you have the Geostatistical Analyst extension, you may be able to process larger datasets with the version of the IDW tool available there.
- The input feature data must contain at least one valid field.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- References:Philip, G. M., and D. F. Watson. "A Precise Method for Determining Contoured Surfaces." Australian Petroleum Exploration Association Journal 22: 205–212. 1982.Watson, D. F., and G. M. Philip. "A Refinement of Inverse Distance Weighted Interpolation." Geoprocessing 2:315–327. 1985.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| Z value field | The field that holds a height or magnitude value for each point.This can be a numeric field or the Shape field if the input point features contain z-values. | Field |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Power(Optional) | The exponent of distance.Controls the significance of surrounding points on the interpolated value. A higher power results in less influence from distant points. It can be any real number greater than 0, but the most reasonable results will be obtained using values from 0.5 to 3. The default is 2. | Double |
| Search radius(Optional) | Defines which of the input points will be used to interpolate the value for each cell in the output raster.There are two options: Variable and Fixed. Variable is the default. VariableUses a variable search radius in order to find a specified number of input sample points for the interpolation. Number of points—An integer value specifying the number of nearest input sample points to be used to perform interpolation. The default is 12 points. Maximum distance—Specifies the distance, in map units, by which to limit the search for the nearest input sample points. The default value is the length of the extent's diagonal. Fixed Uses a specified fixed distance within which all input points will be used for the interpolation. Distance—Specifies the distance as a radius within which input sample points will be used to perform the interpolation. The value of the radius is expressed in map units. The default radius is five times the cell size of the output raster. Minimum number of points—An integer defining the minimum number of points to be used for interpolation. The default value is 0. If the required number of points is not found within the specified distance, the search distance will be increased until the specified minimum number of points is found. When the search radius needs to be increased it is done so until the Minimum number of points fall within that radius, or the extent of the radius crosses the lower (southern) and/or upper (northern) extent of the output raster. NoData is assigned to all locations that do not satisfy the above condition. | Radius |
| Input barrier polyline features(Optional) | Polyline features to be used as a break or limit in searching for the input sample points. | Feature Layer |
| in_point_features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| z_field | The field that holds a height or magnitude value for each point.This can be a numeric field or the Shape field if the input point features contain z-values. | Field |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| power(Optional) | The exponent of distance.Controls the significance of surrounding points on the interpolated value. A higher power results in less influence from distant points. It can be any real number greater than 0, but the most reasonable results will be obtained using values from 0.5 to 3. The default is 2. | Double |
| search_radius(Optional) | The Radius class defines which of the input points will be used to interpolate the value for each cell in the output raster.There are two types of radius classes: RadiusVariable and RadiusFixed. A Variable search radius is used to find a specified number of input sample points for the interpolation. The Fixed type uses a specified fixed distance within which all input points will be used for the interpolation. The Variable type is the default. RadiusVariable ({numberofPoints}, {maxDistance}) {numberofPoints}—An integer value specifying the number of nearest input sample points to be used to perform interpolation. The default is 12 points. {maxDistance}—Specifies the distance, in map units, by which to limit the search for the nearest input sample points. The default value is the length of the extent's diagonal. RadiusFixed ({distance}, {minNumberofPoints}) {distance}—Specifies the distance as a radius within which input sample points will be used to perform the interpolation. The value of the radius is expressed in map units. The default radius is five times the cell size of the output raster. {minNumberofPoints}—An integer defining the minimum number of points to be used for interpolation. The default value is 0. If the required number of points is not found within the specified distance, the search distance will be increased until the specified minimum number of points is found. When the search radius needs to be increased it is done so until the {minNumberofPoints} fall within that radius, or the extent of the radius crosses the lower (southern) and/or upper (northern) extent of the output raster. NoData is assigned to all locations that do not satisfy the above condition. | Radius |
| in_barrier_polyline_features(Optional) | Polyline features to be used as a break or limit in searching for the input sample points. | Feature Layer |

## Code Samples

### Example 1

```python
Idw(in_point_features, z_field, {cell_size}, {power}, {search_radius}, {in_barrier_polyline_features})
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outIDW = Idw("ozone_pts.shp", "ozone", 2000, 2, RadiusVariable(10, 150000))
outIDW.save("C:/sapyexamples/output/idwout.tif")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outIDW = Idw("ozone_pts.shp", "ozone", 2000, 2, RadiusVariable(10, 150000))
outIDW.save("C:/sapyexamples/output/idwout.tif")
```

### Example 4

```python
# Name: IDW_Ex_02.py
# Description: Interpolate a series of point features onto a rectangular 
#   raster using Inverse Distance Weighting (IDW).
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "ca_ozone_pts.shp"
zField = "ozone"
cellSize = 2000.0
power = 2
searchRadius = RadiusVariable(10, 150000)

# Execute IDW
outIDW = Idw(inPointFeatures, zField, cellSize, power, searchRadius)

# Save the output 
outIDW.save("C:/sapyexamples/output/idwout02")
```

### Example 5

```python
# Name: IDW_Ex_02.py
# Description: Interpolate a series of point features onto a rectangular 
#   raster using Inverse Distance Weighting (IDW).
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "ca_ozone_pts.shp"
zField = "ozone"
cellSize = 2000.0
power = 2
searchRadius = RadiusVariable(10, 150000)

# Execute IDW
outIDW = Idw(inPointFeatures, zField, cellSize, power, searchRadius)

# Save the output 
outIDW.save("C:/sapyexamples/output/idwout02")
```

---

## InList (Spatial Analyst)

## Summary

Determines which values from the first input are contained in a set of other inputs, on a cell-by-cell basis.

## Usage

- If all of the inputs are integer, the output raster will be integer. If any of the inputs are floating point, the output will be floating point.
- In the list of input rasters, the order is not relevant to the outcome of this tool.
- If the Process as multiband parameter is unchecked (process_as_multiband is set to SINGLE_BAND in Python), only the first band of a multiband Input raster or constant value (input_raster_or_constant in Python) will be used. Each band from a multiband Input rasters or constant values (in_rasters_or_constants in Python) will be processed separately as a single band raster.
- If the Process as multiband parameter is checked (process_as_multiband is set to MULTI_BAND in Python), each multiband raster input will be processed as a multiband raster.The number of bands in the output depends on the Input raster or constant value parameter. If the input raster is a single band or a constant, the number of bands in the output raster will be the same as the maximum number of bands of all multiband rasters from the Input rasters or constant values. If the input raster is a multiband, the output raster will have the same number of bands as the input raster. If any of the Input rasters or constant values is a raster with a smaller number of bands than the output raster, the missing bands will be interpreted as a band filled with NoData. If any of the entries in the input list is a constant, it will be interpreted as a multiband raster in which the cell values of all bands are the same as the constant and have the same number of bands as the output raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input that defines the value that will be looked for in a list of rasters on a cell-by-cell basis.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant values | A list of input rasters that the first input will be evaluated against. For each location, if the cell value from the first input exists in any of the other rasters, that value will be assigned to the output raster. If the value does not exist in any of the other rasters, the output value at that location will be NoData. A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Process as multiband(Optional) | Specifies how the input multiband raster bands will be processed. Unchecked—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.Checked—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |
| in_raster_or_constant | The input that defines the value that will be looked for in a list of rasters on a cell-by-cell basis.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constants[in_raster_or_constant,...] | A list of input rasters that the first input will be evaluated against. For each location, if the cell value from the first input exists in any of the other rasters, that value will be assigned to the output raster. If the value does not exist in any of the other rasters, the output value at that location will be NoData. A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| process_as_multiband(Optional) | Specifies how the input multiband raster bands will be processed. SINGLE_BAND—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.MULTI_BAND—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |

## Code Samples

### Example 1

```python
InList(in_raster_or_constant, in_raster_or_constants, {process_as_multiband})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outInList = InList("redlandsc1", ["redlandsc2", "redlandsc3"])
outInList.save("C:/sapyexamples/output/outinlist.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outInList = InList("redlandsc1", ["redlandsc2", "redlandsc3"])
outInList.save("C:/sapyexamples/output/outinlist.tif")
```

### Example 4

```python
# Name: InList_Ex_02.py
# Description: Determines which values from the first input are
#              contained in the other inputs
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "redlandsc1"
inRaster2 = "redlandsc2"
inRaster3 = "redlandsc3"

# Execute InList
outInList = InList(inRaster1, [inRaster2, inRaster3])

# Save the output 
outInList.save("C:/sapyexamples/output/outinlist")
```

### Example 5

```python
# Name: InList_Ex_02.py
# Description: Determines which values from the first input are
#              contained in the other inputs
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "redlandsc1"
inRaster2 = "redlandsc2"
inRaster3 = "redlandsc3"

# Execute InList
outInList = InList(inRaster1, [inRaster2, inRaster3])

# Save the output 
outInList.save("C:/sapyexamples/output/outinlist")
```

---

## Inspect Training Samples (Spatial Analyst)

## Summary

Estimates the accuracy of individual training samples. The cross validation accuracy is computed using the previously generated classification training result in an .ecd file and the training samples. Outputs include a raster dataset containing the misclassified class values and a training sample dataset with the accuracy score for each training sample.

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The input raster to be classified. | Mosaic Layer; Raster Layer; Image Service; String |
| Input Training Sample File | A training sample feature class created in the Training Samples Manager pane. | Feature Layer |
| Input Classifier Definition File | The .ecd output classifier file from any of the train classifier tools. The .ecd file is a JSON file that contains attribute information, statistics, or other information needed for the classifier. | File |
| Output Training Sample Feature Class with Score | The output individual training samples saved as a feature class. The associated attribute table contains an addition field listing the accuracy score. | Feature Class |
| Output Misclassified Raster | The output misclassified raster having NoData outside training samples. In training samples, correctly classified pixels are represented as NoData, and misclassified pixels are represented by their class value. The results is an index map of misclassified class values. | Raster Dataset |
| Additional Input Raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for the classifier. This raster is necessary when calculating attributes such as mean or standard deviation. This parameter is optional. | Mosaic Layer; Raster Layer; Image Service; String |
| in_raster | The input raster to be classified. | Mosaic Layer; Raster Layer; Image Service; String |
| in_training_features | A training sample feature class created in the Training Samples Manager pane. | Feature Layer |
| in_classifier_definition | The .ecd output classifier file from any of the train classifier tools. The .ecd file is a JSON file that contains attribute information, statistics, or other information needed for the classifier. | File |
| out_training_feature_class | The output individual training samples saved as a feature class. The associated attribute table contains an addition field listing the accuracy score. | Feature Class |
| out_misclassified_raster | The output misclassified raster having NoData outside training samples. In training samples, correctly classified pixels are represented as NoData, and misclassified pixels are represented by their class value. The results is an index map of misclassified class values. | Raster Dataset |
| in_additional_raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for the classifier. This raster is necessary when calculating attributes such as mean or standard deviation. This parameter is optional. | Mosaic Layer; Raster Layer; Image Service; String |

## Code Samples

### Example 1

```python
InspectTrainingSamples(in_raster, in_training_features, in_classifier_definition, out_training_feature_class, out_misclassified_raster, {in_additional_raster})
```

### Example 2

```python
### InspectTrainingSamples example 1 (Python window)
import arcpy
from arcpy.sa import *

in_img = "C:/Data/wv2.tif"
trn_samples1 = "C:/out/ts.shp"
ecd = "C:/Data/svm.ecd"
seg_in_img = "C:/Data/seg.tif"
trn_samples2 = "C:/out/ts2.shp"

out_misclassified_raster = InspectTrainingSamples(in_img, trn_samples, ecd,
                                                  trn_samples2, seg_in_img); 
out_misclassified_raster.save("C:/temp/misclassified.tif")
```

### Example 3

```python
### InspectTrainingSamples example 1 (Python window)
import arcpy
from arcpy.sa import *

in_img = "C:/Data/wv2.tif"
trn_samples1 = "C:/out/ts.shp"
ecd = "C:/Data/svm.ecd"
seg_in_img = "C:/Data/seg.tif"
trn_samples2 = "C:/out/ts2.shp"

out_misclassified_raster = InspectTrainingSamples(in_img, trn_samples, ecd,
                                                  trn_samples2, seg_in_img); 
out_misclassified_raster.save("C:/temp/misclassified.tif")
```

### Example 4

```python
### InspectTrainingSamples example 2 (stand-alone script)
import arcpy
from arcpy.sa import *

out_misclassified_raster = InspectTrainingSamples("C:/Data/wv2.tif", 
                                                  "C:/out/ts.shp", 
                                                  "C:/Data/svm.ecd", 
                                                  "C:/out/ts2.shp", 
                                                  "C:/Data/seg.tif"); 
out_misclassified_raster.save("C:/temp/misclassified.tif")
```

### Example 5

```python
### InspectTrainingSamples example 2 (stand-alone script)
import arcpy
from arcpy.sa import *

out_misclassified_raster = InspectTrainingSamples("C:/Data/wv2.tif", 
                                                  "C:/out/ts.shp", 
                                                  "C:/Data/svm.ecd", 
                                                  "C:/out/ts2.shp", 
                                                  "C:/Data/seg.tif"); 
out_misclassified_raster.save("C:/temp/misclassified.tif")
```

---

## Int (Spatial Analyst)

## Summary

Converts each cell value of a raster to an integer by truncation.

## Usage

- The input values can be either positive or negative.
- If rounding is preferred to truncating, add a 0.5 input raster prior to performing the operation.
- There is a difference between the Int tool and the Round Down tool. For example, given the following two values, Int always truncates the number: 1.5 becomes 1-1.5 becomes -1For the same two values, Round Down returns the following: 1.5 becomes 1.0-1.5 becomes -2.0 Another difference is that Round Down outputs floating-point values, while Int only outputs integer values.
- 1.5 becomes 1
- -1.5 becomes -1
- 1.5 becomes 1.0
- -1.5 becomes -2.0
- The maximum supported range of integer raster values is -2,147,483,648 (minimum size determined by -231) to 2,147,483,647 (maximum size determined by 231 – 1). If Int is used on a floating-point raster which has cells with values outside this range, those cells will be NoData in the output raster.
- Storing categorical (discrete) data as an integer raster will use significantly less disk space than the same information stored as a floating-point raster. Whenever possible, it is recommended to convert floating-point rasters to integer with this tool.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input raster to be converted to integer.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input raster to be converted to integer.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Int(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outInt = Int("gwhead")
outInt.save("C:/sapyexamples/output/outint2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outInt = Int("gwhead")
outInt.save("C:/sapyexamples/output/outint2")
```

### Example 4

```python
# Name: Int_Ex_02.py
# Description: Converts each cell value of a raster to an integer by truncation
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "gwhead"

# Execute Int
outInt = Int(inRaster)

# Save the output 
outInt.save("C:/sapyexamples/output/outint")
```

### Example 5

```python
# Name: Int_Ex_02.py
# Description: Converts each cell value of a raster to an integer by truncation
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "gwhead"

# Execute Int
outInt = Int(inRaster)

# Save the output 
outInt.save("C:/sapyexamples/output/outint")
```

---

## Interpolate Shape (Spatial Analyst)

## Summary

Creates 3D features by interpolating z-values from a surface.

## Usage

- This tool creates 3D features using height values derived from overlapping portions of the input surface. A 3D polygon will only store z-values on its perimeter, since the interior of a 3D polygon will be randomly defined when it is rendered. For this reason, 3D polygons are generally not suitable for representing nonplanar height information. To generate a true representation of the surface, use the Interpolate Polygon To Multipatch tool.
- Any curved line or polygon segments will be densified based on the Sampling Distance parameter value. If a sampling distance is not defined, this value will be derived from the input surface. For a raster, the default sampling size will be the raster's cell size. For a TIN, terrain, or LAS dataset, the default sampling will be based on the edges produced by the triangulated surface. If the curve is shorter than the sampling size, the curve will be simplified into a two-point line using its start and end points.
- When using natural neighbors interpolation, consider specifying a sampling distance that's equal to or above half of the average point spacing of the data points in the surface.
- When using the Interpolate Vertices Only parameter, features with vertices that fall outside the data area of the surface will not be part of the output unless the input surface is a raster and the nearest neighbor interpolation method is used.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Surface | The surface that will be used for interpolating z-values. | LAS Dataset Layer; Mosaic Layer; Raster Layer; Terrain Layer; TIN Layer; Image Service |
| Input Features | The input features that will be processed. | Feature Layer |
| Output Feature Class | The feature class that will be produced. | Feature Class |
| Sampling Distance(Optional) | The spacing at which z-values will be interpolated. By default, this is a raster dataset's cell size or a triangulated surface's natural densification. | Double |
| Z Factor(Optional) | The factor by which z-values will be multiplied. This is typically used to convert z linear units to match x,y linear units. The default is 1, which leaves elevation values unchanged. This parameter is not available if the spatial reference of the input surface has a z-datum with a specified linear unit. | Double |
| Method (Optional) | Specifies the interpolation method that will be used to determine elevation values for the output features. The available options depend on the surface type.Bilinear—The value of the query point will be determined using bilinear interpolation. This is the default when the input is a raster surface.Nearest Neighbor—The value of the query point will be determined using nearest neighbor interpolation. With this method, surface values will only be interpolated for the input feature's vertices. This option is only available for a raster surface.Linear—Elevation values will be obtained from the plane defined by the triangle that contains the x,y-location of a query point. This is the default interpolation method for TIN, terrain, and LAS datasets. Natural Neighbors—Elevation values will be obtained by applying area-based weights to the natural neighbors of a query point.Conflate Minimum Z— Elevation values will be obtained from the smallest z-value found among the natural neighbors of a query point.Conflate Maximum Z—Elevation values will be obtained from the largest z-value found among the natural neighbors of a query point.Conflate Nearest Z— Elevation values will be obtained from the nearest value among the natural neighbors of a query point.Conflate Z Closest To Mean— Elevation values will be obtained from the z-value that is closest to the average of all the natural neighbors of a query point. | String |
| Interpolate Vertices Only(Optional) | Specifies whether the interpolation will only occur along the vertices of an input feature, ignoring the sample distance option. When the input surface is a raster and the nearest neighbor interpolation method is selected, the z-values can only be interpolated at the feature vertices.Checked—Interpolation will only occur along the vertices.Unchecked—Interpolation will occur using the sampling distance. This is the default. | Boolean |
| Pyramid Level Resolution(Optional) | The z-tolerance or window-size resolution of the terrain pyramid level that will be used. The default is 0, or full resolution. | Double |
| Preserve features partially outside surface (Optional) | Specifies whether features with one or more vertices that fall outside the raster's data area will be retained in the output. This parameter is only available when the input surface is a raster and the nearest neighbor interpolation method is used.Checked—Each vertex that falls outside the raster surface will have its z-value derived from the trend of z-values calculated for the vertices within the raster surface and will be retained in the output.Unchecked—Features with at least one vertex that falls outside the raster surface will be skipped in the output. This is the default. | Boolean |
| in_surface | The surface that will be used for interpolating z-values. | LAS Dataset Layer; Mosaic Layer; Raster Layer; Terrain Layer; TIN Layer; Image Service |
| in_feature_class | The input features that will be processed. | Feature Layer |
| out_feature_class | The feature class that will be produced. | Feature Class |
| sample_distance(Optional) | The spacing at which z-values will be interpolated. By default, this is a raster dataset's cell size or a triangulated surface's natural densification. | Double |
| z_factor(Optional) | The factor by which z-values will be multiplied. This is typically used to convert z linear units to match x,y linear units. The default is 1, which leaves elevation values unchanged. This parameter is not available if the spatial reference of the input surface has a z-datum with a specified linear unit. | Double |
| method(Optional) | Specifies the interpolation method that will be used to determine elevation values for the output features. The available options depend on the surface type. BILINEAR—The value of the query point will be determined using bilinear interpolation. This is the default when the input is a raster surface.NEAREST—The value of the query point will be determined using nearest neighbor interpolation. With this method, surface values will only be interpolated for the input feature's vertices. This option is only available for a raster surface.LINEAR—Elevation values will be obtained from the plane defined by the triangle that contains the x,y-location of a query point. This is the default interpolation method for TIN, terrain, and LAS datasets. NATURAL_NEIGHBORS—Elevation values will be obtained by applying area-based weights to the natural neighbors of a query point.CONFLATE_ZMIN— Elevation values will be obtained from the smallest z-value found among the natural neighbors of a query point.CONFLATE_ZMAX—Elevation values will be obtained from the largest z-value found among the natural neighbors of a query point.CONFLATE_NEAREST— Elevation values will be obtained from the nearest value among the natural neighbors of a query point.CONFLATE_CLOSEST_TO_MEAN— Elevation values will be obtained from the z-value that is closest to the average of all the natural neighbors of a query point. | String |
| vertices_only(Optional) | Specifies whether the interpolation will only occur along the vertices of an input feature, ignoring the sample distance option.DENSIFY—Interpolation will occur using the sampling distance. This is the default.VERTICES_ONLY—Interpolation will only occur along the vertices. | Boolean |
| pyramid_level_resolution(Optional) | The z-tolerance or window-size resolution of the terrain pyramid level that will be used. The default is 0, or full resolution. | Double |
| preserve_features(Optional) | Specifies whether features with one or more vertices that fall outside the raster's data area will be retained in the output. This parameter is only available when the input surface is a raster and the nearest neighbor interpolation method is used.PRESERVE—Each vertex that falls outside the raster surface will have its z-value derived from the trend of z-values calculated for the vertices within the raster surface and will be retained in the output.EXCLUDE—Features with at least one vertex that falls outside the raster surface will be skipped in the output. This is the default. | Boolean |

## Code Samples

### Example 1

```python
InterpolateShape(in_surface, in_feature_class, out_feature_class, {sample_distance}, {z_factor}, {method}, {vertices_only}, {pyramid_level_resolution}, {preserve_features})
```

### Example 2

```python
from arcpy.sa import *
InterpolateShape("my_tin", "roads.shp", "roads_interp.shp")
```

### Example 3

```python
from arcpy.sa import *
InterpolateShape("my_tin", "roads.shp", "roads_interp.shp")
```

### Example 4

```python
# Name: InterpolateShape_Ex_02.py
# Description: This script demonstrates how to use InterpolateShape on the 2D
# features in a target workspace.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/arcpyExamples/data"

# Set the local variables
inFeatureClass = "point.shp"
inSurface = "dtm_tin"
OutFeatureClass = "point_interp.shp"
method = "NEAREST"

# Execute the tool
InterpolateShape(inSurface, inFeatureClass, OutFeatureClass, 15, 1, method, True)
```

### Example 5

```python
# Name: InterpolateShape_Ex_02.py
# Description: This script demonstrates how to use InterpolateShape on the 2D
# features in a target workspace.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/arcpyExamples/data"

# Set the local variables
inFeatureClass = "point.shp"
inSurface = "dtm_tin"
OutFeatureClass = "point_interp.shp"
method = "NEAREST"

# Execute the tool
InterpolateShape(inSurface, inFeatureClass, OutFeatureClass, 15, 1, method, True)
```

---

## Is Null (Spatial Analyst)

## Summary

Determines which values from the input raster are NoData on a cell-by-cell basis.

## Usage

- Is Null can be used along with the Con tool to change NoData cells to a value.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster being tested to identify the cells that are NoData (null).The input can be either integer or floating-point type. | Raster Layer |
| in_raster | The input raster being tested to identify the cells that are NoData (null).The input can be either integer or floating-point type. | Raster Layer |

## Code Samples

### Example 1

```python
IsNull(in_raster)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outIsNull = IsNull("degs")
outIsNull.save("C:/sapyexamples/output/outisnull.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outIsNull = IsNull("degs")
outIsNull.save("C:/sapyexamples/output/outisnull.img")
```

### Example 4

```python
# Name: IsNull_Ex_02.py
# Description: Find which cell values of the input raster are NoData
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute IsNull
outIsNull = IsNull(inRaster)

# Save the output 
outIsNull.save("C:/sapyexamples/output/outisnull")
```

### Example 5

```python
# Name: IsNull_Ex_02.py
# Description: Find which cell values of the input raster are NoData
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute IsNull
outIsNull = IsNull(inRaster)

# Save the output 
outIsNull.save("C:/sapyexamples/output/outisnull")
```

---

## Iso Cluster Unsupervised Classification (Spatial Analyst)

## Summary

Performs unsupervised classification on a series of input raster bands using the Iso Cluster and Maximum Likelihood Classification tools.

## Usage

- This tool combines the functionalities of the Iso Cluster and Maximum Likelihood Classification tools. It outputs a classified raster. It optionally outputs a signature file.
- When a multiband raster is specified as one of the Input raster bands (in_raster_bands in Python), all the bands will be used.To process a selection of bands from a multiband raster, you can first create a new raster dataset composed of those particular bands with the Composite Bands tool, and use the result in the list of the Input raster bands (in_raster_bands in Python).
- The resulting signature file from this tool can be used as the input for another classification tool, such as Maximum Likelihood Classification, for greater control over the classification parameters.
- The minimum valid value for the number of classes is two. There is no maximum number of clusters. In general, more clusters require more iterations.
- To provide the sufficient statistics necessary to generate a signature file for a future classification, each cluster should contain enough cells to accurately represent the cluster. The value entered for the minimum class size should be approximately 10 times larger than the number of layers in the input raster bands.
- The value entered for the sample interval indicates one cell out of every n-by-n block of cells is used in the cluster calculations.
- You shouldn't merge or remove classes or change any of the statistics of the ASCII signature file.
- Generally, the more cells contained in the extent of the intersection of the input bands, the larger the values for minimum class size and sample interval should be specified. Values entered for the sample interval should be small enough that the smallest desirable categories existing in the input data will be appropriately sampled.
- The class ID values on the output signature file start at one and sequentially increase to the number of input classes. The assignment of the class numbers is arbitrary.
- The output signature file's name must have a .gsg extension.
- Better results will be obtained if all input bands have the same data ranges. If the bands have vastly different data ranges, the data ranges can be transformed to the same range using Map Algebra to perform the equation. where: Z is the output raster with new data ranges. X is the input raster. oldmin is the minimum value of the input raster. oldmax is the maximum value of the input raster. newmin is the desired minimum value for the output raster. newmax is the desired maximum value for the output raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster bands | The input raster bands.They can be integer or floating point type. | Raster Layer; Mosaic Layer |
| Number of classes | Number of classes into which to group the cells. | Long |
| Minimum class size(Optional) | Minimum number of cells in a valid class.The default is 20. | Long |
| Sample interval(Optional) | The interval to be used for sampling.The default is 10. | Long |
| Output signature file(Optional) | The output signature file.A .gsg extension must be specified. | File |
| Input_raster_bands[in_raster_band,...] | The input raster bands.They can be integer or floating point type. | Raster Layer; Mosaic Layer |
| Number_of_classesnumber_of_classes | Number of classes into which to group the cells. | Long |
| Minimum_class_sizeminimum_class_size(Optional) | Minimum number of cells in a valid class.The default is 20. | Long |
| Sample_intervalsample_interval(Optional) | The interval to be used for sampling.The default is 10. | Long |
| Output_signature_fileout_signature_file(Optional) | The output signature file.A .gsg extension must be specified. | File |

## Code Samples

### Example 1

```python
where:
   Z is the output raster with new data ranges.
   X is the input raster.
   oldmin is the minimum value of the input raster.
   oldmax is the maximum value of the input raster.
   newmin is the desired minimum value for the output raster.
   newmax is the desired maximum value for the output raster.
```

### Example 2

```python
IsoClusterUnsupervisedClassification(Input_raster_bands, Number_of_classes, {Minimum_class_size}, {Sample_interval}, {Output_signature_file})
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outUnsupervised = IsoClusterUnsupervisedClassification("redlands", 5, 20, 50)
outUnsupervised.save("c:/temp/unsup01")
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outUnsupervised = IsoClusterUnsupervisedClassification("redlands", 5, 20, 50)
outUnsupervised.save("c:/temp/unsup01")
```

### Example 5

```python
# Name: IsoClusterUnsupervisedClassification_Ex_02.py
# Description: Uses an isodata clustering algorithm to determine the 
#    characteristics of the natural groupings of cells in multidimensional 
#    attribute space and stores the results in an output ASCII signature file.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "redlands"
classes = 5
minMembers = 50
sampInterval = 15

# Execute IsoCluster
outUnsupervised = IsoClusterUnsupervisedClassification(inRaster, classes, minMembers, sampInterval)
outUnsupervised.save("c:/temp/outunsup01.tif")
```

### Example 6

```python
# Name: IsoClusterUnsupervisedClassification_Ex_02.py
# Description: Uses an isodata clustering algorithm to determine the 
#    characteristics of the natural groupings of cells in multidimensional 
#    attribute space and stores the results in an output ASCII signature file.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "redlands"
classes = 5
minMembers = 50
sampInterval = 15

# Execute IsoCluster
outUnsupervised = IsoClusterUnsupervisedClassification(inRaster, classes, minMembers, sampInterval)
outUnsupervised.save("c:/temp/outunsup01.tif")
```

---

## Iso Cluster (Spatial Analyst)

## Summary

Uses an isodata clustering algorithm to determine the characteristics of the natural groupings of cells in multidimensional attribute space and stores the results in an output ASCII signature file.

## Usage

- Iso Cluster performs clustering of the multivariate data combined in a list of input bands. The resulting signature file can be used as the input for a classification tool, such as Maximum Likelihood Classification, that produces an unsupervised classification raster.
- When a multiband raster is specified as one of the Input raster bands (in_raster_bands in Python), all the bands will be used.To process a selection of bands from a multiband raster, you can first create a new raster dataset composed of those particular bands with the Composite Bands tool, and use the result in the list of the Input raster bands (in_raster_bands in Python).
- The minimum valid value for the number of classes is two. There is no maximum number of clusters. In general, more clusters require more iterations.
- To provide the sufficient statistics necessary to generate a signature file for a future classification, each cluster should contain enough cells to accurately represent the cluster. The value entered for the minimum class size should be approximately 10 times larger than the number of layers in the input raster bands.
- The value entered for the sample interval indicates one cell out of every n-by-n block of cells is used in the cluster calculations.
- You shouldn't merge or remove classes or change any of the statistics of the ASCII signature file.
- Generally, the more cells contained in the extent of the intersection of the input bands, the larger the values for minimum class size and sample interval should be specified. Values entered for the sample interval should be small enough that the smallest desirable categories existing in the input data will be appropriately sampled.
- The class ID values on the output signature file start at one and sequentially increase to the number of input classes. The assignment of the class numbers is arbitrary.
- Better results will be obtained if all input bands have the same data ranges. If the bands have vastly different data ranges, the data ranges can be transformed to the same range using Map Algebra to perform the equation. where: Z is the output raster with new data ranges. X is the input raster. oldmin is the minimum value of the input raster. oldmax is the maximum value of the input raster. newmin is the desired minimum value for the output raster. newmax is the desired maximum value for the output raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster bands | The input raster bands.They can be integer or floating point type. | Raster Layer |
| Output signature file | The output signature file.A .gsg extension must be specified. | File |
| Number of classes | Number of classes into which to group the cells. | Long |
| Number of iterations(Optional) | Number of iterations of the clustering process to run.The default is 20. | Long |
| Minimum class size(Optional) | Minimum number of cells in a valid class.The default is 20. | Long |
| Sample interval(Optional) | The interval to be used for sampling.The default is 10. | Long |
| in_raster_bands[in_raster_band,...] | The input raster bands.They can be integer or floating point type. | Raster Layer |
| out_signature_file | The output signature file.A .gsg extension must be specified. | File |
| number_classes | Number of classes into which to group the cells. | Long |
| number_iterations(Optional) | Number of iterations of the clustering process to run.The default is 20. | Long |
| min_class_size(Optional) | Minimum number of cells in a valid class.The default is 20. | Long |
| sample_interval(Optional) | The interval to be used for sampling.The default is 10. | Long |

## Code Samples

### Example 1

```python
where:
   Z is the output raster with new data ranges.
   X is the input raster.
   oldmin is the minimum value of the input raster.
   oldmax is the maximum value of the input raster.
   newmin is the desired minimum value for the output raster.
   newmax is the desired maximum value for the output raster.
```

### Example 2

```python
IsoCluster(in_raster_bands, out_signature_file, number_classes, {number_iterations}, {min_class_size}, {sample_interval})
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
IsoCluster("redlands", "c:/sapyexamples/output/isosig.gsg", 5, 20, 50, 15)
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
IsoCluster("redlands", "c:/sapyexamples/output/isosig.gsg", 5, 20, 50, 15)
```

### Example 5

```python
# Name: IsoCluster_Ex_02.py
# Description: Uses an isodata clustering algorithm to determine the 
#    characteristics of the natural groupings of cells in multidimensional 
#    attribute space and stores the results in an output ASCII signature file.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "redlands"
outSig = "redlndiso.gsg"
classes = 5
cycles = 20
minMembers = 50
sampInterval = 15

# Execute IsoCluster
IsoCluster(inRaster, outSig, classes, cycles, minMembers, sampInterval)
```

### Example 6

```python
# Name: IsoCluster_Ex_02.py
# Description: Uses an isodata clustering algorithm to determine the 
#    characteristics of the natural groupings of cells in multidimensional 
#    attribute space and stores the results in an output ASCII signature file.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "redlands"
outSig = "redlndiso.gsg"
classes = 5
cycles = 20
minMembers = 50
sampInterval = 15

# Execute IsoCluster
IsoCluster(inRaster, outSig, classes, cycles, minMembers, sampInterval)
```

---

## Kernel Density (Spatial Analyst)

## Summary

Calculates a magnitude-per-unit area from point or polyline features using a kernel function to fit a smoothly tapered surface to each point or polyline. A barrier can be used to alter the influence of a feature while calculating kernel density.

## Usage

- Very large or very small values in the Population field (population_field in Python) parameter can produce results that may seem non-intuitive. If the mean of the population field is much larger than 1 (for example, as with city populations), the default search radius may be very small, resulting in small rings around the input points. If the mean of the population field is much smaller than 1, the calculated search radius may seem unreasonably large. In these cases, you can enter your own search radius.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Larger values of the Search radius (search_radius in Python) parameter produce a smoother, more generalized density raster. Smaller values produce a raster that shows more detail.
- The default search radius is calculated based on the spatial configuration and number of input points. This approach corrects for spatial outliers—input points that are very far away from the rest—so they will not make the search radius unreasonably large.
- If the area unit scale factor units are small relative to the features (distance between points or length of line sections, depending on feature type), the output values may be small. To obtain larger values, select the area unit scale factor for larger units (for example, square kilometers versus square meters).
- The Output cell values (out_cell_values in Python) parameter specifies what the output raster values represent. If Densities is chosen, the values represent the kernel density value per unit area for each cell. If Expected counts is chosen, the values represent the kernel density per cell area. The equation that calculates the counts from the density values is Count = Density × Area.
- The Planar option in the Method (method in Python) parameter is appropriate if the analysis is to be performed at a local scale with a projection that accurately maintains the correct distance and area. The Geodesic option is appropriate if the analysis is to be performed at a regional or large scale (for example, using Web Mercator or any geographic coordinate system). This method takes into account the curvature of the spheroid and correctly handles data near the poles and the international dateline.
- Only the points or portions of a line that fall within the neighborhood are considered when calculating density. If no points or line sections fall within the neighborhood of a particular cell, that cell is assigned NoData.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- References: Silverman, B. W. Density Estimation for Statistics and Data Analysis. New York: Chapman and Hall, 1986.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point or polyline features | The input features (point or line) for which to calculate the density. | Feature Layer |
| Population field | The field denoting population values for each feature. The population field is the count or quantity to be spread across the landscape to create a continuous surface.Values in the population field can be integer or floating point.The options and default behaviors for the field are listed below.Use None if no item or special value will be used and each feature will be counted once.You can use the Shape field if input features contain z-values.Otherwise, the default field is POPULATION. The following conditions may also apply:If there is no POPULATION field, but there is a POPULATIONabcd field, it will be used by default. The 'abcd' can be any valid characters, for example, POPULATION6, POPULATION1974, or POPULATIONROADTYPE.If there is no POPULATION field or POPULATIONabcd field, but there is a POP field, the POP field will be used by default.If there is no POPULATION field, POPULATIONabcd field, or POP field, but there is a POPabcd field, the POPabcd field will be used by default.If there is no POPULATION field, POPULATIONabcd field, POP field, or POPabcd field, NONE will be used by default. | Field |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Search radius(Optional) | The search radius within which density will be calculated. Units are based on the linear unit of the projection of the output spatial reference.For example, if the units are meters—to include all features within a one-mile neighborhood—set the search radius equal to 1609.344 (1 mile = 1609.344 meters).The default search radius is computed specifically for the input dataset using a spatial variant of Silverman's Rule of Thumb (Silverman, 1986) that is robust enough for spatial outliers (points that are far away from the rest of the points). See the usage tips for a description of the algorithm. | Double |
| Area units(Optional) | Specifies the area units that will be used for the output density values.A default unit is determined based on the linear unit of the output spatial reference. You can change this to the appropriate unit to convert the density output. Values for line density convert the units of both length and area.If no output spatial reference is specified, the output spatial reference will be the same as the input feature class. The default output density units are determined by the linear units of the output spatial reference . If the output linear units are meters, the output area density units will be set to Square kilometers, outputting square kilometers for point features or kilometers per square kilometers for polyline features. If the output linear units are feet, the output area density units will be set to Square miles.If the output units are anything other than feet or meters, the output area density units will be set to Square map units. That is, the output density units will be the square of the linear units of the output spatial reference. For example, if the output linear units are centimeters, the output area density units will be Square map units, which will result in square centimeters. If the output linear units are kilometers, the output area density units will be Square map units, which will result in square kilometers.The available options and their corresponding output density units are the following:Square map units—The square of the linear units of the output spatial reference will be used.Square miles—U.S. miles will be used.Square kilometers—Kilometers will be used.Acres—U.S. acres will be used.Hectares—Hectares will be used.Square yards—U.S. yards will be used.Square feet—U.S. feet will be used.Square inches—U.S. inches will be used.Square meters—Meters will be used.Square centimeters—Centimeters will be used.Square millimeters—Millimeters will be used. | String |
| Output cell values(Optional) | Specifies what the values in the output raster represent.Since the cell value is linked to the specified cell size, the resulting raster cannot be resampled to a different cell size.Densities—The output values represent the calculated density value per unit area for each cell. This is the default.Expected counts—The output values represent the calculated density value per cell area. | String |
| Method(Optional) | Specifies whether the flat earth (planar) or the shortest path on a spheroid (geodesic) method will be used.The geodesic method only supports points as input features.Planar—The planar distance between features will be used. This is the default.Geodesic—The geodesic distance between features will be used. | String |
| Input barrier features(Optional) | The dataset that defines the barriers.The barriers can be a feature layer of polyline or polygon features. | Feature Layer |
| in_features | The input features (point or line) for which to calculate the density. | Feature Layer |
| population_field | The field denoting population values for each feature. The population field is the count or quantity to be spread across the landscape to create a continuous surface.Values in the population field can be integer or floating point.The options and default behaviors for the field are listed below.Use None if no item or special value will be used and each feature will be counted once.You can use the Shape field if input features contain z-values.Otherwise, the default field is POPULATION. The following conditions may also apply:If there is no POPULATION field, but there is a POPULATIONabcd field, it will be used by default. The 'abcd' can be any valid characters, for example, POPULATION6, POPULATION1974, or POPULATIONROADTYPE.If there is no POPULATION field or POPULATIONabcd field, but there is a POP field, the POP field will be used by default.If there is no POPULATION field, POPULATIONabcd field, or POP field, but there is a POPabcd field, the POPabcd field will be used by default.If there is no POPULATION field, POPULATIONabcd field, POP field, or POPabcd field, NONE will be used by default. | Field |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| search_radius(Optional) | The search radius within which density will be calculated. Units are based on the linear unit of the projection of the output spatial reference.For example, if the units are meters—to include all features within a one-mile neighborhood—set the search radius equal to 1609.344 (1 mile = 1609.344 meters).The default search radius is computed specifically for the input dataset using a spatial variant of Silverman's Rule of Thumb (Silverman, 1986) that is robust enough for spatial outliers (points that are far away from the rest of the points). See the usage tips for a description of the algorithm. | Double |
| area_unit_scale_factor(Optional) | Specifies the area units that will be used for the output density values.A default unit is determined based on the linear unit of the output spatial reference. You can change this to the appropriate unit to convert the density output. Values for line density convert the units of both length and area.If no output spatial reference is specified, the output spatial reference will be the same as the input feature class. The default output density units are determined by the linear units of the output spatial reference . If the output linear units are meters, the output area density units will be set to Square kilometers, outputting square kilometers for point features or kilometers per square kilometers for polyline features. If the output linear units are feet, the output area density units will be set to Square miles.If the output units are anything other than feet or meters, the output area density units will be set to Square map units. That is, the output density units will be the square of the linear units of the output spatial reference. For example, if the output linear units are centimeters, the output area density units will be Square map units, which will result in square centimeters. If the output linear units are kilometers, the output area density units will be Square map units, which will result in square kilometers.The available options and their corresponding output density units are the following:SQUARE_MAP_UNITS—The square of the linear units of the output spatial reference will be used.SQUARE_MILES—U.S. miles will be used.SQUARE_KILOMETERS—Kilometers will be used.ACRES—U.S. acres will be used.HECTARES—Hectares will be used.SQUARE_YARDS—U.S. yards will be used.SQUARE_FEET—U.S. feet will be used.SQUARE_INCHES—U.S. inches will be used.SQUARE_METERS—Meters will be used.SQUARE_CENTIMETERS—Centimeters will be used.SQUARE_MILLIMETERS—Millimeters will be used. | String |
| out_cell_values(Optional) | Specifies what the values in the output raster represent.DENSITIES—The output values represent the calculated density value per unit area for each cell. This is the default.EXPECTED_COUNTS—The output values represent the calculated density value per cell area. Since the cell value is linked to the specified cell size, the resulting raster cannot be resampled to a different cell size. | String |
| method(Optional) | Specifies whether the flat earth (planar) or the shortest path on a spheroid (geodesic) method will be used.PLANAR—The planar distance between features will be used. This is the default.GEODESIC—The geodesic distance between features will be used. The geodesic method only supports points as input features. | String |
| in_barriers(Optional) | The dataset that defines the barriers.The barriers can be a feature layer of polyline or polygon features. | Feature Layer |

## Code Samples

### Example 1

```python
KernelDensity(in_features, population_field, {cell_size}, {search_radius}, {area_unit_scale_factor}, {out_cell_values}, {method}, {in_barriers})
```

### Example 2

```python
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outKDens = KernelDensity("rec_sites.shp", "", 45, 1200, "SQUARE_KILOMETERS",
                         "", "GEODESIC")
outKDens.save("C:/sapyexamples/output/KD_out.tif")
```

### Example 3

```python
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outKDens = KernelDensity("rec_sites.shp", "", 45, 1200, "SQUARE_KILOMETERS",
                         "", "GEODESIC")
outKDens.save("C:/sapyexamples/output/KD_out.tif")
```

### Example 4

```python
# Name: KernelDensity_Ex_02.py
# Description: Calculates the ozone concentration pattern divided by
#              Sierra Nevada Mountain in California
#              based on the point samples using a kernel function to
#              fit a smoothly tapered surface.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFeatures = "ozone_california.shp"
populationField = "OZONE"
cellSize = 60
searchRadius = 2500
inBarriers = "SierraNevada.shp"

# Execute KernelDensity
outKernelDensity = KernelDensity(inFeatures, populationField, cellSize, searchRadius,
                                 "SQUARE_KILOMETERS", "DENSITIES", "PLANAR", inBarriers)

# Save the output 
outKernelDensity.save("C:/sapyexamples/output/KD_ozone_california.tif")
```

### Example 5

```python
# Name: KernelDensity_Ex_02.py
# Description: Calculates the ozone concentration pattern divided by
#              Sierra Nevada Mountain in California
#              based on the point samples using a kernel function to
#              fit a smoothly tapered surface.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFeatures = "ozone_california.shp"
populationField = "OZONE"
cellSize = 60
searchRadius = 2500
inBarriers = "SierraNevada.shp"

# Execute KernelDensity
outKernelDensity = KernelDensity(inFeatures, populationField, cellSize, searchRadius,
                                 "SQUARE_KILOMETERS", "DENSITIES", "PLANAR", inBarriers)

# Save the output 
outKernelDensity.save("C:/sapyexamples/output/KD_ozone_california.tif")
```

---

## Kriging (Spatial Analyst)

## Summary

Interpolates a raster surface from points using kriging.

## Usage

- Kriging is a processor-intensive process. The speed of execution is dependent on the number of points in the input dataset and the size of the search window.
- Low values within the optional output variance of prediction raster indicate a high degree of confidence in the predicted value. High values may indicate a need for more data points.
- The Universal kriging types assume that there is a structural component present and that the local trend varies from one location to another.
- The Semivariogram properties allow control of the semivariogram used for kriging. A default value for Lag size is initially set to the default output cell size. For Major range, Partial sill, and Nugget, a default value will be calculated internally if nothing is specified.
- The optional output variance of prediction raster contains the kriging variance at each output raster cell. Assuming the kriging errors are normally distributed, there is a 95.5 percent probability that the actual z-value at the cell is the predicted raster value, plus or minus two times the square root of the value in the variance raster.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Some input datasets may have several points with the same x,y coordinates. If the values of the points at the common location are the same, they are considered duplicates and have no effect on the output. If the values are different, they are considered coincident points.The various interpolation tools may handle this data condition differently. For example, in some cases, the first coincident point encountered is used for the calculation; in other cases, the last point encountered is used. This may cause some locations in the output raster to have different values than what you might expect. The solution is to prepare your data by removing these coincident points. The Collect Events tool in the Spatial Statistics toolbox is useful for identifying any coincident points in your data.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| Z value field | The field that holds a height or magnitude value for each point.This can be a numeric field or the Shape field if the input point features contain z-values. | Field |
| Semivariogram properties | The Semivariogram model to be used. There are two methods for kriging: Ordinary and Universal.Ordinary kriging can use the following semivariogram models:Spherical—Spherical semivariogram model. This is the default.Circular—Circular semivariogram model.Exponential—Exponential semivariogram model.Gaussian—Gaussian or normal distribution semivariogram model.Linear—Linear semivariogram model with a sill.Universal kriging can use the following semivariogram models:Linear with Linear drift—Universal Kriging with linear drift.Linear with Quadratic drift—Universal Kriging with quadratic drift.There are options available via the Advanced Parameters dialog box. These parameters are:Lag size—The default is the output raster cell size.Major range—Represents a distance beyond which there is little or no correlation.Partial sill—The difference between the nugget and the sill.Nugget—Represents the error and variation at spatial scales too fine to detect. The nugget effect is seen as a discontinuity at the origin. | KrigingModel |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Search radius(Optional) | Defines which of the input points will be used to interpolate the value for each cell in the output raster.There are two options: Variable and Fixed. Variable is the default. VariableUses a variable search radius in order to find a specified number of input sample points for the interpolation. Number of points—An integer value specifying the number of nearest input sample points to be used to perform interpolation. The default is 12 points. Maximum distance—Specifies the distance, in map units, by which to limit the search for the nearest input sample points. The default value is the length of the extent's diagonal. Fixed Uses a specified fixed distance within which all input points will be used for the interpolation. Distance—Specifies the distance as a radius within which input sample points will be used to perform the interpolation. The value of the radius is expressed in map units. The default radius is five times the cell size of the output raster. Minimum number of points—An integer defining the minimum number of points to be used for interpolation. The default value is 0. If the required number of points is not found within the specified distance, the search distance will be increased until the specified minimum number of points is found. When the search radius needs to be increased it is done so until the Minimum number of points fall within that radius, or the extent of the radius crosses the lower (southern) and/or upper (northern) extent of the output raster. NoData is assigned to all locations that do not satisfy the above condition. | Radius |
| Output variance of prediction raster(Optional) | Optional output raster where each cell contains the predicted variance values for that location. | Raster Dataset |
| in_point_features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| z_field | The field that holds a height or magnitude value for each point.This can be a numeric field or the Shape field if the input point features contain z-values. | Field |
| semiVariogram_propskriging_model | The KrigingModel class defines which kriging model is to be used.There are two types of kriging classes. The KrigingModelOrdinary method has five types of semivariograms available. The KrigingModelUniversal method has two types of semivariograms available. KrigingModelOrdinary ({semivariogramType}, {lagSize}, {majorRange}, {partialSill}, {nugget}) semivariogramType—The semivariogram model to be used. The available models include the following: SPHERICAL—Spherical semivariogram model. This is the default. CIRCULAR—Circular semivariogram model. EXPONENTIAL—Exponential semivariogram model. GAUSSIAN—Gaussian (or normal distribution) semivariogram model. LINEAR—Linear semivariogram model with a sill. KrigingModelUniversal ({semivariogramType}, {lagSize}, {majorRange}, {partialSill}, {nugget}) semivariogramType—The semivariogram model to be used. The available models include the following: LINEARDRIFT—Universal Kriging with linear drift. QUADRATICDRIFT—Universal Kriging with quadratic drift. After the {semivariogramType}, the other parameters are common between Ordinary and Universal kriging. lagSize—The default is the output raster cell size. majorRange—Represents a distance beyond which there is little or no correlation. partialSill—The difference between the nugget and the sill. nugget—Represents the error and variation at spatial scales too fine to detect. The nugget effect is seen as a discontinuity at the origin. | KrigingModel |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| search_radius(Optional) | The Radius class defines which of the input points will be used to interpolate the value for each cell in the output raster.There are two types of radius classes: RadiusVariable and RadiusFixed. A Variable search radius is used to find a specified number of input sample points for the interpolation. The Fixed type uses a specified fixed distance within which all input points will be used for the interpolation. The Variable type is the default. RadiusVariable ({numberofPoints}, {maxDistance}) {numberofPoints}—An integer value specifying the number of nearest input sample points to be used to perform interpolation. The default is 12 points. {maxDistance}—Specifies the distance, in map units, by which to limit the search for the nearest input sample points. The default value is the length of the extent's diagonal. RadiusFixed ({distance}, {minNumberofPoints}) {distance}—Specifies the distance as a radius within which input sample points will be used to perform the interpolation. The value of the radius is expressed in map units. The default radius is five times the cell size of the output raster. {minNumberofPoints}—An integer defining the minimum number of points to be used for interpolation. The default value is 0. If the required number of points is not found within the specified distance, the search distance will be increased until the specified minimum number of points is found. When the search radius needs to be increased it is done so until the {minNumberofPoints} fall within that radius, or the extent of the radius crosses the lower (southern) and/or upper (northern) extent of the output raster. NoData is assigned to all locations that do not satisfy the above condition. | Radius |
| out_variance_prediction_raster(Optional) | Optional output raster where each cell contains the predicted variance values for that location. | Raster Dataset |

## Code Samples

### Example 1

```python
Kriging(in_point_features, z_field, semiVariogram_props, {cell_size}, {search_radius}, {out_variance_prediction_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outKrig = Kriging("ozone_pts.shp", "OZONE", KrigingModelOrdinary("CIRCULAR", 2000, 2.6, 542, 0), 2000, RadiusFixed(20000, 1))
outKrig.save("c:/sapyexamples/output/krigout")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outKrig = Kriging("ozone_pts.shp", "OZONE", KrigingModelOrdinary("CIRCULAR", 2000, 2.6, 542, 0), 2000, RadiusFixed(20000, 1))
outKrig.save("c:/sapyexamples/output/krigout")
```

### Example 4

```python
# Name: Kriging_Ex_02.py
# Description: Interpolates a surface from points using kriging.
# Requirements: Spatial Analyst Extension
# Import system modules

import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFeatures = "ca_ozone_pts.shp"
field = "OZONE"
cellSize = 2000
outVarRaster = "C:/sapyexamples/output/outvariance"
lagSize = 2000
majorRange = 2.6
partialSill = 542
nugget = 0

# Set complex variables
kModelOrdinary = KrigingModelOrdinary("CIRCULAR", lagSize,
                                majorRange, partialSill, nugget)
kRadius = RadiusFixed(20000, 1)



# Execute Kriging
outKriging = Kriging(inFeatures, field, kModelOrdinary, cellSize,
                     kRadius, outVarRaster)

# Save the output 
outKriging.save("C:/sapyexamples/output/krigoutput02")
```

### Example 5

```python
# Name: Kriging_Ex_02.py
# Description: Interpolates a surface from points using kriging.
# Requirements: Spatial Analyst Extension
# Import system modules

import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFeatures = "ca_ozone_pts.shp"
field = "OZONE"
cellSize = 2000
outVarRaster = "C:/sapyexamples/output/outvariance"
lagSize = 2000
majorRange = 2.6
partialSill = 542
nugget = 0

# Set complex variables
kModelOrdinary = KrigingModelOrdinary("CIRCULAR", lagSize,
                                majorRange, partialSill, nugget)
kRadius = RadiusFixed(20000, 1)



# Execute Kriging
outKriging = Kriging(inFeatures, field, kModelOrdinary, cellSize,
                     kRadius, outVarRaster)

# Save the output 
outKriging.save("C:/sapyexamples/output/krigoutput02")
```

---

## Least Cost Corridor (Spatial Analyst)

## Summary

Calculates the sum of two accumulative cost distance rasters with the option to apply a threshold based on percentage or accumulative cost.

## Usage

- The input rasters should be distance accumulation and back direction rasters output from the Distance Accumulation or Distance Allocation tools.
- Use the cost version of the distance accumulation rasters. The units of the rasters can be, but are not limited to, dollars per meter, preference per foot, or minutes per meter depending on the application. These cost units are captured in the cost surface. For additional information, see Adjust the encountered distance using a cost surface.
- Corridors are nondirectional, meaning that traveling from the first source to the second source costs the same as traveling from the second source to the first source. When creating the accumulative cost distance and back direction rasters, do not specify values for any parameters that depend on directionality, those being the horizontal factor, vertical factor, and travel direction.
- Use the same parameter settings for the Distance Accumulation or Distance Allocation tool when creating the first source's accumulative cost distance and back direction rasters, as well as the second source's accumulative cost distance and back direction rasters.
- All input rasters must be floating-point type and must have the same cell size, extent, and spatial reference.
- The values on the output corridor represent the sum of the accumulative cost to reach a given location with the same units as the input accumulative cost distance rasters.
- If a specified threshold value is greater than the maximum accumulative cost when the two distance accumulation rasters are summed, the output corridor raster will cover the same area as the input accumulative rasters.
- If a specified threshold value is less than the minimum value in the corridor raster, a warning message is returned, and the output raster will be empty.
- The output corridor raster may contain cells with slightly greater accumulative costs than the threshold value. This is from the back direction rasters using cells assigned slightly higher costs than the threshold to connect disconnected cells to the corridor. For additional information, see Connect locations with corridors.
- To generate a corridor, the Cell Size environment setting is ignored, and the cell size of the input accumulative cost rasters will be used to calculate the output raster. The pattern of the input rasters would be altered if the output were resampled to a different resolution.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input accumulative cost distance raster 1 | The input raster representing the accumulative cost distance from the first source.Use the distance accumulation output from the Distance Accumulation or Distance Allocation tool. | Raster Layer |
| Input back direction raster 1 | The input back direction raster from the first source. The units are degrees identifying the next cell along the least-cost path back to the first source.Use the back direction output from the Distance Accumulation or Distance Allocation tool. The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north). | Raster Layer |
| Input accumulative cost distance raster 2 | The input raster representing the accumulative cost distance from the second source.Use the distance accumulation output from the Distance Accumulation or Distance Allocation tool. | Raster Layer |
| Input back direction raster 2 | The input back direction raster from the second source. The units are degrees identifying the next cell along the least-cost path back to the second source.Use the back direction output from the Distance Accumulation or Distance Allocation tool. The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north). | Raster Layer |
| Threshold method | Specifies how the threshold will be defined.No threshold—No threshold will be applied, and the resulting corridor will cover the full extent of the input rasters. This is the default.Percent of least cost—The threshold will be defined as a percent of the minimum value of the summed accumulative cost distance rasters.Accumulative cost—The threshold will be defined in accumulative cost distance units. | String |
| Threshold | A percent or accumulative cost threshold that determines whether a given cell will be included in the output corridor raster. When the Threshold method parameter is set to Percent of least cost, the specified value indicates the percent increase to apply from the minimum value of the summed accumulative cost distance rasters. When the Threshold method parameter is set to Accumulative cost, the value indicates cells that have a summed accumulative cost equal to or below the value will be included in the corridor.This parameter is only active if the Threshold method parameter is set to Percent of least cost or Accumulative cost. | Double |
| in_accumulative_cost_distance_raster1 | The input raster representing the accumulative cost distance from the first source.Use the distance accumulation output from the Distance Accumulation or Distance Allocation tool. | Raster Layer |
| in_back_direction_raster1 | The input back direction raster from the first source. The units are degrees identifying the next cell along the least-cost path back to the first source.Use the back direction output from the Distance Accumulation or Distance Allocation tool. The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north). | Raster Layer |
| in_accumulative_cost_distance_raster2 | The input raster representing the accumulative cost distance from the second source.Use the distance accumulation output from the Distance Accumulation or Distance Allocation tool. | Raster Layer |
| in_back_direction_raster2 | The input back direction raster from the second source. The units are degrees identifying the next cell along the least-cost path back to the second source.Use the back direction output from the Distance Accumulation or Distance Allocation tool. The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north). | Raster Layer |
| threshold_method | Specifies how the threshold will be defined.NO_THRESHOLD—No threshold will be applied, and the resulting corridor will cover the full extent of the input rasters. This is the default.PERCENT_OF_LEAST_COST—The threshold will be defined as a percent of the minimum value of the summed accumulative cost distance rasters.ACCUMULATIVE_COST—The threshold will be defined in accumulative cost distance units. | String |
| threshold | A percent or accumulative cost threshold that determines whether a given cell will be included in the output corridor raster. When the threshold_method parameter is set to PERCENT_OF_LEAST_COST, the specified value indicates the percent increase to apply from the minimum value of the summed accumulative cost distance rasters. When the threshold_method parameter is set to ACCUMULATIVE_COST, the value indicates cells that have a summed accumulative cost equal to or below the value will be included in the corridor.This parameter is only enabled if the threshold_method parameter is set to PERCENT_OF_LEAST_COST or ACCUMULATIVE_COST. | Double |

## Code Samples

### Example 1

```python
LeastCostCorridor(in_accumulative_cost_distance_raster1, in_back_direction_raster1, in_accumulative_cost_distance_raster2, in_back_direction_raster2, threshold_method, threshold)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/arcpyexamples/data"
out_LCC_raster = LeastCostCorridor("DistAccumRaster1.tif", "BackDirRaster1.tif",
                                   "DistAccumRaster2.tif", "BackDirRaster2.tif") 
out_LCC_raster.save("c:/arcpyexamples/output/corridor.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/arcpyexamples/data"
out_LCC_raster = LeastCostCorridor("DistAccumRaster1.tif", "BackDirRaster1.tif",
                                   "DistAccumRaster2.tif", "BackDirRaster2.tif") 
out_LCC_raster.save("c:/arcpyexamples/output/corridor.tif")
```

### Example 4

```python
# Name: LeastCostCorridor_Ex_02.py
# Description: Calculates a potential wildlife corridor between two known 
#               protected areas.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/arcpyexamples/data"

# Set local variables
in_accumulative_cost_distance_raster1 = "distaccum_s1.tif"
in_back_direction_raster1 = "backdir_s1.tif"
in_accumulative_cost_distance_raster2 = "distaccum_s2.tif"
in_back_direction_raster2 = "backdir_s2.tif"
threshold_method = "ACCUMULATIVE_COST" 
threshold = 500

# Run Least Cost Corridor
out_LCC_raster = LeastCostCorridor(
    in_accumulative_cost_distance_raster1, in_back_direction_raster1, 
    in_accumulative_cost_distance_raster2, in_back_direction_raster2, 
    "ACCUMULATIVE_COST", "500")

# Save the output 
out_LCC_raster.save("c:/arcpyexamples/output/corridor.tif")
```

### Example 5

```python
# Name: LeastCostCorridor_Ex_02.py
# Description: Calculates a potential wildlife corridor between two known 
#               protected areas.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/arcpyexamples/data"

# Set local variables
in_accumulative_cost_distance_raster1 = "distaccum_s1.tif"
in_back_direction_raster1 = "backdir_s1.tif"
in_accumulative_cost_distance_raster2 = "distaccum_s2.tif"
in_back_direction_raster2 = "backdir_s2.tif"
threshold_method = "ACCUMULATIVE_COST" 
threshold = 500

# Run Least Cost Corridor
out_LCC_raster = LeastCostCorridor(
    in_accumulative_cost_distance_raster1, in_back_direction_raster1, 
    in_accumulative_cost_distance_raster2, in_back_direction_raster2, 
    "ACCUMULATIVE_COST", "500")

# Save the output 
out_LCC_raster.save("c:/arcpyexamples/output/corridor.tif")
```

---

## Less Than Equal (Spatial Analyst)

## Summary

Performs a Relational less-than-or-equal-to operation on two inputs on a cell-by-cell basis.

## Usage

- Two inputs are necessary for this relational evaluation to take place.
- The order of inputs is relevant for this tool.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "<=" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input being tested to determine if it is less than or equal to the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input against which the first input is tested to be less than or equal to.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input being tested to determine if it is less than or equal to the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input against which the first input is tested to be less than or equal to.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
LessThanEqual(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLTE = LessThanEqual("degs", "negs")
outLTE.save("C:/sapyexamples/output/outlte.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLTE = LessThanEqual("degs", "negs")
outLTE.save("C:/sapyexamples/output/outlte.img")
```

### Example 4

```python
# Name: LessThanEqual_Ex_02.py
# Description: Performs a relational less-than-equal operation on two
#              inputs on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute LessThanEqual
outLTE = LessThanEqual(inRaster1, inRaster2)

# Save the output 
outLTE.save("C:/sapyexamples/output/outlte")
```

### Example 5

```python
# Name: LessThanEqual_Ex_02.py
# Description: Performs a relational less-than-equal operation on two
#              inputs on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute LessThanEqual
outLTE = LessThanEqual(inRaster1, inRaster2)

# Save the output 
outLTE.save("C:/sapyexamples/output/outlte")
```

---

## Less Than Frequency (Spatial Analyst)

## Summary

Evaluates on a cell-by-cell basis the number of times a set of rasters is less than another raster.

## Usage

- An arbitrary number of rasters can be specified in the input rasters list.
- If a cell location contains NoData on any of the input rasters, that location will be assigned NoData on the output.
- The output raster is always of integer type.
- If all inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process, otherwise an error will occur.If all of the inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before performing the operation.If one or more of the inputs are multidimensional rasters and the other inputs are constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input value raster | For each cell location in the input value raster, the number of occurrences (frequency) where a raster in the input list has a lesser value is counted. | Raster Layer |
| Input rasters | The list of rasters that will be compared to the value raster. | Raster Layer |
| Process as multiband(Optional) | Specifies how the input multiband raster bands will be processed.Unchecked—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.Checked—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |
| in_value_raster | For each cell location in the input value raster, the number of occurrences (frequency) where a raster in the input list has a lesser value is counted. | Raster Layer |
| in_rasters[in_raster,...] | The list of rasters that will be compared to the value raster. | Raster Layer |
| process_as_multiband(Optional) | Specifies how the input multiband raster bands will be processed.SINGLE_BAND—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.MULTI_BAND—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |

## Code Samples

### Example 1

```python
LessThanFrequency(in_value_raster, in_rasters, {process_as_multiband})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLTF = LessThanFrequency("cost", ["degs", "negs", "fourgrd"])
outLTF.save("C:/sapyexamples/output/outltf.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLTF = LessThanFrequency("cost", ["degs", "negs", "fourgrd"])
outLTF.save("C:/sapyexamples/output/outltf.img")
```

### Example 4

```python
# Name: LessThanFrequency_Ex_02.py
# Description: Evaluates the number of times a set of rasters is
#              less than another raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inValueRaster = "cost"
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute LessThanFrequency
outLTF = LessThanFrequency(inValueRaster, [inRaster01, inRaster02, inRaster03])

# Save the output 
outLTF.save("C:/sapyexamples/output/outltf")
```

### Example 5

```python
# Name: LessThanFrequency_Ex_02.py
# Description: Evaluates the number of times a set of rasters is
#              less than another raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inValueRaster = "cost"
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute LessThanFrequency
outLTF = LessThanFrequency(inValueRaster, [inRaster01, inRaster02, inRaster03])

# Save the output 
outLTF.save("C:/sapyexamples/output/outltf")
```

---

## Less Than (Spatial Analyst)

## Summary

Performs a Relational less-than operation on two inputs on a cell-by-cell basis.

## Usage

- Two inputs are necessary for this relational evaluation to take place.
- The order of inputs is relevant for this tool.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "<" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input being tested to determine if it is less than the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input against which the first input is tested to be less than.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input being tested to determine if it is less than the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input against which the first input is tested to be less than.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
LessThan(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLessThan = LessThan("degs", "negs")
outLessThan.save("C:/sapyexamples/output/outlt.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLessThan = LessThan("degs", "negs")
outLessThan.save("C:/sapyexamples/output/outlt.tif")
```

### Example 4

```python
# Name: LessThan_Ex_02.py
# Description: Performs a relational less-than operation on two inputs
#              on a cell-by-cell basis within the Analysis window
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute LessThan
outLessThan = LessThan(inRaster1, inRaster2)

# Save the output 
outLessThan.save("C:/sapyexamples/output/outlt")
```

### Example 5

```python
# Name: LessThan_Ex_02.py
# Description: Performs a relational less-than operation on two inputs
#              on a cell-by-cell basis within the Analysis window
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute LessThan
outLessThan = LessThan(inRaster1, inRaster2)

# Save the output 
outLessThan.save("C:/sapyexamples/output/outlt")
```

---

## Line Density (Spatial Analyst)

## Summary

Calculates a magnitude-per-unit area from polyline features that fall within a radius around each cell.

## Usage

- Only the portion of a line within the neighborhood is considered when calculating the density. If no lines fall within the neighborhood at a particular cell, that cell is assigned NoData.
- Larger values of the radius parameter produce a more generalized density raster. Smaller values produce a raster that shows more detail.
- The values on the output raster will always be floating point.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- If the area unit scale factor units are small relative to the features (length of line sections), the output values may be small. To obtain larger values, use the area unit scale factor for larger units (for example, square kilometers versus square meters).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input polyline features | The input line features for which to calculate the density. | Feature Layer |
| Population field | Numeric field denoting population values (the number of times the line should be counted) for each polyline.Values in the population field can be integer or floating point.The options and default behaviors for the field are listed below.Use None if no item or special value will be used and each feature will be counted once.You can use the Shape field if input features contain z-values.Otherwise, the default field is POPULATION. The following conditions may also apply:If there is no POPULATION field, but there is a POPULATIONabcd field, it will be used by default. The 'abcd' can be any valid characters, for example, POPULATION6, POPULATION1974, or POPULATIONROADTYPE.If there is no POPULATION field or POPULATIONabcd field, but there is a POP field, the POP field will be used by default.If there is no POPULATION field, POPULATIONabcd field, or POP field, but there is a POPabcd field, the POPabcd field will be used by default.If there is no POPULATION field, POPULATIONabcd field, POP field, or POPabcd field, NONE will be used by default. | Field |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Search radius(Optional) | The search radius within which density will be calculated. Units are based on the linear unit of the projection of the output spatial reference.For example, if the units are meters—to include all features within a one-mile neighborhood—set the search radius equal to 1609.344 (1 mile = 1609.344 meters).The default is the shortest of the width or height of the output extent in the output spatial reference, divided by 30. | Double |
| Area units(Optional) | Specifies the area units that will be used for the output density values.A default unit is determined based on the linear unit of the output spatial reference. You can change this to the appropriate unit to convert the density output. Values for line density convert the units of both length and area.If no output spatial reference is specified, the output spatial reference will be the same as the input feature class. The default output density units are determined by the linear units of the output spatial reference . If the output linear units are meters, the output area density units will be set to Square kilometers, outputting square kilometers for point features or kilometers per square kilometers for polyline features. If the output linear units are feet, the output area density units will be set to Square miles.If the output units are anything other than feet or meters, the output area density units will be set to Square map units. That is, the output density units will be the square of the linear units of the output spatial reference. For example, if the output linear units are centimeters, the output area density units will be Square map units, which will result in square centimeters. If the output linear units are kilometers, the output area density units will be Square map units, which will result in square kilometers.The available options and their corresponding output density units are the following:Square map units—The square of the linear units of the output spatial reference will be used.Square miles—U.S. miles will be used.Square kilometers—Kilometers will be used.Acres—U.S. acres will be used.Hectares—Hectares will be used.Square yards—U.S. yards will be used.Square feet—U.S. feet will be used.Square inches—U.S. inches will be used.Square meters—Meters will be used.Square centimeters—Centimeters will be used.Square millimeters—Millimeters will be used. | String |
| in_polyline_features | The input line features for which to calculate the density. | Feature Layer |
| population_field | Numeric field denoting population values (the number of times the line should be counted) for each polyline.Values in the population field can be integer or floating point.The options and default behaviors for the field are listed below.Use None if no item or special value will be used and each feature will be counted once.You can use the Shape field if input features contain z-values.Otherwise, the default field is POPULATION. The following conditions may also apply:If there is no POPULATION field, but there is a POPULATIONabcd field, it will be used by default. The 'abcd' can be any valid characters, for example, POPULATION6, POPULATION1974, or POPULATIONROADTYPE.If there is no POPULATION field or POPULATIONabcd field, but there is a POP field, the POP field will be used by default.If there is no POPULATION field, POPULATIONabcd field, or POP field, but there is a POPabcd field, the POPabcd field will be used by default.If there is no POPULATION field, POPULATIONabcd field, POP field, or POPabcd field, NONE will be used by default. | Field |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| search_radius(Optional) | The search radius within which density will be calculated. Units are based on the linear unit of the projection of the output spatial reference.For example, if the units are meters—to include all features within a one-mile neighborhood—set the search radius equal to 1609.344 (1 mile = 1609.344 meters).The default is the shortest of the width or height of the output extent in the output spatial reference, divided by 30. | Double |
| area_unit_scale_factor(Optional) | Specifies the area units that will be used for the output density values.A default unit is determined based on the linear unit of the output spatial reference. You can change this to the appropriate unit to convert the density output. Values for line density convert the units of both length and area.If no output spatial reference is specified, the output spatial reference will be the same as the input feature class. The default output density units are determined by the linear units of the output spatial reference . If the output linear units are meters, the output area density units will be set to Square kilometers, outputting square kilometers for point features or kilometers per square kilometers for polyline features. If the output linear units are feet, the output area density units will be set to Square miles.If the output units are anything other than feet or meters, the output area density units will be set to Square map units. That is, the output density units will be the square of the linear units of the output spatial reference. For example, if the output linear units are centimeters, the output area density units will be Square map units, which will result in square centimeters. If the output linear units are kilometers, the output area density units will be Square map units, which will result in square kilometers.The available options and their corresponding output density units are the following:SQUARE_MAP_UNITS—The square of the linear units of the output spatial reference will be used.SQUARE_MILES—U.S. miles will be used.SQUARE_KILOMETERS—Kilometers will be used.ACRES—U.S. acres will be used.HECTARES—Hectares will be used.SQUARE_YARDS—U.S. yards will be used.SQUARE_FEET—U.S. feet will be used.SQUARE_INCHES—U.S. inches will be used.SQUARE_METERS—Meters will be used.SQUARE_CENTIMETERS—Centimeters will be used.SQUARE_MILLIMETERS—Millimeters will be used. | String |

## Code Samples

### Example 1

```python
LineDensity(in_polyline_features, population_field, {cell_size}, {search_radius}, {area_unit_scale_factor})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLDens = LineDensity("roads.shp", "LENGTH", 45, 1000, "SQUARE_MILES") 
outLDens.save("C:/sapyexamples/output/ldensout")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLDens = LineDensity("roads.shp", "LENGTH", 45, 1000, "SQUARE_MILES") 
outLDens.save("C:/sapyexamples/output/ldensout")
```

### Example 4

```python
# Name: LineDensity_Ex_02.py
# Description: Calculates a magnitude per unit area from polyline features
#    that fall within a radius around each cell.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPolylineFeatures = "roads.shp"
populationField = "length"
cellSize = 120
searchRadius = 1500

# Execute LineDensity
outLineDensity = LineDensity(inPolylineFeatures, populationField, cellSize,
                             searchRadius, "SQUARE_MILES") 

# Save the output 
outLineDensity.save("C:/sapyexamples/output/linedensity")
```

### Example 5

```python
# Name: LineDensity_Ex_02.py
# Description: Calculates a magnitude per unit area from polyline features
#    that fall within a radius around each cell.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPolylineFeatures = "roads.shp"
populationField = "length"
cellSize = 120
searchRadius = 1500

# Execute LineDensity
outLineDensity = LineDensity(inPolylineFeatures, populationField, cellSize,
                             searchRadius, "SQUARE_MILES") 

# Save the output 
outLineDensity.save("C:/sapyexamples/output/linedensity")
```

---

## Line Statistics (Spatial Analyst)

## Summary

Calculates a statistic on the attributes of lines in a circular neighborhood around each output cell.

## Usage

- There are several statistic types to choose from. The selection of available statistics depends on the type of the specified field.
- For integer fields, the valid choices for Statistics type are: majority, maximum, mean, median, minimum, minority, range, variety, and length. For float fields, the valid statistics are: maximum, mean, minimum, range, and length. Majority, minority, and variety are not available.
- If the field type is integer, the output raster will be integer for the following statistics: majority, maximum, median, minimum, minority, range, and variety. The output will be float for the mean and length statistics.If the field type is float, the output raster will be float for all available statistic types.
- Only the part of a line that falls within the neighborhood is considered for the majority, mean, median, minority, and length statistics. For the maximum, minimum, range, and variety statistics, a part or the whole line can be used
- The majority, mean, median, and minority statistics types are weighted according to the length of the lines. For example, if a line is twice as long as another, its value is considered to occur twice as often.
- If there are no lines in the neighborhood of a raster cell, the variety and length statistics assign a value of zero. For the other statistics, NoData is assigned.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input polyline features | The input lines to use in the neighborhood operation.For each output cell, a statistic will be calculated for all of the portions of the input polyline features that fall within a circular neighborhood around that cell.The size the circular neighbourhood is defined by the search radius. | Feature Layer |
| Field | The field for which the specified statistic will be calculated. It can be any numeric field of the input line features. When Statistics type is set to Length, the Field parameter can be set to NONE.It can be the Shape field if the input features contain z-values. | Field |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Search radius(Optional) | The search radius that will be used to calculate the statistic within, in map units.The default radius is five times the output cell size. | Double |
| Statistics type(Optional) | Specifies the statistic type to be calculated.Statistics are calculated on the value of the specified field for all lines within the neighborhood.The default statistic type is Mean.The available choices for the statistic type are determined by the numeric type of the specified field. If the field is integer, the available statistic choices will be majority, maximum, mean, median, minimum, minority, range, variety, and length. If the field is floating point, only the mean, maximum, minimum, range, and length statistics will be available.Mean—The average field value in each neighborhood, weighted by the length, will be calculated.The form of the calculation is: Mean = (sum of (length * field_value)) / (sum_of_length).Only the part of the line that falls within the neighborhood is used.Majority—The value having the greatest length of line in the neighborhood will be identified.Maximum—The largest value in the neighborhood will be identified.Median—The median value, weighted by the length, will be calculated.Conceptually, all line segments in the neighborhood are sorted by value and placed end to end in a straight line. The value of the segment at the midpoint of the straight line is the median.Minimum—The smallest value in each neighborhood will be identified.Minority—The value having the least length of line in the neighborhood will be identified.Range—The range of values (maximum–minimum) will be calculated.Variety—The number of unique values will be calculated.Length—The total line length in the neighborhood will be calculated. If the value of the field is not 1, the lengths are multiplied by the item value before adding them together. This option can be used when the field parameter is set to None. | String |
| in_polyline_features | The input lines to use in the neighborhood operation.For each output cell, a statistic will be calculated for all of the portions of the input polyline features that fall within a circular neighborhood around that cell.The size the circular neighbourhood is defined by the search radius. | Feature Layer |
| field | The field for which the specified statistic will be calculated. It can be any numeric field of the input line features. When statistics_type is set to Length, the field parameter can be set to NONE.It can be the Shape field if the input features contain z-values. | Field |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| search_radius(Optional) | The search radius that will be used to calculate the statistic within, in map units.The default radius is five times the output cell size. | Double |
| statistics_type(Optional) | Specifies the statistic type to be calculated.Statistics are calculated on the value of the specified field for all lines within the neighborhood.MEAN—The average field value in each neighborhood, weighted by the length, will be calculated.The form of the calculation is: Mean = (sum of (length * field_value)) / (sum_of_length).Only the part of the line that falls within the neighborhood is used.MAJORITY—The value having the greatest length of line in the neighborhood will be identified.MAXIMUM—The largest value in the neighborhood will be identified.MEDIAN—The median value, weighted by the length, will be calculated.Conceptually, all line segments in the neighborhood are sorted by value and placed end to end in a straight line. The value of the segment at the midpoint of the straight line is the median.MINIMUM—The smallest value in each neighborhood will be identified.MINORITY—The value having the least length of line in the neighborhood will be identified.RANGE—The range of values (maximum–minimum) will be calculated.VARIETY—The number of unique values will be calculated.LENGTH—The total line length in the neighborhood will be calculated. If the value of the field is not 1, the lengths are multiplied by the item value before adding them together. This option can be used when the field parameter is set to None. The default statistic type is MEAN.The available choices for the statistic type are determined by the numeric type of the specified field. If the field is integer, the available statistic choices will be majority, maximum, mean, median, minimum, minority, range, variety, and length. If the field is floating point, only the mean, maximum, minimum, range, and length statistics will be available. | String |

## Code Samples

### Example 1

```python
LineStatistics(in_polyline_features, field, {cell_size}, {search_radius}, {statistics_type})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
lineStatOut = LineStatistics("streams", "LENGTH", 50, 500, "MEAN")
lineStatOut.save("C:/sapyexamples/output/linestatout")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
lineStatOut = LineStatistics("streams", "LENGTH", 50, 500, "MEAN")
lineStatOut.save("C:/sapyexamples/output/linestatout")
```

### Example 4

```python
# Name: LineStatistics_Ex_02.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inLines = "streams.shp"
field = "LENGTH"
cellSize = 50
searchRadius = 500

# Execute LineStatistics
lineStatOut = LineStatistics(inLines, field, cellSize, searchRadius,
                              "MEAN")

# Save the output 
lineStatOut.save("C:/sapyexamples/output/linestatisout")
```

### Example 5

```python
# Name: LineStatistics_Ex_02.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inLines = "streams.shp"
field = "LENGTH"
cellSize = 50
searchRadius = 500

# Execute LineStatistics
lineStatOut = LineStatistics(inLines, field, cellSize, searchRadius,
                              "MEAN")

# Save the output 
lineStatOut.save("C:/sapyexamples/output/linestatisout")
```

---

## Linear Spectral Unmixing (Spatial Analyst)

## Summary

Performs subpixel classification and calculates the fractional abundance of different land-cover types for individual pixels.

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The input raster dataset. | Raster Dataset; Mosaic Dataset; Mosaic Layer; Raster Layer; File; Image Service |
| Input Training Features or Spectral Profile | The spectral information for the different land-cover classes.This can be provided as polygon features, a training sample feature class generated from the Training Samples Manager pane, a classifier definition file (.ecd) generated from the Train Maximum Likelihood Classifier tool, or a JSON format file (.json) that contains the class spectral profiles. | File; Feature Layer; String |
| Output Value Option (Optional) | Specifies how the output pixel values will be defined.Sum to one—Class values for each pixel will be provided in decimal format with the sum of all classes equal to 1. For example, Class1 = 0.16; Class2 = 0.24; Class3 = 0.60.Non-negative—There will be no negative output values. | String |
| in_raster | The input raster dataset. | Raster Dataset; Mosaic Dataset; Mosaic Layer; Raster Layer; File; Image Service |
| in_spectral_profile_file | The spectral information for the different land-cover classes.This can be provided as polygon features, a classifier definition file (.ecd) generated from the Train Maximum Likelihood Classifier tool, or a JSON format file (.json) that contains the class spectral profiles. | File; Feature Layer; String |
| value_option[value_option,...](Optional) | Specifies how the output pixel values will be defined.SUM_TO_ONE—Class values for each pixel will be provided in decimal format with the sum of all classes equal to 1. For example, Class1 = 0.16; Class2 = 0.24; Class3 = 0.60.NON_NEGATIVE—There will be no negative output values. | String |

## Code Samples

### Example 1

```python
{
  "EsriEndmemberDefinitionFile" : 0,
  "FileVersion" : 1,
  "NumberOfEndmembers" : 3,
  "NumberOfBands" : 7,
  "Endmembers" : [	
    {
      "EndmemberID" : 1,
      "EndmemberName" : "urban",
      "SpectralProfile" : [
            88,
			                     42,
			                     48,
			                     38,
			                     86,
			                    115,
			                     59
          ]
    },
    {
      "EndmemberID" : 2,
      "EndmemberName" : "vegetation",
      "SpectralProfile" : [
			                       50,
			                       21,
			                       20,
			                       35,
			                       50,
			                      110,
			                       23
          ]
    },
    {
      "EndmemberID" : 3,
      "EndmemberName" : "water",
      "SpectralProfile" : [
			                       51,
			                       20,
			                       14,
			                        9,
			                        7,
			                      116,
			                        4
          ]
    }
  ]        
}
```

### Example 2

```python
{
  "EsriEndmemberDefinitionFile" : 0,
  "FileVersion" : 1,
  "NumberOfEndmembers" : 3,
  "NumberOfBands" : 7,
  "Endmembers" : [	
    {
      "EndmemberID" : 1,
      "EndmemberName" : "urban",
      "SpectralProfile" : [
            88,
			                     42,
			                     48,
			                     38,
			                     86,
			                    115,
			                     59
          ]
    },
    {
      "EndmemberID" : 2,
      "EndmemberName" : "vegetation",
      "SpectralProfile" : [
			                       50,
			                       21,
			                       20,
			                       35,
			                       50,
			                      110,
			                       23
          ]
    },
    {
      "EndmemberID" : 3,
      "EndmemberName" : "water",
      "SpectralProfile" : [
			                       51,
			                       20,
			                       14,
			                        9,
			                        7,
			                      116,
			                        4
          ]
    }
  ]        
}
```

### Example 3

```python
LinearSpectralUnmixing(in_raster, in_spectral_profile_file, {value_option})
```

### Example 4

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("SpatialAnalyst")

# Execute 
unmixing_outputs = LinearSpectralUnmixing("C:/data/landsat7_image.crf",
    "C:/data/train_maxi_likelihood_ecd_output.ecd", "SUM_TO_ONE;NON_NEGATIVE")
	
# Save output
unmixing_outputs.save("C:/data/unmixing_outputs.crf")
```

### Example 5

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("SpatialAnalyst")

# Execute 
unmixing_outputs = LinearSpectralUnmixing("C:/data/landsat7_image.crf",
    "C:/data/train_maxi_likelihood_ecd_output.ecd", "SUM_TO_ONE;NON_NEGATIVE")
	
# Save output
unmixing_outputs.save("C:/data/unmixing_outputs.crf")
```

### Example 6

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("SpatialAnalyst")

# Define input parameters
inFile = "C:/data/landsat7_image.crf"
json_file = "C:/data/customized_endmembers.json"
options = "SUM_TO_ONE" 

# Execute 
unmixing_outputs = LinearSpectralUnmixing(inFile, json_file, options)
	
# Save output
unmixing_outputs.save("C:/data/unmixing_outputs_using_json.crf")
```

### Example 7

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("SpatialAnalyst")

# Define input parameters
inFile = "C:/data/landsat7_image.crf"
json_file = "C:/data/customized_endmembers.json"
options = "SUM_TO_ONE" 

# Execute 
unmixing_outputs = LinearSpectralUnmixing(inFile, json_file, options)
	
# Save output
unmixing_outputs.save("C:/data/unmixing_outputs_using_json.crf")
```

### Example 8

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("SpatialAnalyst")

# Define input parameters
inFile = "C:/data/landsat7_image.crf"
training_features = "C:/data/training_features.shp"
options = "SUM_TO_ONE;NON_NEGATIVE" 

# Execute 
unmixing_outputs = LinearSpectralUnmixing(inFile, training_features, options)
	
# Save output
unmixing_outputs.save("C:/data/unmixing_outputs_using_training_features.crf")
```

### Example 9

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("SpatialAnalyst")

# Define input parameters
inFile = "C:/data/landsat7_image.crf"
training_features = "C:/data/training_features.shp"
options = "SUM_TO_ONE;NON_NEGATIVE" 

# Execute 
unmixing_outputs = LinearSpectralUnmixing(inFile, training_features, options)
	
# Save output
unmixing_outputs.save("C:/data/unmixing_outputs_using_training_features.crf")
```

---

## Ln (Spatial Analyst)

## Summary

Calculates the natural logarithm (base e) of cells in a raster.

## Usage

- The input can be of integer or float type.You can review some results for floating-point input values in the examples of output values from the Logarithmic tools.
- Input values that are 0 or negative will be NoData in the output raster.
- The output raster from this tool is always floating-point type, regardless of the input value type.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- The natural logarithm (Ln) is the most commonly used logarithmic function.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | Input values for which to find the natural logarithm (Ln).To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | Input values for which to find the natural logarithm (Ln).To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Ln(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLn = Ln("elevation")
outLn.save("C:/sapyexamples/output/outln2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLn = Ln("elevation")
outLn.save("C:/sapyexamples/output/outln2")
```

### Example 4

```python
# Name: Ln_Ex_02.py
# Description: Calculates natural logarithm (base e) of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"

# Execute Ln
outLn = Ln(inRaster)

# Save the output 
outLn.save("C:/sapyexamples/output/outln")
```

### Example 5

```python
# Name: Ln_Ex_02.py
# Description: Calculates natural logarithm (base e) of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"

# Execute Ln
outLn = Ln(inRaster)

# Save the output 
outLn.save("C:/sapyexamples/output/outln")
```

---

## Locate Regions (Spatial Analyst)

## Summary

Identifies the best regions, or groups of contiguous cells, from an input utility (suitability) raster that satisfy a specified evaluation criterion and that meet identified shape, size, number, and interregion distance constraints.

## Usage

- The input utility raster is often the output from a suitability model. A suitability model identifies how suitable each location is based on the desired attributes actually found at the location. Suitability modeling is one of the most common applications for Spatial Analyst. For additional information on suitability modeling, see Understanding overlay analysis.
- The higher the input values in the utility raster, the greater the utility.
- The settings for Minimum distance between regions and Maximum distance between regions take precedent over Total area. For example, if five regions are desired, but due to the specified minimum and maximum distances only four regions can be located, then only four regions will be selected. As a result, the Total area will not be met. When possible, a warning will be issued, but this is not the case for all situations.
- The parameterized region-growing (PRG) algorithm grows based on utility values within the input raster—the higher value cells are more preferred in the growth. The Evaluation method determines which of the candidate regions are selected; it has no influence on the region growth.
- The Locate Regions tool is very computationally intensive. There are steps you can take with how you set up your input data and the settings of certain parameters to influence this.
- To speed up processing, locations that should not be considered in the selection processing should be set to NoData as a preprocessing step or eliminated using the Mask. No regions will grow from these excluded locations or be allocated in the selection process. Unlike Input raster or feature of existing regions, excluded areas have no effect on the Minimum distance between regions and Maximum distance between regions in the parameterized region-growing (PRG) algorithm or in the selection of the candidate regions.
- The options that are selected for the Number of seeds to grow from and Resolution of the growth parameters can greatly affect the processing time.Selecting the Small and Low options for these parameters, respectively, will provide the best performance. Selecting Small, Medium, or Large for Number of seeds to grow from and Low, Medium, or High for Resolution of the growth produces the most reliable results within a reasonable amount of time.
- If the Number of seeds to grow from or the Resolution of the growth are specified to any option other than Maximum, data will be lost due to not growing regions from every cell and resampling to a coarser resolution. However, depending on the size of the input raster, the Maximum option may be very slow; therefore, the other options may be more practical.
- Depending on the size of the input raster, selecting Maximum for Number of seeds to grow from or Resolution of the growth can take a long time. The Locate Regions algorithm implements a two-step process. It first grows candidate regions and it then selects the best regions from the candidate regions. The growing of the regions for large input rasters can take a long time. However, in the selecting regions step, a distance matrix is first loaded. If the matrix cannot be loaded due to memory limitations, the tool will end processing. If this occurs, either select a smaller number of seeds to grow from or specify a coarser resolution of growth.
- The default values for Number of seeds to grow from and Resolution of the growth are dependent on the number of cells in the input raster. The more cells in the input raster, the longer this tool takes to execute. To avoid extremely long execution times, these default values are set accordingly.Number of input cellsNumber of seeds to grow fromResolution of the growth<= 100,000MaximumMaximum100,000 - 500,000SmallMaximum> 500,000SmallLow
- When the Number of regions is greater than eight, it is recommended to use the Sequential option for the Region selection method. Using the Combinatorial method with more than eight regions selected may result in slow performance.
- Usually, the Number of seeds to grow from value has the greatest impact on the processing speed. The higher the number of seeds to grow from, the longer the tool takes to operate. However, in most cases the results are similar, regardless of the value specified.
- The Number of seeds to grow from are distributed within the input raster based on utility values—areas with higher utility values receive more seeds. The Evaluation method has no influence on their distribution.
- The Resolution of the growth sets the resolution on which the parameterized region growing will occur. The input raster is resampled to the defined resolution using the bilinear resampling method. Once the regions are selected, before the final output raster is created, the results are resampled to the environment Cell Size using the nearest neighbor resampling method.
- A shape adjustment is implemented for the regions at the edge of the input raster. If at least one cell should fall outside the input raster's boundary in order to maintain the shape, the utility of the region will be reduced by 50 percent. Because of this utility reduction, the region is less likely to be selected, but the reduction does not eliminate the region from the selection process.
- The area selected can be more than the specified total area if Islands not allowed in regions is checked. To determine if the discrepancy between the selected area and the specified total area is based on the no-island parameter, rerun the tool with this parameter unchecked. Add the number of cells from COUNT in the output raster attribute table from the original run; then rerun the tool, multiply the sum of each by the area of a cell, and compare the results to the specified area.
- If the Resolution of the growth is specified with any option other than Maximum, through a postprocess, the original utility values for each region can be identified using Zonal Statistics. Enter the output region raster from Locate Regions as the zone raster and the input utility raster as the value raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input utility raster from which the regions will be derived.The higher the value in the input raster, the greater the utility.The raster can be of either integer or floating-point type. | Raster Layer |
| Total area(Optional) | The total amount of area for all regions.The default is 10 percent of the input cells within the processing extent. | Double |
| Area units(Optional) | Defines the area units used for the Total area, Region minimum area, and Region maximum area parameters.The available options and their corresponding units are the following:The default is based on the input raster dataset. If the input raster is in feet, yards, miles or any other imperial unit, Square miles will be used. If the input raster is in meters, kilometers, or any other metric unit, Square kilometers will be used.Square map units—For the square of the linear units of the output spatial referenceSquare miles—For milesSquare kilometers—For kilometersHectares—For hectaresAcres—For acresSquare meters—For metersSquare yards—For yardsSquare feet—For feet | String |
| Number of regions(Optional) | Determines how many regions the Total area will be distributed across.The maximum number of regions that can be specified is 30. The default is 1. | Long |
| Region shape(Optional) | Defines the shape characteristics for the output regions.The regions start out from seed cell locations and grow outward with preference given to the cells that maintain the desired shape.The available shape options are the following:Circle—Cells that maintain circular regions will receive a greater weight. This is the default.Ellipse—Cells that maintain elliptical-shaped regions will receive a greater weight.Equilateral triangle—Cells that maintain equilateral triangular-shaped regions will receive a greater weight.Square—Cells that maintain square-shaped regions will receive a greater weight.Pentagon—Cells that maintain pentagon-shaped regions will receive a greater weight.Hexagon—Cells that maintain hexagon-shaped regions will receive a greater weight.Octagon—Cells that maintain octagon-shaped regions will receive a greater weight. | String |
| Region orientation(Optional) | Defines the orientation of the defined shape. Regions are grown out from the seed locations with preference given to the cells that maintain the desired orientation of the region shapes.The orientation values are in compass degrees ranging from 0 to 360, increasing clockwise starting from north. The default is 0.The default of 0 orients the shapes in the following manner: Circle—no effect; Ellipse—the minor axis is orientated north-south; Triangle and Pentagon—one point is straight up; Square, Hexagon, and Octagon—one flat side is oriented east-west.If the Region shape is set to Circle, the Region orientation parameter is unavailable. | Double |
| Shape/Utility tradeoff (%)(Optional) | Identifies the weight for the cells when growing the candidate regions in the parameterized region-growing algorithm. The weighting is a tradeoff between a cell's contribution for maintaining the region shape relative to the utility contribution of the cell's attribute value.Higher values indicates maintaining the shape of the region is more important than selecting higher utility values. The acceptable percent values are 0 to 100, inclusively. The default is 50.This parameter is used to identify the feasible candidate regions. The candidate regions that will be selected by the algorithm are controlled by the Evaluation method parameter. | Double |
| Evaluation method(Optional) | The evaluation criteria to be used for determining which of the candidate regions identified in the parameterized region-growing algorithm are most preferred. The preference can be specified based on a particular statistic of the utility values, or spatial arrangement of the cells within the regions.The available options are the following:Highest average value—Selects regions based on the highest average value. This is the default.Highest sum—Selects regions based on the highest sum.Highest median value—Selects regions based on the highest median value.Highest value—Selects regions based on the highest individual cell value contained within the region. This option ensures the best individual cells are selected.Lowest value—Selects regions based on the highest lowest individual cell value contained within the region. This option ensures the selected regions contain cells with really low utility.Greatest core area—Selects regions based on the greatest core area.Any cell that is farther than one cell from the edge of a region is considered to be part of the core. The edge distance can be controlled by the analysis cell size. Setting a smaller cell size can increase the core area.Highest sum of core utility values—Selects regions based on the highest cumulative sum of the utility values for the core area. The edge distance can be controlled by the analysis cell size.Greatest edge—Selects regions based on the greatest amount of edge using the P1 ratio, which is the ratio of the perimeter of the shape to the perimeter of a circle of the same area. The P1 ratio for a circle is 1. | String |
| Region minimum area(Optional) | Define the minimum area allowed for each region.The units specified by the Area units parameter will be used. | Double |
| Region maximum area(Optional) | Define the maximum area allowed for each region.The units specified by the Area units parameter will be used. | Double |
| Minimum distance between regions(Optional) | Define the minimum distance allowed between regions. No two regions can be within this distance.This parameter influences the parameterized region-growing (PRG) algorithm. If a cell has the potential of being added to a candidate region, but it is within this distance from any individual region in the dataset specified by the Input raster or feature of existing regions parameter, it will not be considered for the candidate region. The minimum distance setting is not applied to excluded locations (NoData cells).The units specified by the Distance units parameter will be used. | Double |
| Maximum distance between regions(Optional) | Define the maximum distance allowed between regions. No region can be farther apart than this distance from at least one other region.When sequentially selecting regions, if the next best region is farther than this distance from any of the already selected regions, it will not be considered at this time, but it may be selected later when more regions are selected. The maximum distance is applied to the dataset specified in the Input raster or feature of existing regions parameter, in that at least one of the selected regions must be within the maximum distance from existing regions. The maximum distance setting is not applied to excluded areas (NoData cells) and has no effect on the PRG algorithm.The units specified by the Distance units parameter will be used. | Double |
| Distance units(Optional) | Defines the distance units that will be used for the Minimum distance between regions and Maximum distance between regions parameters.The available options and their corresponding units are the following:The default is based on the input raster dataset. If the input raster is in feet, yards, miles, or any other imperial unit, Miles will be used. If the input raster is in meters, kilometers, or any other metric unit, Kilometers will be used.Map units—For the linear units of the output spatial referenceMiles—For milesKilometers—For kilometersMeters—For metersYards—For yardsFeet—For feet | String |
| Input raster or feature of existing regions(Optional) | A dataset identifying where regions already exist.The input can be a raster or feature dataset. If the input is a raster, any location in the raster with a valid value is considered already allocated. All other locations are set to NoData.In the parameterized region-growing algorithm, no region will grow from any location identified as an existing region. Existing regions will be used in the growth and evaluation of the Minimum distance between regions and Maximum distance between regions parameters as described in the corresponding parameter descriptions above. | Raster Layer; Feature Layer |
| Number of neighbors to use in growth(Optional) | Defines which neighboring cells to use in the growth of the regions.The available options are the following:Four—Only the four direct (orthogonal) neighbors of the region cells will be considered in the region growth.Eight—The eight nearest neighbors (orthogonal and diagonal) will be considered in the region growth. This is the default. | String |
| Islands not allowed in regions(Optional) | Defines whether or not islands will be allowed within the potential regions.Checked—The parameterized region-growing algorithm ensures there will be no islands within a region. This is the default. A flood field algorithm is implemented as a postprocess once the regions are created but before the regions are selected. If there are islands within a region, they will be filled in and the cells will join the region. Since the fill process occurs before the selection process, the utility of the island cells will be added to the region, and their values will be included in the selection process of the regions and in the statistics of the output regions. As a result of the fill process, it is likely that the total area allocated will exceed the target specified by the Total area parameter.Unchecked—Islands will be allowed. | Boolean |
| Number of seeds to grow from(Optional) | Defines the number of seeds from which to grow the potential regions.The available options are the following:Based on input—The number of seeds will be based on the number of cells in the input raster. When the input raster has 100,000 cells or fewer, the default is Maximum. When the input raster has more than 100,000 cells, the default is Small. This is the default.Small—The number of seeds will be equal to 10 percent of the number of cells in the input raster, after NoData cells are excluded, but not to exceed 1,600 seeds.Medium—The number of seeds will be equal to 20 percent of the number of cells in the input raster, after NoData cells are excluded, but not to exceed 2,500 seeds.Large—The number of seeds will be equal to 30 percent of the number of cells in the input raster, after NoData cells are excluded, but not to exceed 3,600 seeds.Maximum—The region growth will occur at each available cell within the input raster. Available cells are all cells that are not NoData and not identified as an existing region. | String |
| Resolution of the growth(Optional) | Sets the resolution at which region growth occurs.The input raster will be resampled to the resolution determined by the number of cells identified by this parameter (see below). For example, for LOW, the input raster is resampled to 147,356 cells. The parameterized region-growing algorithm grows on the resampled intermediate raster. Once the regions are selected from the resampled intermediate raster, the selected regions will be resampled to the Environment cell size.An adjustment to the target resolutions identified below may be implemented if the number of cells in the desired average region size is too small or too large. This adjustment makes sure there will be enough cells in each desired region or that unnecessary processing will not occur. As a result, the total cells for the intermediate resampled raster for each of the specified resolutions below can be lower or higher than the target number of cells.If the input has less than 147,356 cells or Maximum is selected, no resampling will occur and the region growth will process on all cells in the input raster. If the input raster has less than 147,356 cells, the Low, Medium, or High options have no effect.The available options are the following:Based on input—The resolution will be based on the number of cells in the input raster. When the input raster has 500,000 cells or fewer, the default is Maximum. When the input raster has more than 500,000 cells, the default is Low. This is the default.Low—The analysis will be performed on an intermediate raster containing 147,356 (384 x 384) cells distributed in the same x and y ratio as the input raster.Medium—The analysis will be performed on an intermediate raster containing 262,144 (512 x 512) cells distributed in the same x and y ratio as the input raster. High—The analysis will be performed on an intermediate raster containing 589,824 (768 x 768) cells distributed in the same x and y ratio as the input raster. Maximum—The analysis will be performed on all cells in the input raster. | String |
| Region selection method(Optional) | Identifies how the regions will be selected.The available options are the following:Based on number of regions—The selection method is based on the Number of regions parameter. If the Number of regions is eight or less, the Combinatorial selection method is used. If the Number of regions parameter is greater than eight, the Sequential selection method is used. This is the default.Combinatorial—Selects the best regions based on the specified evaluation method, while honoring the spatial constraints, by testing all combinations of the desired number of regions within the candidate regions from the parameterized region-growing (PRG) algorithm.Sequential—Sequentially selects the best regions based on the evaluation method and that meets the spatial constraints until the desired number of regions is reached. | String |
| in_raster | The input utility raster from which the regions will be derived.The higher the value in the input raster, the greater the utility.The raster can be of either integer or floating-point type. | Raster Layer |
| total_area(Optional) | The total amount of area for all regions.The default is 10 percent of the input cells within the processing extent. | Double |
| area_units(Optional) | Defines the area units used for the total_area, minimum_area, and maximum_area parameters.The available options and their corresponding units are the following:SQUARE_MAP_UNITS—For the square of the linear units of the output spatial referenceSQUARE_MILES—For milesSQUARE_KILOMETERS—For kilometersHECTARES—For hectaresACRES—For acresSQUARE_METERS—For metersSQUARE_YARDS—For yardsSQUARE_FEET—For feet The default is based on the input raster dataset. If the input raster is in feet, yards, miles or any other imperial unit, Square miles will be used. If the input raster is in meters, kilometers, or any other metric unit, Square kilometers will be used. | String |
| number_of_regions(Optional) | Determines how many regions the total_area will be distributed across.The maximum number of regions that can be specified is 30. The default is 1. | Long |
| region_shape(Optional) | Defines the shape characteristics for the output regions.The regions start out from seed cell locations and grow outward with preference given to the cells that maintain the desired shape.The available shape options are the following:CIRCLE—Cells that maintain circular regions will receive a greater weight. This is the default.ELLIPSE—Cells that maintain elliptical-shaped regions will receive a greater weight.TRIANGLE—Cells that maintain equilateral triangular-shaped regions will receive a greater weight.SQUARE—Cells that maintain square-shaped regions will receive a greater weight.PENTAGON—Cells that maintain pentagon-shaped regions will receive a greater weight.HEXAGON—Cells that maintain hexagon-shaped regions will receive a greater weight.OCTAGON—Cells that maintain octagon-shaped regions will receive a greater weight. | String |
| region_orientation(Optional) | Defines the orientation of the defined shape. Regions are grown out from the seed locations with preference given to the cells that maintain the desired orientation of the region shapes.The orientation values are in compass degrees ranging from 0 to 360, increasing clockwise starting from north. The default is 0.The default of 0 orients the shapes in the following manner: Circle—no effect; Ellipse—the minor axis is orientated north-south; Triangle and Pentagon—one point is straight up; Square, Hexagon, and Octagon—one flat side is oriented east-west. | Double |
| shape_tradeoff(Optional) | Identifies the weight for the cells when growing the candidate regions in the parameterized region-growing algorithm. The weighting is a tradeoff between a cell's contribution for maintaining the region shape relative to the utility contribution of the cell's attribute value.Higher values indicates maintaining the shape of the region is more important than selecting higher utility values. The acceptable percent values are 0 to 100, inclusively. The default is 50.This parameter is used to identify the feasible candidate regions. The candidate regions that will be selected are controlled by the evaluation_method parameter. | Double |
| evaluation_method(Optional) | The evaluation criteria to be used for determining which of the candidate regions identified in the parameterized region-growing algorithm are most preferred. The preference can be specified based on a particular statistic of the utility values, or spatial arrangement of the cells within the regions.The available options are the following:HIGHEST_AVERAGE_VALUE—Selects regions based on the highest average value. This is the default.HIGHEST_SUM—Selects regions based on the highest sum.HIGHEST_MEDIAN_VALUE—Selects regions based on the highest median value.HIGHEST_VALUE—Selects regions based on the highest individual cell value contained within the region. This option ensures the best individual cells are selected.LOWEST_VALUE—Selects regions based on the highest lowest individual cell value contained within the region. This option ensures the selected regions contain cells with really low utility.GREATEST_CORE_AREA—Selects regions based on the greatest core area.Any cell that is farther than one cell from the edge of a region is considered to be part of the core. The edge distance can be controlled by the analysis cell size. Setting a smaller cell size can increase the core area.HIGHEST_CORE_SUM—Selects regions based on the highest cumulative sum of the utility values for the core area. The edge distance can be controlled by the analysis cell size.GREATEST_EDGE—Selects regions based on the greatest amount of edge using the P1 ratio, which is the ratio of the perimeter of the shape to the perimeter of a circle of the same area. The P1 ratio for a circle is 1. | String |
| minimum_area(Optional) | Define the minimum area allowed for each region.The units specified by area_units will be used.To learn more about how regions are created when the minimum and maximum areas are defined, see How regions are determined when a minimum and maximum area are specified. | Double |
| maximum_area(Optional) | Define the maximum area allowed for each region.The units specified by area_units will be used.To learn more about how regions are created when the minimum and maximum areas are defined, see How regions are determined when a minimum and maximum area are specified. | Double |
| minimum_distance(Optional) | Define the minimum distance allowed between regions. No two regions can be within this distance.This parameter influences the parameterized region-growing (PRG) algorithm. If a cell has the potential of being added to a candidate region, but it is within this distance from any individual region in the in_existing_regions, it will not be considered for the candidate region. The minimum distance setting is not applied to excluded locations (NoData cells).The units specified by distance_units will be used. | Double |
| maximum_distance(Optional) | Define the maximum distance allowed between regions. No region can be farther apart than this distance from at least one other region.When sequentially selecting regions, if the next best region is farther than this distance from any of the already selected regions, it will not be considered at this time, but it may be selected later when more regions are selected. The maximum distance is applied to in_existing_regions; that is, at least one of the selected regions must be within the maximum distance from existing regions. The maximum distance setting is not applied to excluded areas (NoData cells), and has no effect on the PRG algorithm.The units specified by distance_units will be used. | Double |
| distance_units(Optional) | Defines the distance units that will be used for the minimum_distance and maximum_distance parameters.The available options and their corresponding units are the following:MAP_UNITS—For the linear units of the output spatial referenceMILES—For milesKILOMETERS—For kilometersMETERS—For metersYARDS—For yardsFEET—For feet The default is based on the input raster dataset. If the input raster is in feet, yards, miles, or any other imperial unit, Miles will be used. If the input raster is in meters, kilometers, or any other metric unit, Kilometers will be used. | String |
| in_existing_regions(Optional) | A dataset identifying where regions already exist.The input can be a raster or feature dataset. If the input is a raster, any location in the raster with a valid value is considered already allocated. All other locations are set to NoData.In the parameterized region-growing algorithm, no region will grow from any location containing an existing region. Existing regions will be used in the growth and evaluation of the minimum_distance and maximum_distance as described in the corresponding parameter descriptions above. | Raster Layer; Feature Layer |
| number_of_neighbors(Optional) | Defines which neighboring cells to use in the growth of the regions.The available options are the following:FOUR—Only the four direct (orthogonal) neighbors of the region cells will be considered in the region growth.EIGHT—The eight nearest neighbors (orthogonal and diagonal) will be considered in the region growth. This is the default. | String |
| no_islands(Optional) | Defines if islands will be allowed within the potential regions.NO_ISLANDS—The parameterized region-growing algorithm ensures there will be no islands within a region.A flood field algorithm is implemented as a postprocess once the regions are created but before the regions are selected. If there are islands within a region, they will be filled in and the cells will join the region. Since the fill process occurs before the selection process, the utility of the island cells will be added to the region, and their values will be included in the selection process of the regions and in the statistics of the output regions. As a result of the fill process, it is likely that the total area allocated will exceed the target total_area value.This is the default.ISLANDS_ALLOWED—Islands will be allowed. | Boolean |
| region_seeds(Optional) | Defines the number of seeds from which to grow the potential regions.To learn more about how the seeds influence the region growth algorithm, see How seeds are distributed.The available options are the following:AUTO—The number of seeds will be based on the number of cells in the input raster. When the input raster has 100,000 cells or fewer, the default is Maximum. When the input raster has more than 100,000 cells, the default is Small. This is the default.SMALL—The number of seeds will be equal to 10 percent of the number of cells in the input raster, after NoData cells are excluded, but not to exceed 1,600 seeds.MEDIUM—The number of seeds will be equal to 20 percent of the number of cells in the input raster, after NoData cells are excluded, but not to exceed 2,500 seeds.LARGE—The number of seeds will be equal to 30 percent of the number of cells in the input raster, after NoData cells are excluded, but not to exceed 3,600 seeds.MAXIMUM—The region growth will occur at each available cell within the input raster. Available cells are all cells that are not NoData and not identified as an existing region. | String |
| region_resolution(Optional) | Sets the resolution at which region growth occurs. The input raster will be resampled to the resolution determined by the number of cells identified by this parameter (see below). For example, for Low the input raster is resampled to 147,356 cells. The parameterized region-growing algorithm grows on the resampled intermediate raster. Once the regions are selected from the resampled intermediate raster, the selected regions will be resampled to the Cell Size.An adjustment to the target resolutions identified below may be implemented if the number of cells in the desired average region size is too small or too large. This adjustment makes sure there will be enough cells in each desired region or that unnecessary processing will not occur. As a result, the total cells for the intermediate resampled raster for each of the specified resolutions below can be lower or higher than the target number of cells. For more information on this adjustment and the thresholds used, see Adjusting the region growth resolution based on the size of the desired regions. If the input has less than 147,356 cells or Maximum is selected, no resampling will occur and the region growth will process on all cells in the input raster. If the input raster has less than 147,356 cells, the Low, Medium, or High options have no effect.The available options are the following:AUTO—The resolution will be based on the number of cells in the input raster. When the input raster has 500,000 cells or fewer, the default is Maximum. When the input raster has more than 500,000 cells, the default is Low. This is the default.LOW—The analysis will be performed on an intermediate raster containing 147,356 (384 x 384) cells distributed in the same x and y ratio as the input raster.MEDIUM—The analysis will be performed on an intermediate raster containing 262,144 (512 x 512) cells distributed in the same x and y ratio as the input raster. HIGH—The analysis will be performed on an intermediate raster containing 589,824 (768 x 768) cells distributed in the same x and y ratio as the input raster. MAXIMUM—The analysis will be performed on all cells in the input raster. | String |
| selection_method(Optional) | Identifies how the regions will be selected.The available options are the following:AUTO—The selection method is based on the Number of regions parameter. If the Number of regions is eight or less, the Combinatorial selection method is used. If the Number of regions parameter is greater than eight, the Sequential selection method is used. This is the default.COMBINATORIAL—Selects the best regions based on the specified evaluation method, while honoring the spatial constraints, by testing all combinations of the desired number of regions within the candidate regions from the parameterized region-growing (PRG) algorithm.SEQUENTIAL—Sequentially selects the best regions based on the evaluation method and that meets the spatial constraints until the desired number of regions is reached. | String |

## Code Samples

### Example 1

```python
LocateRegions(in_raster, {total_area}, {area_units}, {number_of_regions}, {region_shape}, {region_orientation}, {shape_tradeoff}, {evaluation_method}, {minimum_area}, {maximum_area}, {minimum_distance}, {maximum_distance}, {distance_units}, {in_existing_regions}, {number_of_neighbors}, {no_islands}, {region_seeds}, {region_resolution}, {selection_method})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRegions = LocateRegions("suitsurface", 13.5, "SQUARE_MILES", 5, "CIRCLE",
                           0, 50, "HIGHEST_AVERAGE_VALUE", 2, 5, 1, 3, "MILES",
                           "existingreg.shp", "EIGHT", "NO_ISLANDS", "SMALL", 
                           "LOW", "COMBINATORIAL")
outRegions.save("C:/sapyexamples/output/outregions")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRegions = LocateRegions("suitsurface", 13.5, "SQUARE_MILES", 5, "CIRCLE",
                           0, 50, "HIGHEST_AVERAGE_VALUE", 2, 5, 1, 3, "MILES",
                           "existingreg.shp", "EIGHT", "NO_ISLANDS", "SMALL", 
                           "LOW", "COMBINATORIAL")
outRegions.save("C:/sapyexamples/output/outregions")
```

### Example 4

```python
# Name: LocateRegions_Ex_02.py
# Description: Selects the best specified number of regions
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
InRaster1 = "suitsurface"
InTotalArea2 = 13.5
InAreaUnits3 = "SQUARE_MILES"
InNumberofRegions4 = 5
InRegionShape5 = "CIRCLE"
InRegionOrientation6 = 0
InShapeTradeoff7 = 50
InEvaluationMethod8 = "HIGHEST_AVERAGE_VALUE"
InMinimumArea9 = 2
InMaximumArea10 = 5
InMinimumDistance11 = 1
InMaximumDistance12 = 3
InDistanceUnits13 = "MILES"
InExistingRegions14 = "existingreg.shp"
InRegionofNeighbors15 = "EIGHT"
InRegionNoIslands16 = "NO_ISLANDS"
InRegionSeeds17 = "SMALL"
InRegionResolution18 = "LOW"
InCombinatorialThreshold19 = "COMBINATORIAL"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute Locate Regions
outRegions = LocateRegions(InRaster1, InTotalArea2, InAreaUnits3, InNumberofRegions4,
                           InRegionShape5, InRegionOrientation6, InShapeTradeoff7,
                           InEvaluationMethod8, InMinimumArea9, InMaximumArea10,
                           InMinimumDistance11, InMaximumDistance12, InDistanceUnits13,
                           InExistingRegions14, InRegionofNeighbors15, InRegionNoIslands16,
                           InRegionSeeds17, InRegionResolution18, InCombinatorialThreshold19)

# Save the output
outRegions.save("C:/sapyexamples/output/outregions")
```

### Example 5

```python
# Name: LocateRegions_Ex_02.py
# Description: Selects the best specified number of regions
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
InRaster1 = "suitsurface"
InTotalArea2 = 13.5
InAreaUnits3 = "SQUARE_MILES"
InNumberofRegions4 = 5
InRegionShape5 = "CIRCLE"
InRegionOrientation6 = 0
InShapeTradeoff7 = 50
InEvaluationMethod8 = "HIGHEST_AVERAGE_VALUE"
InMinimumArea9 = 2
InMaximumArea10 = 5
InMinimumDistance11 = 1
InMaximumDistance12 = 3
InDistanceUnits13 = "MILES"
InExistingRegions14 = "existingreg.shp"
InRegionofNeighbors15 = "EIGHT"
InRegionNoIslands16 = "NO_ISLANDS"
InRegionSeeds17 = "SMALL"
InRegionResolution18 = "LOW"
InCombinatorialThreshold19 = "COMBINATORIAL"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute Locate Regions
outRegions = LocateRegions(InRaster1, InTotalArea2, InAreaUnits3, InNumberofRegions4,
                           InRegionShape5, InRegionOrientation6, InShapeTradeoff7,
                           InEvaluationMethod8, InMinimumArea9, InMaximumArea10,
                           InMinimumDistance11, InMaximumDistance12, InDistanceUnits13,
                           InExistingRegions14, InRegionofNeighbors15, InRegionNoIslands16,
                           InRegionSeeds17, InRegionResolution18, InCombinatorialThreshold19)

# Save the output
outRegions.save("C:/sapyexamples/output/outregions")
```

---

## Log10 (Spatial Analyst)

## Summary

Calculates the base 10 logarithm of cells in a raster.

## Usage

- The input can be of integer or float type.You can review some results for floating-point input values in the examples of output values from the Logarithmic tools.
- Input values that are 0 or negative will be NoData in the output raster.
- The output raster from this tool is always floating-point type, regardless of the input value type.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | Input values for which to find the base 10 logarithm.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | Input values for which to find the base 10 logarithm.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Log10(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLog10 = Log10("elevation")
outLog10.save("C:/sapyexamples/output/outlog10.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLog10 = Log10("elevation")
outLog10.save("C:/sapyexamples/output/outlog10.img")
```

### Example 4

```python
# Name: Log10_Ex_02.py
# Description: Calculates the base 10 logarithm of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Log10
outLog10 = Log10(inRaster)

# Save the output 
outLog10.save("C:/sapyexamples/output/outlog10")
```

### Example 5

```python
# Name: Log10_Ex_02.py
# Description: Calculates the base 10 logarithm of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Log10
outLog10 = Log10(inRaster)

# Save the output 
outLog10.save("C:/sapyexamples/output/outlog10")
```

---

## Log2 (Spatial Analyst)

## Summary

Calculates the base 2 logarithm of cells in a raster.

## Usage

- The input can be of integer or float type.You can review some results for floating-point input values in the examples of output values from the Logarithmic tools.
- Input values that are 0 or negative will be NoData in the output raster.
- The output raster from this tool is always floating-point type, regardless of the input value type.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | Input values for which to find the base 2 logarithm.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | Input values for which to find the base 2 logarithm.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Log2(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLog2 = Log2("elevation")
outLog2.save("C:/sapyexamples/output/outlog2.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLog2 = Log2("elevation")
outLog2.save("C:/sapyexamples/output/outlog2.img")
```

### Example 4

```python
# Name: Log2_Ex_02.py
# Description: Calculates the base 2 logarithm of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Log2
outLog2 = Log2(inRaster)

# Save the output 
outLog2.save("C:/sapyexamples/output/outlog2")
```

### Example 5

```python
# Name: Log2_Ex_02.py
# Description: Calculates the base 2 logarithm of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Log2
outLog2 = Log2(inRaster)

# Save the output 
outLog2.save("C:/sapyexamples/output/outlog2")
```

---

## Lookup (Spatial Analyst)

## Summary

Creates a raster by looking up values in another field in the table of the input raster.

## Usage

- Both numeric (integer or floating point) or string field types are supported. If the field is integer or string, the output will be an integer raster; otherwise, the output raster will be a floating-point raster.
- If the lookup field is of integer type, the values of that field will be written to the output raster attribute table as Value. Other items in the input raster attribute table will not be transferred to the output raster attribute table.For example, an attribute table of input raster with numeric field Attr1 Value Count Attr1 1 294 1 2 345 8 3 654 3Output attribute table from Lookup on Attr1 field Value Count 1 294 3 654 8 345
- If the lookup field is a string type, the lookup field will appear in the output raster attribute table, and the value field will be the same numeric type as for input raster. Any other items in the input raster's attribute table will not be transferred to the output raster's attribute table.For example, consider the attribute table of an input raster with string field Text1 Value Count Attr1 Text1 1 294 1 A 2 6218 8 B 3 28 3 4 3603 9 3The attribute table of the output raster from running Lookup on the Text1 field would be Value Count Text1 1 294 A 2 6218 B 3 28 4 3603 3
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster that contains a field from which to create a new raster. | Raster Layer |
| Lookup field | Field containing the desired values for the new raster.It can be a numeric or string type. | Field |
| in_raster | The input raster that contains a field from which to create a new raster. | Raster Layer |
| lookup_field | Field containing the desired values for the new raster.It can be a numeric or string type. | Field |

## Code Samples

### Example 1

```python
Value   Count   Attr1
    1       294     1
    2       345     8
    3       654     3
```

### Example 2

```python
Value   Count
    1       294
    3       654
    8       345
```

### Example 3

```python
Value   Count   Attr1   Text1
    1        294    1       A
    2       6218    8       B
    3         28    3
    4       3603    9       3
```

### Example 4

```python
Value   Count   Text1
    1        294    A
    2       6218    B
    3         28    
    4       3603    3
```

### Example 5

```python
Lookup(in_raster, lookup_field)
```

### Example 6

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRaster = Lookup("mycity","land_code")
outRaster.save("C:/sapyexamples/output/mylandcode.img")
```

### Example 7

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRaster = Lookup("mycity","land_code")
outRaster.save("C:/sapyexamples/output/mylandcode.img")
```

### Example 8

```python
# Name: lookup_example02.py
# Description: Creates a new raster by looking up values found in another 
#              field in the table of the input raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "mycity"
lookupField = "land_code"

# Execute Lookup
outRaster = Lookup(inRaster, lookupField)

# Save the output 
outRaster.save("C:/sapyexamples/output/mylandcode")
```

### Example 9

```python
# Name: lookup_example02.py
# Description: Creates a new raster by looking up values found in another 
#              field in the table of the input raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "mycity"
lookupField = "land_code"

# Execute Lookup
outRaster = Lookup(inRaster, lookupField)

# Save the output 
outRaster.save("C:/sapyexamples/output/mylandcode")
```

---

## Lowest Position (Spatial Analyst)

## Summary

Determines on a cell-by-cell basis the position of the raster with the minimum value in a set of rasters.

## Usage

- An arbitrary number of rasters can be specified in the input rasters list.
- The order of the input rasters is relevant for this tool.
- When a multiband raster is specified as one of the Input rasters or constant values parameter values (in_rasters_or_constants in Python), all the bands will be used.To process a selection of bands from a multiband raster, first create a raster dataset composed of those particular bands using the Composite Bands tool; then use the result in the list in the Input rasters or constant values parameter (in_rasters_or_constants in Python).
- If a cell location contains NoData on any of the input rasters, that location will be assigned NoData on the output.
- The output raster is always of integer type.
- If two or more input rasters contain the minimum value for a particular cell location, the position of the first one encountered is returned on the output raster.
- If all inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process, otherwise an error will occur.If all of the inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before performing the operation.If one or more of the inputs are multidimensional rasters and the other inputs are constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input rasters or constant values | The list of input rasters for which the position of the input with the lowest value will be determined.A number can be used as an input; however, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_rasters_or_constants[in_raster_or_constant,...] | The list of input rasters for which the position of the input with the lowest value will be determined.A number can be used as an input; however, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
LowestPosition(in_rasters_or_constants)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLowestPosition = LowestPosition(["degs", "negs", "fourgrd"])
outLowestPosition.save("C:/sapyexamples/output/outlp.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outLowestPosition = LowestPosition(["degs", "negs", "fourgrd"])
outLowestPosition.save("C:/sapyexamples/output/outlp.tif")
```

### Example 4

```python
# Name: LowestPosition_Ex_02.py
# Description: Determines the position of a raster with the minimum
#              value in a set of rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute LowestPosition
outLowestPosition = LowestPosition([inRaster01, inRaster02, inRaster03])

# Save the output 
outLowestPosition.save("C:/sapyexamples/output/outlp")
```

### Example 5

```python
# Name: LowestPosition_Ex_02.py
# Description: Determines the position of a raster with the minimum
#              value in a set of rasters
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute LowestPosition
outLowestPosition = LowestPosition([inRaster01, inRaster02, inRaster03])

# Save the output 
outLowestPosition.save("C:/sapyexamples/output/outlp")
```

---

## Majority Filter (Spatial Analyst)

## Summary

Replaces cells in a raster based on the majority of their contiguous neighboring cells.

## Usage

- The Majority Filter tool must satisfy two criteria before a replacement can occur. The number of neighboring cells of a similar value must be large enough (either by being the majority of, or half of, all the cells), and those cells must be contiguous about the center of the filter kernel. The second criteria concerning the spatial connectivity of the cells minimizes the corruption of cellular spatial patterns.
- Using four for the number of neighbors will retain the corners of rectangular regions. Using eight neighbors will smooth the corners of rectangular regions.
- With the number of neighbors set to eight, contiguous is defined as sharing an edge. With the number of neighbors set to four, contiguous is defined as sharing a corner.
- If the Replacement threshold parameter is set to Half and two values occur as equal portions, no replacement will occur if the value of the processing cell is the same as one of the halves. The Half option allows more extensive filtering than the Majority option.
- While the contiguity criterion is the same for edge and corner raster cells, they obey different rules for the Majority and Half options. When the number of neighbors to be used is four, an edge or corner cell always requires two matching neighbors before replacement will occur. With eight neighbors, a corner cell must have all neighbors of the same value before it is changed, while an edge cell requires three contiguous neighbors, including one along the edge, before any change will occur.
- The output raster will be stabilized (will no longer change) after a few runs of Majority Filter.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster to be filtered based on the majority of contiguous neighboring cells.It must be of integer type. | Raster Layer |
| Number of neighbors to use(Optional) | Determines the number of neighboring cells to use in the kernel of the filter.Four—The kernel of the filter will be the four direct (orthogonal) neighbors to the present cell. This is the default.Eight—The kernel of the filter will be the eight nearest neighbors (a three-by-three window) to the present cell. | String |
| Replacement threshold(Optional) | Specifies the number of contiguous (spatially connected) cells that must be of the same value before a replacement will occur.Majority—A majority of cells must have the same value and be contiguous. Three out of four or five out of eight connected cells must have the same value.Half—Half of the cells must have the same value and be contiguous. Two out of four or four out of eight connected cells must have the same value. This option will have a more smoothing effect than the other. | String |
| in_raster | The input raster to be filtered based on the majority of contiguous neighboring cells.It must be of integer type. | Raster Layer |
| number_neighbors(Optional) | Determines the number of neighboring cells to use in the kernel of the filter.FOUR—The kernel of the filter will be the four direct (orthogonal) neighbors to the present cell. This is the default.EIGHT—The kernel of the filter will be the eight nearest neighbors (a three-by-three window) to the present cell. | String |
| majority_definition(Optional) | Specifies the number of contiguous (spatially connected) cells that must be of the same value before a replacement will occur.MAJORITY—A majority of cells must have the same value and be contiguous. Three out of four or five out of eight connected cells must have the same value.HALF—Half of the cells must have the same value and be contiguous. Two out of four or four out of eight connected cells must have the same value. This option will have a more smoothing effect than the other. | String |

## Code Samples

### Example 1

```python
MajorityFilter(in_raster, {number_neighbors}, {majority_definition})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outMajFilt = MajorityFilter("land", "EIGHT", "HALF")
outMajFilt.save("c:/sapyexamples/output/outmajfilt")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outMajFilt = MajorityFilter("land", "EIGHT", "HALF")
outMajFilt.save("c:/sapyexamples/output/outmajfilt")
```

### Example 4

```python
# Name: MajorityFilter_Ex_02.py
# Description: Replaces cells in a raster based on the 
#              majority of their contiguous neighboring cells.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"

# Execute MajorityFilter
outMajFilt = MajorityFilter(inRaster, "EIGHT", "HALF")

# Save the output 
outMajFilt.save("c:/sapyexamples/output/majfilter")
```

### Example 5

```python
# Name: MajorityFilter_Ex_02.py
# Description: Replaces cells in a raster based on the 
#              majority of their contiguous neighboring cells.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"

# Execute MajorityFilter
outMajFilt = MajorityFilter(inRaster, "EIGHT", "HALF")

# Save the output 
outMajFilt.save("c:/sapyexamples/output/majfilter")
```

---

## Maximum Likelihood Classification (Spatial Analyst)

## Summary

Performs a maximum likelihood classification on a set of raster bands and creates a classified raster as output.

## Usage

- When a multiband raster is specified as one of the Input raster bands (in_raster_bands in Python), all the bands will be used.To process a selection of bands from a multiband raster, you can first create a new raster dataset composed of those particular bands with the Composite Bands tool, and use the result in the list of the Input raster bands (in_raster_bands in Python).
- Any signature file created by the Create Signature, Edit Signature, or Iso Cluster tools is a valid entry for the input signature file. These will have a .gsg extension.
- By default, all cells in the output raster will be classified, with each class having equal probability weights attached to their signatures.
- The input a priori probability file must be an ASCII file consisting of two columns. The values in the left column represent class IDs. The values in the right column represent the a priori probabilities for the respective classes. Valid values for class a priori probabilities must be greater than or equal to zero. If zero is specified as a probability, the class will not appear on the output raster. The sum of the specified a priori probabilities must be less than or equal to one. The format of the file is as follows: 1 .3 2 .1 4 .0 5 .15 7 .05 8 .2The classes omitted in the file will receive the average a priori probability of the remaining portion of the value of one. In the above example, all classes from 1 to 8 are represented in the signature file. The a priori probabilities of classes 3 and 6 are missing in the input a priori probability file. Since the sum of all probabilities specified in the above file is equal to 0.8, the remaining portion of the probability (0.2) is divided by the number of classes not specified (2). Therefore, classes 3 and 6 will each be assigned a probability of 0.1.
- A specified reject fraction, which lies between any two valid values, will be assigned to the next upper valid value. For example, 0.02 will become 0.025.
- There is a direct relationship between the number of unclassified cells on the output raster resulting from the reject fraction and the number of cells represented by the sum of levels of confidence smaller than the respective value entered for the reject fraction.
- If the Class Name in the signature file is different than the Class ID, then an additional field will be added to the output raster attribute table called CLASSNAME. For each class in the output table, this field will contain the Class Name associated with the class. For example, if the Class Names for the classes in the signature file are descriptive string names (for example, conifers, water, and urban), these names will be carried to the CLASSNAME field.
- The extension for an input a priori probability file is .txt.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster bands | The input raster bands.While the bands can be integer or floating point type, the signature file only allows integer class values. | Raster Layer |
| Input signature file | The input signature file whose class signatures are used by the maximum likelihood classifier.A .gsg extension is required. | File |
| Reject fraction(Optional) | Select a reject fraction, which determines whether a cell will be classified based on its likelihood of being correctly assigned to one of the classes. Cells whose likelihood of being correctly assigned to any of the classes is lower than the reject fraction will be given a value of NoData in the output classified raster.The default value is 0.0, which means that every cell will be classified.Valid entries are:0.0— The rejection fraction is 0.00.005— The rejection fraction is 0.0050.01— The rejection fraction is 0.01 0.025— The rejection fraction is 0.0250.05— The rejection fraction is 0.050.1— The rejection fraction is 0.10.25— The rejection fraction is 0.250.5— The rejection fraction is 0.50.75— The rejection fraction is 0.750.9— The rejection fraction is 0.90.95— The rejection fraction is 0.950.975— The rejection fraction is 0.9750.99— The rejection fraction is 0.990.995— The rejection fraction is 0.995 | String |
| A priori probability weighting(Optional) | Specifies how a priori probabilities will be determined.Equal—All classes will have the same a priori probability.Sample—A priori probabilities will be proportional to the number of cells in each class relative to the total number of cells sampled in all classes in the signature file.File—The a priori probabilities will be assigned to each class from an input ASCII a priori probability file. | String |
| Input a priori probability file(Optional) | A text file containing a priori probabilities for the input signature classes.An input for the a priori probability file is only required when the File option is used.The extension for the a priori file can be .txt or .asc. | File |
| Output confidence raster(Optional) | The output confidence raster dataset shows the certainty of the classification in 14 levels of confidence, with the lowest values representing the highest reliability. If there are no cells classified at a particular confidence level, that confidence level will not be present in the output confidence raster.It will be of integer type. | Raster Dataset |
| in_raster_bands[in_raster_band,...] | The input raster bands.While the bands can be integer or floating point type, the signature file only allows integer class values. | Raster Layer |
| in_signature_file | The input signature file whose class signatures are used by the maximum likelihood classifier.A .gsg extension is required. | File |
| reject_fraction(Optional) | Select a reject fraction, which determines whether a cell will be classified based on its likelihood of being correctly assigned to one of the classes. Cells whose likelihood of being correctly assigned to any of the classes is lower than the reject fraction will be given a value of NoData in the output classified raster.The default value is 0.0, which means that every cell will be classified. Valid entries are: 0.0— The rejection fraction is 0.00.005— The rejection fraction is 0.0050.01— The rejection fraction is 0.01 0.025— The rejection fraction is 0.0250.05— The rejection fraction is 0.050.1— The rejection fraction is 0.10.25— The rejection fraction is 0.250.5— The rejection fraction is 0.50.75— The rejection fraction is 0.750.9— The rejection fraction is 0.90.95— The rejection fraction is 0.950.975— The rejection fraction is 0.9750.99— The rejection fraction is 0.990.995— The rejection fraction is 0.995 | String |
| a_priori_probabilities(Optional) | Specifies how a priori probabilities will be determined.EQUAL—All classes will have the same a priori probability.SAMPLE—A priori probabilities will be proportional to the number of cells in each class relative to the total number of cells sampled in all classes in the signature file.FILE—The a priori probabilities will be assigned to each class from an input ASCII a priori probability file. | String |
| in_a_priori_file(Optional) | A text file containing a priori probabilities for the input signature classes.An input for the a priori probability file is only required when the File option is used.The extension for the a priori file can be .txt or .asc. | File |
| out_confidence_raster(Optional) | The output confidence raster dataset shows the certainty of the classification in 14 levels of confidence, with the lowest values representing the highest reliability. If there are no cells classified at a particular confidence level, that confidence level will not be present in the output confidence raster.It will be of integer type. | Raster Dataset |

## Code Samples

### Example 1

```python
1  .3
    2  .1
    4  .0
    5  .15
    7  .05
    8  .2
```

### Example 2

```python
MLClassify(in_raster_bands, in_signature_file, {reject_fraction}, {a_priori_probabilities}, {in_a_priori_file}, {out_confidence_raster})
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
mlcOut = MLClassify("redlands", "c:/sapyexamples/data/wedit5.gsg", "0.0", 
                    "EQUAL", "", "c:/sapyexamples/output/redmlcconf")
mlcOut.save("c:/sapyexamples/output/redmlc")
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
mlcOut = MLClassify("redlands", "c:/sapyexamples/data/wedit5.gsg", "0.0", 
                    "EQUAL", "", "c:/sapyexamples/output/redmlcconf")
mlcOut.save("c:/sapyexamples/output/redmlc")
```

### Example 5

```python
# Name: MLClassify_Ex_02.py
# Description: Performs a maximum likelihood classification on a set of 
#    raster bands.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "redlands"
sigFile = "c:/sapyexamples/data/wedit5.gsg"
probThreshold = "0.0"
aPrioriWeight = "EQUAL"
aPrioriFile = ""
outConfidence = "c:/sapyexamples/output/redconfmlc"


# Execute 
mlcOut = MLClassify(inRaster, sigFile, probThreshold, aPrioriWeight, 
                    aPrioriFile, outConfidence) 

# Save the output 
mlcOut.save("c:/sapyexamples/output/redmlc02")
```

### Example 6

```python
# Name: MLClassify_Ex_02.py
# Description: Performs a maximum likelihood classification on a set of 
#    raster bands.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "redlands"
sigFile = "c:/sapyexamples/data/wedit5.gsg"
probThreshold = "0.0"
aPrioriWeight = "EQUAL"
aPrioriFile = ""
outConfidence = "c:/sapyexamples/output/redconfmlc"


# Execute 
mlcOut = MLClassify(inRaster, sigFile, probThreshold, aPrioriWeight, 
                    aPrioriFile, outConfidence) 

# Save the output 
mlcOut.save("c:/sapyexamples/output/redmlc02")
```

---

## Minus (Spatial Analyst)

## Summary

Subtracts the value of the second input raster from the value of the first input raster on a cell-by-cell basis.

## Usage

- The order of inputs is relevant for this tool.
- If both inputs are integer, the output will be an integer raster; otherwise, it will be a floating-point raster.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "-" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input from which to subtract the values in the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input values to subtract from the values in the first input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input from which to subtract the values in the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input values to subtract from the values in the first input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Minus(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outMinus = Minus("degs", "negs")
outMinus.save("C:/sapyexamples/output/outminus")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outMinus = Minus("degs", "negs")
outMinus.save("C:/sapyexamples/output/outminus")
```

### Example 4

```python
# Name: Minus_Ex_02.py
# Description: Subtracts the value of the second input raster from the
#              value of the first input raster on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute Minus
outMinus = Minus(inRaster1, inRaster2)

# Save the output 
outMinus.save("C:/sapyexamples/output/outminus.tif")
```

### Example 5

```python
# Name: Minus_Ex_02.py
# Description: Subtracts the value of the second input raster from the
#              value of the first input raster on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute Minus
outMinus = Minus(inRaster1, inRaster2)

# Save the output 
outMinus.save("C:/sapyexamples/output/outminus.tif")
```

---

## Mod (Spatial Analyst)

## Summary

Finds the remainder (modulo) of the first raster when divided by the second raster on a cell-by-cell basis.

## Usage

- The order of inputs is relevant for this tool.
- Mod assumes both its inputs are integers. If any inputs are not integer, those inputs will be converted to integers through truncation. Output values are always integers.
- Any value modulated (divided) by 0 is assigned NoData on the output. Therefore, any location on the second input that is either 0 or NoData will return NoData for that location on the output.
- If the second input value (the divisor) is larger than the first input value (the dividend), the output will be the same value as the first input. For example, if you were to divide a value of 8 by value 10, the integer division calculation will return the input value 8 for the remainder.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "%" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The numerator input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The denominator input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The numerator input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The denominator input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Mod(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outMod = Mod("degs", "negs")
outMod.save("C:/sapyexamples/output/outmod.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outMod = Mod("degs", "negs")
outMod.save("C:/sapyexamples/output/outmod.tif")
```

### Example 4

```python
# Name: Mod_Ex_02.py
# Description: Finds the remainder of the first raster when divided by
#              the second raster on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute Mod
outMod = Mod(inRaster1, inRaster2)

# Save the output 
outMod.save("C:/sapyexamples/output/outmod")
```

### Example 5

```python
# Name: Mod_Ex_02.py
# Description: Finds the remainder of the first raster when divided by
#              the second raster on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute Mod
outMod = Mod(inRaster1, inRaster2)

# Save the output 
outMod.save("C:/sapyexamples/output/outmod")
```

---

## Multiscale Surface Difference (Spatial Analyst)

## Summary

Calculates the maximum difference from the mean elevation across a range of spatial scales.

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Surface Raster | The input surface raster. | Raster Layer |
| Output Scale Raster(Optional) | The output raster containing the scale at which the most extreme difference was found for each cell. Scales are represented as their neighborhood distance values.It will be floating-point type. | Raster Dataset |
| Distance Units(Optional) | Specifies the distance unit that will be used for the Minimum Neighborhood Distance, Maximum Neighborhood Distance, and Distance Increment parameters.Distance will be measured in the number of cells or specified unit. The default is the map unit of the spatial reference for the Input Surface Raster value.Cells—The distance unit will be cells.Meters—The distance unit will be meters.Centimeters—The distance unit will be centimeters.Kilometers—The distance unit will be kilometers.Inches—The distance unit will be inches.Feet—The distance unit will be feet.Yard—The distance unit will be yards.Miles—The distance unit will be miles. | String |
| Minimum Neighborhood Distance(Optional) | The distance that defines the minimum neighborhood scale that elevation difference will be calculated for. This is the distance from the target cell center, creating a square of cells around the target cell.This value must be less than or equal to the Maximum Neighborhood Distance parameter value and greater than or equal to the input raster cell size or one cell. The default value is 4 times the cell size of the Input Surface Raster parameter value, resulting in a 9 by 9 cell neighborhood. | Double |
| Maximum Neighborhood Distance(Optional) | The distance that defines the maximum neighborhood scale that elevation difference will be calculated for. This is the distance from the target cell center, creating a square of cells around the target cell.This value must be greater than or equal to the Minimum Neighborhood Distance parameter value and the input raster cell size or one cell.The default value is 13 times the cell size of the Input Surface Raster parameter value, resulting in a 27 by 27 cell neighborhood. | Double |
| Distance Increment(Optional) | The increase in neighborhood distance between scales. This parameter value cannot be less than the Input Surface Raster cell size or 1 cell.The default value is the cell size of the Input Surface Raster parameter value. | Double |
| Target Device for Analysis(Optional) | Specifies the device that will be used to perform the calculation.GPU then CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU only—The calculation will only be performed on the CPU.GPU only—The calculation will only be performed on the GPU. | String |
| in_raster | The input surface raster. | Raster Layer |
| out_scale_raster(Optional) | The output raster containing the scale at which the most extreme difference was found for each cell. Scales are represented as their neighborhood distance values.It will be floating-point type. | Raster Dataset |
| distance_units(Optional) | Specifies the distance unit that will be used for the min_scale, max_scale, and increment parameters.Distance will be measured in the number of cells or specified unit. The default is the map unit of the spatial reference for the in_raster value.CELLS—The distance unit will be cells.METERS—The distance unit will be meters.CENTIMETERS—The distance unit will be centimeters.KILOMETERS—The distance unit will be kilometers.INCHES—The distance unit will be inches.FEET—The distance unit will be feet.YARDS—The distance unit will be yards.MILES—The distance unit will be miles. | String |
| min_scale(Optional) | The distance that defines the minimum neighborhood scale that elevation difference will be calculated for. This is the distance from the target cell center, creating a square of cells around the target cell.This value must be less than or equal to the max_scale parameter value and greater than or equal to the input raster cell size or one cell.The default value is 4 times the cell size of the in_raster parameter value, resulting in a 9 by 9 cell neighborhood. | Double |
| max_scale(Optional) | The distance that defines the maximum neighborhood scale that elevation difference will be calculated for. This is the distance from the target cell center, creating a square of cells around the target cell. This value must be greater than or equal to the min_scale parameter value and the input raster cell size or one cell.The default value is 13 times the cell size of the in_raster parameter value, resulting in a 27 by 27 cell neighborhood. | Double |
| increment(Optional) | The increase in neighborhood distance between scales. This parameter value cannot be less than the in_raster cell size or 1 cell.The default value is the cell size of the in_raster parameter value. | Double |
| analysis_target_device(Optional) | Specifies the device that will be used to perform the calculation.GPU_THEN_CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU_ONLY—The calculation will only be performed on the CPU.GPU_ONLY—The calculation will only be performed on the GPU. | String |

## Code Samples

### Example 1

```python
MultiscaleSurfaceDifference(in_raster, {out_scale_raster}, {distance_units}, {min_scale}, {max_scale}, {increment}, {analysis_target_device})
```

### Example 2

```python
from arcpy.sa import *
outMaxDifferences = MultiscaleSurfaceDifference("elevation.tif", "", "", "", "", "", "")
outMaxDifferences.save("C:/sapyexamples/output/outmaxdifferencs01.tif")
```

### Example 3

```python
from arcpy.sa import *
outMaxDifferences = MultiscaleSurfaceDifference("elevation.tif", "", "", "", "", "", "")
outMaxDifferences.save("C:/sapyexamples/output/outmaxdifferencs01.tif")
```

### Example 4

```python
# Name: MultiscaleSurfaceDifference_standalone.py
# Description: Calculates the maximum difference for each cell from the mean
# over a range of spatial scales.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation.tif"
inDistanceUnits = "METERS"
inMinScale = 10
inMaxScale = 100
inIncrement = 1

# Execute the tool
outMaxDifferences = MultiscaleSurfaceDifference(inRaster, "", inDistanceUnits, inMinScale,
                                                inMaxScale, inIncrement, "")

# Save the output 
outMaxDifference.save("C:/sapyexamples/output/outmaxdifferences02.tif")
```

### Example 5

```python
# Name: MultiscaleSurfaceDifference_standalone.py
# Description: Calculates the maximum difference for each cell from the mean
# over a range of spatial scales.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation.tif"
inDistanceUnits = "METERS"
inMinScale = 10
inMaxScale = 100
inIncrement = 1

# Execute the tool
outMaxDifferences = MultiscaleSurfaceDifference(inRaster, "", inDistanceUnits, inMinScale,
                                                inMaxScale, inIncrement, "")

# Save the output 
outMaxDifference.save("C:/sapyexamples/output/outmaxdifferences02.tif")
```

---

## Multiscale Surface Percentile (Spatial Analyst)

## Summary

Calculates the most extreme percentile across a range of spatial scales.

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Surface Raster | The input surface raster. | Raster Layer |
| Output Scale Raster(Optional) | The output raster containing the scale at which the most extreme percentile was found for each cell. Scales are represented as their neighborhood distance values.It will be floating-point type. | Raster Dataset |
| Distance Units(Optional) | Specifies the distance unit that will be used for the Minimum Neighborhood Distance, Maximum Neighborhood Distance, and Base Distance Increment parameters.Distance will be measured in the number of cells or specified unit. The default is the map unit of the spatial reference for the Input Surface Raster value.Cells—The distance unit will be cells.Meters—The distance unit will be meters.Centimeters—The distance unit will be centimeters.Kilometers—The distance unit will be kilometers.Inches—The distance unit will be inches.Feet—The distance unit will be feet.Yard—The distance unit will be yards.Miles—The distance unit will be miles. | String |
| Minimum Neighborhood Distance(Optional) | The distance that defines the minimum neighborhood scale that elevation percentile will be calculated for. This is the distance from the target cell center, creating a square of cells around the target cell. This value must be less than or equal to the Maximum Neighborhood Distance parameter value and greater than or equal to the input raster cell size or one cell.The default value is 4 times the cell size of the Input Surface Raster parameter value, resulting in a 9 by 9 cell neighborhood. | Double |
| Maximum Neighborhood Distance(Optional) | The distance that defines the maximum neighborhood scale that elevation percentile will be calculated for. This is the distance from the target cell center, creating a square of cells around the target cell. This value must be greater than or equal to the Minimum Neighborhood Distance parameter value and the input raster cell size or one cell.The default value is 13 times the cell size of the Input Surface Raster parameter value, resulting in a 27 by 27 cell neighborhood. | Double |
| Base Distance Increment(Optional) | The initial increase in neighborhood distance between scales.This parameter value cannot be less than the Input Surface Raster cell size or 1 cell.The default value is the cell size of the Input Surface Raster parameter value. | Double |
| Nonlinearity Factor(Optional) | The factor that can introduce nonlinearity into the scale increase at each increment. This causes the increment between scales to increase instead of remaining constant. Generally, values between 1.0 and 2.0 are used.This parameter must be greater than or equal to 1.The default value is 1, which creates a linear increase in neighborhood distances (where the increment between scales remains constant). | Double |
| Target Device for Analysis(Optional) | Specifies the device that will be used to perform the calculation.GPU then CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU only—The calculation will only be performed on the CPU.GPU only—The calculation will only be performed on the GPU. | String |
| in_raster | The input surface raster. | Raster Layer |
| out_scale_raster(Optional) | The output raster containing the scale at which the most extreme percentile was found for each cell. Scales are represented as their neighborhood distance values.It will be floating-point type. | Raster Dataset |
| distance_units(Optional) | Specifies the distance unit that will be used for the min_scale, max_scale, and base_increment parameters.Distance will be measured in the number of cells or specified unit. The default is the map unit of the spatial reference for the in_raster value.CELLS—The distance unit will be cells.METERS—The distance unit will be meters.CENTIMETERS—The distance unit will be centimeters.KILOMETERS—The distance unit will be kilometers.INCHES—The distance unit will be inches.FEET—The distance unit will be feet.YARDS—The distance unit will be yards.MILES—The distance unit will be miles. | String |
| min_scale(Optional) | The distance that defines the minimum neighborhood scale that elevation percentile will be calculated for. This is the distance from the target cell center, creating a square of cells around the target cell. This value must be less than or equal to the max_scale parameter value and greater than or equal to the input raster cell size or one cell.The default value is 4 times the cell size of the in_raster parameter value, resulting in a 9 by 9 cell neighborhood. | Double |
| max_scale(Optional) | The distance that defines the maximum neighborhood scale that elevation percentile will be calculated for. This is the distance from the target cell center, creating a square of cells around the target cell. This value must be greater than or equal to the min_scale parameter value and the input raster cell size or one cell.The default value is 13 times the cell size of the in_raster parameter value, resulting in a 27 by 27 cell neighborhood. | Double |
| base_increment(Optional) | The initial increase in neighborhood distance between scales.This parameter cannot be less than the in_raster cell size or 1 cell.The default value is the cell size of the in_raster parameter value. | Double |
| nonlinearity(Optional) | The factor that can introduce nonlinearity into the scale increase at each increment. This causes the increment between scales to increase instead of remaining constant. Generally, values between 1.0 and 2.0 are used.This parameter must be greater than or equal to 1.The default value is 1, which creates a linear increase in neighborhood distances (where the increment between scales remains constant). | Double |
| analysis_target_device(Optional) | Specifies the device that will be used to perform the calculation.GPU_THEN_CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU_ONLY—The calculation will only be performed on the CPU.GPU_ONLY—The calculation will only be performed on the GPU. | String |

## Code Samples

### Example 1

```python
MultiscaleSurfacePercentile(in_raster, {out_scale_raster}, {distance_units}, {min_scale}, {max_scale}, {base_increment}, {nonlinearity}, {analysis_target_device})
```

### Example 2

```python
from arcpy.sa import *
outPercentiles = MultiscaleSurfacePercentile("elevation.tif", "", "", "", "", "", "", "")
outPercentiles.save("C:/sapyexamples/output/outpercentiles01.tif")
```

### Example 3

```python
from arcpy.sa import *
outPercentiles = MultiscaleSurfacePercentile("elevation.tif", "", "", "", "", "", "", "")
outPercentiles.save("C:/sapyexamples/output/outpercentiles01.tif")
```

### Example 4

```python
# Name: MultiscaleSurfacePercentile_standalone.py
# Description: Calculates the most extreme percentiles over a range of spatial scales.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation.tif"
inDistanceUnits = "METERS"
inMinScale = 10
inMaxScale = 100
inIncrement = 10
inNonlinearity = 1

# Execute the tool
outPercentiles = MultiscaleSurfacePercentile(inRaster, "", inDistanceUnits, inMinScale,
                                             inMaxScale, inIncrement, inNonlinearity, "")

# Save the output 
outPercentiles.save("C:/sapyexamples/output/outpercentiles02.tif")
```

### Example 5

```python
# Name: MultiscaleSurfacePercentile_standalone.py
# Description: Calculates the most extreme percentiles over a range of spatial scales.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation.tif"
inDistanceUnits = "METERS"
inMinScale = 10
inMaxScale = 100
inIncrement = 10
inNonlinearity = 1

# Execute the tool
outPercentiles = MultiscaleSurfacePercentile(inRaster, "", inDistanceUnits, inMinScale,
                                             inMaxScale, inIncrement, inNonlinearity, "")

# Save the output 
outPercentiles.save("C:/sapyexamples/output/outpercentiles02.tif")
```

---

## Natural Neighbor (Spatial Analyst)

## Summary

Interpolates a raster surface from points using a natural neighbor technique.

## Usage

- If the cell center of the perimeter cells of the output raster fall outside the convex hull (defined by the input points), then those cells will be assigned NoData values. If an input point falls within one of these perimeter cells and the cell center falls outside the convex hull, the cell will still be assigned a value of NoData.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Some input datasets may have several points with the same x,y coordinates. If the values of the points at the common location are the same, they are considered duplicates and have no effect on the output. If the values are different, they are considered coincident points.The various interpolation tools may handle this data condition differently. For example, in some cases, the first coincident point encountered is used for the calculation; in other cases, the last point encountered is used. This may cause some locations in the output raster to have different values than what you might expect. The solution is to prepare your data by removing these coincident points. The Collect Events tool in the Spatial Statistics toolbox is useful for identifying any coincident points in your data.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- It is recommended that the input data be in a projected coordinate system rather than in a geographic coordinate system.
- If the ArcGIS 3D Analyst extension is available, an alternative approach is to use a TIN dataset. First, create a TIN surface from your source data. Then, convert the resulting TIN to a raster with the TIN To Raster tool, using the Natural Neighbors option. This is particularly useful if you have breaklines or an irregularly shaped data area.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| Z value field | The field that holds a height or magnitude value for each point.This can be a numeric field or the Shape field if the input point features contain z-values. | Field |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| in_point_features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| z_field | The field that holds a height or magnitude value for each point.This can be a numeric field or the Shape field if the input point features contain z-values. | Field |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |

## Code Samples

### Example 1

```python
NaturalNeighbor(in_point_features, z_field, {cell_size})
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outNaturalNeighbor = NaturalNeighbor("ozone_pts.shp", "ozone", 2000)
outNaturalNeighbor.save("C:/sapyexamples/output/nnout.tif")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outNaturalNeighbor = NaturalNeighbor("ozone_pts.shp", "ozone", 2000)
outNaturalNeighbor.save("C:/sapyexamples/output/nnout.tif")
```

### Example 4

```python
# Name: NaturalNeighbor_Ex_02.py
# Description: Interpolate a series of point features onto a 
#    rectangular raster using Natural Neighbor interpolation.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "ca_ozone_pts.shp"
zField = "ozone"
cellSize = 40000

# Execute NaturalNeighbor
outNatNbr = NaturalNeighbor(inPointFeatures, zField, cellSize)

# Save the output 
outNatNbr.save("C:/sapyexamples/output/nnout02")
```

### Example 5

```python
# Name: NaturalNeighbor_Ex_02.py
# Description: Interpolate a series of point features onto a 
#    rectangular raster using Natural Neighbor interpolation.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "ca_ozone_pts.shp"
zField = "ozone"
cellSize = 40000

# Execute NaturalNeighbor
outNatNbr = NaturalNeighbor(inPointFeatures, zField, cellSize)

# Save the output 
outNatNbr.save("C:/sapyexamples/output/nnout02")
```

---

## Negate (Spatial Analyst)

## Summary

Changes the sign (multiplies by -1) of the cell values of the input raster on a cell-by-cell basis.

## Usage

- If the input is integer, the output raster will be integer type. If the input is floating point, the output raster will be floating point.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- In map algebra, the equivalent operator symbol for this tool is "-" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input raster to be negated (multiplied by -1).To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input raster to be negated (multiplied by -1).To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Negate(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outNegate = Negate("degs")
outNegate.save("C:/sapyexamples/output/outneg")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outNegate = Negate("degs")
outNegate.save("C:/sapyexamples/output/outneg")
```

### Example 4

```python
# Name: Negate_Ex_02.py
# Description: Changes the sign (multiplies by -1) of the cell values
#              of the input raster on a cell-by-cell basis 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Negate
outNegate = Negate(inRaster)

# Save the output 
outNegate.save("C:/sapyexamples/output/outnegate")
```

### Example 5

```python
# Name: Negate_Ex_02.py
# Description: Changes the sign (multiplies by -1) of the cell values
#              of the input raster on a cell-by-cell basis 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Negate
outNegate = Negate(inRaster)

# Save the output 
outNegate.save("C:/sapyexamples/output/outnegate")
```

---

## Nibble (Spatial Analyst)

## Summary

Replaces cells of a raster corresponding to a mask with the value of the nearest neighbor.

## Usage

- You can use the Nibble tool to select areas of a raster and assign them the value of their nearest neighbor. The tool can be used to replace a few individual cells with the values immediately nearby. With larger mask areas, larger swaths of cells can be replaced.A common application is for editing areas of a raster where the data is known to be erroneous.
- Cells that are NoData in the input mask raster define which cells will be replaced. Any locations in the input raster that are not within the mask area will not be replaced, and the output value for them will be the same as the input value.NoData cells in the input raster that are not within the mask are not replaced. The cells will remain NoData regardless of the settings of the two NoData parameters.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. The Parallel processing with Spatial Analyst help topic has more details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have admin privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster with the masked locations that will be replaced by the value of their nearest neighbor.The input raster can be either integer or floating point type. | Raster Layer |
| Input raster mask | The raster that identifies the locations in the input raster that will be replaced.Cells with a value of NoData are considered to be within the masked area. In the output raster, these locations will be replaced by the value of their nearest neighbor in the Input raster value.The mask raster can be either integer or floating point type. | Raster Layer |
| Use NoData values if they are the nearest neighbor(Optional) | Specifies whether NoData cells in the input raster can replace cells in the masked areas if they are the nearest neighbor. Checked—Both NoData and data values can replace cells in the masked area. This means that NoData values in the input raster can replace areas defined in the mask if they are the nearest neighbor. This is the default.Unchecked—Only data values can replace cells in the masked area. NoData values in the input raster cannot replace areas defined in the mask raster even if they are the nearest neighbor. | Boolean |
| Nibble NoData cells(Optional) | Specifies whether NoData cells in the input raster that are within the masked area will be preserved or replaced. Unchecked—Any NoData cells in the input raster that are within the masked area will be preserved (remain as NoData) in the output. This is the default.Checked—NoData cells in the input raster that are within the masked area can be replaced with the value of the nearest neighbor that is outside the masked area. | Boolean |
| Input zone raster(Optional) | The input zone raster. For each zone, input cells that are within the mask will be replaced only by the nearest cell values within that same zone.A zone is all the cells in a raster that have the same value, whether or not they are contiguous. The input zone layer defines the shape, values, and locations of the zones. The zone raster can be either integer or floating point type. | Raster Layer |
| in_raster | The input raster with the masked locations that will be replaced by the value of their nearest neighbor.The input raster can be either integer or floating point type. | Raster Layer |
| in_mask_raster | The raster that identifies the locations in the input raster that will be replaced. Cells with a value of NoData are considered to be within the masked area. In the output raster, these locations will be replaced by the value of their nearest neighbor in the in_raster value.The mask raster can be either integer or floating point type. | Raster Layer |
| nibble_values(Optional) | Specifies whether NoData cells in the input raster can replace cells in the masked areas if they are the nearest neighbor. ALL_VALUES—Both NoData and data values can replace cells in the masked area. This means that NoData values in the input raster can replace areas defined in the mask if they are the nearest neighbor. This is the default.DATA_ONLY—Only data values can replace cells in the masked area. NoData values in the input raster cannot replace areas defined in the mask raster even if they are the nearest neighbor. | Boolean |
| nibble_nodata(Optional) | Specifies whether NoData cells in the input raster that are within the masked area will be preserved or replaced. PRESERVE_NODATA— Any NoData cells in the input raster that are within the masked area will be preserved (remain as NoData) in the output. This is the default.PROCESS_NODATA—NoData cells in the input raster that are within the masked area can be replaced with the value of the nearest neighbor that is outside the masked area. | Boolean |
| in_zone_raster(Optional) | The input zone raster. For each zone, input cells that are within the mask will be replaced only by the nearest cell values within that same zone.A zone is all the cells in a raster that have the same value, whether or not they are contiguous. The input zone layer defines the shape, values, and locations of the zones. The zone raster can be either integer or floating point type. | Raster Layer |

## Code Samples

### Example 1

```python
Nibble(in_raster, in_mask_raster, {nibble_values}, {nibble_nodata}, {in_zone_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
nibbleOut = Nibble("land", "snow", "DATA_ONLY")
nibbleOut.save("C:/sapyexamples/output/nibbleout")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
nibbleOut = Nibble("land", "snow", "DATA_ONLY")
nibbleOut.save("C:/sapyexamples/output/nibbleout")
```

### Example 4

```python
# Name: Nibble_Ex_02.py
# Description: Replaces cells of a raster corresponding to a mask 
#              with the values of the nearest neighbors.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"
inMask = "snow"

# Execute Nibble
nibbleOut = Nibble(inRaster, inMask, "ALL_VALUES")

# Save the output 
nibbleOut.save("C:/sapyexamples/output/outnibble")
```

### Example 5

```python
# Name: Nibble_Ex_02.py
# Description: Replaces cells of a raster corresponding to a mask 
#              with the values of the nearest neighbors.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"
inMask = "snow"

# Execute Nibble
nibbleOut = Nibble(inRaster, inMask, "ALL_VALUES")

# Save the output 
nibbleOut.save("C:/sapyexamples/output/outnibble")
```

---

## Not Equal (Spatial Analyst)

## Summary

Performs a Relational not-equal-to operation on two inputs on a cell-by-cell basis.

## Usage

- Two inputs are necessary for this relational evaluation to take place.
- The order of inputs is irrelevant for this tool.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "!=" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input that will be compared to for inequality by the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input that will be compared from for inequality by the first input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input that will be compared to for inequality by the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input that will be compared from for inequality by the first input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
NotEqual(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outNotEqual = NotEqual("degs", "negs")
outNotEqual.save("C:/sapyexamples/output/outne")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outNotEqual = NotEqual("degs", "negs")
outNotEqual.save("C:/sapyexamples/output/outne")
```

### Example 4

```python
# Name: NotEqual_Ex_02.py
# Description: Performs a relational not-equal operation on two
#              inputs on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute NotEqual
outNotEqual = NotEqual(inRaster1, inRaster2)

# Save the output 
outNotEqual.save("C:/sapyexamples/output/outnotequal")
```

### Example 5

```python
# Name: NotEqual_Ex_02.py
# Description: Performs a relational not-equal operation on two
#              inputs on a cell-by-cell basis
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute NotEqual
outNotEqual = NotEqual(inRaster1, inRaster2)

# Save the output 
outNotEqual.save("C:/sapyexamples/output/outnotequal")
```

---

## Observer Points (Spatial Analyst)

## Summary

Identifies which observer points are visible from each raster surface location.

## Usage

- Determining observer points is a computer-intensive process. The processing time is dependent on the resolution. For preliminary studies, you can use a coarser cell size to reduce the number of cells in the input. Use the full-resolution raster when the final results are ready to be generated.
- If the input raster contains undesirable noise caused by sampling errors, you can smooth the raster with a low-pass filter, such as the Mean option of the Focal Statistics tool, before running this tool.
- The visibility of each cell center is determined by comparing the altitude angle to the cell center with the altitude angle to the local horizon. The local horizon is computed by considering the intervening terrain between the point of observation and the current cell center. If the point lies above the local horizon, it is considered visible.
- An optional above ground level (AGL) output raster is provided by the tool. Each cell on the AGL output raster records the minimum height that needs to be added to that cell to make it visible by at least one observer.When the input observer features contain multiple observers, the output value is the minimum of the AGL values from all of the individual observers.
- When the input raster needs to be resampled, the bilinear technique will be used. An example of when an input raster may be resampled is when the output coordinate system, extent, or cell size is different from that of the input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input surface raster. | Raster Layer |
| Input point observer features | The point feature class that identifies the observer locations.The maximum number of points allowed is 16. | Feature Layer |
| Z factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| Use earth curvature corrections(Optional) | Specifies whether correction for the earth's curvature will be applied.Unchecked—No curvature correction will be applied. This is the default.Checked—Curvature correction will be applied. | Boolean |
| Refractivity coefficient(Optional) | The coefficient of the refraction of visible light in air.The default value is 0.13. | Double |
| Output above ground level raster(Optional) | The output above ground level (AGL) raster.The AGL result is a raster where each cell value is the minimum height that must be added to an otherwise nonvisible cell to make it visible by at least one observer.Cells that were already visible will have a value of 0 in this output raster. | Raster Dataset |
| in_raster | The input surface raster. | Raster Layer |
| in_observer_point_features | The point feature class that identifies the observer locations.The maximum number of points allowed is 16. | Feature Layer |
| z_factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| curvature_correction(Optional) | Specifies whether correction for the earth's curvature will be applied.FLAT_EARTH—No curvature correction will be applied. This is the default.CURVED_EARTH—Curvature correction will be applied. | Boolean |
| refractivity_coefficient(Optional) | The coefficient of the refraction of visible light in air.The default value is 0.13. | Double |
| out_agl_raster(Optional) | The output above ground level (AGL) raster.The AGL result is a raster where each cell value is the minimum height that must be added to an otherwise nonvisible cell to make it visible by at least one observer.Cells that were already visible will have a value of 0 in this output raster. | Raster Dataset |

## Code Samples

### Example 1

```python
ObserverPoints(in_raster, in_observer_point_features, {z_factor}, {curvature_correction}, {refractivity_coefficient}, {out_agl_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outObsPoints = ObserverPoints("elevation","observers.shp", 1, "CURVED_EARTH", 0.13)
outObsPoints.save("C:/sapyexamples/output/outobspnt01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outObsPoints = ObserverPoints("elevation","observers.shp", 1, "CURVED_EARTH", 0.13)
outObsPoints.save("C:/sapyexamples/output/outobspnt01")
```

### Example 4

```python
# Name: ObserverPoints_Ex_02.py
# Description: Identifies exactly which observer points are visible 
#              from each raster surface location.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inObsPoints = "observers.shp"
zFactor = 1
useEarthCurv = "CURVED_EARTH"
refractionVal = 0.13

# Execute ObserverPoints
outObsPoints = ObserverPoints(inRaster, inObsPoints, zFactor, 
                              useEarthCurv, refractionVal)

# Save the output 
outObsPoints.save("C:/sapyexamples/output/outobspnt02")
```

### Example 5

```python
# Name: ObserverPoints_Ex_02.py
# Description: Identifies exactly which observer points are visible 
#              from each raster surface location.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inObsPoints = "observers.shp"
zFactor = 1
useEarthCurv = "CURVED_EARTH"
refractionVal = 0.13

# Execute ObserverPoints
outObsPoints = ObserverPoints(inRaster, inObsPoints, zFactor, 
                              useEarthCurv, refractionVal)

# Save the output 
outObsPoints.save("C:/sapyexamples/output/outobspnt02")
```

---

## Optimal Corridor Connections (Spatial Analyst)

## Summary

Calculates the optimal corridor connections between two or more input regions.

## Usage

- The input regions can be either raster or feature data.
- In a raster, a region is a group of cells with the same value that are contiguous to one another (adjacent). When the input regions are identified by a raster, if any zones (cells with the same value) are composed of multiple regions, run the Region Group tool first as a preprocessing step to assign unique values to each region. Then use the resulting raster as the input regions to this tool.
- When input regions are identified by polygon, line, or point data, they are converted to raster using the feature ID to ensure that the resulting regions have unique values. Multipart polygons cannot be used as input. When multipoint data is provided, the tool randomly selects one of the points at the location as the region value.You can control the resolution of the rasterized input feature regions with the Cell Size environment. By default, the resolution will be set to the resolution of the input cost raster if one is provided.
- When using polygon feature data for the input region data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type method as the Polygon to Raster tool, which is Cell center. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized region and will not be represented in the distance calculations. For example, if the regions are a series of small polygons, such as building footprints that are small relative to the output cell size, only a few of them may fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this, rasterize the input features directly using the Polygon to Raster tool, set a Priority field value, and use the resulting output as input to the this tool. Alternatively, select a small enough cell size to capture the appropriate amount of detail from the input features.
- When the region input is a feature, the ObjectID field will be used as the region identifiers.
- Locations identified by the Input Raster or Feature Barriers parameter, cell locations with NoData in the Input Cost Raster parameter value, or locations that are not within the environment Mask all act as barriers.
- The analysis Mask environment can be set to a feature or a raster dataset. If the mask is a feature, it will be converted to a raster. The cells that have a value define the locations that are within the mask area. NoData cells define the locations that are outside the mask area and will be treated as a barrier.
- The default processing extent is the same as that of the Input Cost Raster parameter value if one is provided; otherwise, it will be set to the extent of the input regions.
- Cost raster values that are negative or zero are invalid but will be treated as small positive values. The accumulative cost algorithm is a multiplicative process, and it cannot calculate accumulative cost correctly if cost values are negative or zero.If the cost raster contains those values, and those locations represent areas that are to be excluded from the analysis, turn those cells into NoData before running the tool. You can do this using the Set Null tool. The NoData value is treated as a barrier in this analysis, so any locations that are NoData in the input will be NoData in the result.
- When the Input Cost Raster parameter value is provided, the tool performs calculations on that cost surface based on the value of the Corridor Width parameter. This ensures that optimal corridors are created for the specified width and it may lead to regions located near the edge of the surface to be unconnected to the other results.Specifying regions located near the Input Raster or Feature Barriers parameter value may also result in unconnected corridors.
- For the Output Neighboring Corridor Polygons and Output Neighboring Connection Lines parameters, if a cost surface is not provided, the neighbors will be identified by Euclidean distance. In which case, a region's closest neighbor is the one that is closest in distance. However, when a cost surface is provided, the neighbors will be identified by cost distance, making a region's closest neighbor the cheapest one to travel to. A cost allocation operation is performed to identify which regions are neighbors to one another.
- The Output Neighboring Corridor Polygons parameter value is created from the paths produced in the optional neighboring connection lines output. The paths in the optional neighboring connection lines output are converted to graph theory. The regions are the vertices, the paths are the edges, and the accumulative distances or costs are the weights for the edges. The minimum spanning tree is calculated from the graph representation of the paths to determine the optimal connection lines network necessary to travel between the regions. Then the optimal corridor polygons network is created from the optimal connection lines network.
- The Output Optimal Connect Lines parameter value is a subset of the paths produced by the Output Optional Neighboring Connection Lines parameter . To calculate this subset, the neighboring connection lines are converted to graph theory. The regions are the vertices, the paths are the edges, and the accumulative distances or costs are the weights for the edges. The minimum spanning tree is calculated from the graph representation of the paths to determine the subset of optimal connection lines necessary to travel between the regions.
- Each optimal line reaches the outer boundary of the polygon or multicell region. From the perimeter of the region, the tool continues the paths with additional line segments, allowing for points of entry and exit between regions, and movement within them. There is no additional distance or cost of movement along these line segments.
- Depending on the configuration of the input regions and their allocation neighbors, a path can pass through an intermediate region to reach a neighboring region. That path will incur costs as it moves through that intermediate region.
- The Output Neighboring Connection Lines parameter value can be used as an alternative network to the minimum spanning tree network. This output connects each region to its neighboring cost regions, producing a more complex network with many paths. The feature class can be used as is or as the base from which to create your own network. To do that, select the specific paths you want within the network using the Select By Attributes button, the Select group on the Map tab, or the Select Layer By Attributes tool. Selection of the paths can be based on knowledge of the area and the statistics associated with the paths in the resulting attribute table.
- The corridors created by this tool are fixed-width corridors. The Corridor Width parameter identifies the fixed width of the corridors as a linear distance. When the Corridor Width parameter value is 0, the output corridors will be the optimal path lines.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Regions | The input regions that will be connected by the optimal corridors.Regions can be defined by either a raster or a feature dataset.If the region input is a raster, the regions are defined by groups of contiguous (adjacent) cells of the same value. Each region must be uniquely numbered. The cells that are not part of any region must be NoData. The raster type must be integer, and the values can be either positive or negative.If the region input is a feature dataset, it can be polygons, polylines, or points. Polygon feature regions cannot be composed of multipart polygons. | Raster Layer; Feature Layer |
| Output Optimal Corridor Polygons | The output polygon or line feature class of the optimal corridors that connect each of the input regions. Corridors (or lines) will overlap in locations where corridors travel the same route.Each corridor (or line) is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following:CORR_ID—The unique identifier for the corridor REGION1—The first region the path connectsREGION2—The other region the path connects | Feature Class |
| Input Raster or Feature Barriers(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| Input Cost Raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point. Cost raster values that are negative or zero are invalid but will be treated as small positive cost values. | Raster Layer |
| Output Optimal Connection Lines(Optional) | The output line feature class identifies the optimal lines to connect each of the input regions. Lines will overlap in locations where paths travel the same route.Each path (or line) is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following: PATHID—The unique identifier for the pathPATHCOST—The total accumulative distance or cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connects | Feature Class |
| Output Neighboring Corridor Polygons(Optional) | The output polygon or line feature class identifying the optimal corridors that connect each region to each of its closest or cost neighbors. Corridors (or lines) will overlap in locations where corridors travel the same route.Each corridor is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following: CORRIDORID—The unique identifier for the corridor REGION1—The first region the path connectsREGION2—The other region the path connects | Feature Class |
| Output Neighboring Connection Lines(Optional) | The output line feature class identifying the optimal line from each region to each of its closest or cost neighbors.Each corridor (or polygon) is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following: PATHID—The unique identifier for the pathPATHCOST—The total accumulative distance or cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connects Since each path is represented by a unique line, there will be multiple lines in locations where the same route is optimal. | Feature Class |
| Corridor Method(Optional) | Specifies how the corridor will be created.Fixed width corridor—The corridor will have a fixed width and the optimal corridors and paths will be created based on this width. This is the default.Note:At this release, there is only one method to create corridors: fixed width. Since there is only a single default option, this parameter will be inactive, and will not appear on the tool dialog box. | String |
| Corridor Width(Optional) | A linear distance that defines the width of the resulting corridors. The value must be greater than or equal to zero. The default is zero. | Double |
| Distance Method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.Planar—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.Geodesic—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| in_regions | The input regions that will be connected by the optimal corridors.Regions can be defined by either a raster or a feature dataset.If the region input is a raster, the regions are defined by groups of contiguous (adjacent) cells of the same value. Each region must be uniquely numbered. The cells that are not part of any region must be NoData. The raster type must be integer, and the values can be either positive or negative.If the region input is a feature dataset, it can be polygons, polylines, or points. Polygon feature regions cannot be composed of multipart polygons. | Raster Layer; Feature Layer |
| out_optimal_polygons | The output polygon or line feature class of the optimal corridors that connect each of the input regions. Corridors (or lines) will overlap in locations where corridors travel the same route.Each corridor (or line) is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following:CORR_ID—The unique identifier for the corridor REGION1—The first region the path connectsREGION2—The other region the path connects | Feature Class |
| in_barriers(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| in_cost_raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point. Cost raster values that are negative or zero are invalid but will be treated as small positive cost values. | Raster Layer |
| out_optimal_lines(Optional) | The output line feature class identifies the optimal lines to connect each of the input regions. Lines will overlap in locations where paths travel the same route.Each path (or line) is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following: PATHID—The unique identifier for the pathPATHCOST—The total accumulative distance or cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connects | Feature Class |
| out_neighbor_polygons(Optional) | The output polygon or line feature class identifying the optimal corridors that connect each region to each of its closest or cost neighbors. Corridors (or lines) will overlap in locations where corridors travel the same route.Each corridor is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following: CORRIDORID—The unique identifier for the corridor REGION1—The first region the path connectsREGION2—The other region the path connects | Feature Class |
| out_neighbor_lines(Optional) | The output line feature class identifying the optimal line from each region to each of its closest or cost neighbors.Each corridor (or polygon) is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following: PATHID—The unique identifier for the pathPATHCOST—The total accumulative distance or cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connects Since each path is represented by a unique line, there will be multiple lines in locations where the same route is optimal. | Feature Class |
| corridor_method(Optional) | Specifies how the corridor will be created.Note:At this release, there is only one method to create corridors: fixed width. Since there is only a single default option, this parameter will be inactive, and will not appear on the tool dialog box.FIXED_WIDTH_CORRIDOR—The corridor will have a fixed width and the optimal corridors and paths will be created based on this width. This is the default. | String |
| corridor_width(Optional) | A linear distance that defines the width of the resulting corridors. The value must be greater than or equal to zero. The default is zero. | Double |
| distance_method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.PLANAR—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.GEODESIC—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |

## Code Samples

### Example 1

```python
OptimalCorridorConnections(in_regions, out_optimal_polygons, {in_barriers}, {in_cost_raster}, {out_optimal_lines}, {out_neighbor_polygons}, {out_neighbor_lines}, {corridor_method}, {corridor_width}, {distance_method})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/arcpyexamples/data"
out_OCC_raster = OptimalCorridorConnections("InRegions.tif", 
    "OutCorridors.shp", "InBarriers.tif", "InCostRaster.tif", 
    "OutOptimalPaths.shp", "OutNbrPoly.shp", "OutNbrLines.shp", 
    "FIXED_WIDTH_CORRIDOR", 5000, "PLANAR")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/arcpyexamples/data"
out_OCC_raster = OptimalCorridorConnections("InRegions.tif", 
    "OutCorridors.shp", "InBarriers.tif", "InCostRaster.tif", 
    "OutOptimalPaths.shp", "OutNbrPoly.shp", "OutNbrLines.shp", 
    "FIXED_WIDTH_CORRIDOR", 5000, "PLANAR")
```

### Example 4

```python
# Name: OptimalCorridorConnections_standalone.py
# Description: Calculates corridor.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/arcpyexamples/data"

# Set local variables
regions = "Lakes.tif"
outCorridors = "NewCorridors.shp"
roadBarriers = "Roads.shp"
costSurface = "CostSurface.tif"
optimalLines = "OutCorridorCenterLines.shp"
outAllCorridors = "OutAllCorridors.shp"
outAllLines = "OutAllCenterLines.shp"
corridorMethod = "FIXED_WIDTH_CORRIDOR"
corridorWidth = 5000
distanceMethod = "GEODESIC"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute  OptimalCorridorConnections

OptimalCorridorConnections(regions, outCorridors, roadBarriers,
                           costSurface, optimalLines,
                           outAllCorridors, outAllLines,
                           corridorMethod, corridorWidth, distanceMethod)
```

### Example 5

```python
# Name: OptimalCorridorConnections_standalone.py
# Description: Calculates corridor.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/arcpyexamples/data"

# Set local variables
regions = "Lakes.tif"
outCorridors = "NewCorridors.shp"
roadBarriers = "Roads.shp"
costSurface = "CostSurface.tif"
optimalLines = "OutCorridorCenterLines.shp"
outAllCorridors = "OutAllCorridors.shp"
outAllLines = "OutAllCenterLines.shp"
corridorMethod = "FIXED_WIDTH_CORRIDOR"
corridorWidth = 5000
distanceMethod = "GEODESIC"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute  OptimalCorridorConnections

OptimalCorridorConnections(regions, outCorridors, roadBarriers,
                           costSurface, optimalLines,
                           outAllCorridors, outAllLines,
                           corridorMethod, corridorWidth, distanceMethod)
```

---

## Optimal Path As Line (Spatial Analyst)

## Summary

Calculates the optimal path from a source to a destination as a line.

## Usage

- The Optimal Path As Line tool produces an output polyline feature that is the optimal path from the source to the destination.
- When the input destination data is a raster, the set of destination cells consists of all cells in the Input Raster or Feature Destination parameter value that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A destination raster can be created using the extraction tools.
- When using polygon feature data for the input feature destinations, care must be taken with how the output cell size is handled, particularly when it is coarse relative to the detail present in the input. An internal rasterization process using the Polygon to Raster tool is applied with the default setting for Cell assignment type of Cell center. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized destination output and will not be represented in the distance calculations. For example, if the destinations are a series of small polygons, such as building footprints, that are small relative to the output cell size, it is possible that only a few of them will fall under the centers of the output raster cells, seemingly causing many of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- Before generating an optimal path, one of the following tools is typically used to create a distance accumulation raster and a back direction raster: Distance Accumulation or Distance Allocation. A distance accumulation raster and a back direction raster are required inputs to generate an optimal path.
- The optimal path created can be a flow path based on D8 flow direction. To generate an optimal path in this way, use a D8 flow direction raster as input for the Input Back Direction or Flow Direction Raster. You also need to supply an Input Distance Accumulation Raster. If the Create Network Paths parameter is not enabled then the Input Distance Accumulation Raster is not used to determine the path. Therefore, whether you use a constant raster or a digital elevation model (DEM), your path will be the same; only an attribute value on your path will vary. However, if Create Network Paths are generated, then the Input Distance Accumulation Raster must be an Output flow accumulation raster. See the Flow Direction tool for more information on D8 flow direction rasters and Flow Accumulation tool to create the accumulation raster.
- The output polyline feature includes a DestID field and a PathCost field. The DestID field identifies the destination where each line leads. The PathCost field shows the total accumulative cost for each path. If the output is written to a file geodatabase, there is a shape_length field that contains the total length of the least-cost path.
- To create paths that cross the edge of the projection, the rasters used as inputs for the Input Distance Accumulation Raster and Input Back Direction Raster parameters must have been created at the full global extent, in either a cylindrical projection or a geographic output coordinate system, while using the Geodesic option for the Distance Method parameter.
- To generate an optimal path, the Cell size environment setting is ignored and the cell size of the Input cost backlink raster value is used to calculate the output raster. The pattern of the back link raster would be altered if it were resampled to a different resolution. To avoid confusion, do not set the cell size when using this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Destinations | An integer raster or feature (point, line, or polygon) that identifies locations from which the optimal path will be determined to the least costly source.If the input is a raster, it must consist of cells that have valid values for the destinations, and the remaining cells must be assigned NoData. Zero is a valid value. | Raster Layer; Feature Layer |
| Input Distance Accumulation Raster | The distance accumulation raster that will be used to determine the optimal path from the sources to the destinations.The distance accumulation raster is usually created with the Distance Accumulation or Distance Allocation tool. Each cell in the distance accumulation raster represents the minimum accumulative cost distance over a surface from each cell to a set of source cells. | Raster Layer |
| Input Back Direction or Flow Direction Raster | The back direction raster contains calculated directions in degrees. The direction identifies the next cell along the optimal path back to the least accumulative cost source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north). | Raster Layer |
| Output Optimal Path as Line | The output feature class that is the optimal path or paths. | Feature Class |
| Destination Field(Optional) | An integer field that will be used to obtain values for the destination locations. | Field |
| Path Type(Optional) | Specifies a keyword defining the manner in which the values and zones on the input destination data will be interpreted in the cost path calculations.Each zone—For each zone on the input destination data, a least-cost path will be determined and saved on the output raster. With this option, the least-cost path for each zone begins at the cell with the lowest cost distance weighting in the zone.Best single—For all cells on the input destination data, the least-cost path will be derived from the cell with the minimum of the least-cost paths to source cells.Each cell—For each cell with valid values on the input destination data, a least-cost path will be determined and saved on the output raster. With this option, each cell of the input destination data is treated separately, and a least-cost path is determined for each cell. | String |
| Create Network Paths(Optional) | Specifies whether complete, and possibly overlapping, paths from the destinations to the sources are calculated or if nonoverlapping network paths are created.Unchecked—Complete paths from the destinations to the sources are calculated, which can be overlapping. This is the default.Checked—Nonoverlapping network paths are calculated. | Boolean |
| in_destination_data | An integer raster or feature (point, line, or polygon) that identifies locations from which the optimal path will be determined to the least costly source.If the input is a raster, it must consist of cells that have valid values for the destinations, and the remaining cells must be assigned NoData. Zero is a valid value. | Raster Layer; Feature Layer |
| in_distance_accumulation_raster | The distance accumulation raster that will be used to determine the optimal path from the sources to the destinations.The distance accumulation raster is usually created with the Distance Accumulation or Distance Allocation tool. Each cell in the distance accumulation raster represents the minimum accumulative cost distance over a surface from each cell to a set of source cells. | Raster Layer |
| in_back_direction_raster | The back direction raster contains calculated directions in degrees. The direction identifies the next cell along the optimal path back to the least accumulative cost source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north). | Raster Layer |
| out_polyline_features | The output feature class that is the optimal path or paths. | Feature Class |
| destination_field(Optional) | An integer field that will be used to obtain values for the destination locations. | Field |
| path_type(Optional) | Specifies a keyword defining the manner in which the values and zones on the input destination data will be interpreted in the cost path calculations.EACH_ZONE—For each zone on the input destination data, a least-cost path will be determined and saved on the output raster. With this option, the least-cost path for each zone begins at the cell with the lowest cost distance weighting in the zone.BEST_SINGLE—For all cells on the input destination data, the least-cost path will be derived from the cell with the minimum of the least-cost paths to source cells.EACH_CELL—For each cell with valid values on the input destination data, a least-cost path will be determined and saved on the output raster. With this option, each cell of the input destination data is treated separately, and a least-cost path is determined for each cell. | String |
| create_network_paths(Optional) | Specifies whether complete, and possibly overlapping, paths from the destinations to the sources are calculated or if nonoverlapping network paths are created.DESTINATIONS_TO_SOURCES—Complete paths from the destinations to the sources are calculated, which can be overlapping. This is the default.NETWORK_PATHS—Nonoverlapping network paths are calculated. | Boolean |

## Code Samples

### Example 1

```python
OptimalPathAsLine(in_destination_data, in_distance_accumulation_raster, in_back_direction_raster, out_polyline_features, {destination_field}, {path_type}, {create_network_paths})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
OptimalPathAsLine("observers.shp", "distaccum.tif", "backdir.tif",
                  "c:/sapyexamples/output/outOptimalPath01.shp")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
OptimalPathAsLine("observers.shp", "distaccum.tif", "backdir.tif",
                  "c:/sapyexamples/output/outOptimalPath01.shp")
```

### Example 4

```python
# Name: OptimalPathAsLine_Ex_02.py
# Description: Calculates the least-cost path from a source to 
#              a destination.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inDestination = "observers.shp"
inDistAccum = "accumraster.tif"
inBackDir = "backdir2.tif"
outPathFeat = "c:/sapyexamples/output.gdb/optimalfeaturepaths02"
destField = "FID"
method = "EACH_CELL"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute
OptimalPathAsLine(inDestination, inDistAccum, inBackDir, 
                  outPathFeat, destField, method)
```

### Example 5

```python
# Name: OptimalPathAsLine_Ex_02.py
# Description: Calculates the least-cost path from a source to 
#              a destination.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inDestination = "observers.shp"
inDistAccum = "accumraster.tif"
inBackDir = "backdir2.tif"
outPathFeat = "c:/sapyexamples/output.gdb/optimalfeaturepaths02"
destField = "FID"
method = "EACH_CELL"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute
OptimalPathAsLine(inDestination, inDistAccum, inBackDir, 
                  outPathFeat, destField, method)
```

---

## Optimal Path As Raster (Spatial Analyst)

## Summary

Calculates the optimal path from a source to a destination as a raster.

## Usage

- The Optimal Path As Raster tool produces an output raster.
- When the input destination data is a raster, the set of destination cells consists of all cells in the Input Raster or Feature Destination parameter value that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A destination raster can be created using the extraction tools.
- When using polygon feature data for the input feature destinations, care must be taken with how the output cell size is handled, particularly when it is coarse relative to the detail present in the input. An internal rasterization process using the Polygon to Raster tool is applied with the default setting for Cell assignment type of Cell center. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized destination output and will not be represented in the distance calculations. For example, if the destinations are a series of small polygons, such as building footprints, that are small relative to the output cell size, it is possible that only a few of them will fall under the centers of the output raster cells, seemingly causing many of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- Before generating an optimal path, one of the following tools is typically used to create a distance accumulation raster and a back direction raster: Distance Accumulation or Distance Allocation. A distance accumulation raster and a back direction raster are required inputs to generate an optimal path.
- The optimal path created can be a flow path based on D8 flow direction. To generate an optimal path in this way, use a D8 flow direction raster as input for the Input Back Direction or Flow Direction raster parameter. You also need to provide an Input Distance Accumulation Raster value; the Input Distance Accumulation Raster value is not used to determine the path. Whether you use a constant raster or a digital elevation model (DEM), the path will be the same; only an attribute value on the path will vary. See the Flow Direction tool documentation for more information about D8 flow direction rasters.
- The values on the output optimal path represent the number of paths at a given location. In many cases, paths follow the same route, leaving a source and diverging to go to different destinations. For example, a value of 1 indicates that there is only one optimal path at a given location, while a value of 5 means at that location, there are five optimal paths going through that cell in the study area.
- To create paths that cross the edge of the projection, the rasters used as inputs for the Input Distance Accumulation Raster and Input Back Direction Raster parameters must have been created at the full global extent, in either a cylindrical projection or a geographic output coordinate system, while using the Geodesic option for the Distance Method parameter.
- To generate an optimal path, the Cell size environment setting is ignored and the cell size of the Input cost backlink raster value is used to calculate the output raster. The pattern of the back link raster would be altered if it were resampled to a different resolution. To avoid confusion, do not set the cell size when using this tool.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Destinations | An integer raster or feature (point, line, or polygon) that identifies locations from which the optimal path will be determined to the least costly source.If the input is a raster, it must consist of cells that have valid values for the destinations, and the remaining cells must be assigned NoData. Zero is a valid value. | Raster Layer; Feature Layer |
| Input Distance Accumulation Raster | The distance accumulation raster that will be used to determine the optimal path from the sources to the destinations.The distance accumulation raster is usually created with the Distance Accumulation or Distance Allocation tool. Each cell in the distance accumulation raster represents the minimum accumulative cost distance over a surface from each cell to a set of source cells. | Raster Layer |
| Input Back Direction or Flow Direction Raster | The back direction raster contains calculated directions in degrees. The direction identifies the next cell along the optimal path back to the least accumulative cost source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north). | Raster Layer |
| Destination Field(Optional) | The field that will be used to obtain values for the destination locations. | Field |
| Path Type(Optional) | Specifies a keyword defining the manner in which the values and zones on the input destination data will be interpreted in the cost path calculations.Each zone—For each zone on the input destination data, a least-cost path will be determined and saved on the output raster. With this option, the least-cost path for each zone begins at the cell with the lowest cost distance weighting in the zone.Best single—For all cells on the input destination data, the least-cost path will be derived from the cell with the minimum of the least-cost paths to source cells.Each cell—For each cell with valid values on the input destination data, a least-cost path will be determined and saved on the output raster. With this option, each cell of the input destination data is treated separately, and a least-cost path is determined for each cell. | String |
| in_destination_data | An integer raster or feature (point, line, or polygon) that identifies locations from which the optimal path will be determined to the least costly source.If the input is a raster, it must consist of cells that have valid values for the destinations, and the remaining cells must be assigned NoData. Zero is a valid value. | Raster Layer; Feature Layer |
| in_distance_accumulation_raster | The distance accumulation raster that will be used to determine the optimal path from the sources to the destinations.The distance accumulation raster is usually created with the Distance Accumulation or Distance Allocation tool. Each cell in the distance accumulation raster represents the minimum accumulative cost distance over a surface from each cell to a set of source cells. | Raster Layer |
| in_back_direction_raster | The back direction raster contains calculated directions in degrees. The direction identifies the next cell along the optimal path back to the least accumulative cost source while avoiding barriers.The range of values is from 0 degrees to 360 degrees, with 0 reserved for the source cells. Due east is 90, and the values increase clockwise (180 is south, 270 is west, and 360 is north). | Raster Layer |
| destination_field(Optional) | The field that will be used to obtain values for the destination locations. | Field |
| path_type(Optional) | Specifies a keyword defining the manner in which the values and zones on the input destination data will be interpreted in the cost path calculations.EACH_ZONE—For each zone on the input destination data, a least-cost path will be determined and saved on the output raster. With this option, the least-cost path for each zone begins at the cell with the lowest cost distance weighting in the zone.BEST_SINGLE—For all cells on the input destination data, the least-cost path will be derived from the cell with the minimum of the least-cost paths to source cells.EACH_CELL—For each cell with valid values on the input destination data, a least-cost path will be determined and saved on the output raster. With this option, each cell of the input destination data is treated separately, and a least-cost path is determined for each cell. | String |

## Code Samples

### Example 1

```python
OptimalPathAsRaster(in_destination_data, in_distance_accumulation_raster, in_back_direction_raster, {destination_field}, {path_type})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outOptimalRasPath = OptimalPathAsRaster("observers", "distAccum.tif", "backDir2", "IdField", "EACH_CELL")
outOptimalRasPath.save("c:/sapyexamples/output/bestpaths.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outOptimalRasPath = OptimalPathAsRaster("observers", "distAccum.tif", "backDir2", "IdField", "EACH_CELL")
outOptimalRasPath.save("c:/sapyexamples/output/bestpaths.tif")
```

### Example 4

```python
# Name: OptimalPathAsRaster_Ex_02.py
# Description: Calculates the least-cost path from a source to 
#              a destination.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inDestination = "observers.shp"
distAccumRaster = "distAccum.tif"
backDir = "backDir2.tif"
destField = "FID"
pathType = "EACH_CELL"

# Execute CostPath
outOptimalRasPath = OptimalPathAsRaster(inDestination, distAccumRaster, backDir, destField,
                       pathType)

# Save the output 
outOptimalRasPath.save("c:/sapyexamples/output/optimalraspath02.tif")
```

### Example 5

```python
# Name: OptimalPathAsRaster_Ex_02.py
# Description: Calculates the least-cost path from a source to 
#              a destination.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inDestination = "observers.shp"
distAccumRaster = "distAccum.tif"
backDir = "backDir2.tif"
destField = "FID"
pathType = "EACH_CELL"

# Execute CostPath
outOptimalRasPath = OptimalPathAsRaster(inDestination, distAccumRaster, backDir, destField,
                       pathType)

# Save the output 
outOptimalRasPath.save("c:/sapyexamples/output/optimalraspath02.tif")
```

---

## Optimal Region Connections (Spatial Analyst)

## Summary

Calculates the optimal connectivity network between two or more input regions.

## Usage

- The input regions can be either raster or feature data.
- In a raster, a region is a group of cells with the same value that are contiguous to one another (adjacent). When your input regions are identified by a raster, if any zones (cells with the same value) are composed of multiple regions, first run the Region Group tool as a preprocessing step to assign unique values to each region. Then use the resulting raster as the input regions to the Optimal Region Connections tool.
- When input regions are identified by polygon, line, or point data, they are converted to raster using the feature ID to ensure that the resulting regions have unique values. Multipart polygons cannot be used as input. When multipoint data is entered, Optimal Region Connections randomly selects one of the points at the location as the region value.You can control the resolution of the rasterized input feature regions with the Cell Size environment. By default, the resolution will be set to the resolution of the input cost raster if one is provided.
- When using polygon feature data for the input region data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type method as the Polygon to Raster tool, which is Cell center. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized region and will not be represented in the distance calculations. For example, if your regions are a series of small polygons, such as building footprints that are small relative to the output cell size, only a few of them may fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, rasterize the input features directly with the Polygon to Raster tool, set a Priority field value, and use the resulting output as input to the Optimal Region Connections tool. Alternatively, select a small enough cell size to capture the appropriate amount of detail from the input features.
- When the region input is a feature, the ObjectID field will be used as the region identifiers.
- If the input regions are raster and the range of the row IDs is very large (even if there are only a few regions), the performance of the Optimal Region Connections tool may be negatively impacted.
- Locations identified by the Input Raster or Feature Barriers parameter, cell locations with NoData in the Input Cost Raster parameter, or locations that are not within the Mask all act as barriers.
- The analysis Mask environment can be set to a feature or a raster dataset. If the mask is a feature, it will be converted to a raster. The cells that have a value define the locations that are within the mask area. NoData cells define the locations that are outside the mask area and will be treated as a barrier.
- The default processing extent is the same as that of the Input Cost Raster value if one is provided; otherwise, it will be set to the extent of the input regions.
- Cost raster values that are negative or zero are invalid but will be treated as small positive values. The accumulative cost algorithm is a multiplicative process, and it cannot calculate accumulative cost correctly if cost values are negative or zero.If the cost raster contains those values, and those locations represent areas that are to be excluded from the analysis, turn those cells into NoData before running the tool. You can do this using the Set Null tool. The NoData value is treated as a barrier in this analysis, so any locations that are NoData in the input will be NoData in the result.
- For the Output Neighboring Connection Lines parameter, if a cost surface is not specified, the neighbors are identified by Euclidean distance. In which case, a region's closest neighbor is the one that is closest in distance. However, when a cost surface is provided, the neighbors are identified by cost distance making a region's closest neighbor the cheapest one to travel to. A cost allocation operation is performed to identify which regions are neighbors to one another.
- The optimal output network is created from the paths produced in the optional neighboring connections output. The paths in the optional neighboring connections output are converted to graph theory. The regions are the vertices, the paths are the edges, and the accumulative distances or costs are the weights for the edges. The minimum spanning tree is calculated from the graph representation of the paths to determine the optimal path network necessary to travel between the regions.
- Each optimal path first reaches the outer boundary of the polygon or multicell region. From the perimeter of the region, the tool continues the paths with additional line segments, allowing for points of entry and exit between regions, and movement within them. There is no additional distance or cost of movement along these line segments.
- Depending on the configuration of the input regions and their allocation neighbors, a path can pass through an intermediate region to reach a neighboring region. That path will incur costs as it moves through that intermediate region.
- The optional neighboring connections output can be used as an alternative network to the minimum spanning tree network. This output connects each region to its neighboring cost regions, producing a more complex network with many paths. The feature class can be used as is or as the base from which to create your own network. To do that, select the specific paths you want within the network using the Select By Attributes button, the Select group on the Map tab, or the Select Layer By Attributes tool. Selection of the paths can be based on knowledge of the area and the statistics associated with the paths in the resulting attribute table.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- The resulting network, from either the minimum spanning tree or the optional neighboring connections, can be converted to a Network Analyst network for additional network analysis.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Regions | The input regions to be connected by the optimal network.Regions can be defined by either a raster or a feature dataset.If the region input is a raster, the regions are defined by groups of contiguous (adjacent) cells of the same value. Each region must be uniquely numbered. The cells that are not part of any region must be NoData. The raster type must be integer, and the values can be either positive or negative.If the region input is a feature dataset, it can be polygons, polylines, or points. Polygon feature regions cannot be composed of multipart polygons. | Raster Layer; Feature Layer |
| Output Optimal Connection Lines | The output polyline feature class of the optimal network of paths that connect each of the input regions.Each path (or line) is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following:PATHID—The unique identifier for the pathPATHCOST—The total accumulative distance or cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connectsThis information provides insight into the paths in the network.Since each path is represented by a unique line, there will be multiple lines in locations where paths travel the same route. | Feature Class |
| Input Raster or Feature Barriers(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| Input Cost Raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point. Cost raster values that are negative or zero are invalid but will be treated as small positive cost values. | Raster Layer |
| Output Neighboring Connection Lines(Optional) | The output polyline feature class identifying all paths from each region to each of its closest or cost neighbors.Each path (or line) is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following:PATHID—The unique identifier for the pathPATHCOST—The total accumulative distance or cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connects This information provides insight into the paths in the network and is useful when deciding which paths should be removed if necessary.Since each path is represented by a unique line, there will be multiple lines in locations where paths travel the same route. | Feature Class |
| Distance Method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.Planar—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.Geodesic—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| Connections Within Regions(Optional) | Specifies whether the paths will continue and connect within the input regions.Generate connections—Paths will continue within the input regions to connect all paths that enter a region.No connections—Paths will stop at the edges of the input regions and will not continue or connect within them. | String |
| in_regions | The input regions to be connected by the optimal network.Regions can be defined by either a raster or a feature dataset.If the region input is a raster, the regions are defined by groups of contiguous (adjacent) cells of the same value. Each region must be uniquely numbered. The cells that are not part of any region must be NoData. The raster type must be integer, and the values can be either positive or negative.If the region input is a feature dataset, it can be polygons, polylines, or points. Polygon feature regions cannot be composed of multipart polygons. | Raster Layer; Feature Layer |
| out_feature_class | The output polyline feature class of the optimal network of paths that connect each of the input regions.Each path (or line) is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following:PATHID—The unique identifier for the pathPATHCOST—The total accumulative distance or cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connectsThis information provides insight into the paths in the network.Since each path is represented by a unique line, there will be multiple lines in locations where paths travel the same route. | Feature Class |
| in_barrier_data(Optional) | The dataset that defines the barriers.The barriers can be defined by an integer or a floating-point raster, or by a point, line, or polygon feature. | Raster Layer; Feature Layer |
| in_cost_raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point. Cost raster values that are negative or zero are invalid but will be treated as small positive cost values. | Raster Layer |
| out_neighbor_paths(Optional) | The output polyline feature class identifying all paths from each region to each of its closest or cost neighbors.Each path (or line) is uniquely numbered and additional fields in the attribute table store specific information about the path. Those additional fields are the following:PATHID—The unique identifier for the pathPATHCOST—The total accumulative distance or cost for the pathREGION1—The first region the path connectsREGION2—The other region the path connects This information provides insight into the paths in the network and is useful when deciding which paths should be removed if necessary.Since each path is represented by a unique line, there will be multiple lines in locations where paths travel the same route. | Feature Class |
| distance_method(Optional) | Specifies whether the distance will be calculated using a planar (flat earth) or a geodesic (ellipsoid) method.PLANAR—The distance calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default.GEODESIC—The distance calculation will be performed on the ellipsoid. Regardless of input or output projection, the results will not change. | String |
| connections_within_regions(Optional) | Specifies whether the paths will continue and connect within the input regions.GENERATE_CONNECTIONS—Paths will continue within the input regions to connect all paths that enter a region.NO_CONNECTIONS—Paths will stop at the edges of the input regions and will not continue or connect within them. | String |

## Code Samples

### Example 1

```python
OptimalRegionConnections(in_regions, out_feature_class, {in_barrier_data}, {in_cost_raster}, {out_neighbor_paths}, {distance_method}, {connections_within_regions})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outOptRegConnect = OptimalRegionConnections("sources.shp", "cost_surface.tif")
outOptRegConnect.save("C:/sapyexamples/output/optregconnect.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outOptRegConnect = OptimalRegionConnections("sources.shp", "cost_surface.tif")
outOptRegConnect.save("C:/sapyexamples/output/optregconnect.tif")
```

### Example 4

```python
# Name: OptimalRegionConnections_Ex_02.py
# Description: Calculates the optimal network of connections for the sources.
#
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSourceData = "sources.shp"
inBarrier = "barriers.tif"
inCostRaster = "cost_surface.tif"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute the tool
outOptRegConnect = OptimalRegionConnections(inSourceData, inBarrier, inCostRaster)

# Save the output 
outOptRegConnect.save("C:/sapyexamples/output/optregconnect.tif")
```

### Example 5

```python
# Name: OptimalRegionConnections_Ex_02.py
# Description: Calculates the optimal network of connections for the sources.
#
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSourceData = "sources.shp"
inBarrier = "barriers.tif"
inCostRaster = "cost_surface.tif"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute the tool
outOptRegConnect = OptimalRegionConnections(inSourceData, inBarrier, inCostRaster)

# Save the output 
outOptRegConnect.save("C:/sapyexamples/output/optregconnect.tif")
```

---

## Over (Spatial Analyst)

## Summary

For the cell values in the first input that are not 0, the output value will be that of the first input. Where the cell values are 0, the output will be that of the second input raster.

## Usage

- Two inputs are necessary for this logical evaluation to take place.
- The order of inputs is relevant for this tool.
- If both inputs are integer, the output will be an integer raster; otherwise, it will be a floating-point raster.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input for which cell values of 0 will be replaced with the value from the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input whose value will be assigned to the output raster cells where the first input value is 0.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input for which cell values of 0 will be replaced with the value from the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input whose value will be assigned to the output raster cells where the first input value is 0.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Over(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outOver = Over("degs", "negs")
outOver.save("C:/sapyexamples/output/outover2")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outOver = Over("degs", "negs")
outOver.save("C:/sapyexamples/output/outover2")
```

### Example 4

```python
# Name: Over_Ex_02.py
# Description: Returns those values from the first input that are
#    non-zero; otherwise, returns the value from the second input
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute Over
outOver = Over(inRaster1, inRaster2)

# Save the output 
outOver.save("C:/sapyexamples/output/outover")
```

### Example 5

```python
# Name: Over_Ex_02.py
# Description: Returns those values from the first input that are
#    non-zero; otherwise, returns the value from the second input
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "negs"

# Execute Over
outOver = Over(inRaster1, inRaster2)

# Save the output 
outOver.save("C:/sapyexamples/output/outover")
```

---

## Particle Track (Spatial Analyst)

## Summary

Calculates the path of a particle through a velocity field, returning an ASCII file of particle tracking data and, optionally, a feature class of track information.

## Usage

- The input direction and magnitude rasters should be from the same run of the Darcy Flow tool.
- The path file generated by this tool is an ASCII text file containing information about position, local velocity direction and magnitude, and cumulative length and time of travel along the path. This file is used for input by Porous Puff. The format of this file is as follows:time x y length flow dir flow mag 0.000000000 0.000000000 482.8400000 0.000000000 90.00000000 0.04418909563 113.1648712 4.999804443 482.7957786 5.000000000 91.01366126 0.04418332249 226.2741353 9.998043277 482.6630814 10.00000000 92.02765240 0.04420504404 339.3574334 14.99315255 482.4419855 15.00000000 93.04094157 0.04421519432 452.3447720 19.98356700 482.1325285 20.00000000 94.05521317 0.04425274599 565.2657591 24.96772671 481.7348453 25.00000000 95.06807622 0.04427874865 678.0514031 29.94406931 481.2490323 30.00000000 96.08254679 0.04433188322 790.7309576 34.91104149 480.6752838 35.00000000 97.09488082 0.04437362239
- No particular system of units is specified by Particle Track. It is important that all data be in a consistent set of units, using the same unit for time (seconds, days, years) and length (feet, meters).
- The source location must be within the boundary of the input rasters and cannot be in an area of NoData.
- The track file will end if the track reaches outside the study area and has not met the specified maximum tracking time.
- If the particle being tracked has reached the edge of the study area at the indicated time and the predictor point is outside the study area, the track file will end.
- If the particle being tracked migrates into a depression at the indicated time, the track file will end. A depression can be created by a discharge well or other sink.
- The two outputs from this tool are: A particle track ASCII file using the name specified as output particle track fileAn optional polyline feature class
- A particle track ASCII file using the name specified as output particle track file
- An optional polyline feature class
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input direction raster | An input raster where each cell value represents the direction of the seepage velocity vector (average linear velocity) at the center of the cell.Directions are expressed in compass coordinates, in degrees clockwise from north. This can be created by the Darcy Flow tool.Direction values must be floating point. | Raster Layer |
| Input magnitude raster | An input raster where each cell value represents the magnitude of the seepage velocity vector (average linear velocity) at the center of the cell.Units are length/time. This can be created by the Darcy Flow tool. | Raster Layer |
| Source point | The location of the source point from which to begin the particle tracking.This is entered as numbers identifying the x,y coordinates of the position in map units. | Point |
| Output particle track file | The output ASCII text file that contains the particle tracking data. | File |
| Step length(Optional) | The step length to be used for calculating the particle track.The default is one-half the cell size. Units are length. | Double |
| Tracking time(Optional) | Maximum elapsed time for particle tracking.The algorithm will follow the track until either this time is met or the particle migrates off the raster or into a depression.The default value is infinity. Units are time. | Double |
| Output track polyline features(Optional) | The optional output line feature class containing the particle track.This feature class contains a series of arcs with attributes for position, local velocity direction and magnitude, and cumulative length and time of travel along the path. | Feature Class |
| in_direction_raster | An input raster where each cell value represents the direction of the seepage velocity vector (average linear velocity) at the center of the cell.Directions are expressed in compass coordinates, in degrees clockwise from north. This can be created by the Darcy Flow tool.Direction values must be floating point. | Raster Layer |
| in_magnitude_raster | An input raster where each cell value represents the magnitude of the seepage velocity vector (average linear velocity) at the center of the cell.Units are length/time. This can be created by the Darcy Flow tool. | Raster Layer |
| source_point | A Python Point class object denotes the location of the source point, in map units, from which to begin the particle tracking.The form of the object is: point(x,y) | Point |
| out_track_file | The output ASCII text file that contains the particle tracking data. | File |
| step_length(Optional) | The step length to be used for calculating the particle track.The default is one-half the cell size. Units are length. | Double |
| tracking_time(Optional) | Maximum elapsed time for particle tracking.The algorithm will follow the track until either this time is met or the particle migrates off the raster or into a depression.The default value is infinity. Units are time. | Double |
| out_track_polyline_features(Optional) | The optional output line feature class containing the particle track.This feature class contains a series of arcs with attributes for position, local velocity direction and magnitude, and cumulative length and time of travel along the path. | Feature Class |

## Code Samples

### Example 1

```python
time         x            y            length       flow dir     flow mag
0.000000000  0.000000000  482.8400000  0.000000000  90.00000000  0.04418909563
113.1648712  4.999804443  482.7957786  5.000000000  91.01366126  0.04418332249
226.2741353  9.998043277  482.6630814  10.00000000  92.02765240  0.04420504404
339.3574334  14.99315255  482.4419855  15.00000000  93.04094157  0.04421519432
452.3447720  19.98356700  482.1325285  20.00000000  94.05521317  0.04425274599
565.2657591  24.96772671  481.7348453  25.00000000  95.06807622  0.04427874865
678.0514031  29.94406931  481.2490323  30.00000000  96.08254679  0.04433188322
790.7309576  34.91104149  480.6752838  35.00000000  97.09488082  0.04437362239
```

### Example 2

```python
ParticleTrack(in_direction_raster, in_magnitude_raster, source_point, out_track_file, {step_length}, {tracking_time}, {out_track_polyline_features})
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
ParticleTrack("gwdir", "gwmag", arcpy.Point(-200,-200), 
              "C:/sapyexamples/output/trackfile.txt",10, 100000, 
              "C:/sapyexamples/output/trackpolyline.shp")
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
ParticleTrack("gwdir", "gwmag", arcpy.Point(-200,-200), 
              "C:/sapyexamples/output/trackfile.txt",10, 100000, 
              "C:/sapyexamples/output/trackpolyline.shp")
```

### Example 5

```python
# Name: ParticleTrack_Ex_02.py
# Description: Calculates the path of a particle through a velocity field.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inDirectionRaster = "gwdir"
inMagnitudeRaster = "gwmag"
sourcePoint = arcpy.Point(-200, -200)
outTrackFile = "C:/sapyexamples/output/trackfile.txt"
stepLength = 10
trackingTime = 10000000
outTrackPolylineFeatures = "C:/sapyexamples/output/trackpolyline.shp"

# Execute ParticleTrack
ParticleTrack(inDirectionRaster, inMagnitudeRaster, sourcePoint, outTrackFile,
              stepLength, trackingTime, outTrackPolylineFeatures)
```

### Example 6

```python
# Name: ParticleTrack_Ex_02.py
# Description: Calculates the path of a particle through a velocity field.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inDirectionRaster = "gwdir"
inMagnitudeRaster = "gwmag"
sourcePoint = arcpy.Point(-200, -200)
outTrackFile = "C:/sapyexamples/output/trackfile.txt"
stepLength = 10
trackingTime = 10000000
outTrackPolylineFeatures = "C:/sapyexamples/output/trackpolyline.shp"

# Execute ParticleTrack
ParticleTrack(inDirectionRaster, inMagnitudeRaster, sourcePoint, outTrackFile,
              stepLength, trackingTime, outTrackPolylineFeatures)
```

---

## Path Distance Allocation (Spatial Analyst)

## Summary

Calculates the least-cost source for each cell based on the least accumulative cost over a cost surface, while accounting for surface distance along with horizontal and vertical cost factors.

## Usage

- The Path Distance tools are comparable to the Cost Distance tools in that both determine the minimum accumulative travel cost from or to a source for each location on a raster surface. However, the Path Distance tools add more complexity to the analysis by accounting for the actual surface distance as well as other horizontal and vertical factors.
- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted internally to a raster before performing the analysis. The resolution of the raster can be controlled with the Cell Size environment. By default, if no other rasters are specified in the tool, the resolution will be determined by the shorter of the width or height of the extent of the input feature, in the input spatial reference, divided by 250.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- To calculate allocation, source locations can have an associated value, which can be specified by the Source Field parameter. If the input source is an integer raster, the default field is VALUE. If it is a feature, it will be the first integer field in the attribute table. If the input source data is a floating-point raster, an integer value raster parameter must be specified.
- Cells with NoData act as barriers in the Path Distance tools. The cost distance for cells behind NoData values is calculated by the accumulative cost necessary to move around the NoData barrier. Any cell location that is assigned NoData on any one of the input rasters will receive NoData on all output rasters.
- If the input source data and the cost raster are different extents, the default output extent is the intersection of the two. To get a cost distance surface for the entire extent, choose the Union of Inputs option on the output Extent environment settings.
- The output of the Aspect tool can be used as input for the Input Horizontal Raster parameter.
- The Maximum Distance parameter value is specified in the same cost units as those on the cost raster.
- For the output distance raster, the least-cost distance (or minimum accumulative cost distance) of a cell from or to a set of source locations is the lower bound of the least-cost distances from the cell to all source locations.
- The default values for the Horizontal factor modifiers are the following:Keywords Zero factor Cut angle Slope Side value -------------- ----------- ----------- ----- --------- Binary 1.0 45 ~ ~ Forward 0.5 45 (fixed) ~ 1.0 Linear 0.5 181 1/90 ~ Inverse linear 2.0 180 -1/90 ~
- The default values for the Vertical factor modifiers are the following:Keyword Zero Low High Slope Power Cos Sec factor cut cut power power angle angle ------------------------ ------ ----- ----- ----- ----- ----- ----- Binary 1.0 -30 30 ~ ~ ~ ~ Linear 1.0 -90 90 1/90 ~ ~ ~ Symmetric linear 1.0 -90 90 1/90 ~ ~ ~ Inverse linear 1.0 -45 45 -1/45 ~ ~ ~ Symmetric inverse linear 1.0 -45 45 -1/45 ~ ~ ~ Cos ~ -90 90 ~ 1.0 ~ ~ Sec ~ -90 90 ~ 1.0 ~ ~ Cos_sec ~ -90 90 ~ ~ 1.0 1.0 Sec_cos ~ -90 90 ~ ~ 1.0 1.0 Hiking time ~ -70 70 ~ ~ ~ ~ Bidirectional hiking time ~ -70 70 ~ ~ ~ ~
- The characteristics of the source, or the movers from or to a source, can be controlled by specific parameters. The Source cost multiplier parameter specifies the mode of travel or magnitude at the source, Source start cost sets the starting cost before the movement begins, Source resistance rate is a dynamic adjustment accounting for the impact of accumulated cost, for example, simulating how much a hiker is getting fatigued, and Source capacity sets how much cost a source can assimilate before reaching its limit. Travel direction identifies whether the mover is starting at a source and moving to nonsource locations or starting at nonsource locations and moving back to a source.
- If any of the source characteristic parameters are specified using a field, the source characteristic will be applied on a source-by-source basis, according to the information in the specified field for the source data. When a keyword or a constant value is provided, it will be applied to all sources.
- If the Source start cost parameter value is specified and Travel direction is set to Travel from source, the source locations on the output cost distance surface will be set to the Source start cost value; otherwise, the source locations on the output cost distance surface will be set to zero.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature source data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. If the input source raster is floating point, the Input value raster parameter must be set, and it must be integer. The value raster will take precedence over the Source field parameter setting. | Raster Layer; Feature Layer |
| Input cost raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| Input surface raster(Optional) | A raster defining the elevation values at each cell location.The values are used to calculate the actual surface distance covered when passing between cells. | Raster Layer |
| Input horizontal raster(Optional) | A raster defining the horizontal direction at each cell.The values on the raster must be integers ranging from 0 to 360, with 0 degrees being north, or toward the top of the screen, and increasing clockwise. Flat areas should be given a value of -1. The values at each location will be used in conjunction with the Horizontal Factor parameter to determine the horizontal cost incurred when moving from a cell to its neighbors. | Raster Layer |
| Horizontal factor(Optional) | Specifies the relationship between the horizontal cost factor and the horizontal relative moving angle (HRMA).There are several factors with modifiers that identify a defined horizontal factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the horizontal factor used in calculating the total cost of moving into a neighboring cell.In the option descriptions below, two acronyms are used: HF stands for horizontal factor, which defines the horizontal difficulty encountered when moving from one cell to the next; HRMA stands for horizontal relative moving angle, which identifies the angle between the horizontal direction from a cell and the moving direction.The options are as follows: Binary—If the HRMA is less than the cut angle, the HF is set to the value associated with the zero factor; otherwise, it is infinity. Forward—Only forward movement is allowed. The HRMA must be greater than or equal to 0 and less than 90 degrees (0 <= HRMA < 90). If the HRMA is greater than 0 and less than 45 degrees, the HF for the cell is set to the value associated with the zero factor. If the HRMA is greater than or equal to 45 degrees, the side value modifier value is used. The HF for any HRMA equal to or greater than 90 degrees is set to infinity. Linear—The HF is a linear function of the HRMA. Inverse Linear—The HF is an inverse linear function of the HRMA. Table—A table file will be used to define the horizontal factor graph used to determine the HFs.The modifiers to the horizontal factors are the following: Zero factor—The horizontal factor to be used when the HRMA is zero. This factor positions the y-intercept for any of the horizontal factor functions. Cut angle—The HRMA angle beyond which the HF will be set to infinity. Slope—The slope of the straight line used with the Linear and Inverse Linear horizontal factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). Side value—The HF when the HRMA is greater than or equal to 45 degrees and less than 90 degrees when the Forward horizontal factor keyword is specified. Table name—The name of the table defining the HF. | Horizontal Factor |
| Input vertical raster(Optional) | A raster defining the z-values for each cell location.The values are used for calculating the slope used to identify the vertical factor incurred when moving from one cell to another. | Raster Layer |
| Vertical factor(Optional) | Specifies the relationship between the vertical cost factor and the vertical relative moving angle (VRMA).There are several factors with modifiers that identify a defined vertical factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the vertical factor used in calculating the total cost for moving into a neighboring cell.In the option descriptions below, two acronyms are used: VF stands for vertical factor, which defines the vertical difficulty encountered in moving from one cell to the next; VRMA stands for vertical relative moving angle, which identifies the slope angle between the FROM or processing cell and the TO cell.The options are as follows: Binary—If the VRMA is greater than the low-cut angle and less than the high-cut angle, the VF is set to the value associated with the zero factor; otherwise, it is infinity. Linear—The VF is a linear function of the VRMA. Symmetric Linear—The VF is a linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis. Inverse Linear—The VF is an inverse linear function of the VRMA. Symmetric Inverse Linear—The VF is an inverse linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis. Cos—The VF is the cosine-based function of the VRMA. Sec—The VF is the secant-based function of the VRMA. Cos-Sec—The VF is the cosine-based function of the VRMA when the VRMA is negative and is the secant-based function of the VRMA when the VRMA is not negative. Sec-Cos—The VF is the secant-based function of the VRMA when the VRMA is negative and is the cosine-based function of the VRMA when the VRMA is not negative. Hiking Time—The VF is the hiking time function of the VRMA.Bidirectional Hiking Time—The VF is a bidirectional modified hiking time function of the VRMA.Table—A table file will be used to define the vertical-factor graph that is used to determine the VFs.The modifiers to the vertical keywords are the following: Zero factor—The vertical factor used when the VRMA is zero. This factor positions the y-intercept of the specified function. By definition, the zero factor is not applicable to any of the trigonometric vertical functions (COS, SEC, COS-SEC, or SEC-COS). The y-intercept is defined by these functions. Low Cut angle—The VRMA angle below which the VF will be set to infinity. High Cut angle—The VRMA angle above which the VF will be set to infinity. Slope—The slope of the straight line used with the Linear and Inverse Linear vertical factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). Table name—The name of the table defining the VF. | Vertical Factor |
| Maximum distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| Input value raster(Optional) | The input integer raster that identifies the zone values that will be used for each input source location.For each source location (cell or feature), this value will be assigned to all cells allocated to the source location for the computation. The value raster will take precedence over the Source field parameter setting. | Raster Layer |
| Source field(Optional) | The field used to assign values to the source locations. It must be of integer type.If the Input value raster parameter has been set, the values in that input will have precedence over this parameter setting. | Field |
| Output distance raster(Optional) | The output path distance raster.The output path distance raster identifies, for each cell, the least accumulative cost distance, over a cost surface to the identified source locations, while accounting for surface distance as well as horizontal and vertical surface factors.A source can be a cell, a set of cells, or one or more feature locations.The output raster is of floating-point type. | Raster Dataset |
| Output backlink raster(Optional) | The output cost backlink raster.The backlink raster contains values 0 through 8, which define the direction or identify the next neighboring cell (the succeeding cell) along the least accumulative cost path from a cell to reach its least-cost source, while accounting for surface distance as well as horizontal and vertical surface factors.If the path is to pass into the right neighbor, the cell will be assigned the value 1, 2 for the lower right diagonal cell, and continue clockwise. The value 0 is reserved for source cells. | Raster Dataset |
| Multiplier to apply to costs(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| Start cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| Accumulative cost resistance rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| Capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| Travel direction(Optional) | Specifies the direction of the traveler when applying horizontal and vertical factors and the source resistance rate.If you select the String option, you can choose between from and to options, which will be applied to all sources.If you select the Field option, you can select the field from the source data that determines the direction to use for each source. The field must contain the text string FROM_SOURCE or TO_SOURCE.Travel from source—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at the input source and travel out to the nonsource cells. This is the default.Travel to source—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at each nonsource cell and travel back to the input source. | String; Field |
| in_source_data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. If the input source raster is floating point, the in_value_raster parameter must be set, and it must integer. The value raster will take precedence over the source_field parameter setting. | Raster Layer; Feature Layer |
| in_cost_raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| in_surface_raster(Optional) | A raster defining the elevation values at each cell location.The values are used to calculate the actual surface distance covered when passing between cells. | Raster Layer |
| in_horizontal_raster(Optional) | A raster defining the horizontal direction at each cell.The values on the raster must be integers ranging from 0 to 360, with 0 degrees being north, or toward the top of the screen, and increasing clockwise. Flat areas should be given a value of -1. The values at each location will be used in conjunction with the horizontal_factor parameter to determine the horizontal cost incurred when moving from a cell to its neighbors. | Raster Layer |
| horizontal_factor(Optional) | The Horizontal Factor object defines the relationship between the horizontal cost factor and the horizontal relative moving angle.There are several factors with modifiers that identify a defined horizontal factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the horizontal factor used in calculating the total cost of moving into a neighboring cell.In the descriptions below, two acronyms are used: HF stands for horizontal factor, which defines the horizontal difficulty encountered when moving from one cell to the next; HRMA stands for horizontal relative moving angle, which identifies the angle between the horizontal direction from a cell and the moving direction.The object comes in the following forms: HfBinary, HfForward, HfLinear, HfInverseLinear, and HfTable. The definitions and parameters of these are the following: HfBinary({zeroFactor}, {cutAngle}) If the HRMA is less than the cut angle, the HF is set to the value associated with the zero factor; otherwise, it is infinity. HfForward({zeroFactor}, {sideValue}) Only forward movement is allowed. The HRMA must be greater than or equal to 0 and less than 90 degrees (0 <= HRMA < 90). If the HRMA is greater than 0 and less than 45 degrees, the HF for the cell is set to the value associated with the zero factor. If the HRMA is greater than or equal to 45 degrees, the side value modifier value is used. The HF for any HRMA equal to or greater than 90 degrees is set to infinity. HfLinear({zeroFactor}, {cutAngle}, {slope}) The HF is a linear function of the HRMA. HfInverseLinear({zeroFactor}, {cutAngle}, {slope}) The HF is an inverse linear function of the HRMA. HfTable(inTable) A table file will be used to define the horizontal factor graph used to determine the HFs.The modifiers to the horizontal keywords are the following: zeroFactor—The horizontal factor to be used when the HRMA is 0. This factor positions the y-intercept for any of the horizontal factor functions. cutAngle—The HRMA angle beyond which the HF will be set to infinity. slope—The slope of the straight line used with the HfLinear and HfInverseLinear horizontal factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). sideValue—The HF when the HRMA is greater than or equal to 45 degrees and less than 90 degrees when the HfForward horizontal factor keyword is specified. inTable—The name of the table defining the HF. | Horizontal Factor |
| in_vertical_raster(Optional) | A raster defining the z-values for each cell location.The values are used for calculating the slope used to identify the vertical factor incurred when moving from one cell to another. | Raster Layer |
| vertical_factor(Optional) | The Vertical factor object defines the relationship between the vertical cost factor and the vertical relative moving angle (VRMA).There are several factors with modifiers that identify a defined vertical factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the vertical factor used in calculating the total cost for moving into a neighboring cell.In the descriptions below, two acronyms are used: VF stands for vertical factor, which defines the vertical difficulty encountered in moving from one cell to the next; VRMA stands for vertical relative moving angle, which identifies the slope angle between the FROM or processing cell and the TO cell.The object comes in the following forms: VfBinary, VfLinear, VfInverseLinear, VfSymLinear, VfSymInverseLinear, VfCos, VfSec, VfSec, VfCosSec, VfSecCos, VfHikingTime, VfBidirHikingTime, VfTable.The definitions and parameters of these are the following:VfBinary({zeroFactor}, {lowCutAngle}, {highCutAngle}) If the VRMA is greater than the low-cut angle and less than the high-cut angle, the VF is set to the value associated with the zero factor; otherwise, it is infinity.VfLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is a linear function of the VRMA.VfInverseLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is an inverse linear function of the VRMA.VfSymLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is a linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis.VfSymInverseLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is an inverse linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis.VfCos({lowCutAngle}, {highCutAngle}, {cosPower}) The VF is the cosine-based function of the VRMA.VfSec({lowCutAngle}, {highCutAngle}, {secPower}) The VF is the secant-based function of the VRMA.VfCosSec({lowCutAngle}, {highCutAngle}, {cosPower}, {secPower}) The VF is the cosine-based function of the VRMA when the VRMA is negative and is the secant-based function of the VRMA when the VRMA is not negative.VfSecCos({lowCutAngle}, {highCutAngle}, {secPower}, {cos_power}) The VF is the secant-based function of the VRMA when the VRMA is negative and is the cosine-based function of the VRMA when the VRMA is not negative.VfHikingTime({lowCutAngle}, {highCutAngle}) The VF is the hiking time function of the VRMA.VfBidirHikingTime({lowCutAngle}, {highCutAngle}) The VF is a bidirectional modified hiking time function of the VRMA.VfTable(inTable) A table file will be used to define the vertical factor graph used to determine the VFs. The modifiers to the vertical parameters are the following: zeroFactor—The vertical factor used when the VRMA is zero. This factor positions the y-intercept of the specified function. By definition, the zero factor is not applicable to any of the trigonometric vertical functions (Cos, Sec, Cos-Sec, or Sec-Cos). The y-intercept is defined by these functions. lowCutAngle—The VRMA angle below which the VF will be set to infinity. highCutAngle—The VRMA angle above which the VF will be set to infinity. slope—The slope of the straight line used with the VfLinear and VfInverseLinear parameters. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). inTable—The name of the table defining the VF. | Vertical Factor |
| maximum_distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| in_value_raster(Optional) | The input integer raster that identifies the zone values that will be used for each input source location.For each source location (cell or feature), this value will be assigned to all cells allocated to the source location for the computation. The value raster will take precedence over the source_field parameter setting. | Raster Layer |
| source_field(Optional) | The field used to assign values to the source locations. It must be of integer type.If the in_value_raster parameter has been set, the values in that input will have precedence over this parameter setting. | Field |
| out_distance_raster(Optional) | The output path distance raster.The output path distance raster identifies, for each cell, the least accumulative cost distance, over a cost surface to the identified source locations, while accounting for surface distance as well as horizontal and vertical surface factors.A source can be a cell, a set of cells, or one or more feature locations.The output raster is of floating-point type. | Raster Dataset |
| out_backlink_raster(Optional) | The output cost backlink raster.The backlink raster contains values 0 through 8, which define the direction or identify the next neighboring cell (the succeeding cell) along the least accumulative cost path from a cell to reach its least-cost source, while accounting for surface distance as well as horizontal and vertical surface factors.If the path is to pass into the right neighbor, the cell will be assigned the value 1, 2 for the lower right diagonal cell, and continue clockwise. The value 0 is reserved for source cells. | Raster Dataset |
| source_cost_multiplier(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| source_start_cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| source_resistance_rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| source_capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| source_direction(Optional) | Specifies the direction of the traveler when applying horizontal and vertical factors and the source resistance rate.FROM_SOURCE—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at the input source and travel out to the nonsource cells. This is the default.TO_SOURCE—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at each nonsource cell and travel back to the input source. Specify the FROM_SOURCE or TO_SOURCE keyword, which will be applied to all sources, or specify a field in the source data that contains the keywords to identify the direction of travel for each source. That field must contain the string FROM_SOURCE or TO_SOURCE. | String; Field |

## Code Samples

### Example 1

```python
Keywords         Zero factor   Cut angle     Slope   Side value
--------------   -----------   -----------   -----   ---------
Binary           1.0            45           ~       ~
Forward          0.5            45 (fixed)   ~       1.0
Linear           0.5           181            1/90   ~
Inverse linear   2.0           180           -1/90   ~
```

### Example 2

```python
Keyword                   Zero    Low    High   Slope  Power  Cos    Sec
                          factor  cut    cut                  power  power
                                  angle  angle                             
------------------------  ------  -----  -----  -----  -----  -----  -----
Binary                    1.0     -30    30     ~      ~      ~      ~
Linear                    1.0     -90    90      1/90  ~      ~      ~
Symmetric linear          1.0     -90    90      1/90  ~      ~      ~
Inverse linear            1.0     -45    45     -1/45  ~      ~      ~
Symmetric inverse linear  1.0     -45    45     -1/45  ~      ~      ~
Cos                       ~       -90    90     ~      1.0    ~      ~
Sec                       ~       -90    90     ~      1.0    ~      ~
Cos_sec                   ~       -90    90     ~      ~      1.0    1.0
Sec_cos                   ~       -90    90     ~      ~      1.0    1.0
Hiking time               ~       -70    70     ~      ~      ~      ~
Bidirectional hiking time ~       -70    70     ~      ~      ~      ~
```

### Example 3

```python
PathAllocation(in_source_data, {in_cost_raster}, {in_surface_raster}, {in_horizontal_raster}, {horizontal_factor}, {in_vertical_raster}, {vertical_factor}, {maximum_distance}, {in_value_raster}, {source_field}, {out_distance_raster}, {out_backlink_raster}, {source_cost_multiplier}, {source_start_cost}, {source_resistance_rate}, {source_capacity}, {source_direction})
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
pathAlloc = PathAllocation("observers.shp", "costraster", "elevation", "hfraster",
                            HfForward(0.5, 1.0), "elevation", VfBinary(1.0, -30, 30),  
                            "", "valueraster", "FID", "c:/sapyexamples/output/optpathdist", 
                            "c:/sapyexamples/output/optpathbl", "Multiplier", "StartCost", "Resistance", 500000)
pathAlloc.save("c:/sapyexamples/output/allocpath")
```

### Example 5

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
pathAlloc = PathAllocation("observers.shp", "costraster", "elevation", "hfraster",
                            HfForward(0.5, 1.0), "elevation", VfBinary(1.0, -30, 30),  
                            "", "valueraster", "FID", "c:/sapyexamples/output/optpathdist", 
                            "c:/sapyexamples/output/optpathbl", "Multiplier", "StartCost", "Resistance", 500000)
pathAlloc.save("c:/sapyexamples/output/allocpath")
```

### Example 6

```python
# Name: PathAllocation_Ex_02.py
# Description: Calculates, for each cell, its nearest source based 
#              on the least accumulative cost over a cost surface, 
#              while accounting for surface distance and horizontal 
#              and vertical cost factors. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
costRast = "costraster"
surfaceRast = "elevation"

# The horizontal factor
inHoriz = "backlink2"
# Create the HfForward Object
zeroFactor = 0.5
sideValue = 1.0
myHorizFactor = HfForward(zeroFactor, sideValue)

#The vertical factor
inVertical = "focalcost.tif"
# Create the VfBinary Object
zeroFactor = 1.0
lowCutAngle = -30
highCutAngle = 30
myVerticalFactor = VfBinary(zeroFactor, lowCutAngle, highCutAngle)

maxDist = 25000
valRaster = "eucdirout"
sourceField = "FID"
optPathDistOut = "c:/sapyexamples/output/optdistpath"
optPathBLOut = "c:/sapyexamples/output/pathblinkout"

# Execute PathAllocation
pathAlloc = PathAllocation(inSource, costRast, surfaceRast, 
                           inHoriz, myHorizFactor, inVertical, myVerticalFactor, 
                           maxDist, valRaster, sourceField, 
                           optPathDistOut, optPathBLOut)

# Save the output 
pathAlloc.save("c:/sapyexamples/output/allocpath02")
```

### Example 7

```python
# Name: PathAllocation_Ex_02.py
# Description: Calculates, for each cell, its nearest source based 
#              on the least accumulative cost over a cost surface, 
#              while accounting for surface distance and horizontal 
#              and vertical cost factors. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
costRast = "costraster"
surfaceRast = "elevation"

# The horizontal factor
inHoriz = "backlink2"
# Create the HfForward Object
zeroFactor = 0.5
sideValue = 1.0
myHorizFactor = HfForward(zeroFactor, sideValue)

#The vertical factor
inVertical = "focalcost.tif"
# Create the VfBinary Object
zeroFactor = 1.0
lowCutAngle = -30
highCutAngle = 30
myVerticalFactor = VfBinary(zeroFactor, lowCutAngle, highCutAngle)

maxDist = 25000
valRaster = "eucdirout"
sourceField = "FID"
optPathDistOut = "c:/sapyexamples/output/optdistpath"
optPathBLOut = "c:/sapyexamples/output/pathblinkout"

# Execute PathAllocation
pathAlloc = PathAllocation(inSource, costRast, surfaceRast, 
                           inHoriz, myHorizFactor, inVertical, myVerticalFactor, 
                           maxDist, valRaster, sourceField, 
                           optPathDistOut, optPathBLOut)

# Save the output 
pathAlloc.save("c:/sapyexamples/output/allocpath02")
```

---

## Path Distance Back Link (Spatial Analyst)

## Summary

Defines the neighbor that is the next cell on the least accumulative cost path to the least-cost source, while accounting for surface distance along with horizontal and vertical cost factors.

## Usage

- The Path Distance tools are comparable to the Cost Distance tools in that both determine the minimum accumulative travel cost from or to a source for each location on a raster surface. However, the Path Distance tools add more complexity to the analysis by accounting for the actual surface distance as well as other horizontal and vertical factors.
- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted internally to a raster before performing the analysis. The resolution of the raster can be controlled with the Cell Size environment. By default, if no other rasters are specified in the tool, the resolution will be determined by the shorter of the width or height of the extent of the input feature, in the input spatial reference, divided by 250.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- Cells with NoData act as barriers in the Path Distance tools. The cost distance for cells behind NoData values is calculated by the accumulative cost necessary to move around the NoData barrier. Any cell location that is assigned NoData on any one of the input rasters will receive NoData on all output rasters.
- If the input source data and the cost raster are different extents, the default output extent is the intersection of the two. To get a cost distance surface for the entire extent, choose the Union of Inputs option on the output Extent environment settings.
- The output of the Aspect tool can be used as input for the Input Horizontal Raster parameter.
- The Maximum Distance parameter value is specified in the same cost units as those on the cost raster.
- For the output distance raster, the least-cost distance (or minimum accumulative cost distance) of a cell from or to a set of source locations is the lower bound of the least-cost distances from the cell to all source locations.
- The default values for the Horizontal factor modifiers are the following:Keywords Zero factor Cut angle Slope Side value -------------- ----------- ----------- ----- --------- Binary 1.0 45 ~ ~ Forward 0.5 45 (fixed) ~ 1.0 Linear 0.5 181 1/90 ~ Inverse linear 2.0 180 -1/90 ~
- The default values for the Vertical factor modifiers are the following:Keyword Zero Low High Slope Power Cos Sec factor cut cut power power angle angle ------------------------ ------ ----- ----- ----- ----- ----- ----- Binary 1.0 -30 30 ~ ~ ~ ~ Linear 1.0 -90 90 1/90 ~ ~ ~ Symmetric linear 1.0 -90 90 1/90 ~ ~ ~ Inverse linear 1.0 -45 45 -1/45 ~ ~ ~ Symmetric inverse linear 1.0 -45 45 -1/45 ~ ~ ~ Cos ~ -90 90 ~ 1.0 ~ ~ Sec ~ -90 90 ~ 1.0 ~ ~ Cos_sec ~ -90 90 ~ ~ 1.0 1.0 Sec_cos ~ -90 90 ~ ~ 1.0 1.0 Hiking time ~ -70 70 ~ ~ ~ ~ Bidirectional hiking time ~ -70 70 ~ ~ ~ ~
- The characteristics of the source, or the movers from or to a source, can be controlled by specific parameters. The Source cost multiplier parameter specifies the mode of travel or magnitude at the source, Source start cost sets the starting cost before the movement begins, Source resistance rate is a dynamic adjustment accounting for the impact of accumulated cost, for example, simulating how much a hiker is getting fatigued, and Source capacity sets how much cost a source can assimilate before reaching its limit. Travel direction identifies whether the mover is starting at a source and moving to nonsource locations or starting at nonsource locations and moving back to a source.
- If any of the source characteristic parameters are specified using a field, the source characteristic will be applied on a source-by-source basis, according to the information in the specified field for the source data. When a keyword or a constant value is provided, it will be applied to all sources.
- If the Source start cost parameter value is specified and Travel direction is set to Travel from source, the source locations on the output cost distance surface will be set to the Source start cost value; otherwise, the source locations on the output cost distance surface will be set to zero.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature source data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| Input cost raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| Input surface raster(Optional) | A raster defining the elevation values at each cell location.The values are used to calculate the actual surface distance covered when passing between cells. | Raster Layer |
| Input horizontal raster(Optional) | A raster defining the horizontal direction at each cell.The values on the raster must be integers ranging from 0 to 360, with 0 degrees being north, or toward the top of the screen, and increasing clockwise. Flat areas should be given a value of -1. The values at each location will be used in conjunction with the Horizontal Factor parameter to determine the horizontal cost incurred when moving from a cell to its neighbors. | Raster Layer |
| Horizontal factor(Optional) | Specifies the relationship between the horizontal cost factor and the horizontal relative moving angle (HRMA).There are several factors with modifiers that identify a defined horizontal factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the horizontal factor used in calculating the total cost of moving into a neighboring cell.In the option descriptions below, two acronyms are used: HF stands for horizontal factor, which defines the horizontal difficulty encountered when moving from one cell to the next; HRMA stands for horizontal relative moving angle, which identifies the angle between the horizontal direction from a cell and the moving direction.The options are as follows: Binary—If the HRMA is less than the cut angle, the HF is set to the value associated with the zero factor; otherwise, it is infinity. Forward—Only forward movement is allowed. The HRMA must be greater than or equal to 0 and less than 90 degrees (0 <= HRMA < 90). If the HRMA is greater than 0 and less than 45 degrees, the HF for the cell is set to the value associated with the zero factor. If the HRMA is greater than or equal to 45 degrees, the side value modifier value is used. The HF for any HRMA equal to or greater than 90 degrees is set to infinity. Linear—The HF is a linear function of the HRMA. Inverse Linear—The HF is an inverse linear function of the HRMA. Table—A table file will be used to define the horizontal factor graph used to determine the HFs.The modifiers to the horizontal factors are the following: Zero factor—The horizontal factor to be used when the HRMA is zero. This factor positions the y-intercept for any of the horizontal factor functions. Cut angle—The HRMA angle beyond which the HF will be set to infinity. Slope—The slope of the straight line used with the Linear and Inverse Linear horizontal factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). Side value—The HF when the HRMA is greater than or equal to 45 degrees and less than 90 degrees when the Forward horizontal factor keyword is specified. Table name—The name of the table defining the HF. | Horizontal Factor |
| Input vertical raster(Optional) | A raster defining the z-values for each cell location.The values are used for calculating the slope used to identify the vertical factor incurred when moving from one cell to another. | Raster Layer |
| Vertical factor(Optional) | Specifies the relationship between the vertical cost factor and the vertical relative moving angle (VRMA).There are several factors with modifiers that identify a defined vertical factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the vertical factor used in calculating the total cost for moving into a neighboring cell.In the option descriptions below, two acronyms are used: VF stands for vertical factor, which defines the vertical difficulty encountered in moving from one cell to the next; VRMA stands for vertical relative moving angle, which identifies the slope angle between the FROM or processing cell and the TO cell.The options are as follows: Binary—If the VRMA is greater than the low-cut angle and less than the high-cut angle, the VF is set to the value associated with the zero factor; otherwise, it is infinity. Linear—The VF is a linear function of the VRMA. Symmetric Linear—The VF is a linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis. Inverse Linear—The VF is an inverse linear function of the VRMA. Symmetric Inverse Linear—The VF is an inverse linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis. Cos—The VF is the cosine-based function of the VRMA. Sec—The VF is the secant-based function of the VRMA. Cos-Sec—The VF is the cosine-based function of the VRMA when the VRMA is negative and is the secant-based function of the VRMA when the VRMA is not negative. Sec-Cos—The VF is the secant-based function of the VRMA when the VRMA is negative and is the cosine-based function of the VRMA when the VRMA is not negative. Hiking Time—The VF is the hiking time function of the VRMA.Bidirectional Hiking Time—The VF is a bidirectional modified hiking time function of the VRMA.Table—A table file will be used to define the vertical-factor graph that is used to determine the VFs.The modifiers to the vertical keywords are the following: Zero factor—The vertical factor used when the VRMA is zero. This factor positions the y-intercept of the specified function. By definition, the zero factor is not applicable to any of the trigonometric vertical functions (COS, SEC, COS-SEC, or SEC-COS). The y-intercept is defined by these functions. Low Cut angle—The VRMA angle below which the VF will be set to infinity. High Cut angle—The VRMA angle above which the VF will be set to infinity. Slope—The slope of the straight line used with the Linear and Inverse Linear vertical factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). Table name—The name of the table defining the VF. | Vertical Factor |
| Maximum distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| Output distance raster(Optional) | The output path distance raster.The output path distance raster identifies, for each cell, the least accumulative cost distance, over a cost surface to the identified source locations, while accounting for surface distance as well as horizontal and vertical surface factors.A source can be a cell, a set of cells, or one or more feature locations.The output raster is of floating-point type. | Raster Dataset |
| Multiplier to apply to costs(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| Start cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| Accumulative cost resistance rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| Capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| Travel direction(Optional) | Specifies the direction of the traveler when applying horizontal and vertical factors and the source resistance rate.If you select the String option, you can choose between from and to options, which will be applied to all sources.If you select the Field option, you can select the field from the source data that determines the direction to use for each source. The field must contain the text string FROM_SOURCE or TO_SOURCE.Travel from source—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at the input source and travel out to the nonsource cells. This is the default.Travel to source—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at each nonsource cell and travel back to the input source. | String; Field |
| in_source_data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| in_cost_raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| in_surface_raster(Optional) | A raster defining the elevation values at each cell location.The values are used to calculate the actual surface distance covered when passing between cells. | Raster Layer |
| in_horizontal_raster(Optional) | A raster defining the horizontal direction at each cell.The values on the raster must be integers ranging from 0 to 360, with 0 degrees being north, or toward the top of the screen, and increasing clockwise. Flat areas should be given a value of -1. The values at each location will be used in conjunction with the horizontal_factor parameter to determine the horizontal cost incurred when moving from a cell to its neighbors. | Raster Layer |
| horizontal_factor(Optional) | The Horizontal Factor object defines the relationship between the horizontal cost factor and the horizontal relative moving angle.There are several factors with modifiers that identify a defined horizontal factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the horizontal factor used in calculating the total cost of moving into a neighboring cell.In the descriptions below, two acronyms are used: HF stands for horizontal factor, which defines the horizontal difficulty encountered when moving from one cell to the next; HRMA stands for horizontal relative moving angle, which identifies the angle between the horizontal direction from a cell and the moving direction.The object comes in the following forms: HfBinary, HfForward, HfLinear, HfInverseLinear, and HfTable. The definitions and parameters of these are the following: HfBinary({zeroFactor}, {cutAngle}) If the HRMA is less than the cut angle, the HF is set to the value associated with the zero factor; otherwise, it is infinity. HfForward({zeroFactor}, {sideValue}) Only forward movement is allowed. The HRMA must be greater than or equal to 0 and less than 90 degrees (0 <= HRMA < 90). If the HRMA is greater than 0 and less than 45 degrees, the HF for the cell is set to the value associated with the zero factor. If the HRMA is greater than or equal to 45 degrees, the side value modifier value is used. The HF for any HRMA equal to or greater than 90 degrees is set to infinity. HfLinear({zeroFactor}, {cutAngle}, {slope}) The HF is a linear function of the HRMA. HfInverseLinear({zeroFactor}, {cutAngle}, {slope}) The HF is an inverse linear function of the HRMA. HfTable(inTable) A table file will be used to define the horizontal factor graph used to determine the HFs.The modifiers to the horizontal keywords are the following: zeroFactor—The horizontal factor to be used when the HRMA is 0. This factor positions the y-intercept for any of the horizontal factor functions. cutAngle—The HRMA angle beyond which the HF will be set to infinity. slope—The slope of the straight line used with the HfLinear and HfInverseLinear horizontal factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). sideValue—The HF when the HRMA is greater than or equal to 45 degrees and less than 90 degrees when the HfForward horizontal factor keyword is specified. inTable—The name of the table defining the HF. | Horizontal Factor |
| in_vertical_raster(Optional) | A raster defining the z-values for each cell location.The values are used for calculating the slope used to identify the vertical factor incurred when moving from one cell to another. | Raster Layer |
| vertical_factor(Optional) | The Vertical factor object defines the relationship between the vertical cost factor and the vertical relative moving angle (VRMA).There are several factors with modifiers that identify a defined vertical factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the vertical factor used in calculating the total cost for moving into a neighboring cell.In the descriptions below, two acronyms are used: VF stands for vertical factor, which defines the vertical difficulty encountered in moving from one cell to the next; VRMA stands for vertical relative moving angle, which identifies the slope angle between the FROM or processing cell and the TO cell.The object comes in the following forms: VfBinary, VfLinear, VfInverseLinear, VfSymLinear, VfSymInverseLinear, VfCos, VfSec, VfSec, VfCosSec, VfSecCos, VfHikingTime, VfBidirHikingTime, VfTable.The definitions and parameters of these are the following:VfBinary({zeroFactor}, {lowCutAngle}, {highCutAngle}) If the VRMA is greater than the low-cut angle and less than the high-cut angle, the VF is set to the value associated with the zero factor; otherwise, it is infinity.VfLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is a linear function of the VRMA.VfInverseLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is an inverse linear function of the VRMA.VfSymLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is a linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis.VfSymInverseLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is an inverse linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis.VfCos({lowCutAngle}, {highCutAngle}, {cosPower}) The VF is the cosine-based function of the VRMA.VfSec({lowCutAngle}, {highCutAngle}, {secPower}) The VF is the secant-based function of the VRMA.VfCosSec({lowCutAngle}, {highCutAngle}, {cosPower}, {secPower}) The VF is the cosine-based function of the VRMA when the VRMA is negative and is the secant-based function of the VRMA when the VRMA is not negative.VfSecCos({lowCutAngle}, {highCutAngle}, {secPower}, {cos_power}) The VF is the secant-based function of the VRMA when the VRMA is negative and is the cosine-based function of the VRMA when the VRMA is not negative.VfHikingTime({lowCutAngle}, {highCutAngle}) The VF is the hiking time function of the VRMA.VfBidirHikingTime({lowCutAngle}, {highCutAngle}) The VF is a bidirectional modified hiking time function of the VRMA.VfTable(inTable) A table file will be used to define the vertical factor graph used to determine the VFs. The modifiers to the vertical parameters are the following: zeroFactor—The vertical factor used when the VRMA is zero. This factor positions the y-intercept of the specified function. By definition, the zero factor is not applicable to any of the trigonometric vertical functions (Cos, Sec, Cos-Sec, or Sec-Cos). The y-intercept is defined by these functions. lowCutAngle—The VRMA angle below which the VF will be set to infinity. highCutAngle—The VRMA angle above which the VF will be set to infinity. slope—The slope of the straight line used with the VfLinear and VfInverseLinear parameters. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). inTable—The name of the table defining the VF. | Vertical Factor |
| maximum_distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| out_distance_raster(Optional) | The output path distance raster.The output path distance raster identifies, for each cell, the least accumulative cost distance, over a cost surface to the identified source locations, while accounting for surface distance as well as horizontal and vertical surface factors.A source can be a cell, a set of cells, or one or more feature locations.The output raster is of floating-point type. | Raster Dataset |
| source_cost_multiplier(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| source_start_cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| source_resistance_rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| source_capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| source_direction(Optional) | Specifies the direction of the traveler when applying horizontal and vertical factors and the source resistance rate.FROM_SOURCE—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at the input source and travel out to the nonsource cells. This is the default.TO_SOURCE—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at each nonsource cell and travel back to the input source. Specify the FROM_SOURCE or TO_SOURCE keyword, which will be applied to all sources, or specify a field in the source data that contains the keywords to identify the direction of travel for each source. That field must contain the string FROM_SOURCE or TO_SOURCE. | String; Field |

## Code Samples

### Example 1

```python
Keywords         Zero factor   Cut angle     Slope   Side value
--------------   -----------   -----------   -----   ---------
Binary           1.0            45           ~       ~
Forward          0.5            45 (fixed)   ~       1.0
Linear           0.5           181            1/90   ~
Inverse linear   2.0           180           -1/90   ~
```

### Example 2

```python
Keyword                   Zero    Low    High   Slope  Power  Cos    Sec
                          factor  cut    cut                  power  power
                                  angle  angle                             
------------------------  ------  -----  -----  -----  -----  -----  -----
Binary                    1.0     -30    30     ~      ~      ~      ~
Linear                    1.0     -90    90      1/90  ~      ~      ~
Symmetric linear          1.0     -90    90      1/90  ~      ~      ~
Inverse linear            1.0     -45    45     -1/45  ~      ~      ~
Symmetric inverse linear  1.0     -45    45     -1/45  ~      ~      ~
Cos                       ~       -90    90     ~      1.0    ~      ~
Sec                       ~       -90    90     ~      1.0    ~      ~
Cos_sec                   ~       -90    90     ~      ~      1.0    1.0
Sec_cos                   ~       -90    90     ~      ~      1.0    1.0
Hiking time               ~       -70    70     ~      ~      ~      ~
Bidirectional hiking time ~       -70    70     ~      ~      ~      ~
```

### Example 3

```python
PathBackLink(in_source_data, {in_cost_raster}, {in_surface_raster}, {in_horizontal_raster}, {horizontal_factor}, {in_vertical_raster}, {vertical_factor}, {maximum_distance}, {out_distance_raster}, {source_cost_multiplier}, {source_start_cost}, {source_resistance_rate}, {source_capacity}, {source_direction})
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPathBL = PathBackLink("source.shp", "costraster", "elevation", "hfraster", 
                         HfForward(0.5, 1.0), "elevation", VfBinary(1.0, -30, 30),  
                         "", "c:/sapyexamples/output/optbldist", "Multiplier", "StartCost", "Resistance", 500000)
outPathBL.save("c:/sapyexamples/output/pathblink")
```

### Example 5

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPathBL = PathBackLink("source.shp", "costraster", "elevation", "hfraster", 
                         HfForward(0.5, 1.0), "elevation", VfBinary(1.0, -30, 30),  
                         "", "c:/sapyexamples/output/optbldist", "Multiplier", "StartCost", "Resistance", 500000)
outPathBL.save("c:/sapyexamples/output/pathblink")
```

### Example 6

```python
# Name: PathBackLink_Ex_02.py
# Description: Defines the neighbor that is the next cell on the least 
#              accumulative cost path to the nearest source, while 
#              accounting for surface distance and horizontal and 
#              vertical cost factors.  
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "source.shp"
inCostRast = "costraster"
inSurfRast = "elevation"

# The horizontal factor
inHoriz = "backlink2"
# Create the HfForward Object
zeroFactor = 0.5
sideValue = 1.0
myHorizFactor = HfForward(zeroFactor, sideValue)

#The vertical factor
inVertical = "focalcost.tif"
# Create the VfBinary Object
zeroFactor = 1.0
lowCutAngle = -30
highCutAngle = 30
myVerticalFactor = VfBinary(zeroFactor, lowCutAngle, highCutAngle)

inMaxDist = 30000
optOutDist = "c:/sapyexamples/output/pthdstout"

# Execute PathBackLink
outPathBL = PathBackLink(inSource, inCostRast, inSurfRast, 
                         inHoriz, myHorizFactor, inVertical,
                         myVerticalFactor, inMaxDist, optOutDist)

# Save the output 
outPathBL.save("c:/sapyexamples/output/pathblink02")
```

### Example 7

```python
# Name: PathBackLink_Ex_02.py
# Description: Defines the neighbor that is the next cell on the least 
#              accumulative cost path to the nearest source, while 
#              accounting for surface distance and horizontal and 
#              vertical cost factors.  
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "source.shp"
inCostRast = "costraster"
inSurfRast = "elevation"

# The horizontal factor
inHoriz = "backlink2"
# Create the HfForward Object
zeroFactor = 0.5
sideValue = 1.0
myHorizFactor = HfForward(zeroFactor, sideValue)

#The vertical factor
inVertical = "focalcost.tif"
# Create the VfBinary Object
zeroFactor = 1.0
lowCutAngle = -30
highCutAngle = 30
myVerticalFactor = VfBinary(zeroFactor, lowCutAngle, highCutAngle)

inMaxDist = 30000
optOutDist = "c:/sapyexamples/output/pthdstout"

# Execute PathBackLink
outPathBL = PathBackLink(inSource, inCostRast, inSurfRast, 
                         inHoriz, myHorizFactor, inVertical,
                         myVerticalFactor, inMaxDist, optOutDist)

# Save the output 
outPathBL.save("c:/sapyexamples/output/pathblink02")
```

---

## Path Distance (Spatial Analyst)

## Summary

Calculates, for each cell, the least accumulative cost distance from or to the least-cost source, while accounting for surface distance along with horizontal and vertical cost factors.

## Usage

- The Path Distance tools are comparable to the Cost Distance tools in that both determine the minimum accumulative travel cost from or to a source for each location on a raster surface. However, the Path Distance tools add more complexity to the analysis by accounting for the actual surface distance as well as other horizontal and vertical factors.
- The input source data can be a feature class or a raster. The feature class can be point, line or polygon.
- When the input source data is a raster, the set of source cells consists of all cells in the source raster that have valid values. Cells that have NoData values are not included in the source set. Zero is a valid value. A source raster can be created using the extraction tools.
- When the input source data is a feature class, the source locations are converted internally to a raster before performing the analysis. The resolution of the raster can be controlled with the Cell Size environment. By default, if no other rasters are specified in the tool, the resolution will be determined by the shorter of the width or height of the extent of the input feature, in the input spatial reference, divided by 250.
- When using feature data for the input source data, care must be taken with how the output cell size is handled when it is coarse, relative to the detail present in the input. The internal rasterization process uses the same default Cell assignment type value as the Feature to Raster tool, which is the cell center method. This means that data that is not located at the center of the cell will not be included in the intermediate rasterized source output, so it will not be represented in the distance calculations. For example, if the sources are a series of small polygons (such as building footprints) that are small relative to the output cell size, it is possible that only a few will fall under the centers of the output raster cells, seemingly causing most of the others to be lost in the analysis.To avoid this situation, as an intermediate step, you can rasterize the input features directly with the Feature to Raster tool and set the Field parameter. Then use the resulting output as input to the particular distance tool you want to use. Alternatively, you can select a small cell size to capture the appropriate amount of detail from the input features.
- Cells with NoData act as barriers in the Path Distance tools. The cost distance for cells behind NoData values is calculated by the accumulative cost necessary to move around the NoData barrier. Any cell location that is assigned NoData on any one of the input rasters will receive NoData on all output rasters.
- If the input source data and the cost raster are different extents, the default output extent is the intersection of the two. To get a cost distance surface for the entire extent, choose the Union of Inputs option on the output Extent environment settings.
- The output of the Aspect tool can be used as input for the Input Horizontal Raster parameter.
- The Maximum Distance parameter value is specified in the same cost units as those on the cost raster.
- For the output distance raster, the least-cost distance (or minimum accumulative cost distance) of a cell from or to a set of source locations is the lower bound of the least-cost distances from the cell to all source locations.
- The default values for the Horizontal factor modifiers are the following:Keywords Zero factor Cut angle Slope Side value -------------- ----------- ----------- ----- --------- Binary 1.0 45 ~ ~ Forward 0.5 45 (fixed) ~ 1.0 Linear 0.5 181 1/90 ~ Inverse linear 2.0 180 -1/90 ~
- The default values for the Vertical factor modifiers are the following:Keyword Zero Low High Slope Power Cos Sec factor cut cut power power angle angle ------------------------ ------ ----- ----- ----- ----- ----- ----- Binary 1.0 -30 30 ~ ~ ~ ~ Linear 1.0 -90 90 1/90 ~ ~ ~ Symmetric linear 1.0 -90 90 1/90 ~ ~ ~ Inverse linear 1.0 -45 45 -1/45 ~ ~ ~ Symmetric inverse linear 1.0 -45 45 -1/45 ~ ~ ~ Cos ~ -90 90 ~ 1.0 ~ ~ Sec ~ -90 90 ~ 1.0 ~ ~ Cos_sec ~ -90 90 ~ ~ 1.0 1.0 Sec_cos ~ -90 90 ~ ~ 1.0 1.0 Hiking time ~ -70 70 ~ ~ ~ ~ Bidirectional hiking time ~ -70 70 ~ ~ ~ ~
- The characteristics of the source, or the movers from or to a source, can be controlled by specific parameters. The Source cost multiplier parameter specifies the mode of travel or magnitude at the source, Source start cost sets the starting cost before the movement begins, Source resistance rate is a dynamic adjustment accounting for the impact of accumulated cost, for example, simulating how much a hiker is getting fatigued, and Source capacity sets how much cost a source can assimilate before reaching its limit. Travel direction identifies whether the mover is starting at a source and moving to nonsource locations or starting at nonsource locations and moving back to a source.
- If any of the source characteristic parameters are specified using a field, the source characteristic will be applied on a source-by-source basis, according to the information in the specified field for the source data. When a keyword or a constant value is provided, it will be applied to all sources.
- If the Source start cost parameter value is specified and Travel direction is set to Travel from source, the source locations on the output cost distance surface will be set to the Source start cost value; otherwise, the source locations on the output cost distance surface will be set to zero.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. See the Parallel processing with Spatial Analyst help topic for details on this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrative privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature source data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| Input cost raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| Input surface raster(Optional) | A raster defining the elevation values at each cell location.The values are used to calculate the actual surface distance covered when passing between cells. | Raster Layer |
| Input horizontal raster(Optional) | A raster defining the horizontal direction at each cell.The values on the raster must be integers ranging from 0 to 360, with 0 degrees being north, or toward the top of the screen, and increasing clockwise. Flat areas should be given a value of -1. The values at each location will be used in conjunction with the Horizontal Factor parameter to determine the horizontal cost incurred when moving from a cell to its neighbors. | Raster Layer |
| Horizontal factor(Optional) | Specifies the relationship between the horizontal cost factor and the horizontal relative moving angle (HRMA).There are several factors with modifiers that identify a defined horizontal factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the horizontal factor used in calculating the total cost of moving into a neighboring cell.In the option descriptions below, two acronyms are used: HF stands for horizontal factor, which defines the horizontal difficulty encountered when moving from one cell to the next; HRMA stands for horizontal relative moving angle, which identifies the angle between the horizontal direction from a cell and the moving direction.The options are as follows: Binary—If the HRMA is less than the cut angle, the HF is set to the value associated with the zero factor; otherwise, it is infinity. Forward—Only forward movement is allowed. The HRMA must be greater than or equal to 0 and less than 90 degrees (0 <= HRMA < 90). If the HRMA is greater than 0 and less than 45 degrees, the HF for the cell is set to the value associated with the zero factor. If the HRMA is greater than or equal to 45 degrees, the side value modifier value is used. The HF for any HRMA equal to or greater than 90 degrees is set to infinity. Linear—The HF is a linear function of the HRMA. Inverse Linear—The HF is an inverse linear function of the HRMA. Table—A table file will be used to define the horizontal factor graph used to determine the HFs.The modifiers to the horizontal factors are the following: Zero factor—The horizontal factor to be used when the HRMA is zero. This factor positions the y-intercept for any of the horizontal factor functions. Cut angle—The HRMA angle beyond which the HF will be set to infinity. Slope—The slope of the straight line used with the Linear and Inverse Linear horizontal factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). Side value—The HF when the HRMA is greater than or equal to 45 degrees and less than 90 degrees when the Forward horizontal factor keyword is specified. Table name—The name of the table defining the HF. | Horizontal Factor |
| Input vertical raster(Optional) | A raster defining the z-values for each cell location.The values are used for calculating the slope used to identify the vertical factor incurred when moving from one cell to another. | Raster Layer |
| Vertical factor(Optional) | Specifies the relationship between the vertical cost factor and the vertical relative moving angle (VRMA).There are several factors with modifiers that identify a defined vertical factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the vertical factor used in calculating the total cost for moving into a neighboring cell.In the option descriptions below, two acronyms are used: VF stands for vertical factor, which defines the vertical difficulty encountered in moving from one cell to the next; VRMA stands for vertical relative moving angle, which identifies the slope angle between the FROM or processing cell and the TO cell.The options are as follows: Binary—If the VRMA is greater than the low-cut angle and less than the high-cut angle, the VF is set to the value associated with the zero factor; otherwise, it is infinity. Linear—The VF is a linear function of the VRMA. Symmetric Linear—The VF is a linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis. Inverse Linear—The VF is an inverse linear function of the VRMA. Symmetric Inverse Linear—The VF is an inverse linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis. Cos—The VF is the cosine-based function of the VRMA. Sec—The VF is the secant-based function of the VRMA. Cos-Sec—The VF is the cosine-based function of the VRMA when the VRMA is negative and is the secant-based function of the VRMA when the VRMA is not negative. Sec-Cos—The VF is the secant-based function of the VRMA when the VRMA is negative and is the cosine-based function of the VRMA when the VRMA is not negative. Hiking Time—The VF is the hiking time function of the VRMA.Bidirectional Hiking Time—The VF is a bidirectional modified hiking time function of the VRMA.Table—A table file will be used to define the vertical-factor graph that is used to determine the VFs.The modifiers to the vertical keywords are the following: Zero factor—The vertical factor used when the VRMA is zero. This factor positions the y-intercept of the specified function. By definition, the zero factor is not applicable to any of the trigonometric vertical functions (COS, SEC, COS-SEC, or SEC-COS). The y-intercept is defined by these functions. Low Cut angle—The VRMA angle below which the VF will be set to infinity. High Cut angle—The VRMA angle above which the VF will be set to infinity. Slope—The slope of the straight line used with the Linear and Inverse Linear vertical factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). Table name—The name of the table defining the VF. | Vertical Factor |
| Maximum distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| Output backlink raster(Optional) | The output cost backlink raster.The backlink raster contains values 0 through 8, which define the direction or identify the next neighboring cell (the succeeding cell) along the least accumulative cost path from a cell to reach its least-cost source, while accounting for surface distance as well as horizontal and vertical surface factors.If the path is to pass into the right neighbor, the cell will be assigned the value 1, 2 for the lower right diagonal cell, and continue clockwise. The value 0 is reserved for source cells. | Raster Dataset |
| Multiplier to apply to costs(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| Start cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| Accumulative cost resistance rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| Capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| Travel direction(Optional) | Specifies the direction of the traveler when applying horizontal and vertical factors and the source resistance rate.If you select the String option, you can choose between from and to options, which will be applied to all sources.If you select the Field option, you can select the field from the source data that determines the direction to use for each source. The field must contain the text string FROM_SOURCE or TO_SOURCE.Travel from source—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at the input source and travel out to the nonsource cells. This is the default.Travel to source—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at each nonsource cell and travel back to the input source. | String; Field |
| in_source_data | The input source locations.This is a raster or feature (point, line, or polygon) identifying the cells or locations that will be used to calculate the least accumulated cost distance for each output cell location.For rasters, the input type can be integer or floating point. | Raster Layer; Feature Layer |
| in_cost_raster(Optional) | A raster defining the impedance or cost to move planimetrically through each cell.The value at each cell location represents the cost-per-unit distance for moving through the cell. Each cell location value is multiplied by the cell resolution while also compensating for diagonal movement to obtain the total cost of passing through the cell.The values of the cost raster can be integer or floating point, but they cannot be negative or zero (you cannot have a negative or zero cost). | Raster Layer |
| in_surface_raster(Optional) | A raster defining the elevation values at each cell location.The values are used to calculate the actual surface distance covered when passing between cells. | Raster Layer |
| in_horizontal_raster(Optional) | A raster defining the horizontal direction at each cell.The values on the raster must be integers ranging from 0 to 360, with 0 degrees being north, or toward the top of the screen, and increasing clockwise. Flat areas should be given a value of -1. The values at each location will be used in conjunction with the horizontal_factor parameter to determine the horizontal cost incurred when moving from a cell to its neighbors. | Raster Layer |
| horizontal_factor(Optional) | The Horizontal Factor object defines the relationship between the horizontal cost factor and the horizontal relative moving angle.There are several factors with modifiers that identify a defined horizontal factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the horizontal factor used in calculating the total cost of moving into a neighboring cell.In the descriptions below, two acronyms are used: HF stands for horizontal factor, which defines the horizontal difficulty encountered when moving from one cell to the next; HRMA stands for horizontal relative moving angle, which identifies the angle between the horizontal direction from a cell and the moving direction.The object comes in the following forms: HfBinary, HfForward, HfLinear, HfInverseLinear, and HfTable. The definitions and parameters of these are the following: HfBinary({zeroFactor}, {cutAngle}) If the HRMA is less than the cut angle, the HF is set to the value associated with the zero factor; otherwise, it is infinity. HfForward({zeroFactor}, {sideValue}) Only forward movement is allowed. The HRMA must be greater than or equal to 0 and less than 90 degrees (0 <= HRMA < 90). If the HRMA is greater than 0 and less than 45 degrees, the HF for the cell is set to the value associated with the zero factor. If the HRMA is greater than or equal to 45 degrees, the side value modifier value is used. The HF for any HRMA equal to or greater than 90 degrees is set to infinity. HfLinear({zeroFactor}, {cutAngle}, {slope}) The HF is a linear function of the HRMA. HfInverseLinear({zeroFactor}, {cutAngle}, {slope}) The HF is an inverse linear function of the HRMA. HfTable(inTable) A table file will be used to define the horizontal factor graph used to determine the HFs.The modifiers to the horizontal keywords are the following: zeroFactor—The horizontal factor to be used when the HRMA is 0. This factor positions the y-intercept for any of the horizontal factor functions. cutAngle—The HRMA angle beyond which the HF will be set to infinity. slope—The slope of the straight line used with the HfLinear and HfInverseLinear horizontal factor keywords. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). sideValue—The HF when the HRMA is greater than or equal to 45 degrees and less than 90 degrees when the HfForward horizontal factor keyword is specified. inTable—The name of the table defining the HF. | Horizontal Factor |
| in_vertical_raster(Optional) | A raster defining the z-values for each cell location.The values are used for calculating the slope used to identify the vertical factor incurred when moving from one cell to another. | Raster Layer |
| vertical_factor(Optional) | The Vertical factor object defines the relationship between the vertical cost factor and the vertical relative moving angle (VRMA).There are several factors with modifiers that identify a defined vertical factor graph. Additionally, a table can be used to create a custom graph. The graphs are used to identify the vertical factor used in calculating the total cost for moving into a neighboring cell.In the descriptions below, two acronyms are used: VF stands for vertical factor, which defines the vertical difficulty encountered in moving from one cell to the next; VRMA stands for vertical relative moving angle, which identifies the slope angle between the FROM or processing cell and the TO cell.The object comes in the following forms: VfBinary, VfLinear, VfInverseLinear, VfSymLinear, VfSymInverseLinear, VfCos, VfSec, VfSec, VfCosSec, VfSecCos, VfHikingTime, VfBidirHikingTime, VfTable.The definitions and parameters of these are the following:VfBinary({zeroFactor}, {lowCutAngle}, {highCutAngle}) If the VRMA is greater than the low-cut angle and less than the high-cut angle, the VF is set to the value associated with the zero factor; otherwise, it is infinity.VfLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is a linear function of the VRMA.VfInverseLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is an inverse linear function of the VRMA.VfSymLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is a linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis.VfSymInverseLinear({zeroFactor}, {lowCutAngle}, {highCutAngle}, {slope}) The VF is an inverse linear function of the VRMA in either the negative or positive side of the VRMA, and the two linear functions are symmetrical with respect to the VF (y) axis.VfCos({lowCutAngle}, {highCutAngle}, {cosPower}) The VF is the cosine-based function of the VRMA.VfSec({lowCutAngle}, {highCutAngle}, {secPower}) The VF is the secant-based function of the VRMA.VfCosSec({lowCutAngle}, {highCutAngle}, {cosPower}, {secPower}) The VF is the cosine-based function of the VRMA when the VRMA is negative and is the secant-based function of the VRMA when the VRMA is not negative.VfSecCos({lowCutAngle}, {highCutAngle}, {secPower}, {cos_power}) The VF is the secant-based function of the VRMA when the VRMA is negative and is the cosine-based function of the VRMA when the VRMA is not negative.VfHikingTime({lowCutAngle}, {highCutAngle}) The VF is the hiking time function of the VRMA.VfBidirHikingTime({lowCutAngle}, {highCutAngle}) The VF is a bidirectional modified hiking time function of the VRMA.VfTable(inTable) A table file will be used to define the vertical factor graph used to determine the VFs. The modifiers to the vertical parameters are the following: zeroFactor—The vertical factor used when the VRMA is zero. This factor positions the y-intercept of the specified function. By definition, the zero factor is not applicable to any of the trigonometric vertical functions (Cos, Sec, Cos-Sec, or Sec-Cos). The y-intercept is defined by these functions. lowCutAngle—The VRMA angle below which the VF will be set to infinity. highCutAngle—The VRMA angle above which the VF will be set to infinity. slope—The slope of the straight line used with the VfLinear and VfInverseLinear parameters. The slope is specified as a fraction of rise over run (for example, 45 percent slope is 1/45, which is input as 0.02222). inTable—The name of the table defining the VF. | Vertical Factor |
| maximum_distance(Optional) | The threshold that the accumulative cost values cannot exceed.If an accumulative cost distance value exceeds this value, the output value for the cell location will be NoData. The maximum distance is the extent for which the accumulative cost distances are calculated.The default distance is to the edge of the output raster. | Double |
| out_backlink_raster(Optional) | The output cost backlink raster.The backlink raster contains values 0 through 8, which define the direction or identify the next neighboring cell (the succeeding cell) along the least accumulative cost path from a cell to reach its least-cost source, while accounting for surface distance as well as horizontal and vertical surface factors.If the path is to pass into the right neighbor, the cell will be assigned the value 1, 2 for the lower right diagonal cell, and continue clockwise. The value 0 is reserved for source cells. | Raster Dataset |
| source_cost_multiplier(Optional) | The multiplier that will be applied to the cost values.This allows for control of the mode of travel or the magnitude at a source. The greater the multiplier, the greater the cost to move through each cell.The values must be greater than zero. The default is 1. | Double; Field |
| source_start_cost(Optional) | The starting cost that will be used to begin the cost calculations. Allows for the specification of the fixed cost associated with a source. Instead of starting at a cost of zero, the cost algorithm will begin with this value. The values must be zero or greater. The default is 0. | Double; Field |
| source_resistance_rate(Optional) | This parameter simulates the increase in the effort to overcome costs as the accumulative cost increases. It is used to model fatigue of the traveler. The growing accumulative cost to reach a cell is multiplied by the resistance rate and added to the cost to move into the subsequent cell.It is a modified version of a compound interest rate formula that is used to calculate the apparent cost of moving through a cell. As the value of the resistance rate increases, it increases the cost of the cells that are visited later. The greater the resistance rate, the more additional cost is added to reach the next cell, which is compounded for each subsequent movement. Since the resistance rate is similar to a compound rate and generally the accumulative cost values are very large, small resistance rates are suggested, such as 0.02, 0.005, or even smaller, depending on the accumulative cost values.The values must be zero or greater. The default is 0. | Double; Field |
| source_capacity(Optional) | The cost capacity for the traveler for a source.The cost calculations continue for each source until the specified capacity is reached.The values must be greater than zero. The default capacity is to the edge of the output raster. | Double; Field |
| source_direction(Optional) | Specifies the direction of the traveler when applying horizontal and vertical factors and the source resistance rate.FROM_SOURCE—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at the input source and travel out to the nonsource cells. This is the default.TO_SOURCE—The horizontal factor, vertical factor, and source resistance rate will be applied beginning at each nonsource cell and travel back to the input source. Specify the FROM_SOURCE or TO_SOURCE keyword, which will be applied to all sources, or specify a field in the source data that contains the keywords to identify the direction of travel for each source. That field must contain the string FROM_SOURCE or TO_SOURCE. | String; Field |

## Code Samples

### Example 1

```python
Keywords         Zero factor   Cut angle     Slope   Side value
--------------   -----------   -----------   -----   ---------
Binary           1.0            45           ~       ~
Forward          0.5            45 (fixed)   ~       1.0
Linear           0.5           181            1/90   ~
Inverse linear   2.0           180           -1/90   ~
```

### Example 2

```python
Keyword                   Zero    Low    High   Slope  Power  Cos    Sec
                          factor  cut    cut                  power  power
                                  angle  angle                             
------------------------  ------  -----  -----  -----  -----  -----  -----
Binary                    1.0     -30    30     ~      ~      ~      ~
Linear                    1.0     -90    90      1/90  ~      ~      ~
Symmetric linear          1.0     -90    90      1/90  ~      ~      ~
Inverse linear            1.0     -45    45     -1/45  ~      ~      ~
Symmetric inverse linear  1.0     -45    45     -1/45  ~      ~      ~
Cos                       ~       -90    90     ~      1.0    ~      ~
Sec                       ~       -90    90     ~      1.0    ~      ~
Cos_sec                   ~       -90    90     ~      ~      1.0    1.0
Sec_cos                   ~       -90    90     ~      ~      1.0    1.0
Hiking time               ~       -70    70     ~      ~      ~      ~
Bidirectional hiking time ~       -70    70     ~      ~      ~      ~
```

### Example 3

```python
PathDistance(in_source_data, {in_cost_raster}, {in_surface_raster}, {in_horizontal_raster}, {horizontal_factor}, {in_vertical_raster}, {vertical_factor}, {maximum_distance}, {out_backlink_raster}, {source_cost_multiplier}, {source_start_cost}, {source_resistance_rate}, {source_capacity}, {source_direction})
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPathDist = PathDistance("observers.shp", "costraster", "elevation", "hfraster",
                            HfForward(0.5, 1.0), "elevation", VfBinary(1.0, -30, 30),  
                            "", "c:/sapyexamples/output/backlinkpath", "Multiplier", "StartCost", "Resistance", 500000)
outPathDist.save("c:/sapyexamples/output/pathdistout")
```

### Example 5

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPathDist = PathDistance("observers.shp", "costraster", "elevation", "hfraster",
                            HfForward(0.5, 1.0), "elevation", VfBinary(1.0, -30, 30),  
                            "", "c:/sapyexamples/output/backlinkpath", "Multiplier", "StartCost", "Resistance", 500000)
outPathDist.save("c:/sapyexamples/output/pathdistout")
```

### Example 6

```python
# Name: PathDistance_Ex_02.py
# Description: Calculates, for each cell, the least accumulative 
#              cost distance to the nearest source, while accounting 
#              for surface distance and horizontal and vertical 
#              cost factors.  
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
inCostRast = "costraster"
inElev = "elevation"

# The horizontal factor
inHoriz = "backlink2"
# Create the HfForward Object
zeroFactor = 0.5
sideValue = 1.0
myHorizFactor = HfForward(zeroFactor, sideValue)

#The vertical factor
inVertical = "focalcost.tif"
# Create the VfBinary Object
zeroFactor = 1.0
lowCutAngle = -30
highCutAngle = 30
myVerticalFactor = VfBinary(zeroFactor, lowCutAngle, highCutAngle)

maxDist = 50000
optBacklinkOut = "c:/sapyexamples/output/pathbacklink"

# Execute PathDistance
outPathDist = PathDistance(inSource, inCostRast, inElev, inHoriz, 
                           myHorizFactor, inVertical, myVerticalFactor, 
                           maxDist, optBacklinkOut)

# Save the output 
outPathDist.save("c:/sapyexamples/output/pathdistout02")
```

### Example 7

```python
# Name: PathDistance_Ex_02.py
# Description: Calculates, for each cell, the least accumulative 
#              cost distance to the nearest source, while accounting 
#              for surface distance and horizontal and vertical 
#              cost factors.  
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inSource = "observers.shp"
inCostRast = "costraster"
inElev = "elevation"

# The horizontal factor
inHoriz = "backlink2"
# Create the HfForward Object
zeroFactor = 0.5
sideValue = 1.0
myHorizFactor = HfForward(zeroFactor, sideValue)

#The vertical factor
inVertical = "focalcost.tif"
# Create the VfBinary Object
zeroFactor = 1.0
lowCutAngle = -30
highCutAngle = 30
myVerticalFactor = VfBinary(zeroFactor, lowCutAngle, highCutAngle)

maxDist = 50000
optBacklinkOut = "c:/sapyexamples/output/pathbacklink"

# Execute PathDistance
outPathDist = PathDistance(inSource, inCostRast, inElev, inHoriz, 
                           myHorizFactor, inVertical, myVerticalFactor, 
                           maxDist, optBacklinkOut)

# Save the output 
outPathDist.save("c:/sapyexamples/output/pathdistout02")
```

---

## Pick (Spatial Analyst)

## Summary

The value from a position raster is used to determine from which raster in a list of input rasters the output cell value will be obtained.

## Usage

- The value of each cell of the Input position raster (in_position_raster in Python) determines which input will be used to obtain the output raster value. For example, if a cell in the Input position raster has a value of 1, the value from the first input in the raster list will be used for the output cell value. If the position input has a value of 2, the output value will come from the second input in the raster list, and so on.
- The order of the Input rasters or constant values (in_rasters_or_constants in Python) is relevant for this tool. If the order of rasters changes, the results will change.
- If a cell value on the Input position raster is zero or negative, the result will be NoData. If the position value is larger than the number of rasters in the list, the result will be NoData.
- If the Input position raster is floating point, the values will be truncated to be integers before they are processed.
- Any cell with a NoData value on the position raster will receive NoData on the output raster.
- If any of the rasters in the input list is floating point, the output raster will be floating point. If they are all integer, the output raster will be integer.
- If the Process as multiband parameter is unchecked (process_as_multiband is set to SINGLE_BAND in Python), only the first band of a multiband Input position raster (in_position_raster in Python) will be used. Each band from a multiband Input rasters or constant values (in_rasters_or_constants in Python) will be processed separately as a single-band raster.
- If the Process as multiband parameter is checked (process_as_multiband is set to MULTI_BAND in Python), each multiband raster input will be processed as a multiband raster.The number of bands in the output depends on the Input position raster. If the Input position raster is a single band, the number of bands on the output raster will be the same as the maximum number of bands of all multiband rasters from the Input rasters or constant values. If the Input position raster is a multiband, the output raster will have the same number of bands as the Input position raster.If any of the Input rasters or constant values is a raster with a smaller number of bands than the output raster, the missing bands will be interpreted as a band filled with NoData. If the cell value of the Input position raster picks value one from the missing band, the output raster will receive NoData. If any of the Input rasters or constant values is a constant, it will be interpreted as a multiband raster, in which the cell values of all bands are the same as the constant and have the same number of bands as the output raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input position raster | The input raster defining the position of the raster to use for the output value.The input can be an integer or float raster. | Raster Layer |
| Input rasters or constant values | The list of inputs from which the output value will be selected.The inputs can be integer or float rasters. A number can also be used as an input. | Raster Layer; Constant |
| Process as multiband(Optional) | Specifies how the input multiband raster bands will be processed.Unchecked—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.Checked—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |
| in_position_raster | The input raster defining the position of the raster to use for the output value.The input can be an integer or float raster. | Raster Layer |
| in_rasters_or_constants[in_raster_or_constant,...] | The list of inputs from which the output value will be selected.The inputs can be integer or float rasters. A number can also be used as an input. | Raster Layer; Constant |
| process_as_multiband(Optional) | Specifies how the input multiband raster bands will be processed.SINGLE_BAND—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.MULTI_BAND—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |

## Code Samples

### Example 1

```python
Pick(in_position_raster, in_rasters_or_constants, {process_as_multiband})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPick = Pick("cost", ["degs", "negs", "fourgrd"], "SINGLE_BAND")
outPick.save("C:/sapyexamples/output/outpick.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPick = Pick("cost", ["degs", "negs", "fourgrd"], "SINGLE_BAND")
outPick.save("C:/sapyexamples/output/outpick.tif")
```

### Example 4

```python
# Name: Pick_Ex_02.py
# Description: Assigns output values using one of a list of rasters
#              determined by the value of an input raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPositionRas = "inzone_MB"
inRas01 = "Ras1_MB"
inRas02 = "Ras2_MB"
inRas03 = "Ras3_MB"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute Pick
outPick = Pick(inPositionRaster, [inRas01, inRas02, inRas03], "MULTI_BAND")

# Save the output 
outPick.save("C:/sapyexamples/output/outpick")
```

### Example 5

```python
# Name: Pick_Ex_02.py
# Description: Assigns output values using one of a list of rasters
#              determined by the value of an input raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPositionRas = "inzone_MB"
inRas01 = "Ras1_MB"
inRas02 = "Ras2_MB"
inRas03 = "Ras3_MB"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute Pick
outPick = Pick(inPositionRaster, [inRas01, inRas02, inRas03], "MULTI_BAND")

# Save the output 
outPick.save("C:/sapyexamples/output/outpick")
```

---

## Plus (Spatial Analyst)

## Summary

Adds (sums) the values of two rasters on a cell-by-cell basis.

## Usage

- The order of inputs is irrelevant for this tool.
- If both inputs are integer, the output will be an integer raster; otherwise, it will be a floating-point raster.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "+" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input whose values will be added to.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input whose values will be added to the first input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input whose values will be added to.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input whose values will be added to the first input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Plus(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPlus = Plus("degs", "negs")
outPlus.save("C:/sapyexamples/output/outplus.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPlus = Plus("degs", "negs")
outPlus.save("C:/sapyexamples/output/outplus.img")
```

### Example 4

```python
# Name: Plus_Ex_02.py
# Description: Adds the values of two rasters on a cell-by-cell basis.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "cost"
inRaster2 = "degs"

# Execute Plus
outPlus = Plus(inRaster1, inRaster2)

# Save the output 
outPlus.save("C:/sapyexamples/output/outplus")
```

### Example 5

```python
# Name: Plus_Ex_02.py
# Description: Adds the values of two rasters on a cell-by-cell basis.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "cost"
inRaster2 = "degs"

# Execute Plus
outPlus = Plus(inRaster1, inRaster2)

# Save the output 
outPlus.save("C:/sapyexamples/output/outplus")
```

---

## Point Density (Spatial Analyst)

## Summary

Calculates a magnitude-per-unit area from point features that fall within a neighborhood around each cell.

## Usage

- Only the points that fall within the neighborhood are considered when calculating the density. If no points fall within the neighborhood at a particular cell, that cell is assigned NoData.
- The values on the output raster will always be floating point.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Larger values of the radius parameter produce a more generalized density raster. Smaller values produce a raster that shows more detail.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- If the area unit scale factor units are small, relative to the distance between the points, the output raster values may be small. To obtain larger values, use the area unit scale factor for larger units (for example, square kilometers versus square meters).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point features | The input point features for which to calculate the density. | Feature Layer |
| Population field | Field denoting population values for each point. The population field is the count or quantity to be used in the calculation of a continuous surface.Values in the population field can be integer or floating point.The options and default behaviors for the field are listed below.Use None if no item or special value will be used and each feature will be counted once.You can use the Shape field if input features contain z-values.Otherwise, the default field is POPULATION. The following conditions may also apply:If there is no POPULATION field, but there is a POPULATIONabcd field, it will be used by default. The 'abcd' can be any valid characters, for example, POPULATION6, POPULATION1974, or POPULATIONROADTYPE.If there is no POPULATION field or POPULATIONabcd field, but there is a POP field, the POP field will be used by default.If there is no POPULATION field, POPULATIONabcd field, or POP field, but there is a POPabcd field, the POPabcd field will be used by default.If there is no POPULATION field, POPULATIONabcd field, POP field, or POPabcd field, NONE will be used by default. | Field |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Neighborhood(Optional) | Dictates the shape of the area around each cell that is used to calculate the density value.Annulus—A torus (donut shaped) neighborhood defined by an inner and outer radius.Circle—A circular neighborhood with the given radius. This is default where the radius is the shortest of the width or height of the extent of the input point features, in the output spatial reference, divided by 30.Rectangle—A rectangular neighborhood with the given height and width.Wedge—A wedge-shaped neighborhood. A wedge is specified by a start angle, an end angle and a radius. The wedge extends counterclockwise from the starting angle to the ending angle. Angles are specified in arithmetic degrees (counterclockwise from the positive x-axis). Negative angles may be used.Cell \| Map—Defines the units of the selected neighborhood measurements in either cells or map units (based on the linear unit of the projection of the output spatial reference). | Neighborhood |
| Area units(Optional) | Specifies the area units that will be used for the output density values.A default unit is determined based on the linear unit of the output spatial reference. You can change this to the appropriate unit to convert the density output. Values for line density convert the units of both length and area.If no output spatial reference is specified, the output spatial reference will be the same as the input feature class. The default output density units are determined by the linear units of the output spatial reference . If the output linear units are meters, the output area density units will be set to Square kilometers, outputting square kilometers for point features or kilometers per square kilometers for polyline features. If the output linear units are feet, the output area density units will be set to Square miles.If the output units are anything other than feet or meters, the output area density units will be set to Square map units. That is, the output density units will be the square of the linear units of the output spatial reference. For example, if the output linear units are centimeters, the output area density units will be Square map units, which will result in square centimeters. If the output linear units are kilometers, the output area density units will be Square map units, which will result in square kilometers.The available options and their corresponding output density units are the following:Square map units—The square of the linear units of the output spatial reference will be used.Square miles—U.S. miles will be used.Square kilometers—Kilometers will be used.Acres—U.S. acres will be used.Hectares—Hectares will be used.Square yards—U.S. yards will be used.Square feet—U.S. feet will be used.Square inches—U.S. inches will be used.Square meters—Meters will be used.Square centimeters—Centimeters will be used.Square millimeters—Millimeters will be used. | String |
| in_point_features | The input point features for which to calculate the density. | Feature Layer |
| population_field | Field denoting population values for each point. The population field is the count or quantity to be used in the calculation of a continuous surface.Values in the population field can be integer or floating point.The options and default behaviors for the field are listed below.Use None if no item or special value will be used and each feature will be counted once.You can use the Shape field if input features contain z-values.Otherwise, the default field is POPULATION. The following conditions may also apply:If there is no POPULATION field, but there is a POPULATIONabcd field, it will be used by default. The 'abcd' can be any valid characters, for example, POPULATION6, POPULATION1974, or POPULATIONROADTYPE.If there is no POPULATION field or POPULATIONabcd field, but there is a POP field, the POP field will be used by default.If there is no POPULATION field, POPULATIONabcd field, or POP field, but there is a POPabcd field, the POPabcd field will be used by default.If there is no POPULATION field, POPULATIONabcd field, POP field, or POPabcd field, NONE will be used by default. | Field |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| neighborhood(Optional) | Dictates the shape of the area around each cell used to calculate the density value.This is a Neighborhood class.There are four types of neighbourhood class: NbrAnnulus, NbrCircle, NbrRectangle, and NbrWedge.The forms and descriptions of the classes are:NbrAnnulus ({innerRadius}, {outerRadius}, {units})A torus (donut shaped) neighborhood defined by an inner radius and an outer radius.NbrCircle ({radius}, {units})A circular neighborhood with the given radius.NbrRectangle ({width}, {height}, {units})A rectangular neighborhood with the given width and height.NbrWedge ({radius}, {startAngle}, {endAngle}, {units})A wedge (pie) shaped neighborhood. A wedge is specified by a start angle, an end angle, and a radius. The wedge extends counterclockwise from the starting angle to the ending angle. Angles are specified in arithmetic degrees (counterclockwise from the positive x-axis). Negative angles may be used.{units}Defines the units as either the number of cells or as value in map units.The default is NbrCircle, where radius is the shortest of the width or height of the output extent in the output spatial reference, divided by 30. | Neighborhood |
| area_unit_scale_factor(Optional) | Specifies the area units that will be used for the output density values.A default unit is determined based on the linear unit of the output spatial reference. You can change this to the appropriate unit to convert the density output. Values for line density convert the units of both length and area.If no output spatial reference is specified, the output spatial reference will be the same as the input feature class. The default output density units are determined by the linear units of the output spatial reference . If the output linear units are meters, the output area density units will be set to Square kilometers, outputting square kilometers for point features or kilometers per square kilometers for polyline features. If the output linear units are feet, the output area density units will be set to Square miles.If the output units are anything other than feet or meters, the output area density units will be set to Square map units. That is, the output density units will be the square of the linear units of the output spatial reference. For example, if the output linear units are centimeters, the output area density units will be Square map units, which will result in square centimeters. If the output linear units are kilometers, the output area density units will be Square map units, which will result in square kilometers.The available options and their corresponding output density units are the following:SQUARE_MAP_UNITS—The square of the linear units of the output spatial reference will be used.SQUARE_MILES—U.S. miles will be used.SQUARE_KILOMETERS—Kilometers will be used.ACRES—U.S. acres will be used.HECTARES—Hectares will be used.SQUARE_YARDS—U.S. yards will be used.SQUARE_FEET—U.S. feet will be used.SQUARE_INCHES—U.S. inches will be used.SQUARE_METERS—Meters will be used.SQUARE_CENTIMETERS—Centimeters will be used.SQUARE_MILLIMETERS—Millimeters will be used. | String |

## Code Samples

### Example 1

```python
PointDensity(in_point_features, population_field, {cell_size}, {neighborhood}, {area_unit_scale_factor})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
pdensOut = PointDensity("rec_sites.shp", "NONE", 60, NbrCircle(2500, "MAP"))
pdensOut.save("C:/sapyexamples/output/pointdensity")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
pdensOut = PointDensity("rec_sites.shp", "NONE", 60, NbrCircle(2500, "MAP"))
pdensOut.save("C:/sapyexamples/output/pointdensity")
```

### Example 4

```python
# Name: PointDensity_Ex_02.py
# Description: Calculates a magnitude per unit area from point 
#    features that fall within a neighborhood around each cell.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFeatures = "rec_sites.shp"
populationField = "NONE"
cellSize = 60

# Create the Neighborhood Object
radius = 2500
myNbrCirc = NbrCircle(radius, "MAP")

# Execute PointDensity
outPdens = PointDensity(inFeatures, populationField, cellSize, 
                        myNbrCirc, "SQUARE_KILOMETERS")

# Save the output 
outPdens.save("C:/sapyexamples/output/outpdens")
```

### Example 5

```python
# Name: PointDensity_Ex_02.py
# Description: Calculates a magnitude per unit area from point 
#    features that fall within a neighborhood around each cell.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFeatures = "rec_sites.shp"
populationField = "NONE"
cellSize = 60

# Create the Neighborhood Object
radius = 2500
myNbrCirc = NbrCircle(radius, "MAP")

# Execute PointDensity
outPdens = PointDensity(inFeatures, populationField, cellSize, 
                        myNbrCirc, "SQUARE_KILOMETERS")

# Save the output 
outPdens.save("C:/sapyexamples/output/outpdens")
```

---

## Point Statistics (Spatial Analyst)

## Summary

Calculates a statistic on the points in a neighborhood around each output cell.

## Usage

- There are several neighborhood shapes and statistic types to choose from. The selection of available statistics depends on the type of the specified field.
- For integer fields, the valid choices for Statistics type are: majority, maximum, mean, median, minimum, minority, range, standard deviation, sum, and variety. For float fields, the valid statistics are: maximum, mean, minimum, range, standard deviation, and sum. Majority, minority, and variety are not available.
- If the field type is integer, the output raster will be integer for the following statistics: majority, maximum, median, minimum, minority, range, sum, and variety. The output will be float for the mean and standard deviation statistics.If the field type is float, the output raster will be float for all available statistic types.
- If there are no points in the neighborhood of a raster cell, the Variety statistic assigns it a value of 0. For the other statistics, NoData is assigned.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point features | The input points to use in the neighborhood operation.For each output cell, any input points that fall within the defined neighborhood shape around it are identified. For the selected points, values from the specified attribute are obtained, and a statistic is calculated.The input can be either a point or multipoint feature class. | Feature Layer |
| Field | The field for which the specified statistic will be calculated. It can be any numeric field of the input point features.It can be the Shape field if the input features contain z-values. | Field |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Neighborhood(Optional) | The area around each processing cell within which any input points found will be used in the statistics calculation. There are several predefined neighborhood types to choose from.Once the neighborhood type is selected, other parameters can be set to fully define the shape, size, and units of measure. The default neighborhood is a square rectangle with a width and height of three cells.The following are the forms of the available neighborhood types: Annulus, Inner radius, Outer radius, Units type A ring or donut-shaped neighborhood defined by an inner radius and an outer radius. The minimum value for radius is 1 cell, and the outer radius must be larger than the inner. The maximum inner radius is 2046 cells, and the maximum outer radius is 2047 cells. The default annulus is an inner radius of 1 cell and an outer radius of 3 cells.Circle, Radius, Units type A circular neighborhood with the given radius. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The default radius is 3 cells.Rectangle, Height, Width, Units type A rectangular neighborhood defined by width and height. The minimum value for width or height is 1 cell, and the maximum value is 4096 cells. The default is a square with a width and height of 3 cells.Wedge, Radius, Start angle, End angle, Units typeA wedge-shaped neighborhood defined by a radius, a start angle, and an end angle. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The wedge extends counterclockwise from the starting angle to the ending angle. Angles are specified in degrees, with 0 or 360 representing east. Negative angles can be used. The default wedge is from 0 to 90 degrees, with a radius of 3 cells.The distance units for the parameters can be specified in Cell units or Map units. Cell units is the default. | Neighborhood |
| Statistics type(Optional) | Specifies the statistic type to be calculated.The calculation is performed on the values of the specified field of the points that fall within the specified neighborhood of each output raster cell.The default statistic type is Mean.The available choices for the statistic type are determined by the numeric type of the specified field. If the field is integer, all the statistics types will be available. If the field is floating point, only the maximum, mean, minimum, range, standard deviation, and sum statistics will be available.Mean—The average of the field values in each neighborhood will be calculated.Majority—The most frequently occurring field value in each neighborhood will be identified. In the case of a tie, the lower value is used.Maximum—The largest field value in each neighborhood will be identified.Median—The median field value in each neighborhood will be calculated. In the case of an even number of points in the neighborhood, the result will be the lower of the two middle values.Minimum—The smallest field value in each neighborhood will be identified.Minority—The least frequently occurring field value in each neighborhood will be identified. In the case of a tie, the lower value is used.Range—The range (the difference between the largest and smallest) of the field values in each neighborhood will be calculated.Standard Deviation—The standard deviation of the field values in each neighborhood will be calculated.Sum—The sum of the field values in the neighborhood will be calculated.Variety—The number of unique field values in each neighborhood will be calculated. | String |
| in_point_features | The input points to use in the neighborhood operation.For each output cell, any input points that fall within the defined neighborhood shape around it are identified. For the selected points, values from the specified attribute are obtained, and a statistic is calculated.The input can be either a point or multipoint feature class. | Feature Layer |
| field | The field for which the specified statistic will be calculated. It can be any numeric field of the input point features.It can be the Shape field if the input features contain z-values. | Field |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| neighborhood(Optional) | The area around each processing cell within which any input points found will be used in the statistics calculation. There are several predefined neighborhood types to choose from.Once the neighborhood type is selected, other parameters can be set to fully define the shape, size, and units of measure. The default neighborhood is a square rectangle with a width and height of three cells. The shape of the neighborhoods around each input point are defined by the Neighborhood class. The available neighborhood types are NbrAnnulus, NbrCircle, NbrRectangle, and NbrWedge.The following are the forms of the available neighborhood types:NbrAnnulus({innerRadius}, {outerRadius}, {units})A ring or donut-shaped neighborhood defined by an inner radius and an outer radius. The minimum value for radius is 1 cell, and the outer radius must be larger than the inner. The maximum inner radius is 2046 cells, and the maximum outer radius is 2047 cells. The default annulus is an inner radius of 1 cell and an outer radius of 3 cells.NbrCircle({radius}, {units}A circular neighborhood with the given radius. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The default radius is 3 cells.NbrRectangle({width}, {height}, {units})A rectangular neighborhood defined by width and height. The minimum value for width or height is 1 cell, and the maximum value is 4096 cells. The default is a square with a width and height of 3 cells.NbrWedge({radius}, {startAngle}, {endAngle}, {units})A wedge-shaped neighborhood defined by a radius, a start angle, and an end angle. The minimum value for radius is 1 cell, and the maximum value is 2047 cells. The wedge extends counterclockwise from the starting angle to the ending angle. Angles are specified in degrees, with 0 or 360 representing east. Negative angles can be used. The default wedge is from 0 to 90 degrees, with a radius of 3 cells.The distance units for the parameters can be specified in CELL units or MAP units. Cell units is the default.The default neighborhood type is NbrRectangle with a height and width of three cells. | Neighborhood |
| statistics_type(Optional) | Specifies the statistic type to be calculated.The calculation is performed on the values of the specified field of the points that fall within the specified neighborhood of each output raster cell.MEAN—The average of the field values in each neighborhood will be calculated.MAJORITY—The most frequently occurring field value in each neighborhood will be identified. In the case of a tie, the lower value is used.MAXIMUM—The largest field value in each neighborhood will be identified.MEDIAN—The median field value in each neighborhood will be calculated. In the case of an even number of points in the neighborhood, the result will be the lower of the two middle values.MINIMUM—The smallest field value in each neighborhood will be identified.MINORITY—The least frequently occurring field value in each neighborhood will be identified. In the case of a tie, the lower value is used.RANGE—The range (the difference between the largest and smallest) of the field values in each neighborhood will be calculated.STD—The standard deviation of the field values in each neighborhood will be calculated.SUM—The sum of the field values in the neighborhood will be calculated.VARIETY—The number of unique field values in each neighborhood will be calculated. The default statistic type is MEAN.The available choices for the statistic type are determined by the numeric type of the specified field. If the field is integer, all the statistics types will be available. If the field is floating point, only the maximum, mean, minimum, range, standard deviation, and sum statistics will be available. | String |

## Code Samples

### Example 1

```python
PointStatistics(in_point_features, field, {cell_size}, {neighborhood}, {statistics_type})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPointStats = PointStatistics("ca_ozone_pts.shp", "OZONE", 500, 
                                NbrCircle(10000, "MAP"), "SUM")
outPointStats.save("C:/sapyexamples/output/pointstatsout")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPointStats = PointStatistics("ca_ozone_pts.shp", "OZONE", 500, 
                                NbrCircle(10000, "MAP"), "SUM")
outPointStats.save("C:/sapyexamples/output/pointstatsout")
```

### Example 4

```python
# Name: PointStatistics_Ex_02.py
# Description: Calculates a statistic on points over a specified 
#    neighborhood outputting a raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "ca_ozone_pts.shp"
field = "OZONE"
cellSize = 500
neighborhood = NbrCircle(6000, "MAP")

# Execute PointStatistics
outPointStatistics = PointStatistics(inPointFeatures, field, cellSize,
                                     neighborhood, "MEAN")

# Save the output 
outPointStatistics.save("C:/sapyexamples/output/pointstatout")
```

### Example 5

```python
# Name: PointStatistics_Ex_02.py
# Description: Calculates a statistic on points over a specified 
#    neighborhood outputting a raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "ca_ozone_pts.shp"
field = "OZONE"
cellSize = 500
neighborhood = NbrCircle(6000, "MAP")

# Execute PointStatistics
outPointStatistics = PointStatistics(inPointFeatures, field, cellSize,
                                     neighborhood, "MEAN")

# Save the output 
outPointStatistics.save("C:/sapyexamples/output/pointstatout")
```

---

## Points Solar Radiation (Spatial Analyst)

## Summary

Derives incoming solar radiation for specific locations in a point feature class or location table.

## Usage

- The input locations can be a point feature class or a table of point coordinates. The table can be a geodatabase table, a .dbf file, an INFO table, or a text table file. The values can be of type long integer, float, or double.
- When inputting locations by table, a list of locations must be specified with an x,y coordinate. Using an ASCII coordinate file, each line should contain an x,y pair separated by a comma, space, or tab. The following is a space-delimited example:X Y 325541.218750 4314768.5 325169.250000 4313907.0 325874.031250 4313134.0 325825.093750 4314181.5Alternatively, you can specify slope (degrees) and aspect in the location table. Along with the x,y coordinate, the file should contain the slope and aspect value for each location, in either order. The following is a comma-delimited example:x, y, slope, aspect 325541.218750, 4314768.5, 15.84516716, 310.2363586 325169.250000, 4313907.0, 39.39801788, 2.03503442 325874.031250, 4313134.0, 16.10847282, 223.8308563 325825.093750, 4314181.5, 8.89850712, 205.2011261
- For multiday time configurations, the maximum range of days is a total of one year (365 days, or 366 days for leap years). If the start day is greater than the end day, the time calculations will proceed into the following year.For example, [start day, end day] = [365, 31] represents December 31 to January 31 of the following year. For the example of [1, 2], the time is inclusive for the first day from 0:00 hours (January 1) to 0:00 (January 2). The start day and end day cannot be equal.
- The year value for time configuration is used to determine a leap year. It does not have any other influence on the solar radiation analysis, as the calculations are a function of the time period determined by Julian days.
- For within-day time configurations, the maximum range of time is one day (24 hours). Calculations will not be performed across days (for example, from 12:00 p.m. to 12:00 p.m. the next day). The start time must be less than the end time.
- The use of a z-factor is essential for correcting calculations when the surface z-units are expressed in units different from the ground x,y units. For accurate results, the z-units should be the same as the x,y ground units. If the units are not the same, use a z-factor to convert z-units to x,y units. For example, if the x,y units are meters and the z-units are feet, you can specify a z-factor of 0.3048 to convert feet to meters.
- It is recommended that you have the data in a projected coordinate system with units of meters. If you run the analysis with a spherical coordinate system, you must specify an appropriate z-factor for that latitude. The following is a list of appropriate z-factors to use if the x,y units are decimal degrees and the z-units are meters: Latitude Z-factor 0 0.00000898 10 0.00000912 20 0.00000956 30 0.00001036 40 0.00001171 50 0.00001395 60 0.00001792 70 0.00002619 80 0.00005156
- The height offset must be specified in meters.
- The latitude for the site area (units: decimal degree, positive for the northern hemisphere and negative for the southern hemisphere) is used in calculations such as solar declination and solar position. Because the solar analysis is designed for landscape scales and local scales, it is acceptable to use one latitude value for the whole DEM. For broader geographic regions, you must divide the study area into zones with different latitudes.
- For input surface rasters containing a spatial reference, the mean latitude is automatically calculated; otherwise, the latitude default is 45 degrees. When using an input layer, the spatial reference of the data frame is used.
- Sky size is the resolution of the viewshed, sky map, and sun map rasters that are used in the radiation calculations (units: cells per side). These are upward-looking, hemispherical raster representations of the sky and do not have a geographic coordinate system. These rasters are square (equal number of rows and columns).The following are recommended sky size values when a time configuration of a whole year or multiple days is used:For a 1 day interval, use a sky size of 1000 and above.For a 0.25 day interval, use a sky size of 2000 and above.For a 0.1 hour interval, use a sky size of 4000 and above.Increasing the sky size increases calculation accuracy but also increases calculation time considerably.
- For a 1 day interval, use a sky size of 1000 and above.
- For a 0.25 day interval, use a sky size of 2000 and above.
- For a 0.1 hour interval, use a sky size of 4000 and above.
- When the day interval setting is small (for example, < 14 days), use a larger sky size. During analysis, the sun map (determined by the sky size) is used to represent sun positions (tracks) for particular time periods to calculate direct radiation. With smaller day intervals, if the sky size resolution is not large enough, sun tracks may overlap, resulting in zero or lower radiation values for that track. Increasing the resolution provides a more accurate result.
- The maximum sky size value is 10,000. A value of 200 is the default and is sufficient for whole DEMs with large day intervals (for example, > 14 days). A sky size value of 512 is sufficient for calculations at point locations where calculation time is less of an issue. At smaller day intervals (for example, < 14 days), it is recommended that you use higher values. For example, to calculate insolation for a location at the equator with day interval = 1, use a sky size of 2,800 or above.
- Day intervals greater than 3 are recommended, as sun tracks within three days typically overlap, depending on sky size and time of year. For calculations of the whole year with monthly interval, day interval is disabled and the program uses calendar month intervals. The default value is 14.
- Because the viewshed calculation can be highly intensive, horizon angles are only traced for the number of calculation directions specified. Valid values must be multiples of 8 (8, 16, 24, 32, and so on). Typically, a value of 8 or 16 is adequate for areas with gentle topography, and a value of 32 is adequate for complex topography. The default value is 32.
- The number of calculation directions needed is related to the resolution of the input DEM. Natural terrain at 30-meters resolution is usually quite smooth, so fewer directions are sufficient for most situations (16 or 32). With finer DEMs, and particularly with human-made structures incorporated in the DEMs, the number of directions needs to increase. Increasing the number of directions increases accuracy but also increase calculation time.
- The Create outputs for each interval parameter allows for the flexibility to calculate insolation integrated over a specified time period or insolation for each interval in a time series. For example, for the within-day time period with an hour interval of one, checking this parameter will create hourly insolation values; otherwise, insolation integrated for the entire day will be calculated.
- The Create outputs for each interval parameter affects the number of attributes for output features. When checked for point radiation analysis, the output feature class includes additional attributes (t0, t1, t2, and so on), which indicate radiation or duration values for each time interval (hour interval when time configuration is less than one day, or day interval when multiple days). If, for example, start time = 0, then t0 will be sun rise and t1 will be at the next time increment after sun rise.
- The amount of solar radiation received by the surface is only a portion of what would be received outside the atmosphere. Transmittivity is a property of the atmosphere that is expressed as the ratio of the energy (averaged overall wavelengths) reaching the earth's surface to that which is received at the upper limit of the atmosphere (extraterrestrial). Values range from 0 (no transmission) to 1 (complete transmission). Typically observed values are 0.6 or 0.7 for very clear sky conditions and 0.5 for a generally clear sky.The value for the energy received at the earth's surface is at the shortest path through the atmosphere (that is, the sun is at the zenith, or directly overhead) and for sea level. For areas beyond Tropic of Capricorn and Tropic of Cancer, the sun can never be at the exact zenith, even at noon; however, this value still refers to the moment when the sun is at the zenith. Because the algorithm corrects for elevation effects, transmittivity should always be given for sea level.Transmittivity has an inverse relation with the diffuse proportion parameter.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input elevation surface raster. | Raster Layer |
| Input points feature or table | The input point feature class or table containing the locations where solar radiation will be analyzed. | Feature Layer; Table View |
| Output global radiation features | The output feature class representing the global radiation or amount of incoming solar insolation (direct + diffuse) calculated for each location.The output has units of watt hours per square meter (WH/m2). | Feature Class |
| Height offset(Optional) | The height (in meters) above the DEM surface for which calculations will be performed.The height offset will be applied to all input locations. | Double |
| Latitude(Optional) | The latitude for the site area. The units are decimal degrees with positive values for the northern hemisphere and negative values for the southern hemisphere.For input surface rasters containing a spatial reference, the mean latitude is automatically calculated; otherwise, the latitude default is 45 degrees. | Double |
| Sky size / Resolution(Optional) | The resolution or sky size for the viewshed, sky map, and sun map rasters. The units are cells.The default is a raster of 200 by 200 cells. | Long |
| Time configuration(Optional) | Specifies the time period that will be used for the calculations.Special days—Solar insolation will be calculated for the solstice days (summer and winter) and the equinox days (when the insolation for both spring and fall equinox are the same).Within day—Calculations will be performed for a specified time period within a single day. Select the Julian day and provide the start and end times. When the start time and the end time are the same, instantaneous insolation will be calculated. When the start time is before sunrise and the end time is after sunset, insolation will be calculated for the whole day.To enter the correct day, use the calendar button to open the Calendar dialog box. Multiple days—Calculations will be performed for a specific multiple-day period within a year.Specify the start year, start day, and end day. When the end day is smaller than the start day, the end day is considered to be in the following year. The default time configuration starts on day 5 and ends on day 160 of the current Julian year.To enter the correct days, use the calendar button to open the Calendar dialog box.Whole year—Calculations will be performed for an entire year using monthly intervals for calculations.If the Create outputs for each interval parameter is checked, output files will be created for each month; otherwise, a single output will be created for the whole year. | Time configuration |
| Day interval(Optional) | The time interval through the year (units: days) that will be used to calculate sky sectors for the sun map.The default value is 14 (biweekly). | Long |
| Hour interval(Optional) | The time interval through the day (units: hours) that will be used to calculate sky sectors for the sun map.The default value is 0.5. | Double |
| Create outputs for each interval(Optional) | Specifies whether a single total insolation value will be calculated for all locations or multiple values will be calculated for the specified hour and day interval.Unchecked—A single total radiation value will be calculated for the entire time configuration. This is the default.Checked—Multiple radiation values will be calculated for each time interval over the entire time configuration. The number of outputs depends on the hour or day interval. For example, for a whole year with monthly intervals, the result will contain 12 output radiation values for each location. | Boolean |
| Z factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect.For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| Slope and aspect input type(Optional) | Specifies how slope and aspect information will be derived for analysis.From the input surface raster—The slope and aspect rasters will be calculated from the input surface raster. This is the default.From a flat surface—Constant values of zero will be used for slope and aspect.From the input points table—The slope and aspect values will be specified along with the x,y coordinates in the locations file. | String |
| Calculation directions(Optional) | The number of azimuth directions that will be used when calculating the viewshed.Valid values must be multiples of 8 (8, 16, 24, 32, and so on). The default value is 32 directions, which is adequate for complex topography. | Long |
| Zenith divisions(Optional) | The number of zenith divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to zenith). Values must be greater than zero and less than half the sky size value. | Long |
| Azimuth divisions(Optional) | The number of azimuth divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to north). Valid values must be multiples of 8. Values must be greater than zero and less than 160. | Long |
| Diffuse model type(Optional) | Specifies the type of diffuse radiation model that will be used.Uniform sky—The uniform diffuse model will be used. The incoming diffuse radiation is the same from all sky directions. This is the default.Standard overcast sky—The standard overcast diffuse model will be used. The incoming diffuse radiation flux varies with the zenith angle. | String |
| Diffuse proportion(Optional) | The proportion of global normal radiation flux that is diffuse. Values range from 0 to 1.Set this value according to atmospheric conditions. The default value is 0.3 for generally clear sky conditions. | Double |
| Transmittivity(Optional) | The fraction of radiation that passes through the atmosphere (averaged overall wavelengths). Values range from 0 (no transmission) to 1 (all transmission).The default is 0.5 for a generally clear sky. | Double |
| Output direct radiation features(Optional) | The output feature class representing the direct incoming solar radiation for each location.The output has units of watt hours per square meter (WH/m2). | Feature Class |
| Output diffuse radiation features(Optional) | The output feature class representing the incoming solar radiation for each location that is diffuse.The output has units of watt hours per square meter (WH/m2). | Feature Class |
| Output direct duration features(Optional) | The output feature class representing the duration of direct incoming solar radiation.The output has units of hours. | Feature Class |
| in_surface_raster | The input elevation surface raster. | Raster Layer |
| in_points_feature_or_table | The input point feature class or table containing the locations where solar radiation will be analyzed. | Feature Layer; Table View |
| out_global_radiation_features | The output feature class representing the global radiation or amount of incoming solar insolation (direct + diffuse) calculated for each location.The output has units of watt hours per square meter (WH/m2). | Feature Class |
| height_offset(Optional) | The height (in meters) above the DEM surface for which calculations will be performed.The height offset will be applied to all input locations. | Double |
| latitude(Optional) | The latitude for the site area. The units are decimal degrees with positive values for the northern hemisphere and negative values for the southern hemisphere.For input surface rasters containing a spatial reference, the mean latitude is automatically calculated; otherwise, the latitude default is 45 degrees. | Double |
| sky_size(Optional) | The resolution or sky size for the viewshed, sky map, and sun map rasters. The units are cells.The default is a raster of 200 by 200 cells. | Long |
| time_configuration(Optional) | Specifies the time configuration (period) that will be used for calculating solar radiation.The Time class objects will be used to specify the time configuration.The different types of time configurations available are TimeWithinDay, TimeMultipleDays, TimeSpecialDays, and TimeWholeYear.The following are the forms:TimeWithinDay({day},{startTime},{endTime})TimeMultipleDays({year},{startDay},{endDay})TimeSpecialDays()TimeWholeYear({year})The default time configuration is TimeMultipleDays with the startDay value of 5 and the endDay value of 160 for the current Julian year. | Time configuration |
| day_interval(Optional) | The time interval through the year (units: days) that will be used to calculate sky sectors for the sun map.The default value is 14 (biweekly). | Long |
| hour_interval(Optional) | The time interval through the day (units: hours) that will be used to calculate sky sectors for the sun map.The default value is 0.5. | Double |
| each_interval(Optional) | Specifies whether a single total insolation value will be calculated for all locations or multiple values will be calculated for the specified hour and day interval.NOINTERVAL—A single total radiation value will be calculated for the entire time configuration. This is the default.INTERVAL—Multiple radiation values will be calculated for each time interval over the entire time configuration. The number of outputs depends on the hour or day interval. For example, for a whole year with monthly intervals, the result will contain 12 output radiation values for each location. | Boolean |
| z_factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect.For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| slope_aspect_input_type(Optional) | Specifies how slope and aspect information will be derived for analysis.FROM_DEM—The slope and aspect rasters will be calculated from the input surface raster. This is the default.FLAT_SURFACE—Constant values of zero will be used for slope and aspect.FROM_POINTS_TABLE—The slope and aspect values will be specified along with the x,y coordinates in the locations file. | String |
| calculation_directions(Optional) | The number of azimuth directions that will be used when calculating the viewshed.Valid values must be multiples of 8 (8, 16, 24, 32, and so on). The default value is 32 directions, which is adequate for complex topography. | Long |
| zenith_divisions(Optional) | The number of zenith divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to zenith). Values must be greater than zero and less than half the sky size value. | Long |
| azimuth_divisions(Optional) | The number of azimuth divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to north). Valid values must be multiples of 8. Values must be greater than zero and less than 160. | Long |
| diffuse_model_type(Optional) | Specifies the type of diffuse radiation model that will be used.UNIFORM_SKY—The uniform diffuse model will be used. The incoming diffuse radiation is the same from all sky directions. This is the default.STANDARD_OVERCAST_SKY—The standard overcast diffuse model will be used. The incoming diffuse radiation flux varies with the zenith angle. | String |
| diffuse_proportion(Optional) | The proportion of global normal radiation flux that is diffuse. Values range from 0 to 1.Set this value according to atmospheric conditions. The default value is 0.3 for generally clear sky conditions. | Double |
| transmittivity(Optional) | The fraction of radiation that passes through the atmosphere (averaged overall wavelengths). Values range from 0 (no transmission) to 1 (all transmission).The default is 0.5 for a generally clear sky. | Double |
| out_direct_radiation_features(Optional) | The output feature class representing the direct incoming solar radiation for each location.The output has units of watt hours per square meter (WH/m2). | Feature Class |
| out_diffuse_radiation_features(Optional) | The output feature class representing the incoming solar radiation for each location that is diffuse.The output has units of watt hours per square meter (WH/m2). | Feature Class |
| out_direct_duration_features(Optional) | The output feature class representing the duration of direct incoming solar radiation.The output has units of hours. | Feature Class |

## Code Samples

### Example 1

```python
X Y
325541.218750 4314768.5
325169.250000 4313907.0
325874.031250 4313134.0
325825.093750 4314181.5
```

### Example 2

```python
x, y, slope, aspect
325541.218750, 4314768.5, 15.84516716, 310.2363586
325169.250000, 4313907.0, 39.39801788,   2.03503442
325874.031250, 4313134.0, 16.10847282, 223.8308563
325825.093750, 4314181.5,  8.89850712, 205.2011261
```

### Example 3

```python
Latitude     Z-factor
       0         0.00000898
      10         0.00000912
      20         0.00000956
      30         0.00001036
      40         0.00001171
      50         0.00001395
      60         0.00001792
      70         0.00002619
      80         0.00005156
```

### Example 4

```python
PointsSolarRadiation(in_surface_raster, in_points_feature_or_table, out_global_radiation_features, {height_offset}, {latitude}, {sky_size}, {time_configuration}, {day_interval}, {hour_interval}, {each_interval}, {z_factor}, {slope_aspect_input_type}, {calculation_directions}, {zenith_divisions}, {azimuth_divisions}, {diffuse_model_type}, {diffuse_proportion}, {transmittivity}, {out_direct_radiation_features}, {out_diffuse_radiation_features}, {out_direct_duration_features})
```

### Example 5

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
PointsSolarRadiation("elevation", "observers.shp", 
                     "c:/sapyexamples/output/outglobalrad1.shp", "", 35, 200, 
                     TimeMultipleDays(2009, 91, 212), 14, 0.5,"NOINTERVAL", 
                     1, "FROM_DEM", 32, 8, 8,"STANDARD_OVERCAST_SKY", 0.3, 0.5, 
                     "c:/sapyexamples/output/outdirectrad1.shp", 
                     "c:/sapyexamples/output/outdiffuserad1.shp", 
                     "c:/sapyexamples/output/outduration1.shp")
```

### Example 6

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
PointsSolarRadiation("elevation", "observers.shp", 
                     "c:/sapyexamples/output/outglobalrad1.shp", "", 35, 200, 
                     TimeMultipleDays(2009, 91, 212), 14, 0.5,"NOINTERVAL", 
                     1, "FROM_DEM", 32, 8, 8,"STANDARD_OVERCAST_SKY", 0.3, 0.5, 
                     "c:/sapyexamples/output/outdirectrad1.shp", 
                     "c:/sapyexamples/output/outdiffuserad1.shp", 
                     "c:/sapyexamples/output/outduration1.shp")
```

### Example 7

```python
# PointsSolarRadiation_Example02.py
# Description: For all point locations, calculates total global, direct,
#    diffuse and direct duration solar radiation for a whole year.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inPntFC = "observers.shp"
outFeatures = "c:/sapyexamples/output/outglobal1.shp"
latitude = 35.75
skySize = 200
timeConfig = TimeMultipleDays(2009, 91, 212)
dayInterval = 14
hourInterval = 0.5
zFactor = 0.3048
calcDirections = 32
zenithDivisions = 8
azimuthDivisions = 8
diffuseProp = 0.3
transmittivity = 0.5
outDirectRad = "C:/sapyexamples/output/outdirectrad1.shp"
outDiffuseRad = "C:/sapyexamples/output/outdiffuserad1.shp"
outDirectDur = "C:/sapyexamples/output/outduration1.shp"

# Execute PointsSolarRadiation...
PointsSolarRadiation(inRaster, inPntFC, outFeatures, "", latitude, skySize, 
                     timeConfig, dayInterval, hourInterval, "INTERVAL", 
                     zFactor, "FROM_DEM", calcDirections, zenithDivisions, 
                     azimuthDivisions,"STANDARD_OVERCAST_SKY", diffuseProp, 
                     transmittivity, outDirectRad, outDiffuseRad, outDirectDur)
```

### Example 8

```python
# PointsSolarRadiation_Example02.py
# Description: For all point locations, calculates total global, direct,
#    diffuse and direct duration solar radiation for a whole year.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inPntFC = "observers.shp"
outFeatures = "c:/sapyexamples/output/outglobal1.shp"
latitude = 35.75
skySize = 200
timeConfig = TimeMultipleDays(2009, 91, 212)
dayInterval = 14
hourInterval = 0.5
zFactor = 0.3048
calcDirections = 32
zenithDivisions = 8
azimuthDivisions = 8
diffuseProp = 0.3
transmittivity = 0.5
outDirectRad = "C:/sapyexamples/output/outdirectrad1.shp"
outDiffuseRad = "C:/sapyexamples/output/outdiffuserad1.shp"
outDirectDur = "C:/sapyexamples/output/outduration1.shp"

# Execute PointsSolarRadiation...
PointsSolarRadiation(inRaster, inPntFC, outFeatures, "", latitude, skySize, 
                     timeConfig, dayInterval, hourInterval, "INTERVAL", 
                     zFactor, "FROM_DEM", calcDirections, zenithDivisions, 
                     azimuthDivisions,"STANDARD_OVERCAST_SKY", diffuseProp, 
                     transmittivity, outDirectRad, outDiffuseRad, outDirectDur)
```

---

## Popularity (Spatial Analyst)

## Summary

Determines the value in an argument list that is at a certain level of popularity on a cell-by-cell basis. The particular level of popularity (the number of occurrences of each value) is specified by the first argument.

## Usage

- The tool evaluates the number of occurrences of the input raster values for each location and ranks them on an ordinal scale—that is, the most popular, second most popular, and so on. It will return the value of the specified nth most popular value defined by the popularity raster value.
- In the list of input rasters, the order is irrelevant. However, the raster that defines the popularity position must precede these.
- An arbitrary number of rasters can be specified in the input rasters list.
- If the input values are the same for any cell location, regardless of the specified popularity, the output value will be the same as the input for that cell location.
- If a cell location contains NoData on any of the input rasters, that location will be assigned NoData on the output.
- If there is no single value found to be the nth most popular, NoData will be assigned to the location on the output raster. This situation occurs when all input raster values at a location are different or when two or more input raster values have the same number of occurrences and that number is the nth most popular. Returning one of the input raster values, such as the first one encountered in the scan process, would be deceptive. You would not know whether the value is truly the nth most popular value.
- If the popularity value is greater than the number of input rasters, each cell location in the output will be assigned NoData.
- If 0 is specified as the popularity value, the output value will be NoData.
- A popularity level of 1 is the majority value, similar to the Majority option of the Cell Statistics tool.
- If any of the input rasters are floating point, the output is floating point; otherwise, it is integer.
- If the Process as multiband parameter is unchecked (process_as_multiband is set to SINGLE_BAND in Python), only the first band of a multiband Input popularity raster or constant value (in_popularity_raster_or_constant in Python) will be used. Each band from a multiband Input rasters (in_rasters in Python) will be processed separately as a single-band raster.
- If the Process as multiband parameter is checked (process_as_multiband is set to MULTI_BAND in Python), each multiband raster input will be processed as a multiband raster.The number of bands in the output depends on the Input popularity raster or constant value. If the popularity raster is a single band, the number of bands on the output raster will be the same as the maximum number of bands of all multiband rasters from the input rasters. If the popularity raster is a multiband, the output raster will have the same number of bands as the popularity raster.If any of the Input rasters is a raster with a smaller number of bands than the output raster, the missing bands will be interpreted as a band filled with NoData. If the cell value of the popularity raster picks value one from the missing band, the output raster will receive NoData. If any of the input rasters is a constant, it will be interpreted as a multiband raster in which the cell values of all bands are the same as the constant and have the same number of bands as the output raster.
- If all inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process, otherwise an error will occur.If all of the inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before performing the operation.If one or more of the inputs are multidimensional rasters and the other inputs are constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input popularity raster or constant value | The input raster that defines the popularity position to be returned.A number can be used as an input; however, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input rasters | The list of input rasters used to evaluate the popularity of the values for each cell location. | Raster Layer |
| Process as multiband (Optional) | Specifies how the input multiband raster bands will be processed.Unchecked—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.Checked—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |
| in_popularity_raster_or_constant | The input raster that defines the popularity position to be returned.A number can be used as an input; however, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_rasters[in_raster,...] | The list of input rasters used to evaluate the popularity of the values for each cell location. | Raster Layer |
| process_as_multiband(Optional) | Specifies how the input multiband raster bands will be processed.SINGLE_BAND—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.MULTI_BAND—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |

## Code Samples

### Example 1

```python
Popularity(in_popularity_raster_or_constant, in_rasters, {process_as_multiband})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPopularity = Popularity("cost", ["degs", "negs", "fourgrd"])
outPopularity.save("C:/sapyexamples/output/outpop.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPopularity = Popularity("cost", ["degs", "negs", "fourgrd"])
outPopularity.save("C:/sapyexamples/output/outpop.img")
```

### Example 4

```python
# Name: Popularity_Ex_02.py
# Description: Determines the value in an argument list that is
#              at a certain level of popularity 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPopularityRaster = "cost"
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute Popularity
outPopularity = Popularity(inPopularityRaster, [inRaster01, inRaster02, inRaster03])

# Save the output 
outPopularity.save("C:/sapyexamples/output/outpop")
```

### Example 5

```python
# Name: Popularity_Ex_02.py
# Description: Determines the value in an argument list that is
#              at a certain level of popularity 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPopularityRaster = "cost"
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute Popularity
outPopularity = Popularity(inPopularityRaster, [inRaster01, inRaster02, inRaster03])

# Save the output 
outPopularity.save("C:/sapyexamples/output/outpop")
```

---

## Porous Puff (Spatial Analyst)

## Summary

Calculates the time-dependent, two-dimensional concentration distribution in mass per volume of a solute introduced instantaneously and at a discrete point into a vertically mixed aquifer.

## Usage

- The effective porosity field, a physical property of the aquifer, is generally estimated from geological data. It is defined as the volume of void space that contributes to fluid flow divided by the entire volume. Porosity is expressed as a number between 0.0 and 1.0, with typical values around 0.35, and is dimensionless. A value of effective porosity of 0.35 means that 35 percent of the volume of the porous medium contributes to fluid flow. The remaining 65 percent, consisting of solid matrix and unconnected pores, does not contribute to fluid flow.
- No particular system of units is specified by this tool. It is important that all data be consistent, using the same unit for time (seconds, days, years), length (feet, meters), and mass (kilograms, slugs).
- The saturated thickness, measured in units of length, is interpreted from geological information. For a confined aquifer, this measure is the thickness of the formation between the upper and lower confining layers. For an unconfined aquifer, the saturated thickness is the distance between the water table and the lower confining layer.
- The decay coefficient λ is related to the half-life T1/2 as:For example, the half-life of Carbon-14 is 5,730 years. Since ln(2) = 0.693, the decay coefficient becomes 0.693/5730 = 1.21x10-4 / year. A stable constituent has a decay coefficient of zero, corresponding to an infinite half-life. Half-lives of radioisotopes are available from several sources, including the CRC Handbook of Chemistry and Physics from CRC Press.
- The requested time must not exceed the latest time recorded in the path file. Either a lesser time must be requested in Porous Puff, or a new path file with a greater time needs to be generated by Particle Track.
- The time requested should not be reached before the completion of the first path step as recorded in the track file. Either a greater time should be requested in Porous Puff, or a new track file should be generated by Particle Track using a shorter step length.
- The centroid of mass must not migrate to the edge of the raster or beyond. In this case, no data is available on which to base the dispersion, so the tool is aborted. Either a lesser time must be requested, or a larger raster must be generated to accommodate the migration.
- The output raster is floating point.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input particle track file | The input particle track path file.This is an ASCII text file containing information about the position, the local velocity vector, and the cumulative length and time of travel along the path.This file is generated using the Particle Track tool. | File |
| Input effective formation porosity raster | The input raster where each cell value represents the effective formation porosity at that location. | Raster Layer |
| Input saturated thickness raster | The input raster where each cell value represents the saturated thickness at that location.The value for the thickness is interpreted from geological properties of the aquifer. | Raster Layer |
| Mass | A value for the amount of mass released instantaneously at the source point, in units of mass. | Double |
| Dispersion time(Optional) | A value representing the time horizon for dispersion of the solute, in units of time.The time must be less than or equal to the maximum time in the track file. If the requested time exceeds the available time from the track file, the tool is aborted. The default time is the latest time (corresponding to the terminal point) in the track file. | Double |
| Longitudinal dispersivity(Optional) | A value representing the dispersivity parallel to the flow direction.For details on how the default value is determined, and how it relates to the scale of the study, see the How Porous Puff works section in the documentation. | Double |
| Dispersivity ratio(Optional) | A value representing the ratio of longitudinal dispersivity over transverse dispersivity.Transverse dispersivity is perpendicular to the flow direction in the same horizontal plane. The default value is three. | Double |
| Retardation factor(Optional) | A dimensionless value representing the retardation of the solute in the aquifer.Retardation varies between one and infinity, with one corresponding to no retardation. The default value is one. | Double |
| Decay coefficient(Optional) | Decay coefficient for solutes undergoing first-order exponential decay (for example, radionuclides) in units of inverse time.The default is zero, corresponding to no decay. | Double |
| in_track_file | The input particle track path file.This is an ASCII text file containing information about the position, the local velocity vector, and the cumulative length and time of travel along the path.This file is generated using the Particle Track tool. | File |
| in_porosity_raster | The input raster where each cell value represents the effective formation porosity at that location. | Raster Layer |
| in_thickness_raster | The input raster where each cell value represents the saturated thickness at that location.The value for the thickness is interpreted from geological properties of the aquifer. | Raster Layer |
| mass | A value for the amount of mass released instantaneously at the source point, in units of mass. | Double |
| dispersion_time(Optional) | A value representing the time horizon for dispersion of the solute, in units of time.The time must be less than or equal to the maximum time in the track file. If the requested time exceeds the available time from the track file, the tool is aborted. The default time is the latest time (corresponding to the terminal point) in the track file. | Double |
| longitudinal_dispersivity(Optional) | A value representing the dispersivity parallel to the flow direction.For details on how the default value is determined, and how it relates to the scale of the study, see the How Porous Puff works section in the documentation. | Double |
| dispersivity_ratio(Optional) | A value representing the ratio of longitudinal dispersivity over transverse dispersivity.Transverse dispersivity is perpendicular to the flow direction in the same horizontal plane. The default value is three. | Double |
| retardation_factor(Optional) | A dimensionless value representing the retardation of the solute in the aquifer.Retardation varies between one and infinity, with one corresponding to no retardation. The default value is one. | Double |
| decay_coefficient(Optional) | Decay coefficient for solutes undergoing first-order exponential decay (for example, radionuclides) in units of inverse time.The default is zero, corresponding to no decay. | Double |

## Code Samples

### Example 1

```python
PorousPuff(in_track_file, in_porosity_raster, in_thickness_raster, mass, {dispersion_time}, {longitudinal_dispersivity}, {dispersivity_ratio}, {retardation_factor}, {decay_coefficient})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPorousPuff = PorousPuff("trackfile.txt", "gwporo", "gwthick", 50, 10000, "", 3,
                         "", "")
outPorousPuff.save("c:/sapyexamples/output/outporpuff")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPorousPuff = PorousPuff("trackfile.txt", "gwporo", "gwthick", 50, 10000, "", 3,
                         "", "")
outPorousPuff.save("c:/sapyexamples/output/outporpuff")
```

### Example 4

```python
# Name: PorousPuff_Ex_02.py
# Description: Calculates the time-dependent, two-dimensional 
#              concentration distribution in mass per volume of a 
#              solute introduced instantaneously and at a discrete 
#              point into a vertically mixed aquifer.

# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inTrackFile = "trackfile.txt"
inPorosityRaster = "gwporo"
inThicknessRaster = "gwthick"
mass = 50
dispersionTime = 10000
longitudinalDispersivity = ""
dispersivityRatio = 3 
retardationFactor = "" 
decayCoefficient = 0


# Execute PorousPuff
outPorousPuff = PorousPuff(inTrackFile, inPorosityRaster, inThicknessRaster, 
                        mass, dispersionTime, longitudinalDispersivity,
                        dispersivityRatio, retardationFactor, 
                        decayCoefficient)

# Save the output 
outPorousPuff.save("c:/sapyexamples/output/outporpuff")
```

### Example 5

```python
# Name: PorousPuff_Ex_02.py
# Description: Calculates the time-dependent, two-dimensional 
#              concentration distribution in mass per volume of a 
#              solute introduced instantaneously and at a discrete 
#              point into a vertically mixed aquifer.

# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inTrackFile = "trackfile.txt"
inPorosityRaster = "gwporo"
inThicknessRaster = "gwthick"
mass = 50
dispersionTime = 10000
longitudinalDispersivity = ""
dispersivityRatio = 3 
retardationFactor = "" 
decayCoefficient = 0


# Execute PorousPuff
outPorousPuff = PorousPuff(inTrackFile, inPorosityRaster, inThicknessRaster, 
                        mass, dispersionTime, longitudinalDispersivity,
                        dispersivityRatio, retardationFactor, 
                        decayCoefficient)

# Save the output 
outPorousPuff.save("c:/sapyexamples/output/outporpuff")
```

---

## Power (Spatial Analyst)

## Summary

Raises the cell values in a raster to the power of the values found in another raster.

## Usage

- The output raster from this tool is always floating-point type, regardless of the input value type.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "**" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input values to be raised to the power defined by the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input that determines the power the values in the first input will be raised to.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input values to be raised to the power defined by the second input.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input that determines the power the values in the first input will be raised to.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Power(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPower = Power("degs", "cost")
outPower.save("C:/sapyexamples/output/outpower.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPower = Power("degs", "cost")
outPower.save("C:/sapyexamples/output/outpower.img")
```

### Example 4

```python
# Name: Power_Ex_02.py
# Description: Raises the cells in a raster to the power of the values
#              found in another raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "cost"

# Execute Power
outPower = Power(inRaster1, inRaster2)

# Save the output 
outPower.save("C:/sapyexamples/output/outpower.img")
```

### Example 5

```python
# Name: Power_Ex_02.py
# Description: Raises the cells in a raster to the power of the values
#              found in another raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "degs"
inRaster2 = "cost"

# Execute Power
outPower = Power(inRaster1, inRaster2)

# Save the output 
outPower.save("C:/sapyexamples/output/outpower.img")
```

---

## Principal Components (Spatial Analyst)

## Summary

Performs Principal Component Analysis (PCA) on a set of raster bands and generates a single multiband raster as output.

## Usage

- The value specified for the number of principal components determines the number of principal component bands in the output multiband raster. The number must not be larger than the total number of raster bands in the input.
- When a multiband raster is specified as one of the Input raster bands (in_raster_bands in Python), all the bands will be used.To process a selection of bands from a multiband raster, you can first create a new raster dataset composed of those particular bands with the Composite Bands tool, and use the result in the list of the Input raster bands (in_raster_bands in Python).
- The raster bands must have a common intersection. If there are none, an error occurs and no output is created.
- The percent variance identifies the amount of the variance each eigenvalue captures. This can be useful to help interpret the results of PCA. If a few eigenvalues (each corresponding to bands in the output raster) capture the majority of the variance, it may be adequate to use this subset of bands in a subsequent analysis, since they may capture the majority of the interactions within the original multiband dataset.
- When determining the percent variance each eigenvalue captures, the sum of eigenvalues is entered into the following formula: (eigenvalue * 100)/Sum. The first eigenvalue (and its associated band) captures the greatest variance, and the subsequent eigenvalues capture sequentially lesser variance. The accumulative percent of variance is a sequential sum of the variance each eigenvalue captures.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster bands | The input raster bands.They can be integer or floating point type. | Raster Layer |
| Number of Principal components(Optional) | Number of principal components.The number must be greater than zero and less than or equal to the total number of input raster bands.The default is the total number of rasters in the input. | Long |
| Output data file(Optional) | Output ASCII data file storing principal component parameters.The output data file records the correlation and covariance matrices, the eigenvalues and eigenvectors, the percent variance each eigenvalue captures, and the accumulative variance described by the eigenvalues.The extension for the output file can be .txt or .asc. | File |
| in_raster_bands[in_raster_band,...] | The input raster bands.They can be integer or floating point type. | Raster Layer |
| number_components(Optional) | Number of principal components.The number must be greater than zero and less than or equal to the total number of input raster bands.The default is the total number of rasters in the input. | Long |
| out_data_file(Optional) | Output ASCII data file storing principal component parameters.The output data file records the correlation and covariance matrices, the eigenvalues and eigenvectors, the percent variance each eigenvalue captures, and the accumulative variance described by the eigenvalues.The extension for the output file can be .txt or .asc. | File |

## Code Samples

### Example 1

```python
PrincipalComponents(in_raster_bands, {number_components}, {out_data_file})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPrincipalComp = PrincipalComponents(["redlands"], 4,"pcdata.txt")
outPrincipalComp.save("C:/sapyexamples/output/outpc01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outPrincipalComp = PrincipalComponents(["redlands"], 4,"pcdata.txt")
outPrincipalComp.save("C:/sapyexamples/output/outpc01")
```

### Example 4

```python
# Name: PrincipalComponents_Ex_02.py
# Description: Performs principal components analysis on a set of raster bands.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasterBand1 = "redlands/redlandsc1"
inRasterBand2 = "redlands/redlandsc3"
numberComponents = 2
outDataFile = "C:/sapyexamples/output/pcdatafile.txt"

# Execute PrincipalComponents
outPrincipalComp = PrincipalComponents([inRasterBand1, inRasterBand2], 2,
                                       outDataFile)

# Save the output 
outPrincipalComp.save("C:/sapyexamples/output/outpc01")
```

### Example 5

```python
# Name: PrincipalComponents_Ex_02.py
# Description: Performs principal components analysis on a set of raster bands.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasterBand1 = "redlands/redlandsc1"
inRasterBand2 = "redlands/redlandsc3"
numberComponents = 2
outDataFile = "C:/sapyexamples/output/pcdatafile.txt"

# Execute PrincipalComponents
outPrincipalComp = PrincipalComponents([inRasterBand1, inRasterBand2], 2,
                                       outDataFile)

# Save the output 
outPrincipalComp.save("C:/sapyexamples/output/outpc01")
```

---

## Rank (Spatial Analyst)

## Summary

Ranks on a cell-by-cell basis the values from a set of input rasters and determines which values are returned based on the value of the rank input raster.

## Usage

- In the list of input rasters, the order is irrelevant. However, the raster that defines the rank must precede these.
- An arbitrary number of rasters can be specified in the input rasters list.
- If a cell location contains NoData on any of the input rasters, that location will be assigned NoData on the output.
- If all of the input values are the same for any cell location, regardless of the specified rank, the output for that cell location will be that value.
- If the rank raster value is greater than the number of input rasters, each cell location in the output will be assigned NoData.
- If any of the input rasters are floating point, the output is floating point; otherwise, it is integer.
- If the Process as multiband parameter is unchecked (process_as_multiband is set to SINGLE_BAND in Python), only the first band of a multiband Input rank raster or constant value (in_rank_raster_or_constant in Python) will be used. Each band from a multiband Input rasters (in_rasters in Python) will be processed separately as a single-band raster.
- If the Process as multiband parameter is checked (process_as_multiband is set to MULTI_BAND in Python), each multiband raster input will be processed as a multiband raster.The number of bands in the output depends on the Input rank raster or constant value. If the rank raster is a single band, the number of bands on the output raster will be the same as the maximum number of bands of all multiband rasters from the input rasters. If the rank raster is a multiband, the output raster will have the same number of bands as the rank raster.If any of the Input rasters is a raster with a smaller number of bands than the output raster, the missing bands will be interpreted as a band filled with NoData. If the cell value of the rank raster picks value one from the missing band, the output raster will receive NoData. If any of the input rasters is a constant, it will be interpreted as a multiband raster in which the cell values of all bands are the same as the constant and have the same number of bands as the output raster.
- If all inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process, otherwise an error will occur.If all of the inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before performing the operation.If one or more of the inputs are multidimensional rasters and the other inputs are constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input rank raster or constant value | The input raster that defines the rank position to be returned.A number can be used as an input; however, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input rasters | The list of input rasters from which the cell value of the raster at the specified rank position will be obtained. For example, consider a particular location where the cell values in the three input rasters are 17, 8 and 11. The rank value for that location is defined as 3. The tool will first sort the input values. Since the rank value being requested is 3, the output value will be 17. | Raster Layer |
| Process as multiband(Optional) | Specifies how the input multiband raster bands will be processed. Unchecked—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.Checked—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |
| in_rank_raster_or_constant | The input raster that defines the rank position to be returned.A number can be used as an input; however, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_rasters[in_raster,...] | The list of input rasters from which the cell value of the raster at the specified rank position will be obtained. For example, consider a particular location where the cell values in the three input rasters are 17, 8 and 11. The rank value for that location is defined as 3. The tool will first sort the input values. Since the rank value being requested is 3, the output value will be 17. | Raster Layer |
| process_as_multiband(Optional) | Specifies how the input multiband raster bands will be processed. SINGLE_BAND—Each band from a multiband raster input will be processed separately as a single band raster. This is the default.MULTI_BAND—Each multiband raster input will be processed as a multiband raster. The operation will be performed for each band from one input using the corresponding band number from the other inputs. | Boolean |

## Code Samples

### Example 1

```python
Rank(in_rank_raster_or_constant, in_rasters, {process_as_multiband})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRank = Rank("cost", ["degs", "negs", "fourgrd"])
outRank.save("C:/sapyexamples/output/outrank.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRank = Rank("cost", ["degs", "negs", "fourgrd"])
outRank.save("C:/sapyexamples/output/outrank.tif")
```

### Example 4

```python
# Name: Rank_Ex_02.py
# Description: Returns the value of a set of rasters based on
#              a rank level specified by another raster 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRankRaster = "cost"
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute Rank
outRank = Rank(inRankRaster, [inRaster01, inRaster02, inRaster03])

# Save the output 
outRank.save("C:/sapyexamples/output/outrank")
```

### Example 5

```python
# Name: Rank_Ex_02.py
# Description: Returns the value of a set of rasters based on
#              a rank level specified by another raster 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRankRaster = "cost"
inRaster01 = "degs"
inRaster02 = "negs"
inRaster03 = "fourgrd"

# Execute Rank
outRank = Rank(inRankRaster, [inRaster01, inRaster02, inRaster03])

# Save the output 
outRank.save("C:/sapyexamples/output/outrank")
```

---

## Raster Calculator (Spatial Analyst)

## Summary

Build and run a single map algebra expression using Python syntax.

## Usage

- The Raster Calculator tool allows you to create and run a map algebra expression that will output a raster.
- Use the Rasters list to choose the datasets and variables to use in the expression. The Tools list provides a selection of commonly used conditional and mathematical tools, allowing you to add them to the expression. Numerical values (and mathematical operator symbols) can be added to the expression directly.
- Full paths to data or data existing in the specified current workspace environment setting can be entered in quotes (""). Numbers and scalars can be directly entered into an expression.
- The supported operators are listed in the following table:+(Addition)>(Greater Than)&(Boolean And)-(Subtraction)(Negate)<(Less Than)|(Boolean Or)*(Multiplication)<=(Less Than or Equal to)^(Boolean XOr)/(Division)>=(Greater Than or Equal to)~(Boolean Not)==(Equal To)!=(Not Equal)Map algebra operators
- Multiple geoprocessing tools and operations can be combined in a map algebra expression using standard Python syntax.Caution:When typing tool names, ensure that the tool name syntax is correct. If the capitalization is incorrect, the expression will be invalid and fail to process because Python is case sensitive.An example of the general format of a map algebra expression using geoprocessing tools is:Con(IsNull("streams"), 0, "streams")
- The tool supports the standard map algebra syntax that is used in Python scripting. The only differences are the following: You do not need to include the output raster name or the equal sign (=) in the expression because the output name is specified in the Output raster parameter.You do not need to cast input data as a Raster object when using operators.
- You do not need to include the output raster name or the equal sign (=) in the expression because the output name is specified in the Output raster parameter.
- You do not need to cast input data as a Raster object when using operators.
- You can clip a raster dataset by setting the Extent environment and specifying the input raster name in the expression. When the tool runs, the resulting raster output will be clipped based on the specified extent.
- To create a raster with cells of a constant value, specify the appropriate Extent and Cell Size environment settings and enter the numerical value into the expression.
- When there are multiple operators in an expression, the operators are not necessarily run in left-to-right order. The operator with the highest precedence value will be run first. For more information, see the operator precedence table in Work with operators in map algebra. Use parentheses to control the run order.
- Boolean (~, &, ^, |) operators have a higher precedence level than Relational (<, <=, >, >=, ==, !=) operators. Therefore, when Boolean operators are used in the same expression as Relational operators, the Boolean operators will be run first. To change the order in which the operators are run, use parentheses.
- When multiple Relational or Boolean operators are used consecutively in a single expression, the expression may fail to run in some cases. To avoid, use appropriate parentheses in the expression so that the run order of the operators is explicitly defined. For more information, see Complex statement rules.
- The performance of an operation may be enhanced by the deferred evaluation capabilities of map algebra. Deferred evaluation is an optimization technique in which individual components of an expression are intelligently processed so as to minimize the creation of intermediate datasets on disk.Only operators and tools that process on a per-cell basis can take advantage of this capability. Operators and tools that support deferred evaluation are included on the raster calculator tool either as a button or in the list of tools provided.
- The Raster Calculator tool can be used in ModelBuilder, but keep the following details in mind.The syntax of the expression determines how variables will be specified. If you choose a variable from the variable list, it will be automatically added to the expression at the current cursor location. Upon model validation, the following occur:Layer names will be enclosed in double-quote symbols (""). Example: "inlayer"Long, double, or Boolean-type variables will be enclosed in percent symbols (%%). They do not need to be in quotes. Example: %scale_factor%Variables representing dataset names or strings will be enclosed in both quotes and percent symbols ("%%"). For example, inraster will become "%inraster%" in the expression.In ModelBuilder, the following variable types are valid inputs for an expression:StringBooleanNumeric (Double and Long)Data (raster dataset, raster layer, raster band, layer file .lyr)The Raster Calculator tool generally follows the standard connectivity behavior of models in ModelBuilder, with some exceptions resulting from the requirements of formulating a valid map algebra expression. These include the following:Variables are connected to the Raster Calculator tool when they are selected from the list of variables. All variables are automatically listed in the Variable list in the tool. When a dataset or variable is used in the expression, a link between the variable and the tool will be created. If you remove the variable from the expression, the associated link between the variable and the tool will also be removed.If you delete the connection to a variable, the variable is not removed from the expression.Do not rename a variable that is connected to the tool, since the variable will not be renamed in the expression. If you do rename a variable, the expression will be invalid.
- Layer names will be enclosed in double-quote symbols (""). Example: "inlayer"
- Long, double, or Boolean-type variables will be enclosed in percent symbols (%%). They do not need to be in quotes. Example: %scale_factor%
- Variables representing dataset names or strings will be enclosed in both quotes and percent symbols ("%%"). For example, inraster will become "%inraster%" in the expression.
- String
- Boolean
- Numeric (Double and Long)
- Data (raster dataset, raster layer, raster band, layer file .lyr)
- Variables are connected to the Raster Calculator tool when they are selected from the list of variables. All variables are automatically listed in the Variable list in the tool.
- When a dataset or variable is used in the expression, a link between the variable and the tool will be created. If you remove the variable from the expression, the associated link between the variable and the tool will also be removed.
- If you delete the connection to a variable, the variable is not removed from the expression.
- Do not rename a variable that is connected to the tool, since the variable will not be renamed in the expression. If you do rename a variable, the expression will be invalid.
- Certain Raster storage environments may apply to this tool when output is in a raster format other than Esri Grid.For the Raster Statistics environments, only the Calculate Statistics check box is supported.For the Compression environments, only the type of Compression is supported. This environment will only apply when the output would be of integer type. Compression is not supported on floating point rasters, so this environment will only apply when the output would be of integer type.The Tile Size environment is only supported for raster output in the following formats: TIFF, file geodatabase, or enterprise geodatabase.
- For the Raster Statistics environments, only the Calculate Statistics check box is supported.
- For the Compression environments, only the type of Compression is supported. This environment will only apply when the output would be of integer type. Compression is not supported on floating point rasters, so this environment will only apply when the output would be of integer type.
- The Tile Size environment is only supported for raster output in the following formats: TIFF, file geodatabase, or enterprise geodatabase.
- If all the inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variable in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If all inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Map Algebra expression | The map algebra expression that will be run. Create the expression by specifying the inputs, values, operators, and tools to use. You can type in the expression directly or use the controls to create it.The Rasters list identifies the datasets available to use in the map algebra expression.The Tools list contains commonly used tools you can use. | Raster Calculator Expression |
| Output raster | The output raster resulting from the map algebra expression. | Raster Dataset |
| expression | Note:In Python, create and run map algebra expressions using the Spatial Analyst module, which is an extension of the ArcPy Python site package.See Map algebra to learn how to perform an analysis in Python. | Raster Calculator Expression |
| output_raster | Note:See Create output for information about producing output from map algebra expressions in Python. | Raster Dataset |

## Code Samples

### Example 1

```python
RasterCalculator(expression, output_raster)
```

---

## Raster Solar Radiation (Spatial Analyst)

## Summary

Calculates the incoming solar insolation for every raster cell of a digital surface model for Earth or the Moon.

## Usage

- Calculating insolation can be computationally intensive for large data extents and when calculating many time intervals. This may require a lot of computing power and hard disk space. You can perform preliminary runs with data at a coarser resolution or a subset of the data to ensure that the settings are correct before committing a run with the full-resolution data.
- The defined spatial reference of the Input surface raster parameter specifies whether the analysis will be for Earth or the Moon.
- The solar radiation computation requires the Output Coordinate System environment value to be in a projected coordinate system (PCS). It is recommended that the data be in a PCS with units of meters. If you run the analysis with a spherical coordinate system, you must set the Output Coordinate System environment to a valid PCS.
- When the input raster needs to be resampled, the bilinear technique will be used. An example of when an input raster may be resampled is when the output coordinate system, extent, or cell size is different from that of the input.
- Daylight saving time is supported for Earth only. For the Moon, times must be specified in UTC.
- The End date and time parameter value must be equal to or greater than the start date. The total span of time must not be greater than one year. The start and end date times can cross the calendar year.
- Output radiation values will be calculated for each respective time interval. If no solar radiation was received for a time interval, the result for that location will have a value of zero.If the total time specified between the start and end times is not equally divisible by the time interval, the total duration will be extended internally to provide the required number of time slices. For example, if the Time Interval parameter is set to cover three days but the difference between the specified start and end times covers eight days, the time interval will be extended to nine days. No partial results for times will be returned.
- The minimum time interval for Earth data is 30 minutes and must be proportional to 30. The minimum time interval for Moon data is two hours and must be proportional to 2.
- Use the Input analysis mask parameter (in_analysis_mask in Python) to limit the output raster to only the locations or cells defined by the mask area. Additionally, it is important to consider the effect of the surface outside your area of interest. The mask can be defined by raster or feature data.The analysis mask does not affect the analysis extent used for calculations. This means that the topography or potential obstructions outside the mask area will influence the solar radiation values that are calculated for the defined areas.If the mask input is a feature dataset, it will be converted to a raster internally using the cell size and cell alignment from the input surface raster value by default.
- Specifying precomputed slope and aspect rasters as input will improve performance, especially if the tool will be run repeatedly or when analyzing larger datasets. If either the input slope or aspect raster values are not provided, values will be calculated from the input surface raster.
- The Neighborhood Distance (neighborhood_distance in Python) parameter determines the neighborhood size and calculates the surface parameter over this distance from the target cell center. The value cannot be less than the input raster cell size.A small neighborhood distance captures more local variability in the landscape, such as characteristics of smaller landscape features. With high-resolution elevation data, larger distances may be more appropriate.
- If the Use adaptive neighborhood parameter is checked (use_adaptive_neighborhood = "ADAPTIVE_NEIGHBORHOOD" in Python), the neighborhood distance will change with variability in the terrain. The neighborhood distance will shrink if there is too much variability in the calculation window.
- Earth's Moon does not have an atmosphere; the radiation parameters diffuse proportion and transmittivity are not relevant during analysis. As a result, the incoming diffuse solar radiation is zero and the total radiation is equal to direct solar radiation.
- The diffuse proportion is the fraction of global normal radiation flux that is diffuse. Values range from 0 to 1. Set this value according to atmospheric conditions. Typical values are 0.2 for very clear sky conditions and 0.3 for generally clear sky conditions.
- Transmittivity is the ratio of the energy reaching Earth's surface to that which is received at the upper limit of the atmosphere. Values range from 0 (no transmission) to 1 (complete transmission). Typically observed values are 0.6 or 0.7 for very clear sky conditions and 0.5 for a generally clear sky.
- Transmittivity has an inverse relationship with the diffuse proportion parameter. Altering these values may affect the model result. Identifying the best values for the area of interest depends on several variables (such as location and time). You can change these values to compare how they affect the result.
- The Sun Map Grid Level parameter controls the speed and accuracy of the computation. It adjusts the resolution of the hexagonal grid cells that will be used for the internal calculations, based on the H3 geospatial indexing system.A lower grid level creates fewer larger sun map areas and decreases tool run time. A higher grid level creates more smaller sun maps, improving the accuracy of the result.Valid values of the sun map grid level for Earth range from 5 to 7. For the Moon, the valid value range is from 4 to 6.The default level is determined by the input surface raster. When analyzing surface data on Earth, if the analysis cell size is less than or equal to 4 meters, the default grid level is 6. If the cell size is greater than 4 meters, the default grid level is 5. For analyzing surface data on the Moon, the default level is 6.The following table shows the average area of the hexagon grid cells for each sun map level, in units of square kilometers:LevelEarthMoon4Not applicable131.65252.9 (default > 4m)18.8636.1 (default < 4m)2.69 (default)75.16Not applicable
- This tool can be GPU accelerated, which means that if a compatible graphics processing unit (GPU) is available on your system, it will be used to enhance the performance of the tool. Use the Target device for analysis (analysis_target_device in Python) parameter to control whether the GPU or CPU will be used to run the tool.See GPU processing with Spatial Analyst for details on compatible GPUs, configuring and working with GPU devices, as well as troubleshooting tips.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- Additional resources: Acton, Charles A. 1996. "Ancillary data services of NASA's Navigation and Ancillary Information Facility." Planetary and Space Science Volume 44, Issue 1, January 1996, pp. 65–70. https://doi.org/10.1016/0032-0633(95)00107-7Acton, Charles, Nathaniel Bachman, Boris Semenov, and Edward Wright. 2018. "A look towards the future in the handling of space science mission geometry." Planetary and Space Science Volume 150, January 2018, pp. 9–12. https://doi.org/10.1016/j.pss.2017.02.013Brodsky, Isaac. 2018. "Uber’s Hexagonal Hierarchical Spatial Index H3." Engineering (blog), June 27, 2018. https://www.uber.com/blog/h3/

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Surface Raster | The input elevation surface raster. | Raster Layer |
| Start Date and Time | The start date and time for the analysis. | Date |
| End Date and Time | The end date and time for the analysis. | Date |
| Input Analysis Mask(Optional) | The input data that defines the locations where the analysis will occur. | Composite Geodataset |
| Input Slope Raster(Optional) | The input slope raster that will be used when calculating the output solar radiation.If this input is not specified, the tool will calculate slope values internally from the input surface raster. Providing this value will improve performance, especially if the tool will be run repeatedly or when analyzing larger datasets. | Raster Layer |
| Input Aspect Raster(Optional) | The input aspect raster that will be used when calculating the output solar radiation.If this input is not specified, the tool will calculate aspect values internally from the input surface raster. Providing this value will improve performance, especially if the tool will be run repeatedly or when analyzing larger datasets. | Raster Layer |
| Output Direct Radiation Raster(Optional) | The output raster representing the direct incoming solar radiation value for each location.The output has units of kilowatt hours per square meter (kWh/m2). | Raster Dataset |
| Output Diffuse Radiation Raster(Optional) | The output raster representing the incoming solar radiation that is diffused by the sky, layers of atmosphere, and other surroundings.The output has units of kilowatt hours per square meter (kWh/m2). | Raster Dataset |
| Output Direct Duration Raster(Optional) | The output raster representing the duration of direct incoming solar radiation.The output has units of hours. | Raster Dataset |
| Time Zone(Optional) | The time zone that will be used for the start and end time. The default is coordinated universal time (UTC).UTC—The time zone will be UTC.Dateline Standard Time—The time zone will be Dateline Standard Time (UTC-12:00).UTC-11—The time zone will be UTC-11 (UTC-11:00).Aleutian Standard Time—The time zone will be Aleutian Standard Time (UTC-10:00).Hawaiian Standard Time—The time zone will be Hawaiian Standard Time (UTC-10:00).Marquesas Standard Time—The time zone will be Marquesas Standard Time (UTC-09:30).Alaskan Standard Time—The time zone will be Alaskan Standard Time (UTC-09:00).UTC-09—The time zone will be UTC-09 (UTC-09:00).Pacific Standard Time (Mexico)—The time zone will be Pacific Standard Time (Mexico) (UTC-08:00).UTC-08—The time zone will be UTC-08 (UTC-08:00).Pacific Standard Time—The time zone will be Pacific Standard Time (UTC-08:00).US Mountain Standard Time—The time zone will be US Mountain Standard Time (UTC-07:00).Mountain Standard Time (Mexico)—The time zone will be Mountain Standard Time (Mexico) (UTC-07:00).Mountain Standard Time—The time zone will be Mountain Standard Time (UTC-07:00).Yukon Standard Time—The time zone will be Yukon Standard Time (UTC-07:00).Central America Standard Time—The time zone will be Central America Standard Time (UTC-06:00).Central Standard Time—The time zone will be Central Standard Time (UTC-06:00).Easter Island Standard Time—The time zone will be Easter Island Standard Time (UTC-06:00).Central Standard Time (Mexico)—The time zone will be Central Standard Time (Mexico) (UTC-06:00).Canada Central Standard Time—The time zone will be Canada Central Standard Time (UTC-06:00).SA Pacific Standard Time—The time zone will be SA Pacific Standard Time (UTC-05:00).Eastern Standard Time (Mexico)—The time zone will be Eastern Standard Time (Mexico) (UTC-05:00).Eastern Standard Time—The time zone will be Eastern Standard Time (UTC-05:00).Haiti Standard Time—The time zone will be Haiti Standard Time (UTC-05:00).Cuba Standard Time—The time zone will be Cuba Standard Time (UTC-05:00).US Eastern Standard Time—The time zone will be US Eastern Standard Time (UTC-05:00).Turks And Caicos Standard Time—The time zone will be Turks And Caicos Standard Time (UTC-04:00).Paraguay Standard Time—The time zone will be Paraguay Standard Time (UTC-04:00).Atlantic Standard Time—The time zone will be Atlantic Standard Time (UTC-04:00).Venezuela Standard Time—The time zone will be Venezuela Standard Time (UTC-04:00).Central Brazilian Standard Time—The time zone will be Central Brazilian Standard Time (UTC-04:00).SA Western Standard Time—The time zone will be SA Western Standard Time (UTC-04:00).Pacific SA Standard Time—The time zone will be Pacific SA Standard Time (UTC-04:00).Newfoundland Standard Time—The time zone will be Newfoundland Standard Time (UTC-03:30).Tocantins Standard Time—The time zone will be Tocantins Standard Time (UTC-03:00).E. South America Standard Time—The time zone will be E. South America Standard Time (UTC-03:00).SA Eastern Standard Time—The time zone will be SA Eastern Standard Time (UTC-03:00).Argentina Standard Time—The time zone will be Argentina Standard Time (UTC-03:00).Greenland Standard Time—The time zone will be Greenland Standard Time (UTC-03:00).Montevideo Standard Time—The time zone will be Montevideo Standard Time (UTC-03:00).Magallanes Standard Time—The time zone will be Magallanes Standard Time (UTC-03:00).Saint Pierre Standard Time—The time zone will be Saint Pierre Standard Time (UTC-03:00).Bahia Standard Time—The time zone will be Bahia Standard Time (UTC-03:00).UTC-02—The time zone will be UTC-02 (UTC-02:00).Mid-Atlantic Standard Time—The time zone will be Mid-Atlantic Standard Time (UTC-02:00).Azores Standard Time—The time zone will be Azores Standard Time (UTC-01:00).Cape Verde Standard Time—The time zone will be Cape Verde Standard Time (UTC-01:00).GMT Standard Time—The time zone will be GMT Standard Time (UTC+00:00).Greenwich Standard Time—The time zone will be Greenwich Standard Time (UTC+00:00).Sao Tome Standard Time—The time zone will be Sao Tome Standard Time (UTC+00:00).Morocco Standard Time—The time zone will be Morocco Standard Time (UTC+00:00).W. Europe Standard Time—The time zone will be W. Europe Standard Time (UTC+01:00).Central Europe Standard Time—The time zone will be Central Europe Standard Time (UTC+01:00).Romance Standard Time—The time zone will be Romance Standard Time (UTC+01:00).Central European Standard Time—The time zone will be Central European Standard Time (UTC+01:00).W. Central Africa Standard Time—The time zone will be W. Central Africa Standard Time (UTC+01:00).Jordan Standard Time—The time zone will be Jordan Standard Time (UTC+02:00).GTB Standard Time—The time zone will be GTB Standard Time (UTC+02:00).Middle East Standard Time—The time zone will be Middle East Standard Time (UTC+02:00).Egypt Standard Time—The time zone will be Egypt Standard Time (UTC+02:00).E. Europe Standard Time—The time zone will be E. Europe Standard Time (UTC+02:00).Syria Standard Time—The time zone will be Syria Standard Time (UTC+02:00).West Bank Standard Time—The time zone will be West Bank Standard Time (UTC+02:00).South Africa Standard Time—The time zone will be South Africa Standard Time (UTC+02:00).FLE Standard Time—The time zone will be FLE Standard Time (UTC+02:00).Israel Standard Time—The time zone will be Israel Standard (UTC+02:00).South Sudan Standard Time—The time zone will be South Sudan Standard Time (UTC+02:00).Kaliningrad Standard Time—The time zone will be Kaliningrad Standard Time (UTC+02:00).Sudan Standard Time—The time zone will be Sudan Standard Time (UTC+02:00).Libya Standard Time—The time zone will be Libya Standard Time (UTC+02:00).Namibia Standard Time—The time zone will be Namibia Standard Time (UTC+02:00).Arabic Standard Time—The time zone will be Arabic Standard Time (UTC+03:00).Turkey Standard Time—The time zone will be Turkey Standard Time (UTC+03:00).Arab Standard Time—The time zone will be Arab Standard Time (UTC+03:00).Belarus Standard Time—The time zone will be Belarus Standard Time (UTC+03:00).Russian Standard Time—The time zone will be Russian Standard Time (UTC+03:00).E. Africa Standard Time—The time zone will be E. Africa Standard Time (UTC+03:00).Volgograd Standard Time—The time zone will be Volgograd Standard Time (UTC+03:00).Iran Standard Time—The time zone will be Iran Standard Time (UTC+03:30).Arabian Standard Time—The time zone will be Arabian Standard Time (UTC+04:00).Astrakhan Standard Time—The time zone will be Astrakhan Standard Time (UTC+04:00).Azerbaijan Standard Time—The time zone will be Azerbaijan Standard Time (UTC+04:00).Russia Time Zone 3—The time zone will be Russia Time Zone 3 (UTC+04:00).Mauritius Standard Time—The time zone will be Mauritius Standard Time (UTC+04:00).Saratov Standard Time—The time zone will be Saratov Standard Time (UTC+04:00).Georgian Standard Time—The time zone will be Georgian Standard Time (UTC+04:00).Caucasus Standard Time—The time zone will be Caucasus Standard Time (UTC+04:00).Afghanistan Standard Time—The time zone will be Afghanistan Standard Time (UTC+04:30).West Asia Standard Time—The time zone will be West Asia Standard Time (UTC+05:00).Ekaterinburg Standard Time—The time zone will be Ekaterinburg Standard Time (UTC+05:00).Pakistan Standard Time—The time zone will be Pakistan Standard Time (UTC+05:00).Qyzylorda Standard Time—The time zone will be Qyzylorda Standard Time (UTC+05:00).India Standard Time—The time zone will be India Standard Time (UTC+05:30).Sri Lanka Standard Time—The time zone will be Sri Lanka Standard Time (UTC+05:30).Nepal Standard Time—The time zone will be Nepal Standard Time (UTC+05:45).Central Asia Standard Time—The time zone will be Central Asia Standard Time (UTC+06:00).Bangladesh Standard Time—The time zone will be Bangladesh Standard Time (UTC+06:00).Omsk Standard Time—The time zone will be Omsk Standard Time (UTC+06:00).Myanmar Standard Time—The time zone will be Myanmar Standard Time (UTC+06:30).SE Asia Standard Time—The time zone will be SE Asia Standard Time (UTC+07:00).Altai Standard Time—The time zone will be Altai Standard Time (UTC+07:00).W. Mongolia Standard Time—The time zone will be W. Mongolia Standard Time (UTC+07:00).North Asia Standard Time—The time zone will be North Asia Standard Time (UTC+07:00).N. Central Asia Standard Time—The time zone will be N. Central Asia Standard Time (UTC+07:00).Tomsk Standard Time—The time zone will be Tomsk Standard Time (UTC+07:00).China Standard Time—The time zone will be China Standard Time (UTC+08:00).North Asia East Standard Time—The time zone will be North Asia East Standard Time (UTC+08:00).Singapore Standard Time—The time zone will be Singapore Standard Time (UTC+08:00).W. Australia Standard Time—The time zone will be W. Australia Standard Time (UTC+08:00).Taipei Standard Time—The time zone will be Taipei Standard Time (UTC+08:00).Ulaanbaatar Standard Time—The time zone will be Ulaanbaatar Standard Time (UTC+08:00).Aus Central W. Standard Time—The time zone will be Aus Central W. Standard Time (UTC+08:45).Transbaikal Standard Time—The time zone will be Transbaikal Standard Time (UTC+09:00).Tokyo Standard Time—The time zone will be Tokyo Standard Time (UTC+09:00).North Korea Standard Time—The time zone will be North Korea Standard Time (UTC+09:00).Korea Standard Time—The time zone will be Korea Standard Time (UTC+09:00).Yakutsk Standard Time—The time zone will be Yakutsk Standard Time (UTC+09:00).Cen. Australia Standard Time—The time zone will be Cen. Australia Standard Time (UTC+09:30).AUS Central Standard Time—The time zone will be AUS Central Standard Time (UTC+09:30).E. Australia Standard Time—The time zone will be E. Australia Standard Time (UTC+10:00).AUS Eastern Standard Time—The time zone will be AUS Eastern Standard Time (UTC+10:00).West Pacific Standard Time—The time zone will be West Pacific Standard Time (UTC+10:00).Tasmania Standard Time—The time zone will be Tasmania Standard Time (UTC+10:00).Vladivostok Standard Time—The time zone will be Vladivostok Standard Time (UTC+10:00).Lord Howe Standard Time—The time zone will be Lord Howe Standard Time (UTC+10:30).Bougainville Standard Time—The time zone will be Bougainville Standard Time (UTC+11:00).Russia Time Zone 10—The time zone will be Russia Time Zone 10 (UTC+11:00).Magadan Standard Time—The time zone will be Magadan Standard Time (UTC+11:00).Norfolk Standard Time—The time zone will be Norfolk Standard Time (UTC+11:00).Sakhalin Standard Time—The time zone will be Sakhalin Standard Time (UTC+11:00).Central Pacific Standard Time—The time zone will be Central Pacific Standard Time (UTC+11:00).Russia Time Zone 11—The time zone will be Russia Time Zone 11 (UTC+11:00).New Zealand Standard Time—The time zone will be New Zealand Standard Time (UTC+12:00).UTC+12—The time zone will be UTC+12 (UTC+12:00).Fiji Standard Time—The time zone will be Fiji Standard Time (UTC+12:00).Kamchatka Standard Time—The time zone will be Kamchatka Standard Time (UTC+12:00).Chatham Islands Standard Time—The time zone will be Chatham Islands Standard Time (UTC+12:45).UTC+13—The time zone will be UTC+13 (UTC+13:00).Tonga Standard Time—The time zone will be Tonga Standard Time (UTC+13:00).Samoa Standard Time—The time zone will be Samoa Standard Time (UTC+13:00).Line Islands Standard Time—The time zone will be Line Islands Standard Time (UTC+14:00). | String |
| Adjust times for daylight saving time(Optional) | Specifies whether the input time configuration will be adjusted for daylight saving time.This parameter is not applicable for analysis on the Moon.Unchecked—The input time values will not be adjusted for daylight saving time. This is the default.Checked—The input time values will be adjusted for daylight saving time. | Boolean |
| Calculate insolation for time intervals(Optional) | Specifies whether a single total insolation value will be calculated for the entire time configuration or multiple radiation values will be calculated for the specified interval.Unchecked—A single total radiation value will be calculated for the entire time configuration. This is the default.Checked—Multiple radiation values will be calculated for each time interval over the entire time configuration. The number of outputs depends on the interval value. For example, for a whole year with monthly intervals, the result will contain 12 output radiation values for each location. | Boolean |
| Time Interval Unit(Optional) | Specifies the time unit that will be used for calculating solar radiation values over the entire time configuration.This parameter is only available when the Calculate insolation for time intervals parameter is checked.Minute—The interval unit will be minutes. This option is only available for Earth-based data.Hour—The interval unit will be hours.Day—The interval unit will be days. This is the defaultWeek—The interval unit will be weeks. | String |
| Time Interval(Optional) | The value of the duration or time between intervals.The default value is dependent on the interval unit specified. The default value for each of the available units are listed below. Minute—60Hour—4Day—14 Week—2 | Long |
| Neighborhood Distance(Optional) | The distance from the target cell center for which the output insolation value will be calculated. It determines the size of the neighborhood.The default value is the input surface raster cell size, resulting in a 3 by 3 neighborhood. | Linear Unit |
| Use adaptive neighborhood(Optional) | Specifies whether neighborhood distance will vary with landscape changes (adaptive). The maximum distance is determined by the neighborhood distance. The minimum distance is the input raster cell size. Unchecked—A single (fixed) neighborhood distance will be used at all locations. This is the default.Checked—An adaptive neighborhood distance will be used at all locations. | Boolean |
| Diffuse Model Type(Optional) | Specifies the type of diffuse radiation model that will be used.Uniform sky—The uniform diffuse model will be used. The incoming diffuse radiation is the same from all sky directions. This is the default.Standard overcast sky—The standard overcast diffuse model will be used. The incoming diffuse radiation flux varies with the zenith angle. | String |
| Diffuse Proportion(Optional) | The proportion of global normal radiation flux that is diffuse. Values range from 0 to 1.Set this value according to atmospheric conditions. The default value is 0.3 for generally clear sky conditions. | Double |
| Transmittivity(Optional) | The fraction of radiation that passes through the atmosphere (averaged overall wavelengths). Values range from 0 (no transmission) to 1 (all transmission).The default is 0.5 for a generally clear sky. | Double |
| Target Device for Analysis(Optional) | Specifies the device that will be used to perform the calculation.GPU then CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU only—The calculation will only be performed on the CPU.GPU only—The calculation will only be performed on the GPU. | String |
| Sun Map Grid Level(Optional) | The resolution that will be used to generate the H3 hexagonal grid cells used for internal calculations. A lower grid level value creates fewer, larger sun map areas and decreases tool run time. A higher grid level creates more smaller sun maps improving the accuracy of the result.Valid values of the sun map grid level for Earth range from 5 to 7. For the Moon, the valid value range is from 4 to 6.By default, the grid level is determined by the input surface raster. When analyzing surface data on Earth, if the analysis cell size is less than or equal to 4 meters, the default grid level is 6. If the analysis cell size is greater than 4 meters, the default grid level is 5. For analyzing surface data on the Moon, the default grid level is 6. | Long |
| in_surface_raster | The input elevation surface raster. | Raster Layer |
| start_date_time | The start date and time for the analysis. | Date |
| end_date_time | The end date and time for the analysis. | Date |
| in_analysis_mask(Optional) | The input data that defines the locations where the analysis will occur. | Composite Geodataset |
| in_slope_raster(Optional) | The input slope raster that will be used when calculating the output solar radiation.If this input is not specified, the tool will calculate slope values internally from the input surface raster. Providing this value will improve performance, especially if the tool will be run repeatedly or when analyzing larger datasets. | Raster Layer |
| in_aspect_raster(Optional) | The input aspect raster that will be used when calculating the output solar radiation.If this input is not specified, the tool will calculate aspect values internally from the input surface raster. Providing this value will improve performance, especially if the tool will be run repeatedly or when analyzing larger datasets. | Raster Layer |
| out_direct_radiation_raster(Optional) | The output raster representing the direct incoming solar radiation value for each location.The output has units of kilowatt hours per square meter (kWh/m2). | Raster Dataset |
| out_diffuse_radiation_raster(Optional) | The output raster representing the incoming solar radiation that is diffused by the sky, layers of atmosphere, and other surroundings.The output has units of kilowatt hours per square meter (kWh/m2). | Raster Dataset |
| out_duration_raster(Optional) | The output raster representing the duration of direct incoming solar radiation.The output has units of hours. | Raster Dataset |
| time_zone(Optional) | The time zone that will be used for the start and end time. The default is coordinated universal time (UTC).UTC—The time zone will be UTC.Dateline_Standard_Time—The time zone will be Dateline Standard Time (UTC-12:00).UTC-11—The time zone will be UTC-11 (UTC-11:00).Aleutian_Standard_Time—The time zone will be Aleutian Standard Time (UTC-10:00).Hawaiian_Standard_Time—The time zone will be Hawaiian Standard Time (UTC-10:00).Marquesas_Standard_Time—The time zone will be Marquesas Standard Time (UTC-09:30).Alaskan_Standard_Time—The time zone will be Alaskan Standard Time (UTC-09:00).UTC-09—The time zone will be UTC-09 (UTC-09:00).Pacific_Standard_Time_(Mexico)—The time zone will be Pacific Standard Time (Mexico) (UTC-08:00).UTC-08—The time zone will be UTC-08 (UTC-08:00).Pacific_Standard_Time—The time zone will be Pacific Standard Time (UTC-08:00).US_Mountain_Standard_Time—The time zone will be US Mountain Standard Time (UTC-07:00).Mountain_Standard_Time_(Mexico)—The time zone will be Mountain Standard Time (Mexico) (UTC-07:00).Mountain_Standard_Time—The time zone will be Mountain Standard Time (UTC-07:00).Yukon_Standard_Time—The time zone will be Yukon Standard Time (UTC-07:00).Central_America_Standard_Time—The time zone will be Central America Standard Time (UTC-06:00).Central_Standard_Time—The time zone will be Central Standard Time (UTC-06:00).Easter_Island_Standard_Time—The time zone will be Easter Island Standard Time (UTC-06:00).Central_Standard_Time_(Mexico)—The time zone will be Central Standard Time (Mexico) (UTC-06:00).Canada_Central_Standard_Time—The time zone will be Canada Central Standard Time (UTC-06:00).SA_Pacific_Standard_Time—The time zone will be SA Pacific Standard Time (UTC-05:00).Eastern_Standard_Time_(Mexico)—The time zone will be Eastern Standard Time (Mexico) (UTC-05:00).Eastern_Standard_Time—The time zone will be Eastern Standard Time (UTC-05:00).Haiti_Standard_Time—The time zone will be Haiti Standard Time (UTC-05:00).Cuba_Standard_Time—The time zone will be Cuba Standard Time (UTC-05:00).US_Eastern_Standard_Time—The time zone will be US Eastern Standard Time (UTC-05:00).Turks_And_Caicos_Standard_Time—The time zone will be Turks And Caicos Standard Time (UTC-04:00).Paraguay_Standard_Time—The time zone will be Paraguay Standard Time (UTC-04:00).Atlantic_Standard_Time—The time zone will be Atlantic Standard Time (UTC-04:00).Venezuela_Standard_Time—The time zone will be Venezuela Standard Time (UTC-04:00).Central_Brazilian_Standard_Time—The time zone will be Central Brazilian Standard Time (UTC-04:00).SA_Western_Standard_Time—The time zone will be SA Western Standard Time (UTC-04:00).Pacific_SA_Standard_Time—The time zone will be Pacific SA Standard Time (UTC-04:00).Newfoundland_Standard_Time—The time zone will be Newfoundland Standard Time (UTC-03:30).Tocantins_Standard_Time—The time zone will be Tocantins Standard Time (UTC-03:00).E._South_America_Standard_Time—The time zone will be E. South America Standard Time (UTC-03:00).SA_Eastern_Standard_Time—The time zone will be SA Eastern Standard Time (UTC-03:00).Argentina_Standard_Time—The time zone will be Argentina Standard Time (UTC-03:00).Greenland_Standard_Time—The time zone will be Greenland Standard Time (UTC-03:00).Montevideo_Standard_Time—The time zone will be Montevideo Standard Time (UTC-03:00).Magallanes_Standard_Time—The time zone will be Magallanes Standard Time (UTC-03:00).Saint_Pierre_Standard_Time—The time zone will be Saint Pierre Standard Time (UTC-03:00).Bahia_Standard_Time—The time zone will be Bahia Standard Time (UTC-03:00).UTC-02—The time zone will be UTC-02 (UTC-02:00).Mid-Atlantic_Standard_Time—The time zone will be Mid-Atlantic Standard Time (UTC-02:00).Azores_Standard_Time—The time zone will be Azores Standard Time (UTC-01:00).Cape_Verde_Standard_Time—The time zone will be Cape Verde Standard Time (UTC-01:00).GMT_Standard_Time—The time zone will be GMT Standard Time (UTC+00:00).Greenwich_Standard_Time—The time zone will be Greenwich Standard Time (UTC+00:00).Sao_Tome_Standard_Time—The time zone will be Sao Tome Standard Time (UTC+00:00).Morocco_Standard_Time—The time zone will be Morocco Standard Time (UTC+00:00).W._Europe_Standard_Time—The time zone will be W. Europe Standard Time (UTC+01:00).Central_Europe_Standard_Time—The time zone will be Central Europe Standard Time (UTC+01:00).Romance_Standard_Time—The time zone will be Romance Standard Time (UTC+01:00).Central_European_Standard_Time—The time zone will be Central European Standard Time (UTC+01:00).W._Central_Africa_Standard_Time—The time zone will be W. Central Africa Standard Time (UTC+01:00).Jordan_Standard_Time—The time zone will be Jordan Standard Time (UTC+02:00).GTB_Standard_Time—The time zone will be GTB Standard Time (UTC+02:00).Middle_East_Standard_Time—The time zone will be Middle East Standard Time (UTC+02:00).Egypt_Standard_Time—The time zone will be Egypt Standard Time (UTC+02:00).E._Europe_Standard_Time—The time zone will be E. Europe Standard Time (UTC+02:00).Syria_Standard_Time—The time zone will be Syria Standard Time (UTC+02:00).West_Bank_Standard_Time—The time zone will be West Bank Standard Time (UTC+02:00).South_Africa_Standard_Time—The time zone will be South Africa Standard Time (UTC+02:00).FLE_Standard_Time—The time zone will be FLE Standard Time (UTC+02:00).Israel_Standard_Time—The time zone will be Israel Standard (UTC+02:00).South_Sudan_Standard_Time—The time zone will be South Sudan Standard Time (UTC+02:00).Kaliningrad_Standard_Time—The time zone will be Kaliningrad Standard Time (UTC+02:00).Sudan_Standard_Time—The time zone will be Sudan Standard Time (UTC+02:00).Libya_Standard_Time—The time zone will be Libya Standard Time (UTC+02:00).Namibia_Standard_Time—The time zone will be Namibia Standard Time (UTC+02:00).Arabic_Standard_Time—The time zone will be Arabic Standard Time (UTC+03:00).Turkey_Standard_Time—The time zone will be Turkey Standard Time (UTC+03:00).Arab_Standard_Time—The time zone will be Arab Standard Time (UTC+03:00).Belarus_Standard_Time—The time zone will be Belarus Standard Time (UTC+03:00).Russian_Standard_Time—The time zone will be Russian Standard Time (UTC+03:00).E._Africa_Standard_Time—The time zone will be E. Africa Standard Time (UTC+03:00).Volgograd_Standard_Time—The time zone will be Volgograd Standard Time (UTC+03:00).Iran_Standard_Time—The time zone will be Iran Standard Time (UTC+03:30).Arabian_Standard_Time—The time zone will be Arabian Standard Time (UTC+04:00).Astrakhan_Standard_Time—The time zone will be Astrakhan Standard Time (UTC+04:00).Azerbaijan_Standard_Time—The time zone will be Azerbaijan Standard Time (UTC+04:00).Russia_Time_Zone_3—The time zone will be Russia Time Zone 3 (UTC+04:00).Mauritius_Standard_Time—The time zone will be Mauritius Standard Time (UTC+04:00).Saratov_Standard_Time—The time zone will be Saratov Standard Time (UTC+04:00).Georgian_Standard_Time—The time zone will be Georgian Standard Time (UTC+04:00).Caucasus_Standard_Time—The time zone will be Caucasus Standard Time (UTC+04:00).Afghanistan_Standard_Time—The time zone will be Afghanistan Standard Time (UTC+04:30).West_Asia_Standard_Time—The time zone will be West Asia Standard Time (UTC+05:00).Ekaterinburg_Standard_Time—The time zone will be Ekaterinburg Standard Time (UTC+05:00).Pakistan_Standard_Time—The time zone will be Pakistan Standard Time (UTC+05:00).Qyzylorda_Standard_Time—The time zone will be Qyzylorda Standard Time (UTC+05:00).India_Standard_Time—The time zone will be India Standard Time (UTC+05:30).Sri_Lanka_Standard_Time—The time zone will be Sri Lanka Standard Time (UTC+05:30).Nepal_Standard_Time—The time zone will be Nepal Standard Time (UTC+05:45).Central_Asia_Standard_Time—The time zone will be Central Asia Standard Time (UTC+06:00).Bangladesh_Standard_Time—The time zone will be Bangladesh Standard Time (UTC+06:00).Omsk_Standard_Time—The time zone will be Omsk Standard Time (UTC+06:00).Myanmar_Standard_Time—The time zone will be Myanmar Standard Time (UTC+06:30).SE_Asia_Standard_Time—The time zone will be SE Asia Standard Time (UTC+07:00).Altai_Standard_Time—The time zone will be Altai Standard Time (UTC+07:00).W._Mongolia_Standard_Time—The time zone will be W. Mongolia Standard Time (UTC+07:00).North_Asia_Standard_Time—The time zone will be North Asia Standard Time (UTC+07:00).N._Central_Asia_Standard_Time—The time zone will be N. Central Asia Standard Time (UTC+07:00).Tomsk_Standard_Time—The time zone will be Tomsk Standard Time (UTC+07:00).China_Standard_Time—The time zone will be China Standard Time (UTC+08:00).North_Asia_East_Standard_Time—The time zone will be North Asia East Standard Time (UTC+08:00).Singapore_Standard_Time—The time zone will be Singapore Standard Time (UTC+08:00).W._Australia_Standard_Time—The time zone will be W. Australia Standard Time (UTC+08:00).Taipei_Standard_Time—The time zone will be Taipei Standard Time (UTC+08:00).Ulaanbaatar_Standard_Time—The time zone will be Ulaanbaatar Standard Time (UTC+08:00).Aus_Central_W._Standard_Time—The time zone will be Aus Central W. Standard Time (UTC+08:45).Transbaikal_Standard_Time—The time zone will be Transbaikal Standard Time (UTC+09:00).Tokyo_Standard_Time—The time zone will be Tokyo Standard Time (UTC+09:00).North_Korea_Standard_Time—The time zone will be North Korea Standard Time (UTC+09:00).Korea_Standard_Time—The time zone will be Korea Standard Time (UTC+09:00).Yakutsk_Standard_Time—The time zone will be Yakutsk Standard Time (UTC+09:00).Cen._Australia_Standard_Time—The time zone will be Cen. Australia Standard Time (UTC+09:30).AUS_Central_Standard_Time—The time zone will be AUS Central Standard Time (UTC+09:30).E._Australia_Standard_Time—The time zone will be E. Australia Standard Time (UTC+10:00).AUS_Eastern_Standard_Time—The time zone will be AUS Eastern Standard Time (UTC+10:00).West_Pacific_Standard_Time—The time zone will be West Pacific Standard Time (UTC+10:00).Tasmania_Standard_Time—The time zone will be Tasmania Standard Time (UTC+10:00).Vladivostok_Standard_Time—The time zone will be Vladivostok Standard Time (UTC+10:00).Lord_Howe_Standard_Time—The time zone will be Lord Howe Standard Time (UTC+10:30).Bougainville_Standard_Time—The time zone will be Bougainville Standard Time (UTC+11:00).Russia_Time_Zone_10—The time zone will be Russia Time Zone 10 (UTC+11:00).Magadan_Standard_Time—The time zone will be Magadan Standard Time (UTC+11:00).Norfolk_Standard_Time—The time zone will be Norfolk Standard Time (UTC+11:00).Sakhalin_Standard_Time—The time zone will be Sakhalin Standard Time (UTC+11:00).Central_Pacific_Standard_Time—The time zone will be Central Pacific Standard Time (UTC+11:00).Russia_Time_Zone_11—The time zone will be Russia Time Zone 11 (UTC+11:00).New_Zealand_Standard_Time—The time zone will be New Zealand Standard Time (UTC+12:00).UTC+12—The time zone will be UTC+12 (UTC+12:00).Fiji_Standard_Time—The time zone will be Fiji Standard Time (UTC+12:00).Kamchatka_Standard_Time—The time zone will be Kamchatka Standard Time (UTC+12:00).Chatham_Islands_Standard_Time—The time zone will be Chatham Islands Standard Time (UTC+12:45).UTC+13—The time zone will be UTC+13 (UTC+13:00).Tonga_Standard_Time—The time zone will be Tonga Standard Time (UTC+13:00).Samoa_Standard_Time—The time zone will be Samoa Standard Time (UTC+13:00).Line_Islands_Standard_Time—The time zone will be Line Islands Standard Time (UTC+14:00). | String |
| adjust_DST(Optional) | Specifies whether the input time configuration will be adjusted for daylight saving time.This parameter is not applicable for analysis on the Moon.NOT_ADJUSTED_FOR_DST—The input time values will not be adjusted for daylight saving time. This is the default.ADJUSTED_FOR_DST—The input time values will be adjusted for daylight saving time. | Boolean |
| use_time_interval(Optional) | Specifies whether a single total insolation value will be calculated for the entire time configuration or multiple radiation values will be calculated for the specified interval.NO_INTERVAL—A single radiation value will be calculated for the entire time configuration. This is default.INTERVAL—Multiple radiation values will be calculated for each time interval over the entire time configuration. | Boolean |
| interval_unit(Optional) | Specifies the time unit that will be used for calculating solar radiation values over the entire time configuration.This parameter is only supported when the use_time_interval parameter is set to INTERVAL.MINUTE—The interval unit will be minutes. This option is only available for Earth-based data.HOUR—The interval unit will be hours.DAY—The interval unit will be days. This is the defaultWEEK—The interval unit will be weeks. | String |
| interval(Optional) | The value of the duration or time between intervals.The default value is dependent on the interval unit specified. The default value for each of the available units are listed below. MINUTE—60HOUR—4DAY—14 WEEK—2 | Long |
| neighborhood_distance(Optional) | The distance from the target cell center for which the output insolation value will be calculated. It determines the size of the neighborhood.The default value is the input surface raster cell size, resulting in a 3 by 3 neighborhood. | Linear Unit |
| use_adaptive_neighborhood(Optional) | Specifies whether neighborhood distance will vary with landscape changes (adaptive). The maximum distance is determined by the neighborhood distance. The minimum distance is the input raster cell size. FIXED_NEIGHBORHOOD—A single (fixed) neighborhood distance will be used at all locations. This is the default.ADAPTIVE_NEIGHBORHOOD—An adaptive neighborhood distance will be used at all locations. | Boolean |
| diffuse_model_type(Optional) | Specifies the type of diffuse radiation model that will be used.UNIFORM_SKY—The uniform diffuse model will be used. The incoming diffuse radiation is the same from all sky directions. This is the default.STANDARD_OVERCAST_SKY—The standard overcast diffuse model will be used. The incoming diffuse radiation flux varies with the zenith angle. | String |
| diffuse_proportion(Optional) | The proportion of global normal radiation flux that is diffuse. Values range from 0 to 1.Set this value according to atmospheric conditions. The default value is 0.3 for generally clear sky conditions. | Double |
| transmittivity(Optional) | The fraction of radiation that passes through the atmosphere (averaged overall wavelengths). Values range from 0 (no transmission) to 1 (all transmission).The default is 0.5 for a generally clear sky. | Double |
| analysis_target_device(Optional) | Specifies the device that will be used to perform the calculation.GPU_THEN_CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU_ONLY—The calculation will only be performed on the CPU.GPU_ONLY—The calculation will only be performed on the GPU. | String |
| sunmap_grid_level(Optional) | The resolution that will be used to generate the H3 hexagonal grid cells used for internal calculations. A lower grid level value creates fewer, larger sun map areas and decreases tool run time. A higher grid level creates more smaller sun maps improving the accuracy of the result.Valid values of the sun map grid level for Earth range from 5 to 7. For the Moon, the valid value range is from 4 to 6.By default, the grid level is determined by the input surface raster. When analyzing surface data on Earth, if the analysis cell size is less than or equal to 4 meters, the default grid level is 6. If the analysis cell size is greater than 4 meters, the default grid level is 5. For analyzing surface data on the Moon, the default grid level is 6. | Long |

## Code Samples

### Example 1

```python
RasterSolarRadiation(in_surface_raster, start_date_time, end_date_time, {in_analysis_mask}, {in_slope_raster}, {in_aspect_raster}, {out_direct_radiation_raster}, {out_diffuse_radiation_raster}, {out_duration_raster}, {time_zone}, {adjust_DST}, {use_time_interval}, {interval_unit}, {interval}, {neighborhood_distance}, {use_adaptive_neighborhood}, {diffuse_model_type}, {diffuse_proportion}, {transmittivity}, {analysis_target_device}, {sunmap_grid_level})
```

### Example 2

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "C:/sapyexamples/data"
out_raster = arcpy.sa.RasterSolarRadiation("dsm30m_CA.tif", "9/1/2023 06:00:00 AM","9/30/2023 06:30:00 PM",
                                           time_zone="Pacific_Standard_Time")
out_raster.save("C:/sapyexamples/output/dsm30_total_radiation_092023.tif")
```

### Example 3

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "C:/sapyexamples/data"
out_raster = arcpy.sa.RasterSolarRadiation("dsm30m_CA.tif", "9/1/2023 06:00:00 AM","9/30/2023 06:30:00 PM",
                                           time_zone="Pacific_Standard_Time")
out_raster.save("C:/sapyexamples/output/dsm30_total_radiation_092023.tif")
```

### Example 4

```python
# Name: RasterSolarRadiation_standalone.py
# Description: Calculate solar insolation for the year 2023 at one month 
#  time intervals. Return all output radiation rasters.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Run RasterSolarRadiation
out_solar_radiation_raster = arcpy.sa.RasterSolarRadiation(
	in_surface_raster="dsm30m_CA.tif",
	start_date_time="1/1/2023",
	end_date_time="12/31/2023",
	in_analysis_mask=None,
	in_slope_raster=None,
	in_aspect_raster=None,
	out_direct_radiation_raster=r"C:\sapyexamples\output\dsm30_direct_radiation_2023_1mo.crf",
	out_diffuse_radiation_raster=r"C:\sapyexamples\output\dsm30_diffuse_radiation_2023_1mo.crf",
	out_duration_raster=r"C:\sapyexamples\output\dsm30_duration_radiation_2023_1mo.crf",
	time_zone="Pacific_Standard_Time",
	adjust_DST="ADJUSTED_FOR_DST",
	use_time_interval="INTERVAL",
	interval_unit="MONTH",
	interval="1",
	neighborhood_distance="",
	use_adaptive_neighborhood="",
	diffuse_model_type="UNIFORM_SKY",
	diffuse_proportion=0.3,
	transmittivity=0.5,
	analysis_target_device="GPU_THEN_CPU"
)

# Save the output 
out_solar_radiation_raster.save(r"C:\sapyexamples\output\dsm30_total_radiation_2023_1mo.crf")
```

### Example 5

```python
# Name: RasterSolarRadiation_standalone.py
# Description: Calculate solar insolation for the year 2023 at one month 
#  time intervals. Return all output radiation rasters.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Run RasterSolarRadiation
out_solar_radiation_raster = arcpy.sa.RasterSolarRadiation(
	in_surface_raster="dsm30m_CA.tif",
	start_date_time="1/1/2023",
	end_date_time="12/31/2023",
	in_analysis_mask=None,
	in_slope_raster=None,
	in_aspect_raster=None,
	out_direct_radiation_raster=r"C:\sapyexamples\output\dsm30_direct_radiation_2023_1mo.crf",
	out_diffuse_radiation_raster=r"C:\sapyexamples\output\dsm30_diffuse_radiation_2023_1mo.crf",
	out_duration_raster=r"C:\sapyexamples\output\dsm30_duration_radiation_2023_1mo.crf",
	time_zone="Pacific_Standard_Time",
	adjust_DST="ADJUSTED_FOR_DST",
	use_time_interval="INTERVAL",
	interval_unit="MONTH",
	interval="1",
	neighborhood_distance="",
	use_adaptive_neighborhood="",
	diffuse_model_type="UNIFORM_SKY",
	diffuse_proportion=0.3,
	transmittivity=0.5,
	analysis_target_device="GPU_THEN_CPU"
)

# Save the output 
out_solar_radiation_raster.save(r"C:\sapyexamples\output\dsm30_total_radiation_2023_1mo.crf")
```

---

## Reclass by ASCII File (Spatial Analyst)

## Summary

Reclassifies (or changes) the values of the input cells of a raster using an ASCII remap file.

## Usage

- The input raster must have valid statistics. If the statistics do not exist, you can create them using the Calculate Statistics tool in the Data Management toolbox.
- The output raster will always be of integer type. If the output assignment values in the ASCII file are floating-point values, an error message will be returned and the program will halt.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster to be reclassified. | Raster Layer |
| Input ASCII remap file | ASCII remap file defining the single values or ranges to be reclassified and the values they will become.Allowed extensions for the ASCII remap files are .rmp, .txt, and .asc. | File |
| Change missing values to NoData(Optional) | Denotes whether missing values in the reclass file retain their value or get mapped to NoData.Unchecked—Signifies that if any cell location on the input raster contains a value that is not present or reclassed in the remap file, the value should remain intact and be written for that location to the output raster. This is the default.Checked—Signifies that if any cell location on the input raster contains a value that is not present or reclassed in the remap file, the value will be reclassed to NoData for that location on the output raster. | Boolean |
| in_raster | The input raster to be reclassified. | Raster Layer |
| in_remap_file | ASCII remap file defining the single values or ranges to be reclassified and the values they will become.Allowed extensions for the ASCII remap files are .rmp, .txt, and .asc. | File |
| missing_values(Optional) | Denotes whether missing values in the reclass file retain their value or get mapped to NoData.DATA—Signifies that if any cell location on the input raster contains a value that is not present or reclassed in the remap file, the value should remain intact and be written for that location to the output raster. This is the default.NODATA—Signifies that if any cell location on the input raster contains a value that is not present or reclassed in the remap file, the value will be reclassed to NoData for that location on the output raster. | Boolean |

## Code Samples

### Example 1

```python
ReclassByASCIIFile(in_raster, in_remap_file, {missing_values})
```

### Example 2

```python
import arcpy
from arcpy.sa import *
from arcpy import env  
env.workspace = "C:/sapyexamples/data"
outReclass = ReclassByASCIIFile("slope","remapslope.rmp")
outReclass.save("C:/sapyexamples/output/recslope")
```

### Example 3

```python
import arcpy
from arcpy.sa import *
from arcpy import env  
env.workspace = "C:/sapyexamples/data"
outReclass = ReclassByASCIIFile("slope","remapslope.rmp")
outReclass.save("C:/sapyexamples/output/recslope")
```

### Example 4

```python
# Name: reclassbyasciifile_example02.py
# Description: Reclassifies  values of the input raster using an ASCII remap file
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "slope"
inRemapFile = "remapslope.rmp"

# Execute Reclassify
outRaster = ReclassByASCIIFile(inRaster, inRemapFile)

# Save the output 
outRaster.save("C:/sapyexamples/output/recslope")
```

### Example 5

```python
# Name: reclassbyasciifile_example02.py
# Description: Reclassifies  values of the input raster using an ASCII remap file
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "slope"
inRemapFile = "remapslope.rmp"

# Execute Reclassify
outRaster = ReclassByASCIIFile(inRaster, inRemapFile)

# Save the output 
outRaster.save("C:/sapyexamples/output/recslope")
```

---

## Reclass by Table (Spatial Analyst)

## Summary

Reclassifies (or changes) the values of the input cells of a raster using a remap table.

## Usage

- The input raster must have valid statistics. If the statistics do not exist, you can create them using the Calculate Statistics tool in the Data Management toolbox.
- The From value field, To value field, and Output value field are the field names in the table that define the remapping.
- To reclassify individual values, use a simple remap table of two items. The first item identifies the value to reclassify, and the other item identifies the value to assign to it. Set the To value field the same as the From value field. The value to assign to the output is Output value field.
- To reclassify ranges of values, the remap table must have items defining the start and end of each range, along with the value to assign the range. The item defining the start of the range is the From value field, and the value defining the end of the range is the To value field. The value to assign to the output is Output value field.
- The remap table can be a geodatabase table, a text file, or a dbase file.
- The values in the from and to fields can be any numerical item. The assignment values in the output field must be integers.
- Values in the From value field for .dbf and Geodatabase tables do not need to be sorted. For text-file based tables, they must be sorted in ascending order. The values should not overlap in either case.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster to be reclassified. | Raster Layer |
| Input remap table | Table holding fields defining value ranges to be reclassified and the values they will become. | Table View |
| From value field | Field holding the beginning value for each value range to be reclassified.This is a numeric field of the input remap table. | Field |
| To value field | Field holding the ending value for each value range to be reclassified.This is a numeric field of the input remap table. | Field |
| Output value field | Field holding the integer values to which each range should be changed.This is an integer field of the input remap table. | Field |
| Change missing values to NoData(Optional) | Denotes whether missing values in the reclass table retain their value or get mapped to NoData.Unchecked—Signifies that if any cell location on the input raster contains a value not present or reclassed in a remap table, the value should remain intact and be written for that location to the output raster. This is the default.Checked—Signifies that if any cell location on the input raster contains a value not present or reclassed in a remap table, the value will be reclassed to NoData for that location on the output raster. | Boolean |
| in_raster | The input raster to be reclassified. | Raster Layer |
| in_remap_table | Table holding fields defining value ranges to be reclassified and the values they will become. | Table View |
| from_value_field | Field holding the beginning value for each value range to be reclassified.This is a numeric field of the input remap table. | Field |
| to_value_field | Field holding the ending value for each value range to be reclassified.This is a numeric field of the input remap table. | Field |
| output_value_field | Field holding the integer values to which each range should be changed.This is an integer field of the input remap table. | Field |
| missing_values(Optional) | Denotes whether missing values in the reclass table retain their value or get mapped to NoData.DATA—Signifies that if any cell location on the input raster contains a value not present or reclassed in a remap table, the value should remain intact and be written for that location to the output raster. This is the default.NODATA—Signifies that if any cell location on the input raster contains a value not present or reclassed in a remap table, the value will be reclassed to NoData for that location on the output raster. | Boolean |

## Code Samples

### Example 1

```python
ReclassByTable(in_raster, in_remap_table, from_value_field, to_value_field, output_value_field, {missing_values})
```

### Example 2

```python
import arcpy
from arcpy.sa import *
from arcpy import env  
env.workspace = "C:/sapyexamples/data"
outReclass = ReclassByTable("slope","remapslope","FROM","TO","OUT")
outReclass.save("C:/sapyexamples/output/recslope")
```

### Example 3

```python
import arcpy
from arcpy.sa import *
from arcpy import env  
env.workspace = "C:/sapyexamples/data"
outReclass = ReclassByTable("slope","remapslope","FROM","TO","OUT")
outReclass.save("C:/sapyexamples/output/recslope")
```

### Example 4

```python
# Name: reclassbytable_example02.py
# Description: Reclassifies the values of the input raster using a remap table.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "slope"
inRemapTable = "remapslope"

# Execute Reclassify
outRaster = ReclassByTable(inRaster, inRemapTable,"FROM","TO","OUT","NODATA")

# Save the output 
outRaster.save("C:/sapyexamples/output/recslope")
```

### Example 5

```python
# Name: reclassbytable_example02.py
# Description: Reclassifies the values of the input raster using a remap table.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "slope"
inRemapTable = "remapslope"

# Execute Reclassify
outRaster = ReclassByTable(inRaster, inRemapTable,"FROM","TO","OUT","NODATA")

# Save the output 
outRaster.save("C:/sapyexamples/output/recslope")
```

---

## Reclassify (Spatial Analyst)

## Summary

Reclassifies (or changes) the values in a raster.

## Usage

- If a range of values is to be reclassed, the ranges should not overlap except at the boundary of two input ranges. Where overlapping occurs, the higher end of the lower input range is inclusive, and the lower end of the higher input range is exclusive.For example, if two ranges are specified, such as reclassifying values 1 to 5 as 100 and values 5 to 10 as 200, an input value less than or equal to 5 will be assigned the value 100 in the output, and an input value that is larger than 5, such as 5.01, will be assigned to 200.
- In the tool dialog, the Classify or Unique options in the Reclassification parameter allows you to generate a remap table based on the values of the input raster. The Classify option opens a dialog and allow you to specify a method from one of the Data classification methods and number of classes. The Unique option will populate the remap table using the unique values from the input dataset.
- It is recommended to calculate statistics on a mosaic dataset before reclassifying the data.
- From the tool dialog, the remap table can be stored for future use with the Save option. You can save the remap to any relational table format. Use the Load option to reload remap tables you previously created with the Save button.
- It is recommended to only load tables previously saved by the Reclassify tool. The table format is specific and must contain the fields FROM, TO, OUT, and MAPPING.
- If the input raster has an attribute table, it will be used to create the initial reclassification table. If the input raster does not have an attribute table, you can run the Build Raster Attribute Table tool from the Data Management toolbox to build one before inputting the raster into the Reclassify tool. Otherwise, when you input the raster, a reclassification table will be created for it by first applying geoprocessing environment settings, such as Extent and Cell size, and scanning the raster.When the input raster is a layer from Contents, the default reclassification table will import the unique values or classified break values as specified by the layer symbology. The current geoprocessing environment settings will be ignored when importing those values. Otherwise, the reclassification must be manually entered or generated using the unique or classification options.
- Once the remap table of the reclassification has been modified, the table will not be updated if a new input raster is selected. If the reclassification is not suitable for the new raster, a new reclassification can be reinitialized by one of the following methodsRemove all remap records using the erase option and manually add the new values.Select the unique or classification options to generate a new reclassification.
- Remove all remap records using the erase option and manually add the new values.
- Select the unique or classification options to generate a new reclassification.
- When using the Reclassify tool as part of a modelIf the input to the tool is derived data from a tool that isn't already run, the remap parameter in the Reclassify tool will be empty until the preceding tool is run and the model is validated. To avoid this, always run preceding tools before connecting their output variables as input to the Reclassify tool. Alternatively, you can create a custom reclassification table by adding entries.If exposing the reclassification table as a model parameter, the reclass field must be exposed as a variable; however, it does not need to be set as a model parameter. If the field is not exposed as a variable, the classify and unique values buttons will be disabled in the model tool dialog box.
- If the input to the tool is derived data from a tool that isn't already run, the remap parameter in the Reclassify tool will be empty until the preceding tool is run and the model is validated. To avoid this, always run preceding tools before connecting their output variables as input to the Reclassify tool. Alternatively, you can create a custom reclassification table by adding entries.
- If exposing the reclassification table as a model parameter, the reclass field must be exposed as a variable; however, it does not need to be set as a model parameter. If the field is not exposed as a variable, the classify and unique values buttons will be disabled in the model tool dialog box.
- By default, this tool will use multicore processors if available. The maximum number of cores that can be used is four.To use fewer cores, use the Parallel Processing Factor environment setting.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster to be reclassified. | Raster Layer |
| Reclass field | Field denoting the values that will be reclassified. | Field |
| Reclassification | A remap table that defines how the values will be reclassified. Working with the table and it options are as follows:The values of the input raster can be classified as ranges of values or as individual values. The table will be displayed with Start and End values or single unique values, respectively. If the input is a layer in Contents, it will import the unique values or classified breaks of the symbology.Specify the New value that will be assigned in the output raster. Only integer values are supported.Use the Classify or Unique options to generate a remap table based on the values of the input raster. The Classify option opens a dialog and allow you to specify a method from one of the Data classification methods and number of classes. The Unique option will populate the remap table using the unique values from the input dataset.The Reverse New Values option resorts the new values list (for example, 1,2,3 becomes 3,2,1).To modify the table, new entries can be added by typing in the empty cells in the table and pressing the Enter key. This will validate the new entry and create a new, empty row for subsequent input. You can delete rows by selecting one or many rows and pressing the Delete key.Use the load and save options to save a remap for later use and apply it to other input data or for quickly repeating an analysis. | Remap |
| Change missing values to NoData(Optional) | Denotes whether missing values in the reclass table retain their value or get mapped to NoData.Unchecked—Signifies that if any cell location on the input raster contains a value that is not present or reclassed in a remap table, the value should remain intact and be written for that location to the output raster. This is the default.Checked—Signifies that if any cell location on the input raster contains a value that is not present or reclassed in a remap table, the value will be reclassed to NoData for that location on the output raster. | Boolean |
| in_raster | The input raster to be reclassified. | Raster Layer |
| reclass_field | Field denoting the values that will be reclassified. | Field |
| remap | The Remap object is used to specify how to reclassify values of the input raster.There are two ways to define how the values will be reclassified in the output raster: RemapRange and RemapValue. Either ranges of input values can be assigned to a new output value, or individual values can be assigned to a new output value.The following are the forms of the remap objects.RemapRange (remapTable)RemapValue (remapTable) | Remap |
| missing_values(Optional) | Denotes whether missing values in the reclass table retain their value or get mapped to NoData.DATA—Signifies that if any cell location on the input raster contains a value that is not present or reclassed in a remap table, the value should remain intact and be written for that location to the output raster. This is the default.NODATA—Signifies that if any cell location on the input raster contains a value that is not present or reclassed in a remap table, the value will be reclassed to NoData for that location on the output raster. | Boolean |

## Code Samples

### Example 1

```python
Reclassify(in_raster, reclass_field, remap, {missing_values})
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

outReclass1 = Reclassify("landuse", "Value", 
                         RemapValue([[1,9],[2,8],[3,1],[4,6],[5,3],[6,3],[7,1]]))
outReclass1.save("C:/sapyexamples/output/landuse_rcls")

outReclass2 = Reclassify("slope_grd", "Value", 
                         RemapRange([[0,10,"NODATA"],[10,20,1],[20,30,2],
                                     [30,40,3],[40,50,4],[50,60,5],[60,75,6]]))
outReclass2.save("C:/sapyexamples/output/slope_rcls")

outReclass3 = Reclassify("pop_density", "Value", 
                         RemapRange([[10,10,1],[10,20,2],[20,25,3],
                                     [25,50,4],[50,]]), "NODATA")
outReclass3.save("C:/sapyexamples/output/popden_rcls")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

outReclass1 = Reclassify("landuse", "Value", 
                         RemapValue([[1,9],[2,8],[3,1],[4,6],[5,3],[6,3],[7,1]]))
outReclass1.save("C:/sapyexamples/output/landuse_rcls")

outReclass2 = Reclassify("slope_grd", "Value", 
                         RemapRange([[0,10,"NODATA"],[10,20,1],[20,30,2],
                                     [30,40,3],[40,50,4],[50,60,5],[60,75,6]]))
outReclass2.save("C:/sapyexamples/output/slope_rcls")

outReclass3 = Reclassify("pop_density", "Value", 
                         RemapRange([[10,10,1],[10,20,2],[20,25,3],
                                     [25,50,4],[50,]]), "NODATA")
outReclass3.save("C:/sapyexamples/output/popden_rcls")
```

### Example 4

```python
# Name: reclassify_example02.py
# Description: Reclassifies the values in a raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "landuse"
reclassField = "LANDUSE"
remap = RemapValue([["Brush/transitional", 0], ["Water", 1],["Barren land", 2]])

# Execute Reclassify
outReclassify = Reclassify(inRaster, reclassField, remap, "NODATA")

# Save the output 
outReclassify.save("C:/sapyexamples/output/outreclass02")
```

### Example 5

```python
# Name: reclassify_example02.py
# Description: Reclassifies the values in a raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "landuse"
reclassField = "LANDUSE"
remap = RemapValue([["Brush/transitional", 0], ["Water", 1],["Barren land", 2]])

# Execute Reclassify
outReclassify = Reclassify(inRaster, reclassField, remap, "NODATA")

# Save the output 
outReclassify.save("C:/sapyexamples/output/outreclass02")
```

---

## Region Group (Spatial Analyst)

## Summary

For each cell in the output, the identity of the connected region to which that cell belongs is recorded. A unique number is assigned to each region.

## Usage

- In general, the first region scanned receives the value one, the second two, and so on, until all regions are assigned a value. The scan moves from left to right, top to bottom. The values assigned to the output zones are based on when they are encountered in the scanning process.
- There are two parameters that control how connectivity between regions is established. The Number of neighbors to use parameter determines the geometry of the connectivity, either as orthogonal (four way) only, or as diagonal as well as orthogonal (eight way). The Zone grouping method parameter determines which cell values are considered when evaluating connectivity.
- By default, the Add link field to output (ADD_LINK in Python) parameter is enabled. This will create a LINK field in the attribute table of the output raster, which retains the original zone value for each cell from the input raster.This parameter only applies when the Zone grouping method (zone_connectivity in Python) parameter is set to Within. If it is set to Cross, the attribute table of the output raster will only contain the usual Value and Count fields.
- When available, the LINK field allows you to trace the parentage of each newly created region back to the original input zone values, to be used for additional analysis.For example, the attribute table for the output raster shown in the illustration above is the following:
- If the Mask environment is set, the spatial configuration and the number of regions may be altered in the output raster.
- Cell locations that contain the excluded value receive zero on the output so that these zones are not confused with existing NoData cell locations. Since the numbering begins with the value 1, the cells that are excluded from the regroup are considered background. These background cells can be reclassed or manipulated in the same way as any other value.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster for which unique connected regions of cells will be identified.It must be of integer type. | Raster Layer |
| Number of neighbors to use(Optional) | Specifies the number of neighboring cells to use when evaluating connectivity between cells that define a region.Four—Connectivity is evaluated for the four nearest (orthogonal) neighbors of each input cell. Only the cells with the same value that share at least one side will contribute to an individual region. If two cells with the same value are diagonal from one another, they are not considered connected. This is the default.Eight—Connectivity is evaluated for the eight nearest neighbors (both orthogonal and diagonal) of each input cell. Cells with the same value that are connected either along a common edge or corner to each other will contribute to an individual region. | String |
| Zone grouping method(Optional) | Defines which cell values should be considered when testing for connectivity.Within—Connectivity for a region is evaluated for input cells that are part of the same zone (cell value). The only cells that can be grouped are cells from the same zone that meet the spatial requirements of connectivity specified by the Number of neighbors to use parameter (four or eight). This is the default.Cross—Connectivity for a region is evaluated between cells of any value, except for the zone cells identified to be excluded by the Excluded value parameter, and subject to the spatial requirements specified by the Number of neighbors to use parameter. Groupings of regions in the input that are separated from other groupings by a buffer of NoData cells will be processed independently from each other. | String |
| Add link field to output(Optional) | Specifies whether a link field will be added to the table of the output when the Zone grouping method parameter is set to Within. It is ignored if that parameter is set to Cross.Checked—A LINK field will be added to the table of the output raster. This field stores the value of the zone to which the cells of each region in the output belong, according to the connectivity rule defined in the Number of neighbors to use parameter. This is the default.Unchecked—A LINK field will not be added. The attribute table for the output raster will only contain the Value and Count fields. | Boolean |
| Excluded value(Optional) | A value that excludes all cells of that zone from the connectivity evaluation. If a cell location contains the value, no spatial connectivity will be evaluated, regardless of how the number of neighbors is specified. Cells with the excluded value will be treated in a similar way to NoData cells, and are eliminated from consideration in the operation. Input cells that contain the excluded value will receive 0 on the output raster. The excluded value is similar to the concept of a background value.By default, there is no value defined for this parameter, which means that all of the input cells will be considered in the operation. | Long |
| in_raster | The input raster for which unique connected regions of cells will be identified.It must be of integer type. | Raster Layer |
| number_neighbors(Optional) | Specifies the number of neighboring cells to use when evaluating connectivity between cells that define a region.FOUR—Connectivity is evaluated for the four nearest (orthogonal) neighbors of each input cell. Only the cells with the same value that share at least one side will contribute to an individual region. If two cells with the same value are diagonal from one another, they are not considered connected. This is the default.EIGHT—Connectivity is evaluated for the eight nearest neighbors (both orthogonal and diagonal) of each input cell. Cells with the same value that are connected either along a common edge or corner to each other will contribute to an individual region. | String |
| zone_connectivity(Optional) | Defines which cell values should be considered when testing for connectivity.WITHIN—Connectivity for a region is evaluated for input cells that are part of the same zone (cell value). The only cells that can be grouped are cells from the same zone that meet the spatial requirements of connectivity specified by the number_neighbors parameter (four or eight). This is the default.CROSS—Connectivity for a region is evaluated between cells of any value, except for the zone cells identified to be excluded by the excluded_value parameter, and subject to the spatial requirements specified by the number_neighbors parameter. Groupings of regions in the input that are separated from other groupings by a buffer of NoData cells will be processed independently from each other. | String |
| add_link(Optional) | Specifies whether a link field will be added to the table of the output when the zone_connectivity parameter is set to WITHIN. It is ignored if that parameter is set to CROSS.ADD_LINK—A LINK field will be added to the table of the output raster. This field stores the value of the zone to which the cells of each region in the output belong according to the connectivity rule defined in the number_neighbors parameter. This is the default.NO_LINK—A LINK field will not be added. The attribute table for the output raster will only contain the Value and Count fields. | Boolean |
| excluded_value(Optional) | A value that excludes all cells of that zone from the connectivity evaluation. If a cell location contains the value, no spatial connectivity will be evaluated, regardless of how the number of neighbors is specified. Cells with the excluded value will be treated in a similar way to NoData cells, and are eliminated from consideration in the operation. Input cells that contain the excluded value will receive 0 on the output raster. The excluded value is similar to the concept of a background value.By default, there is no value defined for this parameter, which means that all of the input cells will be considered in the operation. | Long |

## Code Samples

### Example 1

```python
RegionGroup(in_raster, {number_neighbors}, {zone_connectivity}, {add_link}, {excluded_value})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRgnGrp = RegionGroup("land", "EIGHT", "", "", 5)
outRgnGrp.save("c:/sapyexamples/output/reggrp_ex5")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRgnGrp = RegionGroup("land", "EIGHT", "", "", 5)
outRgnGrp.save("c:/sapyexamples/output/reggrp_ex5")
```

### Example 4

```python
# Name: RegionGroup_Ex_02.py
# Description: Records, for each cell in the output, the
#              identity of the connected region to which 
#              it belongs within the Analysis window. A 
#              unique number is assigned to each region.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"
valToIgnore = 5

# Execute RegionGroup
outRegionGrp = RegionGroup(inRaster, "EIGHT", "CROSS", 
                           "NO_LINK", valToIgnore)

# Save the output 
outRegionGrp.save("C:/sapyexamples/output/reggrpout")
```

### Example 5

```python
# Name: RegionGroup_Ex_02.py
# Description: Records, for each cell in the output, the
#              identity of the connected region to which 
#              it belongs within the Analysis window. A 
#              unique number is assigned to each region.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"
valToIgnore = 5

# Execute RegionGroup
outRegionGrp = RegionGroup(inRaster, "EIGHT", "CROSS", 
                           "NO_LINK", valToIgnore)

# Save the output 
outRegionGrp.save("C:/sapyexamples/output/reggrpout")
```

---

## Remove Raster Segment Tiling Artifacts (Spatial Analyst)

## Summary

Corrects segments or objects cut by tile boundaries during the segmentation process performed as a raster function. This tool is helpful for some regional processes, such as image segmentation, that have inconsistencies near image tile boundaries.

## Usage

- This tool can be used with the Generate Raster from Raster Function geoprocessing tool, which allows you to use the segmentation raster function in a parallel processing environment and write the output to disk.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Segmented RGB Or Gray Raster | Select the segmented raster with the tiling artifacts that you want to remove. | Raster Dataset; Mosaic Dataset; Raster Layer; Mosaic Layer; Image Service; String |
| Tile width used for segmentation(Optional) | Specify the tile width from Segment Mean Shift. If left blank, the default is 512 pixels. | Long |
| Tile height used for segmentation(Optional) | Specify the tile height from Segment Mean Shift. If left blank, the default is 512 pixels. | Long |
| in_segmented_raster | Select the segmented raster with the tiling artifacts that you want to remove. | Raster Dataset; Mosaic Dataset; Raster Layer; Mosaic Layer; Image Service; String |
| tileSizeX(Optional) | Specify the tile width from Segment Mean Shift. If left blank, the default is 512 pixels. | Long |
| tileSizeY(Optional) | Specify the tile height from Segment Mean Shift. If left blank, the default is 512 pixels. | Long |

## Code Samples

### Example 1

```python
RemoveRasterSegmentTilingArtifacts(in_segmented_raster, {tileSizeX}, {tileSizeY})
```

### Example 2

```python
import arcpy
from arcpy.sa import *

refined_seg_raster = arcpy.sa.RemoveRasterSegmentTilingArtifacts("C:/test/segmented_raster.tif","512","512")
refined_seg_raster.save("C:/test/refined_segmented_raster.tif")
```

### Example 3

```python
import arcpy
from arcpy.sa import *

refined_seg_raster = arcpy.sa.RemoveRasterSegmentTilingArtifacts("C:/test/segmented_raster.tif","512","512")
refined_seg_raster.save("C:/test/refined_segmented_raster.tif")
```

### Example 4

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Set local variables
inRaster = "C:/test/segmented_raster.tif"
tile_width = "512"
tile_height = "512"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute 
refined_seg_raster = arcpy.sa.RemoveRasterSegmentTilingArtifacts(inRaster, tile_width, tile_height)

# Save the output 
refined_seg_raster.save("C:/test/refined_segmented_raster.tif")
```

### Example 5

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Set local variables
inRaster = "C:/test/segmented_raster.tif"
tile_width = "512"
tile_height = "512"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute 
refined_seg_raster = arcpy.sa.RemoveRasterSegmentTilingArtifacts(inRaster, tile_width, tile_height)

# Save the output 
refined_seg_raster.save("C:/test/refined_segmented_raster.tif")
```

---

## Rescale by Function (Spatial Analyst)

## Summary

Rescales the input raster values by applying a selected transformation function and transforming the resulting values onto a specified continuous evaluation scale.

## Usage

- The primary benefits of using this tool over other reclassification methods is the greater level of control over how the input values are reclassified: Accepts and directly processes continuous input values without requiring the values to be grouped into categories.Allows for linear and nonlinear continuous functions to be applied to the input data.Rescales the input values onto a continuous floating-point evaluation scale.
- Accepts and directly processes continuous input values without requiring the values to be grouped into categories.
- Allows for linear and nonlinear continuous functions to be applied to the input data.
- Rescales the input values onto a continuous floating-point evaluation scale.
- Reviewing the essential vocabulary for this tool may help with understanding the following explanations.
- Rescaling input data on a continuous scale is conceptually a two-step process: Apply the specified function to the input raster values.Linearly transform the function values to a specified evaluation scale. In an ascending evaluation scale, the minimum and maximum function values are set to the specified minimum (From scale) and maximum (To scale) of the evaluation scale, respectively. However, the evaluation scale can also be reversed for a descending scale.
- Apply the specified function to the input raster values.
- Linearly transform the function values to a specified evaluation scale. In an ascending evaluation scale, the minimum and maximum function values are set to the specified minimum (From scale) and maximum (To scale) of the evaluation scale, respectively. However, the evaluation scale can also be reversed for a descending scale.
- The following illustration shows an example of a Power function graph to introduce the general concepts and terminology associated with applying a transformation function.An example plot of the Power function, with a value of 2 for the exponent and an evaluation scale of 1 to 10The input data range for this example is from 3,000 to 5,000. The lowest value in the input raster is set to the Lower threshold value and the highest to the Upper threshold (seen on the x-axis), with the Power function being constrained (fit) between the thresholds. Shape-controlling parameters define the shape of the function--such as Input shift and Exponent for the Power function--allowing you to control where the function begins and how steeply it will rise. The resulting function values from the Power function are then linearly transformed to the evaluation scale to assign the output values. In the graph above, a 1 to 10 evaluation scale has been defined using the From scale and To scale parameters, as can be seen on the y-axis.
- By default, the minimum value from the Input raster is assigned to the Lower threshold value and the maximum value to the Upper threshold value.
- By default, the specified function is constrained (fit) between the lower and upper thresholds, if possible, using the Input raster values. How the function is fit between the lower and upper thresholds varies based on the particular transformation function being used in the following ways: Linear and Symmetrical Linear functions, by definition, are fitted since the minimum and maximum of the functions are set to the minimum (the lower threshold) and maximum (the upper threshold) of the Input raster.A fitted version of the Exponential and Logarithm functions is applied to the values from the Input raster.As many of the parameters as possible are derived from the Input raster (for example, the Midpoint, Factor, and Input shift) to obtain the best fit for Gaussian, Near, Small, MS Small, Large, MS Large, Power, Logistic Growth, and Logistic Decay functions.
- Linear and Symmetrical Linear functions, by definition, are fitted since the minimum and maximum of the functions are set to the minimum (the lower threshold) and maximum (the upper threshold) of the Input raster.
- A fitted version of the Exponential and Logarithm functions is applied to the values from the Input raster.
- As many of the parameters as possible are derived from the Input raster (for example, the Midpoint, Factor, and Input shift) to obtain the best fit for Gaussian, Near, Small, MS Small, Large, MS Large, Power, Logistic Growth, and Logistic Decay functions.
- When the Lower threshold and Upper threshold values are altered, the following interactions apply: If an input cell has a value lower than the Lower threshold, it will be assigned to the value set in the Value below threshold parameter.If an input cell has a value greater than the Upper threshold, it will be assigned to the value set in the Value above threshold parameter.All cell values, including and between the Lower threshold and Upper threshold, will be assigned to the corresponding evaluation scale based on the function value, f(x). In certain cases, when a shape-controlling parameter (for example, Spread and Exponent) is altered, the output raster may not have any cells assigned to the From scale or To scale values.
- If an input cell has a value lower than the Lower threshold, it will be assigned to the value set in the Value below threshold parameter.
- If an input cell has a value greater than the Upper threshold, it will be assigned to the value set in the Value above threshold parameter.
- All cell values, including and between the Lower threshold and Upper threshold, will be assigned to the corresponding evaluation scale based on the function value, f(x). In certain cases, when a shape-controlling parameter (for example, Spread and Exponent) is altered, the output raster may not have any cells assigned to the From scale or To scale values.
- By default, the parameters defining the shape of the function (for example, Spread or Base factor) will be calculated to best fit (constrain) the function to the minimum and maximum of the Input raster. However, the shape-controlling parameters can be altered to refine the fit of the function to the preference interaction of the phenomenon to the criterion values. When a value is specified for any shape-controlling parameter, the resulting function, in conjunction with the lower and upper threshold values, will be used in rescaling the Input raster values; the fitted version on the function will not be used.
- The From scale and To scale define the upper and lower values of the continuous evaluation scale. The smallest function value is assigned to the value set for From scale and the largest function value is assigned to the value set for the To scale. All function values in between are assigned to the appropriate evaluation values.
- The evaluation scale can be set to range from low to high (for example, 1 to 10) or from high to low (for example, 10 to 1).
- The Value below threshold and Value above threshold values are assigned to all cells that have an input value below and above the thresholds, respectively. These values are assigned directly to the final output raster, and these cells are not considered in the processing of the transformation function.
- In the tool dialog box, generally when the Lower threshold or Upper threshold is altered, the shape-controlling parameters—parameters defining the shape of the function, for example, Spread or Base factor—are automatically recalculated. However, when a shape-controlling parameter is altered, the Lower threshold and Upper threshold values will not change automatically, and if the Lower threshold or Upper threshold is subsequently changed, the altered shape-controlling parameter (and any other associated shape-controlling parameters) will retain the changed setting and it will not be recalculated.
- The shape-controlling parameters for the function (for example, Spread or Base factor) and the lower and upper thresholds are based on statistics calculated for the current processing extent, cell size, and snap raster environment settings. If none of these are set, the statistics associated with the full extent of the input raster are used.
- In the tool dialog box, if the input raster does not have valid statistics to calculate the shape-controlling parameters or to determine the thresholds, these parameters will be empty and you will receive a warning message. You will need to click the Calculate Statistics button to recalculate statistics to the current environment settings to populate the parameters. The Lower threshold value will default to the minimum value within the processing extent. and the Upper threshold to the maximum value, with the shape-controlling parameter values appropriately determined. You may not have valid statistics for the following conditions: The environment processing extent, cell size, or snap raster is set prior to launching the tool dialog box.The input raster does not have statistics.
- The environment processing extent, cell size, or snap raster is set prior to launching the tool dialog box.
- The input raster does not have statistics.
- In the tool dialog box, if the environment processing extent, cell size, or snap raster is changed after an input raster is entered and a function has been specified, the function parameters may be set to empty (no value in the parameter). Click the Calculate Stats button to repopulate the parameters to view the values for the new extent. If the Lower threshold, Upper threshold, or any shape-controlling parameters are changed by typing in a value, the tool will track that these parameters have been altered. If the processing extent is changed, the values for these parameters will remain as specified after clicking the Calculate Stats button.
- Multiple functions can be applied to different ranges of the input raster. To do so, the functions can be concatenated by running the Rescale by Function tool multiple times, first specifying a transformation function for a certain range of the input values and then running it again, applying another function to a different range of the values. The resulting output rasters are then combined, for example Run Rescale by Function applying a linear function to the input values from 1,500 to 3,200 and set the values above and below the thresholds to 0.Run the tool a second time on the same input raster, this time, applying an Exponential function to the values greater than 3,200 and up to 5,000, and set the values above and below the thresholds to 0.Add the two resulting output rasters together with the Plus tool.
- Run Rescale by Function applying a linear function to the input values from 1,500 to 3,200 and set the values above and below the thresholds to 0.
- Run the tool a second time on the same input raster, this time, applying an Exponential function to the values greater than 3,200 and up to 5,000, and set the values above and below the thresholds to 0.
- Add the two resulting output rasters together with the Plus tool.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster to rescale. | Raster Layer |
| Transformation function(Optional) | Specifies the continuous function to transform the values from the input raster.The transformation functions are used to specify the function to rescale the input data. A general description of each function and the default values for the functions are detailed in the table below.Exponential—Rescale input values using an exponential function.Use when the preference increases with an increase in the input values and the preference increases more rapidly as the input values become larger. Input shift—The default is derived from the input raster.Base factor—The default is derived from the input raster.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.Gaussian—Rescale input values using a Gaussian function.The midpoint of the normal distribution defines the most preferred value and is generally assigned to the To scale. Preference values decrease as the values move from the midpoint until eventually reaching the least preference with the lowest and highest input values generally being assigned to the From scale. Midpoint—The default is derived from the input raster.Spread—The default is derived from the input raster.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.Large—Used to indicate that the larger values from the input raster have higher preference.The midpoint identifies the crossover point with input values greater than the midpoint having increasing preference and values below having decreasing preference. Midpoint—The default is derived from the input raster.Spread—The default is 5.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.Linear—Rescale the input values using a linear function.When the minimum is less than the maximum the larger values are more preferred. Minimum—The default is the minimum of the input raster.Maximum—The default is the maximum of the input raster.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.Logarithm—Rescale input data using a logarithm function.Used when the preference for the lower input values increases rapidly. As the input values increase, the preference tapers off, with a further increase in the input values. Input shift—The default is derived from the input raster.Factor—The default is derived from the input raster.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.LogisticDecay—Rescale input data using a logistic decay function.Used when small input values are most preferred. As the values increase, the preferences rapidly decrease, until the preferences taper off at the larger input values. Minimum—The default is the minimum of the input raster.Maximum—The default is the maximum of the input raster.Y intercept percent—The default is 99.0.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.LogisticGrowth—Rescale input data using a logistic growth function.Used when small input values are least preferred. As the values increase, the preferences rapidly increase, until the preferences taper off at the larger input values. Minimum—The default is the minimum of the input raster.Maximum—The default is the maximum of the input raster.Y intercept percent—The default is 1.0.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.MSLarge—Rescale input data based on the mean and standard deviation, where larger values in the input raster have higher preference.The result can be similar to the Large function, depending on how the multipliers of the mean and standard deviation are defined. Mean multiplier—The default is 1.Standard deviation multiplier—The default is 1.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.MSSmall—Rescale input data based on the mean and standard deviation, where smaller values in the input raster have higher preference.The result can be similar to the Small function, depending on how the multipliers of the mean and standard deviation are defined. Mean multiplier—The default is 1.Standard deviation multiplier—The default is 1.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.Near—Use when the input values very close to the midpoint are preferred.Near is similar to the Gaussian function but decreases at a faster rate. Midpoint—The default is derived from the input raster.Spread—The default is derived from the input raster.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.Power—Rescale the input data, applying a power function using a specified exponent.Use when the preference for the input values increases rapidly, with an increase in the input values. Input shift—The default is derived from the input raster.Exponent—The default is derived from the input raster.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.Small—Use to indicate that the smaller values from the input raster have higher preference.The midpoint identifies the crossover point, with input values below the midpoint having increasing preference, and values that are greater having decreasing preference. Midpoint—The default is derived from the input raster.Spread—The default is 5.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.SymmetricLinear—Rescale input data by mirroring a linear function around the midpoint of the minimum and maximum.Use when a particular input value is the most preferred, with the preferences decreasing linearly as the input values move from the mirrored point. Minimum—The default is the minimum of the input raster.Maximum—The default is the maximum of the input raster.Lower threshold—The default is the minimum of the input raster.Value below threshold—The default is the From scale value.Upper threshold—The default is the maximum of the input raster.Value above threshold—The default is the To scale value.The default transformation is MS Small. | Transformation function |
| From scale(Optional) | The starting value of the output evaluation scale.The From scale value cannot be equal to the To scale value. The From scale can be lower or higher than the To scale (for example, from 1 to 10, or from 10 to 1).The value must be positive and it can be either an integer or double.The default is 1. | Double |
| To scale(Optional) | The ending value of the output evaluation scale.The To scale value cannot be equal to the From scale value. The To scale can be lower or higher than the From scale (for example, from 1 to 10, or from 10 to 1).The value must be positive and it can be either an integer or double.The default is 10. | Double |
| in_raster | The input raster to rescale. | Raster Layer |
| transformation_function(Optional) | Specifies the continuous function to transform the input raster.The transformation function classes are used to specify the type of transformation function.The types of transformation function classes are TfExponential, TfGaussian, TfLarge, TfLinear, TfLogarithm, TfLogisticDecay, TfLogisticGrowth, TfMSLarge, TfMSSmall, TfNear, TfPower, TfSmall, and TfSymmetricLinearWhich transformation function to use depends on which function best captures the interaction of the phenomenon's preference to the input values. To better understand how the lower and upper thresholds affect the output values, For more information on the parameters that control the thresholds, see The interaction of the lower and upper thresholds on the output values.The following are the forms of the transformation function classes: TfExponential({shift}, {baseFactor}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfGaussian({midpoint}, {spread}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfLarge({midpoint}, {spread}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfLinear({minimum}, {maximum}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfLogarithm({shift}, {factor}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfLogisticDecay({minimum}, {maximum}, {yInterceptPercent}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfLogisticGrowth({minimum}, {maximum}, {yInterceptPercent}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfMSLarge({meanMultiplier}, {STDMultiplier}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfMSSmall({meanMultiplier}, {STDMultiplier}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfNear({midpoint}, {spread}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfPower({shift}, {exponent}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfSmall({midpoint}, {spread}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})TfSymmetricLinear({minimum}, {maximum}, {lowerThreshold}, {valueBelowThreshold}, {upperThreshold}, {valueAboveThreshold})The default transformation function is TfMSSmall.The parameter defaults for the transformation functions include the following: baseFactor (for TfExponential) is derived from the input raster.exponent (for TfPower) is derived from the input raster.factor (for TfLogarithm) is derived from the input raster.lowerThreshold (for all functions) is set to the Minimum of the input raster.maximum (for TfLinear, TfLogisticDecay, TfLogisticGrowth, and TfSymmetricLinear) is set to the Maximum of the input raster.meanMultiplier (for TfMSLarge and TfMSSmall) is 1.midpoint (for TfGaussian and TfNear) is set to the midpoint of the value range of the input raster.midpoint (for TfLarge and TfSmall) is set to the mean of the input raster.minimum (for TfLinear, TfLogisticDecay, TfLogisticGrowth, and TfSymmetricLinear) is set to the Minimum of the input raster.shift (for TfExponential, TfLogarithm, and TfPower) is derived from the input raster.spread (for TfGaussian and TfNear) is derived from the input raster.spread (for TfLarge and TfSmall) is 5.STDMultiplier (for TfMSLarge and TFMSSmall) is 1.upperThreshold (for all functions) is set to the Maximum of the input raster.valueAboveThreshold (for all functions) is set to the to_scale value.valueBelowThreshold (for all functions) is set to the from_scale value.yInterceptPercent (for TfLogisticDecay) is 99.0000.yInterceptPercent (for TfLogisticGrowth) is 1.0000. | Transformation function |
| from_scale(Optional) | The starting value of the output evaluation scale.The from_scale value cannot be equal to the to_scale value. The from_scale can be lower or higher than the to_scale (for example, from 1 to 10, or from 10 to 1).The value must be positive and it can be either an integer or double.The default is 1. | Double |
| to_scale(Optional) | The ending value of the output evaluation scale.The to_scale value cannot be equal to the from_scale value. The to_scale can be lower or higher than the from_scale (for example, from 1 to 10, or from 10 to 1).The value must be positive and it can be either an integer or double.The default is 10. | Double |

## Code Samples

### Example 1

```python
RescaleByFunction(in_raster, {transformation_function}, {from_scale}, {to_scale})
```

### Example 2

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "c:/sapyexamples/data"
outRescale = RescaleByFunction("elevation", TfMSSmall(1.25, 1.5, "#", "#", 4000, "NoData"), 1, 10)
outRescale.save("c:/sapyexamples/rescaletfms1")
```

### Example 3

```python
import arcpy
from arcpy.sa import *
from arcpy import env
env.workspace = "c:/sapyexamples/data"
outRescale = RescaleByFunction("elevation", TfMSSmall(1.25, 1.5, "#", "#", 4000, "NoData"), 1, 10)
outRescale.save("c:/sapyexamples/rescaletfms1")
```

### Example 4

```python
# Name: TfMSSmall_Ex_02.py
# Description: Rescales input raster data using a MSSmall function and
#     transforms the function values onto a specified evaluation scale. 
# Requirements: Spatial Analyst Extension
# Author: esri

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"

# Create the TfMSSmall object
meanmult = 1.25
stdmult = 1.5
lowerthresh = "#"
valbelowthresh = "10"
upperthresh = 4000
valabovethresh = "NoData"
myTfFunction = TfMSSmall(meanmult, stdmult, lowerthresh, valbelowthresh, upperthresh, valabovethresh)

# Set evaluation scale
fromscale = 1
toscale = 10

# Execute RescaleByFunction
outRescale = RescaleByFunction(inRaster, myTfFunction, fromscale, toscale)

# Save the output
outRescale.save("c:/sapyexamples/rescaletfms2")
```

### Example 5

```python
# Name: TfMSSmall_Ex_02.py
# Description: Rescales input raster data using a MSSmall function and
#     transforms the function values onto a specified evaluation scale. 
# Requirements: Spatial Analyst Extension
# Author: esri

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"

# Create the TfMSSmall object
meanmult = 1.25
stdmult = 1.5
lowerthresh = "#"
valbelowthresh = "10"
upperthresh = 4000
valabovethresh = "NoData"
myTfFunction = TfMSSmall(meanmult, stdmult, lowerthresh, valbelowthresh, upperthresh, valabovethresh)

# Set evaluation scale
fromscale = 1
toscale = 10

# Execute RescaleByFunction
outRescale = RescaleByFunction(inRaster, myTfFunction, fromscale, toscale)

# Save the output
outRescale.save("c:/sapyexamples/rescaletfms2")
```

---

## Round Down (Spatial Analyst)

## Summary

Returns the next lower integer value, just represented as a floating point, for each cell in a raster.

## Usage

- Input values can be positive or negative.
- The output raster from this tool is always floating-point type, regardless of the input value type.
- If the input number has any values to the right of the decimal point, the output will be assigned the next lower integer value, but will be represented as a floating point number with no decimal portion. For example: Input Output 5.3 5.0 4.9 4.0 3.0 3.0 6.5 6.0 -0.2 -1.0 -2.8 -3.0
- There is a difference between the Int tool and the Round Down tool. For example, given the following two values, Int always truncates the number: 1.5 becomes 1-1.5 becomes -1For the same two values, Round Down returns the following: 1.5 becomes 1.0-1.5 becomes -2.0 Another difference is that Round Down outputs floating-point values, while Int only outputs integer values.
- 1.5 becomes 1
- -1.5 becomes -1
- 1.5 becomes 1.0
- -1.5 becomes -2.0
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input values to be rounded down.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input values to be rounded down.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Input   Output
     5.3     5.0
     4.9     4.0
     3.0     3.0
     6.5     6.0
    -0.2    -1.0
    -2.8    -3.0
```

### Example 2

```python
RoundDown(in_raster_or_constant)
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRoundDown = RoundDown("gwhead")
outRoundDown.save("C:/sapyexamples/output/outrd")
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRoundDown = RoundDown("gwhead")
outRoundDown.save("C:/sapyexamples/output/outrd")
```

### Example 5

```python
# Name: RoundDown_Ex_02.py
# Description: Returns the next lower whole number for each cell in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "gwhead"

# Execute RoundDown
outRoundDRaster = RoundDown(inRaster)

# Save the output 
outRoundDRaster.save("C:/sapyexamples/output/outrounddown")
```

### Example 6

```python
# Name: RoundDown_Ex_02.py
# Description: Returns the next lower whole number for each cell in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "gwhead"

# Execute RoundDown
outRoundDRaster = RoundDown(inRaster)

# Save the output 
outRoundDRaster.save("C:/sapyexamples/output/outrounddown")
```

---

## Round Up (Spatial Analyst)

## Summary

Returns the next higher integer value, just represented as a floating point, for each cell in a raster.

## Usage

- Input values can be positive or negative.
- The output raster from this tool is always floating-point type, regardless of the input value type.
- If the input number has any values to the right of the decimal point, the output will be assigned the next higher integer value, but will be represented as a floating point number with no decimal portion. For example: Input Output 5.3 6.0 4.9 5.0 3.0 3.0 6.5 7.0 -0.2 0.0 -2.8 -2.0
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input values to be rounded up.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input values to be rounded up.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Input   Output
    5.3     6.0
    4.9     5.0
    3.0     3.0
    6.5     7.0
   -0.2     0.0
   -2.8    -2.0
```

### Example 2

```python
RoundUp(in_raster_or_constant)
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRoundUp = RoundUp("gwhead")
outRoundUp.save("C:/sapyexamples/output/outru")
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outRoundUp = RoundUp("gwhead")
outRoundUp.save("C:/sapyexamples/output/outru")
```

### Example 5

```python
# Name: RoundUp_Ex_02.py
# Description: Returns the next higher whole number for each cell
#              in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "gwhead"

# Execute RoundUp
outRoundURaster = RoundUp(inRaster)

# Save the output 
outRoundURaster.save("C:/sapyexamples/output/outroundup")
```

### Example 6

```python
# Name: RoundUp_Ex_02.py
# Description: Returns the next higher whole number for each cell
#              in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "gwhead"

# Execute RoundUp
outRoundURaster = RoundUp(inRaster)

# Save the output 
outRoundURaster.save("C:/sapyexamples/output/outroundup")
```

---

## Sample (Spatial Analyst)

## Summary

Creates a table or a point feature class that shows the values of cells from a raster, or a set of rasters, for defined locations. The locations are defined by raster cells, points, polylines, or polygons.

## Usage

- Cell values will be extracted from all Input rasters (in_rasters in Python) at each location. A table or a point feature class will be created with fields containing the cell values for each input raster.
- Additional attributes from the input raster table, if any, will not be included in the output table.
- Any combination of rasters (single band or multiband) can be specified for the input rasters. The structure of the output table changes automatically when the input rasters are multidimensional. When a multiband raster is specified as one of the Input rasters, all of the bands in that input will be used.
- The following can be used as Input location raster or features (in_location_data in Python) parameter values: Raster—Cells containing valid values (not NoData) will be used to extract the cell values from all input rasters, and the center of the cell will be used as point locations.Point—Values will be sampled at each point location.Polyline or polygon—The mean value of all cells that intersect each polyline or polygon will be calculated if the input is a two-dimensional raster or multiple rasters. Additional statistic types can be specified if the input is a multidimensional raster and is processed as multidimensional.
- Raster—Cells containing valid values (not NoData) will be used to extract the cell values from all input rasters, and the center of the cell will be used as point locations.
- Point—Values will be sampled at each point location.
- Polyline or polygon—The mean value of all cells that intersect each polyline or polygon will be calculated if the input is a two-dimensional raster or multiple rasters. Additional statistic types can be specified if the input is a multidimensional raster and is processed as multidimensional.
- Locations that extract values from NoData cells in the input raster will be given a <null> value in the output table. For shapefiles, because null fields are not supported, NoData cells are instead represented in the table with a value of -9999.
- The Input rasters are sampled in their native spatial reference and resolution. If there are multiple input rasters with different spatial references, the input locations are first projected to the spatial reference of each raster individually; then the values are extracted. This means that while the input rasters will not honor any analysis environment settings, the appropriate environments will be applied to the input locations.
- By default, the spatial reference of the x,y coordinates in the Output table or feature class (out_table in Python) parameter will be the same as that of the Input location raster or features parameter values, unless a different one is specified in the Output Coordinate System environment. If the spatial reference of the input locations data is unknown, the spatial reference of the x,y coordinates is also unknown.The spatial reference of the x,y coordinates is reported at the end of tool execution as a geoprocessing message.
- If the Input location raster or features is a point feature class with no spatial index, a warning will be issued. To improve tool performance for an input with a large number of points, create a spatial index. See Add spatial index for more information.
- The tool will fail to execute with multipoint features. To perform analysis with multipoint features, convert them to single point features before using them in the extraction tool. See processing multipoint data for more information.
- When the Resampling technique parameter is set to Nearest (resampling_type = "NEAREST" in Python), the field type in the output table will match that of the raster type. When the resampling option is Bilinear or Cubic, the field type will always be floating point to maintain the precision of the interpolated values.
- A field will be added to the output table to store the values specified in the Unique ID field parameter (unique_id_field in Python). By default, the name of the field is the same as the input location dataset name. It is recommended that you use a field containing unique values as the identifier for each location for further analysis.
- If the Process as multidimensional parameter is unchecked (process_as_multidimensional = "CURRENT_SLICE" in Python), the following conditions will apply: If the input is a multidimensional raster, only the current slice will be sampled.If the input is a multivariate raster, only the current variable will be sampled.
- If the input is a multidimensional raster, only the current slice will be sampled.
- If the input is a multivariate raster, only the current variable will be sampled.
- If the Process as multidimensional parameter is checked (process_as_multidimensional = "ALL_SLICES" in Python), the following conditions will apply: If the input is a multidimensional raster, all the slices will be sampled.If the input is a multivariate raster, all the variables will be sampled.If the input is a multidimensional raster with multiple variables, all slices from all variables will be sampled. The variables must have the same dimensions.
- If the input is a multidimensional raster, all the slices will be sampled.
- If the input is a multivariate raster, all the variables will be sampled.
- If the input is a multidimensional raster with multiple variables, all slices from all variables will be sampled. The variables must have the same dimensions.
- If the Process as multidimensional parameter is checked (process_as_multidimensional = "ALL_SLICES" in Python), the appropriate scenario from the following will apply: The Acquisition information of location data parameter (acquisition_definition in Python) will be used to specify the subset of the input raster to use for sampling.When dimension, start value, and end value are specified, the slices within the start and end values are processed. The default end value is the maximum dimension value. For a time dimension, specify the value in the standard format. For other dimensions, specify the value in the same unit as that of the input raster.When dimension, start field, and end field are specified (start field and end field come from the location data), values from these fields are used to specify a subset of the input raster while sampling values at that location.The Relative value or days before and Relative value or days after values can be used to specify a subset relative to the start value, in which the before value specifies the beginning of the subset and the after value specifies the end of the subset. The time values are specified in days and the other dimension values are specified in the same unit as that of the input raster.The Statistic type parameter (statistics_type in Python) aggregates the values of the Input raster parameter as specified by the subset in the Acquisition information of location data parameter.If the Column-wise layout parameter is unchecked (layout = "ROW_WISE" in Python), the extracted values are stored in a field with the same name as the variable. Additional fields are created to store the nonspatial dimension values with the same name as the dimension.If the Column-wise layout parameter is checked (layout = "COLUMN_WISE" in Python), the extracted values are stored in fields with names that follow a <variable_name>_<dimension_name>_<dimension_value> convention. Note that the Column-wise layout parameter is supported when the multidimensional raster contains only one variable, the variable has only one dimension, and each slice has a single band. Otherwise, an error message will be generated.If the multidimensional raster has multiple bands, an additional field is created for each band, which stores the value extracted from that band.Locations that extract values from NoData cells will be assigned the NoData value from the input multidimensional raster.
- The Acquisition information of location data parameter (acquisition_definition in Python) will be used to specify the subset of the input raster to use for sampling.When dimension, start value, and end value are specified, the slices within the start and end values are processed. The default end value is the maximum dimension value. For a time dimension, specify the value in the standard format. For other dimensions, specify the value in the same unit as that of the input raster.When dimension, start field, and end field are specified (start field and end field come from the location data), values from these fields are used to specify a subset of the input raster while sampling values at that location.The Relative value or days before and Relative value or days after values can be used to specify a subset relative to the start value, in which the before value specifies the beginning of the subset and the after value specifies the end of the subset. The time values are specified in days and the other dimension values are specified in the same unit as that of the input raster.
- When dimension, start value, and end value are specified, the slices within the start and end values are processed. The default end value is the maximum dimension value. For a time dimension, specify the value in the standard format. For other dimensions, specify the value in the same unit as that of the input raster.
- When dimension, start field, and end field are specified (start field and end field come from the location data), values from these fields are used to specify a subset of the input raster while sampling values at that location.
- The Relative value or days before and Relative value or days after values can be used to specify a subset relative to the start value, in which the before value specifies the beginning of the subset and the after value specifies the end of the subset. The time values are specified in days and the other dimension values are specified in the same unit as that of the input raster.
- The Statistic type parameter (statistics_type in Python) aggregates the values of the Input raster parameter as specified by the subset in the Acquisition information of location data parameter.
- If the Column-wise layout parameter is unchecked (layout = "ROW_WISE" in Python), the extracted values are stored in a field with the same name as the variable. Additional fields are created to store the nonspatial dimension values with the same name as the dimension.
- If the Column-wise layout parameter is checked (layout = "COLUMN_WISE" in Python), the extracted values are stored in fields with names that follow a <variable_name>_<dimension_name>_<dimension_value> convention. Note that the Column-wise layout parameter is supported when the multidimensional raster contains only one variable, the variable has only one dimension, and each slice has a single band. Otherwise, an error message will be generated.
- If the multidimensional raster has multiple bands, an additional field is created for each band, which stores the value extracted from that band.
- Locations that extract values from NoData cells will be assigned the NoData value from the input multidimensional raster.
- A multidimensional raster can be a netCDF raster layer, multidimensional raster layer, multidimensional mosaic dataset, multidimensional CRF, multidimensional image service, or netCDF file. You cannot browse to a netCDF file from the tool dialog box, but you can specify the path to file.
- If the Generate Feature Class parameter is checked (generate_feature_class = "FEATURE_CLASS" in Python), the output is a point feature class with the sampled values in its attribute table. The following are the possible location types with descriptions of how the values will be sampled: Raster—Points will be created using the location of the cell center.Point—A point will be created at each of the point locations.Polyline or polygon—A point will be created at each polygon or polyline centroid.
- Raster—Points will be created using the location of the cell center.
- Point—A point will be created at each of the point locations.
- Polyline or polygon—A point will be created at each polygon or polyline centroid.
- The spatial reference of the output feature class is the same as that of the Input location raster or features, unless it is specified in the Output Coordinate System environment.
- The Parallel Processing Factor environment is only supported when the Process as multidimensional parameter is checked.
- If a feature is specified in the Mask environment, an internal raster is created using the minimum cell size of the input rasters. During extraction, the internal mask raster is again resampled to the cell size of each input raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input rasters | The rasters with values that will be sampled based on the input location data.The Process as multidimensional parameter is only available when the input is a single, multidimensional raster. | Raster Layer |
| Input location raster or features | The data identifying positions where a sample will be taken.The input can be a raster or a feature class. | Raster Layer; Feature Layer |
| Output table or feature class | The output table or feature class containing the sampled cell values.The output format is determined by the output location and path. By default, the output will be a geodatabase table or a geodatabase feature class in a geodatabase workspace or a dBASE table or a shapefile feature class in a folder workspace.The output data type to generate a table or a feature class is controlled by the Generate feature class parameter. | Table; Point feature class |
| Resampling technique(Optional) | The resampling algorithm that will be used to sample a raster to determine how the values will be obtained from the raster.Nearest—Nearest neighbor assignment will be used. This is the default.Bilinear—Bilinear interpolation will be used.Cubic—Cubic convolution will be used. | String |
| Unique ID field(Optional) | A field containing a different value for every location or feature in the input location raster or features. | Field |
| Process as multidimensional(Optional) | Specifies how the input rasters will be processed.This parameter is only available when the input is a single, multidimensional raster.Unchecked—Samples will be processed from the current slice of a multidimensional dataset. This is the default.Checked—Samples will be processed for all dimensions (such as time or depth) of a multidimensional dataset. | Boolean |
| Acquisition information of location data(Optional) | Specifies the time, depth, or other acquisition data associated with the location features.Only the following combinations are supported: Dimension + Start field or valueDimension + Start field or value + End field or valueDimension + Start field or value + Relative value or days before + Relative value or days after Relative value or days before and Relative value or days after only support nonnegative values.Statistics will be calculated using the Statistics type parameter for variables within this dimension range. | Value Table |
| Statistics type(Optional) | Specifies the statistic type to be calculated.Minimum—The minimum value within the specified range will be calculated.Maximum—The maximum value within the specified range will be calculated.Median—The median value within the specified range will be calculated.Mean—The average for the specified range will be calculated. Sum—The total value of the variables within the specified range will be calculated.Majority—The value that occurs most frequently will be calculated.Minority—The value that occurs least frequently will be calculated.Standard deviation—The standard deviation will be calculated.Percentile—A defined percentile within the specified range will be calculated. | String |
| Percentile value(Optional) | This value can range from 0 to 100. The default is 90. | Double |
| Buffer distance field or value(Optional) | The distance around the location data features. The buffer distance is specified in the linear unit of the location feature's spatial reference. If the feature uses a geographic reference, the unit will be degrees.Statistics will be calculated within this buffer area. | Double; Field |
| Column-wise layout(Optional) | Specifies whether sampled values will appear in rows or columns in the output table.Unchecked—Sampled values will appear in separate rows in the output table. This is the default.Checked—Sampled values will appear in separate columns in the output table. This option is only valid when the input multidimensional raster contains one variable and one dimension, and each slice is a single-band raster. | Boolean |
| Generate feature class(Optional) | Specifies whether a point feature class with sampled values in its attribute table or a table with sampled values will be generated.Unchecked—A table with sampled values will be generated. This is the default.Checked—A point feature class with sampled values in its attribute table will be generated. | Boolean |
| in_rasters[in_raster,...] | The rasters with values that will be sampled based on the input location data. The process_as_multidimensional parameter is only supported when the input is a single, multidimensional raster. | Raster Layer |
| in_location_data | The data identifying positions where a sample will be taken.The input can be a raster or a feature class. | Raster Layer; Feature Layer |
| out_table | The output table or feature class containing the sampled cell values.The output format is determined by the output location and path. By default, the output will be a geodatabase table or a geodatabase feature class in a geodatabase workspace or a dBASE table or a shapefile feature class in a folder workspace.The output data type to generate a table or a feature class is controlled by the generate_feature_class parameter. | Table; Point feature class |
| resampling_type(Optional) | The resampling algorithm that will be used to sample a raster to determine how the values will be obtained from the raster. NEAREST—Nearest neighbor assignment will be used. This is the default.BILINEAR—Bilinear interpolation will be used.CUBIC—Cubic convolution will be used. | String |
| unique_id_field(Optional) | A field containing a different value for every location or feature in the input location raster or features. | Field |
| process_as_multidimensional(Optional) | Specifies how the input rasters will be processed.This parameter is only available when the input is a single, multidimensional raster.ALL_SLICES—Samples will be processed for all dimensions (such as time or depth) of a multidimensional dataset.CURRENT_SLICE—Samples will be processed from the current slice of a multidimensional dataset. This is the default. | Boolean |
| acquisition_definition[acquisition_definition,...](Optional) | Specifies the time, depth, or other acquisition data associated with the location features.Only the following combinations are supported: Dimension + Start field or valueDimension + Start field or value + End field or valueDimension + Start field or value + Relative value or days before + Relative value or days after Relative value or days before and Relative value or days after only support nonnegative values. Statistics will be calculated using the statistics_type parameter for variables within this dimension range. | Value Table |
| statistics_type(Optional) | Specifies the statistic type to be calculated.MINIMUM—The minimum value within the specified range will be calculated.MAXIMUM—The maximum value within the specified range will be calculated.MEDIAN—The median value within the specified range will be calculated.MEAN—The average for the specified range will be calculated. SUM—The total value of the variables within the specified range will be calculated.MAJORITY—The value that occurs most frequently will be calculated.MINORITY—The value that occurs least frequently will be calculated.STD—The standard deviation will be calculated.PERCENTILE—A defined percentile within the specified range will be calculated. | String |
| percentile_value(Optional) | The percentile to calculate when the Statistics Type parameter is set to Percentile. The percentile to calculate when the statistics_type parameter is set to PERCENTILE.This value can range from 0 to 100. The default is 90. | Double |
| buffer_distance(Optional) | The distance around the location data features. The buffer distance is specified in the linear unit of the location feature's spatial reference. If the feature uses a geographic reference, the unit will be degrees.Statistics will be calculated within this buffer area. | Double; Field |
| layout(Optional) | Specifies whether sampled values will appear in rows or columns in the output table.ROW_WISE—Sampled values will appear in separate rows in the output table. This is the default.COLUMN_WISE—Sampled values will appear in separate columns in the output table. This option is only valid when the input multidimensional raster contains one variable and one dimension, and each slice is a single-band raster. | Boolean |
| generate_feature_class(Optional) | Specifies whether a point feature class with sampled values in its attribute table or a table with sampled values will be generated.TABLE—A table with sampled values will be generated. This is the default.FEATURE_CLASS—A point feature class with sampled values in its attribute table will be generated. | Boolean |

## Code Samples

### Example 1

```python
Sample(in_rasters, in_location_data, out_table, {resampling_type}, {unique_id_field}, {process_as_multidimensional}, {acquisition_definition}, {statistics_type}, {percentile_value}, {buffer_distance}, {layout}, {generate_feature_class})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
Sample(["elevation", "costraster"], "observers.shp",
       "c:/sapyexamples/output/samptable.dbf")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
Sample(["elevation", "costraster"], "observers.shp",
       "c:/sapyexamples/output/samptable.dbf")
```

### Example 4

```python
# Name: Sample_Ex_02.py
# Description: Creates a feature class that shows the values of cells from 
#              rasters, for defined locations. 
#              The locations are defined by a set of points.
#              Sampling method is Bilinear.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasters = ["elevation",
             "costraster"]
locations = "observers.shp"
outFeatureClass = "c:/sapyexamples/output/samptable02.shp"
sampMethod = "BILINEAR"
generate_feature_class = "FEATURE_CLASS"

# Execute Sample
Sample(inRasters, locations, outFeatureClass, sampMethod, "", "", "", "", "", "", "", generate_feature_class)
```

### Example 5

```python
# Name: Sample_Ex_02.py
# Description: Creates a feature class that shows the values of cells from 
#              rasters, for defined locations. 
#              The locations are defined by a set of points.
#              Sampling method is Bilinear.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasters = ["elevation",
             "costraster"]
locations = "observers.shp"
outFeatureClass = "c:/sapyexamples/output/samptable02.shp"
sampMethod = "BILINEAR"
generate_feature_class = "FEATURE_CLASS"

# Execute Sample
Sample(inRasters, locations, outFeatureClass, sampMethod, "", "", "", "", "", "", "", generate_feature_class)
```

### Example 6

```python
# Name: Sample_Ex_03.py
# Description: Creates a table that shows the temperature values from 
#              a multidimensional raster, for defined locations. 
#              Each temperature has a unique OBSERVATION_ID
#              Sampling method is Bilinear
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasters = "temperature_1990_2019.nc"
locations = "observers.shp"
outTable = "C:/sapyexamples/output/samptable_03.dbf"
sampMethod = "BILINEAR"
uniqueIDField = "OBSERVATION_ID"
process_as_multidimensional = True

# Execute Sample
# the temperature value at each slice in temperature_1990_2019.nc will be extracted for each point
Sample(inRasters, locations, outTable, sampMethod, uniqueIDField, process_as_multidimensional)
```

### Example 7

```python
# Name: Sample_Ex_03.py
# Description: Creates a table that shows the temperature values from 
#              a multidimensional raster, for defined locations. 
#              Each temperature has a unique OBSERVATION_ID
#              Sampling method is Bilinear
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasters = "temperature_1990_2019.nc"
locations = "observers.shp"
outTable = "C:/sapyexamples/output/samptable_03.dbf"
sampMethod = "BILINEAR"
uniqueIDField = "OBSERVATION_ID"
process_as_multidimensional = True

# Execute Sample
# the temperature value at each slice in temperature_1990_2019.nc will be extracted for each point
Sample(inRasters, locations, outTable, sampMethod, uniqueIDField, process_as_multidimensional)
```

### Example 8

```python
# Name: Sample_Ex_04.py
# Description: Creates a table that shows, for each polygon, the maximum temperature value within the period [1999-01-01T00:00:00 , 2019-01-01-T00:00:00]
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasters = "temperature_1990_2019.nc"
locations = "observers_polygons.shp"
outTable = "C:/sapyexamples/output/samptable_04.dbf"
sampMethod = "BILINEAR"
uniqueIDField = "OBSERVATIONID"
process_as_multidimensional = True
# StdTime in acquisition_definition is the name of the dimension in inRasters that are related with time
# 1999-01-01T00:00:00 in acquisition_definition is the start time of the period
# 2019-01-01-T00:00:00 in acquisition_definition is the end time of the period
acquisition_definition = "StdTime 1999-01-01T00:00:00 2019-01-01-T00:00:00"
statistic_method = "MAXIMUM"

# Execute Sample
# for each polygon in locations, the maximum temperature value within the period [1999-01-01T00:00:00 , 2019-01-01-T00:00:00] will be extracted
Sample(inRasters, locations, outTable, sampMethod, uniqueIDField, process_as_multidimensional, acquisition_definition, statistic_method)
```

### Example 9

```python
# Name: Sample_Ex_04.py
# Description: Creates a table that shows, for each polygon, the maximum temperature value within the period [1999-01-01T00:00:00 , 2019-01-01-T00:00:00]
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRasters = "temperature_1990_2019.nc"
locations = "observers_polygons.shp"
outTable = "C:/sapyexamples/output/samptable_04.dbf"
sampMethod = "BILINEAR"
uniqueIDField = "OBSERVATIONID"
process_as_multidimensional = True
# StdTime in acquisition_definition is the name of the dimension in inRasters that are related with time
# 1999-01-01T00:00:00 in acquisition_definition is the start time of the period
# 2019-01-01-T00:00:00 in acquisition_definition is the end time of the period
acquisition_definition = "StdTime 1999-01-01T00:00:00 2019-01-01-T00:00:00"
statistic_method = "MAXIMUM"

# Execute Sample
# for each polygon in locations, the maximum temperature value within the period [1999-01-01T00:00:00 , 2019-01-01-T00:00:00] will be extracted
Sample(inRasters, locations, outTable, sampMethod, uniqueIDField, process_as_multidimensional, acquisition_definition, statistic_method)
```

---

## Segment Mean Shift (Spatial Analyst)

## Summary

Groups adjacent pixels that have similar spectral characteristics into segments.

## Usage

- The input can be any Esri-supported raster, with any valid bit depth.
- The Band Index parameter is a list of three bands, separated by a space delimiter.
- To achieve optimal results, use the Symbology tab in the dataset properties to interactively stretch your Input Raster so the features you want to classify are apparent. Then use these optimal settings in the Stretch raster function to enhance your imagery for optimum results, and specify the Output Pixel Type as 8 bit unsigned from the General tab.The output layer from the previously executed Stretch raster function can be the Input Raster for the Segment Mean Shift tool.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The raster dataset to segment. This can be a multispectral or grayscale image. | Mosaic Layer; Raster Layer |
| Spectral Detail(Optional) | The level of importance given to the spectral differences of features in the imagery.Valid values range from 1.0 to 20.0. A higher value is appropriate when there are features to classify separately that have similar spectral characteristics. Smaller values create spectrally smoother outputs. For example, with higher spectral detail in a forested scene, there will be greater discrimination between the tree species. | Double |
| Spatial Detail(Optional) | The level of importance given to the proximity between features in the imagery.Valid values range from 1.0 to 20. A higher value is appropriate for a scene in which the features of interest are small and clustered together. Smaller values create spatially smoother outputs. For example, in an urban scene, impervious surfaces can be classified using a smaller spatial detail, or buildings and roads can be classified as separate classes using a higher spatial detail. | Long |
| Minimum Segment Size In Pixels(Optional) | The minimum size of a segment. Merge segments smaller than this size with their best fitting neighbor segment. This is related to the minimum mapping unit for your project.Units are in pixels. | Long |
| Band Indexes(Optional) | The bands that will be used to segment the imagery, separated by a space. If no band indexes are specified, they are determined by the following criteria: If the raster has only 3 bands, those 3 bands are used If the raster has more than 3 bands, the tool assigns the red, green, and blue bands according to the raster's properties.If the red, green, and blue bands are not identified in the raster dataset's properties, bands 1, 2, and 3 are used.The band order will not change the result.Select bands that offer the most differentiation between the features of interest. | String |
| Maximum Segment Size In Pixels(Optional) | The maximum size of a segment. Segments that are larger than the specified size will be divided. Use this parameter to prevent artifacts in the output raster resulting from large segments.Units are in pixels.The default value is -1, meaning there is no limit on the segment size. | Long |
| in_raster | The raster dataset to segment. This can be a multispectral or grayscale image. | Mosaic Layer; Raster Layer |
| spectral_detail(Optional) | The level of importance given to the spectral differences of features in the imagery.Valid values range from 1.0 to 20.0. A higher value is appropriate when there are features to classify separately that have similar spectral characteristics. Smaller values create spectrally smoother outputs. For example, with higher spectral detail in a forested scene, there will be greater discrimination between the tree species. | Double |
| spatial_detail(Optional) | The level of importance given to the proximity between features in the imagery.Valid values range from 1.0 to 20. A higher value is appropriate for a scene in which the features of interest are small and clustered together. Smaller values create spatially smoother outputs. For example, in an urban scene, impervious surfaces can be classified using a smaller spatial detail, or buildings and roads can be classified as separate classes using a higher spatial detail. | Long |
| min_segment_size(Optional) | The minimum size of a segment. Merge segments smaller than this size with their best fitting neighbor segment. This is related to the minimum mapping unit for your project.Units are in pixels. | Long |
| band_indexes(Optional) | The bands that will be used to segment the imagery, separated by a space. If no band indexes are specified, they are determined by the following criteria: If the raster has only 3 bands, those 3 bands are used If the raster has more than 3 bands, the tool assigns the red, green, and blue bands according to the raster's properties.If the red, green, and blue bands are not identified in the raster dataset's properties, bands 1, 2, and 3 are used.The band order will not change the result.Select bands that offer the most differentiation between the features of interest. | String |
| max_segment_size(Optional) | The maximum size of a segment. Segments that are larger than the specified size will be divided. Use this parameter to prevent artifacts in the output raster resulting from large segments.Units are in pixels.The default value is -1, meaning there is no limit on the segment size. | Long |

## Code Samples

### Example 1

```python
SegmentMeanShift(in_raster, {spectral_detail}, {spatial_detail}, {min_segment_size}, {band_indexes}, {max_segment_size})
```

### Example 2

```python
import arcpy
from arcpy.sa import *

seg_raster = SegmentMeanShift("c:/test/moncton.tif", "15", "10", "20", "4 3 2")

seg_raster.save("c:/test/moncton_seg.tif")
```

### Example 3

```python
import arcpy
from arcpy.sa import *

seg_raster = SegmentMeanShift("c:/test/moncton.tif", "15", "10", "20", "4 3 2")

seg_raster.save("c:/test/moncton_seg.tif")
```

### Example 4

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
inRaster = "c:/test/moncton.tif"
spectral_detail = "14.5"
spatial_detail = "10"
min_segment_size = "20"
band_indexes = "4 3 2"

# Execute 
seg_raster = SegmentMeanShift(inRaster, spectral_detail, spatial_detail, 
                              min_segment_size, min_segment_size)

# Save the output 
seg_raster.save("c:/output/moncton_seg.tif")
```

### Example 5

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
inRaster = "c:/test/moncton.tif"
spectral_detail = "14.5"
spatial_detail = "10"
min_segment_size = "20"
band_indexes = "4 3 2"

# Execute 
seg_raster = SegmentMeanShift(inRaster, spectral_detail, spatial_detail, 
                              min_segment_size, min_segment_size)

# Save the output 
seg_raster.save("c:/output/moncton_seg.tif")
```

---

## Set Null (Spatial Analyst)

## Summary

Set Null sets identified cell locations to NoData based on a specified criteria. It returns NoData if a conditional evaluation is true, and returns the value specified by another raster if it is false.

## Usage

- If the evaluation of the where clause is true, the cell location on the output raster will be assigned NoData. If the evaluation is false, the output raster will be defined by the input false raster or constant value.
- If no where clause is specified, the output raster will have NoData wherever the conditional raster is not 0.
- The input conditional raster does not affect whether the output data type is integer or floating point. If the input false raster (or constant value) contains floating-point values, the output raster will be floating point. If it contains all integer values, the output will be an integer raster.
- If the Input conditional raster (in_conditional_raster in Python) is a single-band raster and the Input false raster or constant value (in_false_raster_or_constant In Python) raster is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the output will be a multiband raster. The output raster will also be multiband if the false raster input is a constant. The number of bands in each multiband input must be the same.
- The tool will perform the operation on each band from the conditional raster using the corresponding band from the other input. If the conditional input is a multiband raster and the false raster input is a constant, the tool will perform the operation using the constant value for each band in the multiband input.
- The Expression uses an SQL query. See the following topics for more details on creating queries: Build an SQL querySQL reference for query expressions used in ArcGIS
- Build an SQL query
- SQL reference for query expressions used in ArcGIS
- In order to use a {where_clause} in Python, it should be enclosed in quotes. For example, "Value > 5000".You can consult the help for more information on specifying a query in Python.
- The maximum length of the logical expression is 4,096 characters.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input conditional raster | The input raster representing the true or false result of the desired condition.It can be of integer or floating point type. | Raster Layer |
| Input false raster or constant value | The input whose values will be used as the output cell values if the condition is false.It can be an integer or a floating-point raster, or a constant value. | Raster Layer; Constant |
| Expression(Optional) | A logical expression that determines which of the input cells are to be true or false.The Where clause follows the general form of an SQL expression. It can be entered directly, for example, VALUE > 100, if you click the Edit SQL mode button . If in the Edit Clause Mode , you can begin constructing the expression by clicking on the Add Clause Mode button. | SQL Expression |
| in_conditional_raster | The input raster representing the true or false result of the desired condition.It can be of integer or floating point type. | Raster Layer |
| in_false_raster_or_constant | The input whose values will be used as the output cell values if the condition is false.It can be an integer or a floating-point raster, or a constant value. | Raster Layer; Constant |
| where_clause(Optional) | A logical expression that determines which of the input cells are to be true or false. The expression follows the general form of an SQL expression. An example of a where_clause is "VALUE > 100". | SQL Expression |

## Code Samples

### Example 1

```python
SetNull(in_conditional_raster, in_false_raster_or_constant, {where_clause})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSetNull = SetNull("elevation", "elevation", "VALUE < 0")
outSetNull.save("C:/sapyexamples/output/outsetnull.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSetNull = SetNull("elevation", "elevation", "VALUE < 0")
outSetNull.save("C:/sapyexamples/output/outsetnull.img")
```

### Example 4

```python
# Name: SetNull_Ex_02.py
# Description: Returns NoData if a conditional evaluation is 
#              true and returns the value specified by another
#              raster if it is false, on a cell-by-cell basis.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "landclass"
inFalseRaster = 1
whereClause = "VALUE <> 7"

# Execute SetNull
outSetNull = SetNull(inRaster, inFalseRaster, whereClause)

# Save the output 
outSetNull.save("C:/sapyexamples/output/outsetnull")
```

### Example 5

```python
# Name: SetNull_Ex_02.py
# Description: Returns NoData if a conditional evaluation is 
#              true and returns the value specified by another
#              raster if it is false, on a cell-by-cell basis.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "landclass"
inFalseRaster = 1
whereClause = "VALUE <> 7"

# Execute SetNull
outSetNull = SetNull(inRaster, inFalseRaster, whereClause)

# Save the output 
outSetNull.save("C:/sapyexamples/output/outsetnull")
```

---

## Setting values to NoData with Set Null

## Code Samples

### Example 1

```python
OutRas = SetNull(InRas1 > 5, InRas1)
```

### Example 2

```python
OutRas = SetNull(InRas1 > 5, InRas1)
```

---

## Shrink (Spatial Analyst)

## Summary

Shrinks the selected zones by a specified number of cells by replacing them with the value of the cell that is most frequent in its neighborhood.

## Usage

- The specified zone values are considered to be foreground zones, while the remaining zone values are considered to be background zones. With this tool, cells in the foreground zones are allowed to be replaced by cells in the background zones.
- When two adjacent regions are part of the selected set to shrink, there is no change at the boundary between them.
- NoData has the same priority as any valid value to invade areas vacated by shrinking selected values. Therefore, if a selected value is adjacent to NoData, it may become NoData after shrinking.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster for which the identified zones are to be shrunk.It must be of integer type. | Raster Layer |
| Number of cells | The number of cells by which to shrink each specified zone.The value must be an integer greater than 0. | Long |
| Zone values | The list of zone values to shrink.The zone values must be integers. They can be in any order. | Long |
| Shrink method(Optional) | The method to use to shrink the selected zones.The Distance option supports parallelization, and can be controlled with the Parallel Processing Factor environment setting.Morphological—Uses a mathematical morphology method to shrink the zones. This is the default.Distance—Uses a distance-based method to shrink the zones. | String |
| in_raster | The input raster for which the identified zones are to be shrunk.It must be of integer type. | Raster Layer |
| number_cells | The number of cells by which to shrink each specified zone.The value must be an integer greater than 0. | Long |
| zone_values[zone_value,...] | The list of zone values to shrink.The zone values must be integers. They can be in any order. | Long |
| shrink_method(Optional) | The method to use to shrink the selected zones.MORPHOLOGICAL—Uses a mathematical morphology method to shrink the zones. This is the default.DISTANCE—Uses a distance-based method to shrink the zones. The DISTANCE option supports parallelization, and can be controlled with the parallelProcessingFactor environment setting. | String |

## Code Samples

### Example 1

```python
Shrink(in_raster, number_cells, zone_values, {shrink_method})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outShrink = Shrink("land", 2, [1, 3, 7])
outShrink.save("c:/sapyexamples/output/shrinkout")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outShrink = Shrink("land", 2, [1, 3, 7])
outShrink.save("c:/sapyexamples/output/shrinkout")
```

### Example 4

```python
# Name: Shrink_Ex_02.py
# Description: Shrinks the selected zones by a 
#              specified number of cells.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"
cellRemove = 2
zoneSet = [1,3,7,9]

# Execute Shrink
outShrink = Shrink(inRaster, cellRemove, zoneSet)

# Save the output 
outShrink.save("c:/sapyexamples/output/outshrink")
```

### Example 5

```python
# Name: Shrink_Ex_02.py
# Description: Shrinks the selected zones by a 
#              specified number of cells.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"
cellRemove = 2
zoneSet = [1,3,7,9]

# Execute Shrink
outShrink = Shrink(inRaster, cellRemove, zoneSet)

# Save the output 
outShrink.save("c:/sapyexamples/output/outshrink")
```

---

## Sin (Spatial Analyst)

## Summary

Calculates the sine of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -∞ < [in_value] < ∞ The Range is: -1 ≤ [out_value] ≤ 1 Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: -∞ < [in_value] < ∞
- The Range is: -1 ≤ [out_value] ≤ 1
- The input values for this tool are interpreted to be in radians. If the input you want to use is in degrees, the values must first be divided by the radians-to-degrees conversion factor of 180/pi, or approximately 57.296.For further assistance, a procedure to follow and examples of converting input values in degrees to radians are available.
- The output values from this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- Due to the range of values, applying a linear stretch renderer can be useful to better see the results.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the sine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the sine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Sin(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSin = Sin("degs")
outSin.save("C:/sapyexamples/output/outsin")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSin = Sin("degs")
outSin.save("C:/sapyexamples/output/outsin")
```

### Example 4

```python
# Name: Sin_Ex_02.py
# Description: Calculates the sine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Sin
outSin = Sin(inRaster)

# Save the output 
outSin.save("C:/sapyexamples/output/outsin.img")
```

### Example 5

```python
# Name: Sin_Ex_02.py
# Description: Calculates the sine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Sin
outSin = Sin(inRaster)

# Save the output 
outSin.save("C:/sapyexamples/output/outsin.img")
```

---

## SinH (Spatial Analyst)

## Summary

Calculates the hyperbolic sine of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -∞ < [in_value] < ∞ The Range is: -∞ < [out_value] < ∞ Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: -∞ < [in_value] < ∞
- The Range is: -∞ < [out_value] < ∞
- The input and output values for this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the hyperbolic sine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the hyperbolic sine values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
SinH(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSinH = SinH("degs")
outSinH.save("C:/sapyexamples/output/outsinh")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSinH = SinH("degs")
outSinH.save("C:/sapyexamples/output/outsinh")
```

### Example 4

```python
# Name: SinH_Ex_02.py
# Description: Calculates the hyperbolic sine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute SinH
outSinH = SinH(inRaster)

# Save the output 
outSinH.save("C:/sapyexamples/output/outsinh.tif")
```

### Example 5

```python
# Name: SinH_Ex_02.py
# Description: Calculates the hyperbolic sine of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute SinH
outSinH = SinH(inRaster)

# Save the output 
outSinH.save("C:/sapyexamples/output/outsinh.tif")
```

---

## Sink (Spatial Analyst)

## Summary

Creates a raster identifying all sinks or areas of internal drainage.

## Usage

- A sink is a cell or set of spatially connected cells whose flow direction cannot be assigned one of the eight valid values in a flow direction raster. This can occur when all neighboring cells are higher than the processing cell or when two cells flow into each other, creating a two-cell loop.
- The Sink tool only supports a D8 input flow direction raster. D8 flow directions can be created using the Flow Direction tool, run with default flow direction type D8.
- The output of the Sink tool is an integer raster with each sink being assigned a unique value. Sinks are numbered between one and the number of sinks.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. The Parallel processing with Spatial Analyst help topic includes details about this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrator privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input D8 flow direction raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool, run using the default flow direction type D8. | Raster Layer |
| in_flow_direction_raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool, run using the default flow direction type D8. | Raster Layer |

## Code Samples

### Example 1

```python
Sink(in_flow_direction_raster)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSink = Sink("flowdir")
outSink.save("C:/sapyexamples/output/outsink01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSink = Sink("flowdir")
outSink.save("C:/sapyexamples/output/outsink01")
```

### Example 4

```python
# Name: Sink_Ex_02.py
# Description: Creates a raster identifying all sinks or areas of internal drainage.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFlowDirectionRaster = "flowdir"

# Execute FlowDirection
outSink = Sink(inFlowDirectionRaster)

# Save the output 
outSink.save("C:/sapyexamples/output/outsink02")
```

### Example 5

```python
# Name: Sink_Ex_02.py
# Description: Creates a raster identifying all sinks or areas of internal drainage.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFlowDirectionRaster = "flowdir"

# Execute FlowDirection
outSink = Sink(inFlowDirectionRaster)

# Save the output 
outSink.save("C:/sapyexamples/output/outsink02")
```

---

## Slice (Spatial Analyst)

## Summary

Slices or reclassifies the range of values of the input cells into zones (classes). The available data classification methods are equal interval, equal area (quantile), natural breaks, standard deviation (mean-centered), standard deviation (mean as a break), defined interval, and geometric interval.

## Usage

- The following options are available for the Slice method parameter. They generate output zones with different characteristics. Equal area—The output raster will have the defined number of zones, with a similar number of cells in each zone.Equal interval—The output raster will have the defined number of zones, each containing equal value ranges.Natural breaks and Geometric interval—The output raster will have the specified number of zones, with the number of cells in each determined by the class breaks.Standard deviation (mean-centered), Standard deviation (mean as a break), and Defined interval—The output raster will have the number of zones determined by the Interval size parameter value, with the number of cells in each determined by the class breaks.
- Equal area—The output raster will have the defined number of zones, with a similar number of cells in each zone.
- Equal interval—The output raster will have the defined number of zones, each containing equal value ranges.
- Natural breaks and Geometric interval—The output raster will have the specified number of zones, with the number of cells in each determined by the class breaks.
- Standard deviation (mean-centered), Standard deviation (mean as a break), and Defined interval—The output raster will have the number of zones determined by the Interval size parameter value, with the number of cells in each determined by the class breaks.
- Depending on the specified slice method, either the Number of output zones parameter value or the Interval size parameter value must be specified. The Number of output zones parameter is required when using the Equal area, Equal interval, Natural breaks, or Geometric interval slice method.The Interval size parameter is required when using the Defined interval, Standard deviation (mean-centered), or Standard deviation (mean as a break) slice method.
- The Number of output zones parameter is required when using the Equal area, Equal interval, Natural breaks, or Geometric interval slice method.
- The Interval size parameter is required when using the Defined interval, Standard deviation (mean-centered), or Standard deviation (mean as a break) slice method.
- You can use the Change NoData to value for output parameter to replace NoData values with an integer value in the output. If you need to prevent NoData cells from being combined with any output zones, specify an integer value that is outside the expected range of output zones. For example, with output zones ranging from 1 to 5, specify a value that is less than 1 or larger than 5. Candidate values include 0, 100, and -99. To merge NoData values into an existing zone, use the integer value for this zone. If this parameter is not set, input NoData cells will remain as NoData in the output raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster to be reclassified. | Raster Layer |
| Number of output zones(Optional) | The number of zones that the input raster will be reclassified into.This parameter is required when the Slice method parameter value is Equal area, Equal interval, Natural breaks, or Geometric interval.When the Slice method parameter value is Defined interval, Standard deviation (mean-centered), or Standard deviation (mean as a break), the Number of output zones parameter will be inactive. The number of output zones will be determined by the Interval size parameter value. | Long |
| Slice method(Optional) | Specifies the manner in which the input raster will be reclassified into zones.Equal interval—The range of input values will be equally divided into the specified number of output zones to determine the class breaks. This is the default.Equal area—The number of input cells will be equally divided into the specified number of output zones to determine the class breaks. Each zone will have a similar number of cells, indicating a similar amount of area.Natural breaks—The class breaks will be determined in a way that minimizes the variance within classes and maximizes the variance between classes. The breaks are usually set at relatively big changes in the data values.Standard deviation (mean-centered)—The class breaks will be placed above and below the mean value at a specified interval size, such as 2, 1, or 0.5, in the unit of standard deviation, until reaching the minimum and maximum values of the input raster. Mean is not used as a break but centered by two class breaks. One break is at half of the specified interval size above the mean and the other is at half of the specified interval size below the mean. Standard deviation is calculated with the n-1 denominator, where n is the number of pixels with value.Standard deviation (mean as a break)—The mean value will be used as a class break. Other class breaks will be placed above and below the mean value at a specified interval size, such as 2, 1, or 0.5, in the unit of standard deviation, until reaching the minimum and maximum values of the input raster. Standard deviation is calculated with the n-1 denominator, where n is the number of pixels with value.Defined interval—The class breaks will be set to zero and a multiple of the specified interval size relative to zero. They will then be clipped to the minimum and maximum values of the input data for the first and last classes. For a value range that contains zero, zero will always be included as a break point.Geometric interval—The class breaks will be created based on class intervals that have a geometric series. This is a pattern in which the current value equals the previous value divided by a geometric coefficient. The geometric coefficient in this classifier can change once (to its inverse) to optimize the class ranges. The algorithm creates these geometrical intervals by minimizing the sum of squares of the number of elements in each class. This ensures that each class has approximately the same number of values and that the change between intervals is consistent. | String |
| Starting value for output(Optional) | The starting value that will be used for zones (classes) on the output raster dataset.Classes will be assigned integer values, increasing by 1 from the starting value.The default starting value is 1. | Long |
| Change NoData to value for output(Optional) | Replace NoData with a value in the output.If this parameter is not set, NoData cells will remain as NoData in the output raster. | Long |
| Interval size(Optional) | The size of the interval between classes.This parameter is required when the Slice method parameter is set to Defined interval, Standard deviation (mean-centered), or Standard deviation (mean as a break).If Defined interval is used, the interval size indicates the actual value range of a class used to calculate class breaks.If Standard deviation (mean-centered) or Standard deviation (mean as a break) is used, the interval size indicates the number of standard deviations used to calculate class breaks. | Double |
| in_raster | The input raster to be reclassified. | Raster Layer |
| number_zones(Optional) | The number of zones that the input raster will be reclassified into.This parameter is required when the slice_type parameter value is EQUAL_AREA, EQUAL_INTERVAL, NATURAL_BREAKS, or GEOMETRIC_INTERVAL.When the slice_type parameter value is STANDARD_DEVIATION_MEAN_CENTERED, STANDARD_DEVIATION_MEAN_BREAK, or DEFINED_INTERVAL, the number_zones parameter is not supported. The number of output zones will be determined by the class_interval_size parameter value. | Long |
| slice_type(Optional) | Specifies the manner in which the input raster will be reclassified into zones.EQUAL_INTERVAL—The range of input values will be equally divided into the specified number of output zones to determine the class breaks. This is the default.EQUAL_AREA—The number of input cells will be equally divided into the specified number of output zones to determine the class breaks. Each zone will have a similar number of cells, indicating a similar amount of area.NATURAL_BREAKS—The class breaks will be determined in a way that minimizes the variance within classes and maximizes the variance between classes. The breaks are usually set at relatively big changes in the data values.STANDARD_DEVIATION_MEAN_CENTERED—The class breaks will be placed above and below the mean value at a specified interval size, such as 2, 1, or 0.5, in the unit of standard deviation, until reaching the minimum and maximum values of the input raster. Mean is not used as a break but centered by two class breaks. One break is at half of the specified interval size above the mean and the other is at half of the specified interval size below the mean. Standard deviation is calculated with the n-1 denominator, where n is the number of pixels with value.STANDARD_DEVIATION_MEAN_BREAK—The mean value will be used as a class break. Other class breaks will be placed above and below the mean value at a specified interval size, such as 2, 1, or 0.5, in the unit of standard deviation, until reaching the minimum and maximum values of the input raster. Standard deviation is calculated with the n-1 denominator, where n is the number of pixels with value.DEFINED_INTERVAL—The class breaks will be set to zero and a multiple of the specified interval size relative to zero. They will then be clipped to the minimum and maximum values of the input data for the first and last classes. For a value range that contains zero, zero will always be included as a break point.GEOMETRIC_INTERVAL—The class breaks will be created based on class intervals that have a geometric series. This is a pattern in which the current value equals the previous value divided by a geometric coefficient. The geometric coefficient in this classifier can change once (to its inverse) to optimize the class ranges. The algorithm creates these geometrical intervals by minimizing the sum of squares of the number of elements in each class. This ensures that each class has approximately the same number of values and that the change between intervals is consistent. | String |
| base_output_zone(Optional) | The starting value that will be used for zones (classes) on the output raster dataset.Classes will be assigned integer values, increasing by 1 from the starting value.The default starting value is 1. | Long |
| nodata_to_value(Optional) | Replace NoData with a value in the output.If this parameter is not set, NoData cells will remain as NoData in the output raster. | Long |
| class_interval_size(Optional) | The size of the interval between classes.This parameter is required when the slice_type parameter is set to DEFINED_INTERVAL, STANDARD_DEVIATION_MEAN_CENTERED, or STANDARD_DEVIATION_MEAN_BREAK.If DEFINED_INTERVAL is used, the interval size indicates the actual value range of a class used to calculate class breaks.If STANDARD_DEVIATION_MEAN_CENTERED or STANDARD_DEVIATION_MEAN_BREAK is used, the interval size indicates the number of standard deviations used to calculate class breaks. | Double |

## Code Samples

### Example 1

```python
Slice(in_raster, {number_zones}, {slice_type}, {base_output_zone}, {nodata_to_value}, {class_interval_size})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

outslice = Slice("elevation", 5, "NATURAL_BREAKS")
outslice.save("C:/sapyexamples/output/elev_slice.tif")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

outslice = Slice("elevation", 5, "NATURAL_BREAKS")
outslice.save("C:/sapyexamples/output/elev_slice.tif")
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

outslice = Slice("elevation", "", "DEFINED_INTERVAL", "", "", 10)
outslice.save("C:/sapyexamples/output/elev_slice_02.tif")
```

### Example 5

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

outslice = Slice("elevation", "", "DEFINED_INTERVAL", "", "", 10)
outslice.save("C:/sapyexamples/output/elev_slice_02.tif")
```

### Example 6

```python
# Name: Slice_Ex_03.py
# Description: Slices the input raster into 10 zones(classes) based on natural groupings inherent in the data.
#              Specify the starting value for output classes to be -5.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
numberZones = 10
baseOutputZone = -5

# Execute Slice
outSlice = Slice(inRaster, numberZones, "NATURAL_BREAKS", baseOutputZone)

# Save the output
outSlice.save("C:/sapyexamples/output/elev_slice_03.tif")
```

### Example 7

```python
# Name: Slice_Ex_03.py
# Description: Slices the input raster into 10 zones(classes) based on natural groupings inherent in the data.
#              Specify the starting value for output classes to be -5.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
numberZones = 10
baseOutputZone = -5

# Execute Slice
outSlice = Slice(inRaster, numberZones, "NATURAL_BREAKS", baseOutputZone)

# Save the output
outSlice.save("C:/sapyexamples/output/elev_slice_03.tif")
```

### Example 8

```python
# Name: Slice_Ex_04.py
# Description: Slices the input raster into 10 zones(classes) based on equal area.
#              Assign NoData cells to have a value of -99 in the output.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
numberZones = 10
baseOutputZone = 5
nodataToValue = -99
classIntervalSize = "" # or None

# Execute Slice
outSlice = Slice(inRaster, numberZones, "EQUAL_AREA", baseOutputZone, nodataToValue, classIntervalSize)

# Save the output
outSlice.save("C:/sapyexamples/output/elev_slice_04.tif")
```

### Example 9

```python
# Name: Slice_Ex_04.py
# Description: Slices the input raster into 10 zones(classes) based on equal area.
#              Assign NoData cells to have a value of -99 in the output.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
numberZones = 10
baseOutputZone = 5
nodataToValue = -99
classIntervalSize = "" # or None

# Execute Slice
outSlice = Slice(inRaster, numberZones, "EQUAL_AREA", baseOutputZone, nodataToValue, classIntervalSize)

# Save the output
outSlice.save("C:/sapyexamples/output/elev_slice_04.tif")
```

---

## Slope (Spatial Analyst)

## Summary

Identifies the slope (gradient or steepness) from each cell of a raster.

## Usage

- The Surface Parameters tool provides a newer implementation of slope and is recommended to be used instead of the Slope tool. The Slope tool fits a plane to the nine local cells, but a plane may not be a good descriptor of the landscape and may mask or exaggerate natural variations of interest. The Surface Parameters tool fits a surface to the neighborhood of cells instead of a plane, which provides a more natural fit to the terrain.The Slope tool uses a 3 by 3 window of cells to compute the value, while the Surface Parameters tool allows window sizes from 3 by 3 to 15 by 15 cells. Larger window sizes are useful with high resolution elevation data to capture land surface processes at an appropriate scale. The Surface Parameters tool also provides an adaptive window option that evaluates the local variability of the terrain and identifies the largest appropriate neighborhood size for each cell. This can be useful with gradual homogeneous terrain interrupted by streams, roads, or sharp breaks in slope.You can continue to use the traditional approach of the Slope tool if you need the results to exactly match previous tool runs or if fast processing time is more important than a better algorithm.
- This tool uses a 3 by 3 cell moving window to process the data. If the processing cell is NoData, the output for that location will be NoData.
- Of the eight cells neighboring the processing cell, this tool requires that at least seven of them have a valid value. If there are fewer than seven valid cells, the calculation will not be performed, and the output at that processing cell will be NoData.
- The cells in the outermost rows and columns of the output raster will be NoData. This is because along the boundary of the input dataset, those cells do not have enough valid neighbors.
- The range of values in the output depends on the type of measurement units. For degrees, the range of slope values is 0 to 90.For percent rise, the range is 0 to essentially infinity. A flat surface is 0 percent, a 45 degree surface is 100 percent, and as the surface becomes more vertical, the percent rise becomes increasingly larger.
- For degrees, the range of slope values is 0 to 90.
- For percent rise, the range is 0 to essentially infinity. A flat surface is 0 percent, a 45 degree surface is 100 percent, and as the surface becomes more vertical, the percent rise becomes increasingly larger.
- For the planar method, the use of a z-factor is essential for correct slope calculations when the surface (vertical) z-units are expressed in units different from the ground x,y units. The Z factor parameter will be enabled only when the planar method is selected.
- For the geodesic method, specifying the surface z-unit ensures the accuracy of the output. The Z unit parameter will be enabled only when the geodesic method is selected.
- If a z-unit is available in the vertical coordinate system of the input raster, it will be applied automatically. It is recommended that you define a z-unit for the input raster if it is missing. You can use the Define Projection tool to specify a z-unit. If it is undefined, meter will be used by default.
- When the input raster needs to be resampled, the bilinear technique will be used. An example of when an input raster may be resampled is when the output coordinate system, extent, or cell size is different from that of the input.
- If the Input raster parameter value is high resolution with a cell size of less than a few meters, or particularly noisy, consider using the Surface Parameters tool and its user-defined neighborhood distance option instead of the immediate 3 by 3 neighborhood of this tool. Using a larger neighborhood can minimize the effect of noisy surfaces. Using a larger neighborhood can also better represent landforms and surface characteristics when using high resolution surfaces.
- This tool can be GPU accelerated, which means that if a compatible graphics processing unit (GPU) is available on your system, it will be used to enhance the performance of the tool. Use the Target device for analysis (analysis_target_device in Python) parameter to control whether the GPU or CPU will be used to run the tool. See GPU processing with Spatial Analyst for details on compatible GPUs, configuring and working with GPU devices, as well as troubleshooting tips.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input surface raster. | Raster Layer |
| Output measurement(Optional) | Specifies the measurement units (degrees or percentages) of the output slope raster.Degree—The inclination of slope will be calculated in degrees.Percent rise—The inclination of slope will be calculated as percent rise, also referred to as the percent slope. | String |
| Z factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| Method(Optional) | Specifies whether the calculation will be based on a planar (flat earth) or a geodesic (ellipsoid) method.The planar method is appropriate to use on local areas in a projection that maintains correct distance and area. It is suitable for analyses that cover areas such cities, counties, or smaller states in area. The geodesic method produces a more accurate result, at the potential cost of an increase in processing time.Planar—The calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default method.Geodesic—The calculation will be performed in a 3D Cartesian coordinate system by considering the shape of the earth as an ellipsoid. | String |
| Z unit(Optional) | Specifies the linear unit that will be used for vertical z-values.It is defined by a vertical coordinate system if it exists. If no vertical coordinate system exists, define the z-unit using the unit list to ensure correct geodesic computation. The default is meter.Inch—The linear unit will be inches.Foot—The linear unit will be feet.Yard—The linear unit will be yards.Mile US—The linear unit will be miles.Nautical mile—The linear unit will be nautical miles.Millimeter—The linear unit will be millimeters.Centimeter—The linear unit will be centimeters.Meter—The linear unit will be meters.Kilometer—The linear unit will be kilometers.Decimeter—The linear unit will be decimeters. | String |
| Target device for analysis(Optional) | Specifies the device that will be used to perform the calculation.GPU then CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU only—The calculation will only be performed on the CPU.GPU only—The calculation will only be performed on the GPU. | String |
| in_raster | The input surface raster. | Raster Layer |
| output_measurement(Optional) | Specifies the measurement units (degrees or percentages) of the output slope raster.DEGREE—The inclination of slope will be calculated in degrees.PERCENT_RISE—The inclination of slope will be calculated as percent rise, also referred to as the percent slope. | String |
| z_factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| method(Optional) | Specifies whether the calculation will be based on a planar (flat earth) or a geodesic (ellipsoid) method.PLANAR—The calculation will be performed on a projected flat plane using a 2D Cartesian coordinate system. This is the default method.GEODESIC—The calculation will be performed in a 3D Cartesian coordinate system by considering the shape of the earth as an ellipsoid. The planar method is appropriate to use on local areas in a projection that maintains correct distance and area. It is suitable for analyses that cover areas such cities, counties, or smaller states in area. The geodesic method produces a more accurate result, at the potential cost of an increase in processing time. | String |
| z_unit(Optional) | Specifies the linear unit that will be used for vertical z-values.It is defined by a vertical coordinate system if it exists. If no vertical coordinate system exists, define the z-unit using the unit list to ensure correct geodesic computation. The default is meter.INCH—The linear unit will be inches.FOOT—The linear unit will be feet.YARD—The linear unit will be yards.MILE_US—The linear unit will be miles.NAUTICAL_MILE—The linear unit will be nautical miles.MILLIMETER—The linear unit will be millimeters.CENTIMETER—The linear unit will be centimeters.METER—The linear unit will be meters.KILOMETER—The linear unit will be kilometers.DECIMETER—The linear unit will be decimeters. | String |
| analysis_target_device(Optional) | Specifies the device that will be used to perform the calculation.GPU_THEN_CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU_ONLY—The calculation will only be performed on the CPU.GPU_ONLY—The calculation will only be performed on the GPU. | String |

## Code Samples

### Example 1

```python
Slope(in_raster, {output_measurement}, {z_factor}, {method}, {z_unit}, {analysis_target_device})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSlope = Slope("elevation", "DEGREE", 0.3043)
outSlope.save("C:/sapyexamples/output/outslope01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSlope = Slope("elevation", "DEGREE", 0.3043)
outSlope.save("C:/sapyexamples/output/outslope01")
```

### Example 4

```python
# Name: _Ex_02.py
# Description: Identifies slope from each cell.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
outMeasurement = "DEGREE"
zFactor = ""
method = "GEODESIC"
zUnit = "FOOT"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute Slope
outSlope = Slope(inRaster, outMeasurement, zFactor, method, zUnit)

# Save the output 
outSlope.save("C:/sapyexamples/output/outslope02")
```

### Example 5

```python
# Name: _Ex_02.py
# Description: Identifies slope from each cell.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
outMeasurement = "DEGREE"
zFactor = ""
method = "GEODESIC"
zUnit = "FOOT"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute Slope
outSlope = Slope(inRaster, outMeasurement, zFactor, method, zUnit)

# Save the output 
outSlope.save("C:/sapyexamples/output/outslope02")
```

---

## Snap Pour Point (Spatial Analyst)

## Summary

Snaps pour points to the cell of highest flow accumulation within a specified distance.

## Usage

- The Snap Pour Point tool is used to ensure the selection of points of high accumulated flow when delineating drainage basins using the Watershed tool. Snap Pour Point will search within a snap distance around the specified pour points for the cell of highest accumulated flow and move the pour point to that location.
- If the input pour point data is a point feature class, it will be converted to a raster internally for processing.
- The output is an integer raster when the original pour point locations have been snapped to locations of higher accumulated flow.
- When there is only one input pour point location, the extent of the output is that of the accumulation raster. If there is more than one pour point location, the extent of the output is determined by the settings in the Output extent environment.
- When specifying the input pour point locations as feature data, the default field will be the first available valid field. If no valid field exists, the ObjectID field (for example, OID or FID) will be the default.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature pour point data | The input pour point locations that are to be snapped.For a raster input, all cells that are not NoData (that is, have a value) will be considered pour points and will be snapped.For a point feature input, this specifies the locations of cells that will be snapped. | Raster Layer; Feature Layer |
| Input accumulation raster | The input flow accumulation raster.This can be created with the Flow Accumulation tool. | Raster Layer |
| Snap distance | Maximum distance, in map units, to search for a cell of higher accumulated flow. | Double |
| Pour point field(Optional) | The field used to assign values to the pour point locations.If the pour point dataset is a raster, use Value.If the pour point dataset is a feature, use a numeric field. If the field contains floating-point values, they will be truncated into integers. | Field |
| in_pour_point_data | The input pour point locations that are to be snapped.For a raster input, all cells that are not NoData (that is, have a value) will be considered pour points and will be snapped.For a point feature input, this specifies the locations of cells that will be snapped. | Raster Layer; Feature Layer |
| in_accumulation_raster | The input flow accumulation raster.This can be created with the Flow Accumulation tool. | Raster Layer |
| snap_distance | Maximum distance, in map units, to search for a cell of higher accumulated flow. | Double |
| pour_point_field(Optional) | The field used to assign values to the pour point locations.If the pour point dataset is a raster, use Value.If the pour point dataset is a feature, use a numeric field. If the field contains floating-point values, they will be truncated into integers. | Field |

## Code Samples

### Example 1

```python
SnapPourPoint(in_pour_point_data, in_accumulation_raster, snap_distance, {pour_point_field})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSnapPour = SnapPourPoint("pourpoint", "flowaccumulation.img", 5,"VALUE") 
outSnapPour.save("c:/sapyexamples/output/outsnpprpnt01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSnapPour = SnapPourPoint("pourpoint", "flowaccumulation.img", 5,"VALUE") 
outSnapPour.save("c:/sapyexamples/output/outsnpprpnt01")
```

### Example 4

```python
# Name: SnapPourPoints_Ex_02.py
# Description: Snaps pour points to the cell of highest 
#              flow accumulation within a specified distance.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPourPoint = "pourpoint"
inFlowAccum = "flowaccumulation.img"
tolerance = 5
pourField = "VALUE"

# Execute SnapPourPoints
outSnapPour = SnapPourPoint(inPourPoint, inFlowAccum, tolerance, 
                            pourField) 

# Save the output 
outSnapPour.save("c:/sapyexamples/output/outsnpprpnt02")
```

### Example 5

```python
# Name: SnapPourPoints_Ex_02.py
# Description: Snaps pour points to the cell of highest 
#              flow accumulation within a specified distance.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPourPoint = "pourpoint"
inFlowAccum = "flowaccumulation.img"
tolerance = 5
pourField = "VALUE"

# Execute SnapPourPoints
outSnapPour = SnapPourPoint(inPourPoint, inFlowAccum, tolerance, 
                            pourField) 

# Save the output 
outSnapPour.save("c:/sapyexamples/output/outsnpprpnt02")
```

---

## Solar Radiation Graphics (Spatial Analyst)

## Summary

Derives raster representations of a hemispherical viewshed, sun map, and sky map, which are used in the calculation of direct, diffuse, and global solar radiation.

## Usage

- Outputs from the Solar Radiation Graphics tool are raster representations and are not maps that correspond to the outputs from the area or point solar radiation analysis. Rather, they are representations of directions in a hemisphere of directions looking upward from a given location. In a hemispherical projection, the center is the zenith, the edge of the circular map representation is the horizon, and the angle relative to the zenith is proportionate to the radius. Hemispherical projections do not have a geographic coordinate system and have a lower left corner of (0,0).
- It would not be practical to store viewsheds for all locations in a DEM, so when input locations are not specified, a single viewshed is created for the center of the input surface raster. When input point features or locations files are specified, multiple viewshed rasters are created for each input location. When multiple locations are specified, the output will be a multiband raster, where each band corresponds to the viewshed for a specific location.
- The input locations table can be a point feature class or a table of point coordinates. When inputting locations by table, a list of locations must be specified with an x,y coordinate. The table can be a geodatabase table, a .dbf file, an INFO table, or a text table file. If using an ASCII coordinate file, each line should contain an x,y pair separated by a comma, space, or tab.
- Output graphic display rasters do not honor extent or cell size environment settings. The output extents are always respective of the sky size/resolution and have a cell size equal to one. However, the underlying analysis will use the environment settings and may affect the results of the viewshed.
- One or two sun map rasters may be generated, depending on whether the time configuration includes overlapping sun positions throughout the year. When two sun maps are created, one represents the period between the winter and summer solstice, and the other represents the period between the summer solstice and the winter solstice. Depending on the year, the solistices typically fall on the 20th or 21st of December and June, but occasionally they may be on the 22nd. When multiple sun maps are created, the default output is a multiband raster.
- The latitude for the site area (units: decimal degree, positive for the northern hemisphere and negative for the southern hemisphere) is used in calculations such as solar declination and solar position.The analysis is designed specifically for local landscape scales, so it is generally acceptable to use one latitude value for the whole DEM. With larger datasets, such as for states, countries, or continents, the insolation results will differ significantly at different latitudes (greater than 1 degree). To analyze broader geographic regions, you must divide the study area into zones with different latitudes.
- For input surface rasters containing a spatial reference, the mean latitude is automatically calculated; otherwise, the latitude will default to 45 degrees. When using an input layer, the spatial reference of the data frame is used.
- Sky size is the resolution of the viewshed, sky map, and sun map rasters that are used in the radiation calculations (units: cells per side). These are upward-looking, hemispherical raster representations of the sky and do not have a geographic coordinate system. These rasters are square (equal number of rows and columns).The following are recommended sky size values when a time configuration of a whole year or multiple days is used:For a 1 day interval, use a sky size of 1000 and above.For a 0.25 day interval, use a sky size of 2000 and above.For a 0.1 hour interval, use a sky size of 4000 and above.Increasing the sky size increases calculation accuracy but also increases calculation time considerably.
- For a 1 day interval, use a sky size of 1000 and above.
- For a 0.25 day interval, use a sky size of 2000 and above.
- For a 0.1 hour interval, use a sky size of 4000 and above.
- When the day interval setting is small (for example, < 14 days), use a larger sky size. During analysis, the sun map (determined by the sky size) is used to represent sun positions (tracks) for particular time periods to calculate direct radiation. With smaller day intervals, if the sky size resolution is not large enough, sun tracks may overlap, resulting in zero or lower radiation values for that track. Increasing the resolution provides a more accurate result.
- The maximum sky size value is 10,000. A value of 200 is the default and is sufficient for whole DEMs with large day intervals (for example, > 14 days). A sky size value of 512 is sufficient for calculations at point locations where calculation time is less of an issue. At smaller day intervals (for example, < 14 days), it is recommended that you use higher values. For example, to calculate insolation for a location at the equator with day interval = 1, use a sky size of 2,800 or above.
- Day intervals greater than 3 are recommended, as sun tracks within three days typically overlap, depending on sky size and time of year. For calculations of the whole year with monthly interval, day interval is disabled and the program uses calendar month intervals. The default value is 14.
- Because the viewshed calculation can be highly intensive, horizon angles are only traced for the number of calculation directions specified. Valid values must be multiples of 8 (8, 16, 24, 32, and so on). Typically, a value of 8 or 16 is adequate for areas with gentle topography, and a value of 32 is adequate for complex topography. The default value is 32.
- The number of calculation directions needed is related to the resolution of the input DEM. Natural terrain at 30-meters resolution is usually quite smooth, so fewer directions are sufficient for most situations (16 or 32). With finer DEMs, and particularly with human-made structures incorporated in the DEMs, the number of directions needs to increase. Increasing the number of directions increases accuracy but also increase calculation time.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input elevation surface raster. | Raster Layer |
| Input points feature or table(Optional) | The input point feature class or table containing the locations where solar radiation will be analyzed. | Feature Layer; Table View |
| Sky size / Resolution(Optional) | The resolution or sky size for the viewshed, sky map, and sun map rasters. The units are cells.The default is a raster of 200 by 200 cells. | Long |
| Height offset(Optional) | The height (in meters) above the DEM surface for which calculations will be performed.The height offset will be applied to all input locations. | Double |
| Calculation directions(Optional) | The number of azimuth directions that will be used when calculating the viewshed.Valid values must be multiples of 8 (8, 16, 24, 32, and so on). The default value is 32 directions, which is adequate for complex topography. | Long |
| Latitude(Optional) | The latitude for the site area. The units are decimal degrees with positive values for the northern hemisphere and negative values for the southern hemisphere.For input surface rasters containing a spatial reference, the mean latitude is automatically calculated; otherwise, the latitude default is 45 degrees. | Double |
| Time configuration(Optional) | Specifies the time period that will be used for the calculations.Special days—Solar insolation will be calculated for the solstice days (summer and winter) and the equinox days (when the insolation for both spring and fall equinox are the same).Within day—Calculations will be performed for a specified time period within a single day. Select the Julian day and provide the start and end times. When the start time and the end time are the same, instantaneous insolation will be calculated. When the start time is before sunrise and the end time is after sunset, insolation will be calculated for the whole day.To enter the correct day, use the calendar button to open the Calendar dialog box. Multiple days—Calculations will be performed for a specific multiple-day period within a year.Specify the start year, start day, and end day. When the end day is smaller than the start day, the end day is considered to be in the following year. The default time configuration starts on day 5 and ends on day 160 of the current Julian year.To enter the correct days, use the calendar button to open the Calendar dialog box.Whole year—Calculations will be performed for an entire year using monthly intervals for calculations.If the Create outputs for each interval parameter is checked, output files will be created for each month; otherwise, a single output will be created for the whole year. | Time configuration |
| Day interval(Optional) | The time interval through the year (units: days) that will be used to calculate sky sectors for the sun map.The default value is 14 (biweekly). | Long |
| Hour interval(Optional) | The time interval through the day (units: hours) that will be used to calculate sky sectors for the sun map.The default value is 0.5. | Double |
| Output sunmap raster(Optional) | The output sun map raster.The output is a representation that specifies sun tracks, the apparent position of the sun as it varies through time. The output is at the same resolution as the viewshed and sky map. | Raster Dataset |
| Zenith divisions(Optional) | The number of zenith divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to zenith). Values must be greater than zero and less than half the sky size value. | Long |
| Azimuth divisions(Optional) | The number of azimuth divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to north). Valid values must be multiples of 8. Values must be greater than zero and less than 160. | Long |
| Output skymap raster(Optional) | The output sky map raster.The output is constructed by dividing the whole sky into a series of sky sectors defined by zenith and azimuth divisions. The output is at the same resolution as the viewshed and sun map. | Raster Dataset |
| in_surface_raster | The input elevation surface raster. | Raster Layer |
| in_points_feature_or_table(Optional) | The input point feature class or table containing the locations where solar radiation will be analyzed. | Feature Layer; Table View |
| sky_size(Optional) | The resolution or sky size for the viewshed, sky map, and sun map rasters. The units are cells.The default is a raster of 200 by 200 cells. | Long |
| height_offset(Optional) | The height (in meters) above the DEM surface for which calculations will be performed.The height offset will be applied to all input locations. | Double |
| calculation_directions(Optional) | The number of azimuth directions that will be used when calculating the viewshed.Valid values must be multiples of 8 (8, 16, 24, 32, and so on). The default value is 32 directions, which is adequate for complex topography. | Long |
| latitude(Optional) | The latitude for the site area. The units are decimal degrees with positive values for the northern hemisphere and negative values for the southern hemisphere.For input surface rasters containing a spatial reference, the mean latitude is automatically calculated; otherwise, the latitude default is 45 degrees. | Double |
| time_configuration(Optional) | Specifies the time configuration (period) that will be used for calculating solar radiation.The Time class objects will be used to specify the time configuration.The different types of time configurations available are TimeWithinDay, TimeMultipleDays, TimeSpecialDays, and TimeWholeYear.The following are the forms:TimeWithinDay({day},{startTime},{endTime})TimeMultipleDays({year},{startDay},{endDay})TimeSpecialDays()TimeWholeYear({year})The default time configuration is TimeMultipleDays with the startDay value of 5 and the endDay value of 160 for the current Julian year. | Time configuration |
| day_interval(Optional) | The time interval through the year (units: days) that will be used to calculate sky sectors for the sun map.The default value is 14 (biweekly). | Long |
| hour_interval(Optional) | The time interval through the day (units: hours) that will be used to calculate sky sectors for the sun map.The default value is 0.5. | Double |
| out_sunmap_raster(Optional) | The output sun map raster.The output is a representation that specifies sun tracks, the apparent position of the sun as it varies through time. The output is at the same resolution as the viewshed and sky map. | Raster Dataset |
| zenith_divisions(Optional) | The number of zenith divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to zenith). Values must be greater than zero and less than half the sky size value. | Long |
| azimuth_divisions(Optional) | The number of azimuth divisions that will be used to create sky sectors in the sky map.The default is eight divisions (relative to north). Valid values must be multiples of 8. Values must be greater than zero and less than 160. | Long |
| out_skymap_raster(Optional) | The output sky map raster.The output is constructed by dividing the whole sky into a series of sky sectors defined by zenith and azimuth divisions. The output is at the same resolution as the viewshed and sun map. | Raster Dataset |

## Code Samples

### Example 1

```python
SolarRadiationGraphics(in_surface_raster, {in_points_feature_or_table}, {sky_size}, {height_offset}, {calculation_directions}, {latitude}, {time_configuration}, {day_interval}, {hour_interval}, {out_sunmap_raster}, {zenith_divisions}, {azimuth_divisions}, {out_skymap_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outViewshedMap = SolarRadiationGraphics("elevation", "observers.shp", 200, 2, 32, 52,
                                 TimeMultipleDays(2009, 91, 212), 14, 0.5, 
                                 "c:/sapyexamples/output/sunmap", 8, 8, 
                                 "c:/sapyexamples/output/skymap")
outViewshedMap.save("c:/sapyexamples/output/viewmap")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outViewshedMap = SolarRadiationGraphics("elevation", "observers.shp", 200, 2, 32, 52,
                                 TimeMultipleDays(2009, 91, 212), 14, 0.5, 
                                 "c:/sapyexamples/output/sunmap", 8, 8, 
                                 "c:/sapyexamples/output/skymap")
outViewshedMap.save("c:/sapyexamples/output/viewmap")
```

### Example 4

```python
# Name: SolarRadiationGraphics_Ex_02.py
# Description: Derives raster representations of a hemispherical viewshed, 
#    sunmap, and skymap, which are used in the calculation of direct, diffuse, 
#    and global solar radiation.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
pntFC = "observers.shp"
skySize = 200
zOffset = 2
directions = 32
latitude = 52
timeConfig = TimeMultipleDays(2009, 91, 212)
dayInterval = 14
hourInterval = 0.5
outSunMap = "c:/sapyexamples/output/sunmap"
zenDivisions = 8
aziDivisions = 8
outSkyMap = "c:/sapyexamples/output/skymap"

# Execute SolarRadiationGraphics
outViewshedMap = SolarRadiationGraphics(inRaster, pntFC, skySize, zOffset, 
                                    directions, latitude, timeConfig,
                                    dayInterval, hourInterval, outSunMap,
                                    zenDivisions, aziDivisions, outSkyMap)

# Save the output
outViewshedMap.save("c:/sapyexamples/output/viewmap")
```

### Example 5

```python
# Name: SolarRadiationGraphics_Ex_02.py
# Description: Derives raster representations of a hemispherical viewshed, 
#    sunmap, and skymap, which are used in the calculation of direct, diffuse, 
#    and global solar radiation.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
pntFC = "observers.shp"
skySize = 200
zOffset = 2
directions = 32
latitude = 52
timeConfig = TimeMultipleDays(2009, 91, 212)
dayInterval = 14
hourInterval = 0.5
outSunMap = "c:/sapyexamples/output/sunmap"
zenDivisions = 8
aziDivisions = 8
outSkyMap = "c:/sapyexamples/output/skymap"

# Execute SolarRadiationGraphics
outViewshedMap = SolarRadiationGraphics(inRaster, pntFC, skySize, zOffset, 
                                    directions, latitude, timeConfig,
                                    dayInterval, hourInterval, outSunMap,
                                    zenDivisions, aziDivisions, outSkyMap)

# Save the output
outViewshedMap.save("c:/sapyexamples/output/viewmap")
```

---

## Space Time Kernel Density (Spatial Analyst)

## Summary

Expands kernel density calculations from analyzing the relative position and magnitude of the input features to include other dimensions such as time and depth (elevation). The resulting output identifies the magnitude-per-unit area using the multiple kernel functions to fit a smoothly tapered surface to each input point.

## Usage

- You must provide a value for the Elevation Field (elevation_field in Python) parameter or the Time Field (time_field in Python) parameter, or both. While the tool will initially show both as being required, once a value for one of them has been provided, the other becomes optional.The kernel functions are defined based on the parameter values provided. When the Elevation Field parameter value is provided, the kernel is extended along the direction (z) axis. When the Time Field parameter value is provided, the kernel is extended along the time (t) axis. When both values are provided, kernels are extended along the z-axis and t-axis.If only one of the of these parameter values is provided, the output will be a three-dimensional raster. If both parameter values are provided, the output will be a four-dimensional raster.
- Only the points that fall within the neighborhood are considered when calculating density. If no points fall within the neighborhood of a particular cell, that cell is assigned NoData.
- The tool generates an output raster in either the NetCDF format or Cloud Raster Format (CRF). The location and name you provide for the output raster determines the format in which it is created. For the Output Raster parameter value, use the .nc extension to create the output in the netCDF format. Use the .crf extension to create an output CRF raster. By default, the tool will output a CRF raster.
- You can create a voxel layer output using the optional Output Voxel Layer parameter. This parameter is only available if the Output Raster parameter value is set to create NetCDF output with the .nc extension. If you attempt to specify a voxel layer output using the .crf extension for a CRF raster in the Output raster parameter, the tool will produce an error message and not run.
- If you run the tool in a local scene with the same horizontal and vertical coordinate systems as the input features, a voxel layer will be added to the scene allowing you to interactively explore the results. A notification appears stating that the coordinate system is unknown if no coordinate system is defined. You can also add the output NetCDF raster as a voxel layer using the Make Multidimensional Voxel Layer tool or the Add Multidimensional Voxel Layer dialog box.You can convert the output netCDF raster to a multidimensional raster using the Copy Raster tool. You can also add it to a map as a feature layer or raster layer using the Make NetCDF Feature Layer tool or Make NetCDF Raster Layer tool, respectively.The generated voxel layer is a temporary layer that will not persist unless it is saved using the Save To Layer File tool. You can use the Create Voxel Scene Layer Content tool to create a scene layer package (.slpk file) from a voxel layer input.
- Very large or very small values in the Population Field (population_field in Python) parameter may produce results that seem nonintuitive. If the mean of the population field is much larger than 1 (for example, as with city populations), the default search radius may be very small, resulting in small rings around the input points. If the mean of the population field is much smaller than 1, the calculated search radius may seem unreasonably large. In these cases, you can provide a custom search radius.
- The Cell Size (cell_size in Python) parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been provided as the parameter value, it is derived from the Cell Size environment if it has been specified. If neither the parameter cell size nor the environment cell size have been provided, but the Snap Raster environment has been set, the cell size of the snap raster will be used. If nothing is specified, the cell size will be calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- The Resultant Values (resultant_values in Python) parameter specifies what the output raster values represent. If Densities (DENSITIES in Python) is specified, the values represent the kernel density value per unit area for each cell. If Expected Counts (EXPECTED_COUNTS in Python) is specified, the values represent the kernel density per cell area.
- The Planar option for the Method (method in Python) parameter is appropriate if the analysis will be performed at a local scale with a projection that accurately maintains the correct distance and area. The Geodesic option is appropriate if the analysis will be performed at a regional or large scale. This method takes into account the curvature of the spheroid and correctly handles data near the poles and the international dateline.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- References:Härdle, W. K., Müller, M, Sperlich, S., and Werwatz, A. Nonparametric and semiparametric models (Vol. 1). Berlin: Springer, 2004.Hu, Y., Wang, F., Guin, C., and Zhu, H. "A spatio-temporal kernel density estimation framework for predictive crime hotspot mapping and evaluation." Applied geography, 99, 2018, 89-97.Nakaya, T., and Yano, K. "Visualising crime clusters in a space‐time cube: An exploratory data analysis approach using space time kernel density estimation and scan statistics." Transactions in GIS, 14(3), 2010, 223-239.Silverman, B. W. Density Estimation for Statistics and Data Analysis. New York: Chapman and Hall, 1986.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Point Features | The input point features for which density will be calculated. | Feature Layer |
| Population Field | The field denoting population values for each feature. The population is the count or quantity to be spread across the landscape to create a continuous surface.Values in the population field can be integer or floating point. Use None if no item or special value will be used and each feature will be counted once. | Field |
| Elevation Field(Optional) | The field denoting elevation values for each feature.Values in the elevation field can be integer or floating point. Use Empty to support 3D kernel density with time. For 3D features, a pseudo field, Shape.Z, will be added to the field list. | Field |
| Elevation Field Unit(Optional) | Specifies the unit of measure that will be used for the input elevation field value. The default is meters.Use the appropriate unit to represent the values in the Elevation Field parameter value.Inch—Inches will be used.Foot—Feet will be used. Yard—Yards will be used.Mile (US)—U.S. miles will be used.Nautical Mile—Nautical miles will be used.Millimeter—Millimeters will be used.Centimeter—Centimeters will be used.Meter—Meters will be used.Kilometers—Kilometers will be used.Decimeter—Decimeters will be used. | String |
| Time Field(Optional) | The field denoting time values for each feature. | Field |
| Cell Size(Optional) | The cell size of the multidimensional raster output that will be created.The value can be defined by a numeric value or obtained from an existing raster dataset. If no cell size is provided, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the tool usage for details. | Analysis Cell Size |
| Search Radius (x and y)(Optional) | The search radius on the x,y plane within which density will be calculated. Provide the value and the appropriate units. For example, to include all features within a 1-mile neighborhood when the units are meters, set the search radius to 1609.344 (1 mile = 1609.344 meters).By default, the units are based on the linear unit of the output spatial reference. | Linear Unit |
| Search Radius (z)(Optional) | The vertical search distance in the z-direction within which density will be calculated. This vertical distance will be used to search for features in the upward and downward directions along the z-axis. Provide the value and the appropriate units. | Linear Unit |
| Search Time Window (t)(Optional) | The search range of time within which density will be calculated. Provide the value and the appropriate units. | Time Unit |
| Resultant Values(Optional) | Specifies what the values in the output raster will represent.Since the output cell value is related to the specified cell size, the resulting raster cannot be resampled to a different cell size.Densities—The output values will represent the calculated density value per unit area for each cell. This is the default.Expected Counts—The output values will represent the calculated density value per cell area. | String |
| Method(Optional) | Specifies whether the flat earth (planar) or the shortest path on a spheroid (geodesic) method will be used.Planar—The planar distance between features will be used. This is the default.Geodesic—The geodesic distance between features will be used. | String |
| Minimum Elevation (Optional) | The minimum (lowest) elevation that will be used for the multidimensional raster output. | Double |
| Maximum Elevation (Optional) | The maximum (highest) elevation that will be used for the multidimensional raster output. | Double |
| Elevation Interval (Optional) | The elevation interval between slices in the multidimensional raster output.The value must be greater than zero. | Double |
| Elevation Unit(Optional) | Specifies the unit of elevation interval that will be used for the multidimensional raster output. The default is meter.Inch—Inches will be used.Foot—Feet will be used. Yard—Yards will be used.Mile (US)—U.S. miles will be used.Nautical Mile—Nautical miles will be used.Millimeter—Millimeters will be used.Centimeter—Centimeters will be used.Meter—Meters will be used.Kilometers—Kilometers will be used.Decimeter—Decimeters will be used. | String |
| Start Time(Optional) | The start time that will be used for the multidimensional raster output. | Date |
| End Time(Optional) | The end time that will be used for the multidimensional raster output. | Date |
| Time Interval(Optional) | The time interval between slices in the multidimensional raster output.The value must be greater than zero. | Double |
| Time Interval Unit(Optional) | Specifies the unit of the time interval that will be used for the multidimensional raster output. The default is day.Second—The time interval unit will be seconds.Minute—The time interval unit will be minutes.Hour—The time interval unit will be hours.Day—The time interval unit will be days.Week—The time interval unit will be weeks. | String |
| Output Voxel Layer(Optional) | The output voxel layer based on volumetric data stored in the output netCDF raster. This output type can only be created when the Output Raster parameter is set to create a netCDF raster with the .nc extension. | Voxel Layer |
| in_features | The input point features for which density will be calculated. | Feature Layer |
| population_field | The field denoting population values for each feature. The population is the count or quantity to be spread across the landscape to create a continuous surface.Values in the population field can be integer or floating point. Use '' if no item or special value will be used and each feature will be counted once. | Field |
| elevation_field(Optional) | The field denoting elevation values for each feature.Values in the elevation field can be integer or floating point. Use '' to support 3D kernel density with time. For 3D features, a pseudo field, Shape.Z, will be added to the field list. | Field |
| elevation_field_unit(Optional) | Specifies the unit of measure that will be used for the input elevation field value. The default is meters. Use the appropriate unit to represent the values in the elevation_field parameter value. INCH—Inches will be used.FOOT—Feet will be used. YARD—Yards will be used.MILE_US—U.S. miles will be used.NAUTICAL_MILE—Nautical miles will be used.MILLIMETER—Millimeters will be used.CENTIMETER—Centimeters will be used.METER—Meters will be used.KILOMETER—Kilometers will be used.DECIMETER—Decimeters will be used. | String |
| time_field(Optional) | The field denoting time values for each feature. | Field |
| cell_size(Optional) | The cell size of the multidimensional raster output that will be created.The value can be defined by a numeric value or obtained from an existing raster dataset. If no cell size is provided, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the tool usage for details. | Analysis Cell Size |
| kernel_search_radius_xy(Optional) | The search radius on the x,y plane within which density will be calculated. Provide the value and the appropriate units. For example, to include all features within a 1-mile neighborhood when the units are meters, set the search radius to 1609.344 (1 mile = 1609.344 meters).By default, the units are based on the linear unit of the output spatial reference. | Linear Unit |
| kernel_search_radius_z(Optional) | The vertical search distance in the z-direction within which density will be calculated. This vertical distance will be used to search for features in the upward and downward directions along the z-axis. Provide the value and the appropriate units. | Linear Unit |
| kernel_search_time_window(Optional) | The search range of time within which density will be calculated. Provide the value and the appropriate units. | Time Unit |
| resultant_values(Optional) | Specifies what the values in the output raster will represent.Since the output cell value is related to the specified cell size, the resulting raster cannot be resampled to a different cell size. DENSITIES—The output values will represent the calculated density value per unit area for each cell. This is the default.EXPECTED_COUNTS—The output values will represent the calculated density value per cell area. | String |
| method(Optional) | Specifies whether the flat earth (planar) or the shortest path on a spheroid (geodesic) method will be used.PLANAR—The planar distance between features will be used. This is the default.GEODESIC—The geodesic distance between features will be used. | String |
| min_elevation(Optional) | The minimum (lowest) elevation that will be used for the multidimensional raster output. | Double |
| max_elevation(Optional) | The maximum (highest) elevation that will be used for the multidimensional raster output. | Double |
| elevation_interval(Optional) | The elevation interval between slices in the multidimensional raster output.The value must be greater than zero. | Double |
| elevation_unit(Optional) | Specifies the unit of elevation interval that will be used for the multidimensional raster output. The default is meter.INCH—Inches will be used.FOOT—Feet will be used. YARD—Yards will be used.MILE_US—U.S. miles will be used.NAUTICAL_MILE—Nautical miles will be used.MILLIMETER—Millimeters will be used.CENTIMETER—Centimeters will be used.METER—Meters will be used.KILOMETER—Kilometers will be used.DECIMETER—Decimeters will be used. | String |
| start_time(Optional) | The start time that will be used for the multidimensional raster output. | Date |
| end_time(Optional) | The end time that will be used for the multidimensional raster output. | Date |
| time_interval(Optional) | The time interval between slices in the multidimensional raster output.The value must be greater than zero. | Double |
| time_interval_unit(Optional) | Specifies the unit of the time interval that will be used for the multidimensional raster output. The default is day.SECOND—The time interval unit will be seconds.MINUTE—The time interval unit will be minutes.HOUR—The time interval unit will be hours.DAY—The time interval unit will be days.WEEK—The time interval unit will be weeks. | String |
| out_voxel_layer(Optional) | The output voxel layer based on volumetric data stored in the output netCDF raster. This output type can only be created when the out_raster parameter is set to create a netCDF raster with the .nc extension. | Voxel Layer |

## Code Samples

### Example 1

```python
SpaceTimeKernelDensity(in_features, population_field, {elevation_field}, {elevation_field_unit}, {time_field}, {cell_size}, {kernel_search_radius_xy}, {kernel_search_radius_z}, {kernel_search_time_window}, {resultant_values}, {method}, {min_elevation}, {max_elevation}, {elevation_interval}, {elevation_unit}, {start_time}, {end_time}, {time_interval}, {time_interval_unit}, {out_voxel_layer})
```

### Example 2

```python
from arcpy import env  
from arcpy.sa import * 

env.workspace = "C:/sapyexamples/data" 
STKD_out_raster = SpaceTimeKernelDensity("WOD_subset.shp", "Salinity", "Z", "Meter",
                                         "Time", "0.001", resultant_values="Densities",
                                         method="Planar", elevation_unit="Meter")  

STKD_out_raster.save("C:/sapyexamples/output/STKD_out.crf")
```

### Example 3

```python
from arcpy import env  
from arcpy.sa import * 

env.workspace = "C:/sapyexamples/data" 
STKD_out_raster = SpaceTimeKernelDensity("WOD_subset.shp", "Salinity", "Z", "Meter",
                                         "Time", "0.001", resultant_values="Densities",
                                         method="Planar", elevation_unit="Meter")  

STKD_out_raster.save("C:/sapyexamples/output/STKD_out.crf")
```

### Example 4

```python
## Name: SpaceTimeKernelDensity_Ex_standalone.py  
## Description: Calculate spatial temporal salinity concentration using a multidimensional dataset 
## Requirements: Spatial Analyst Extension 
 
## Import system modules 
import arcpy  
from arcpy import env   
from arcpy.sa import *

## Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")
 
## Set environment settings 
env.workspace = r" C:\STKD_Test"
# To allow overwriting outputs change overwriteOutput option to True. 
env.overwriteOutput = False 
  
## Set local variables 
in_features = "WOD_subset"  
Population_Field = "Salinity"  
Elevation_Field = "Z"  
Elevation_Field_Unit = "Meter"  
Time_Field = "Time"  
Cell_Size = "30"  
Resultant_values = "Densities"  
Method = "Planar" 
Elevation_Unit = "Meter"  
  
## Execute: Space Time Kernel Density  
STKD_out_raster = SpaceTimeKernelDensity(in_features, Population_Field,   
                                Elevation_Field, Elevation_Field_Unit,   
                                Time_Field, Cell_Size,   
                                resultant_values=Resultant_values,   
                                method=Method, 
                                elevation_unit=Elevation_Unit) 
  
## Save the output 
STKD_out_raster.save("STKD_test.crf")
```

### Example 5

```python
## Name: SpaceTimeKernelDensity_Ex_standalone.py  
## Description: Calculate spatial temporal salinity concentration using a multidimensional dataset 
## Requirements: Spatial Analyst Extension 
 
## Import system modules 
import arcpy  
from arcpy import env   
from arcpy.sa import *

## Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")
 
## Set environment settings 
env.workspace = r" C:\STKD_Test"
# To allow overwriting outputs change overwriteOutput option to True. 
env.overwriteOutput = False 
  
## Set local variables 
in_features = "WOD_subset"  
Population_Field = "Salinity"  
Elevation_Field = "Z"  
Elevation_Field_Unit = "Meter"  
Time_Field = "Time"  
Cell_Size = "30"  
Resultant_values = "Densities"  
Method = "Planar" 
Elevation_Unit = "Meter"  
  
## Execute: Space Time Kernel Density  
STKD_out_raster = SpaceTimeKernelDensity(in_features, Population_Field,   
                                Elevation_Field, Elevation_Field_Unit,   
                                Time_Field, Cell_Size,   
                                resultant_values=Resultant_values,   
                                method=Method, 
                                elevation_unit=Elevation_Unit) 
  
## Save the output 
STKD_out_raster.save("STKD_test.crf")
```

---

## Spline with Barriers (Spatial Analyst)

## Summary

Interpolates a raster surface, using barriers, from points using a minimum curvature spline technique. The barriers are entered as either polygon or polyline features.

## Usage

- The output raster cannot have more than 65,536 columns or rows.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Some input datasets may have several points with the same x,y coordinates. If the values of the points at the common location are the same, they are considered duplicates and have no effect on the output. If the values are different, they are considered coincident points. The various interpolation tools may handle this data condition differently. For example, in some cases, the first coincident point encountered is used for the calculation; in other cases, the last point encountered is used. This may cause some locations in the output raster to have different values than what you might expect. The solution is to prepare your data by removing these coincident points. The Collect Events tool in the Spatial Statistics toolbox is useful for identifying any coincident points in your data. For the Spline with Barriers tool, by default the values for each set of coincident points will be averaged.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| Z value field | The field that holds a height or magnitude value for each point. This can be a numeric field or the Shape field if the input point features contain z-values. | Field |
| Input barrier features(Optional) | The optional input barrier features to constrain the interpolation. | Feature Layer |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Smoothing Factor(Optional) | The parameter that influences the smoothing of the output surface. No smoothing is applied when the value is zero and the maximum amount of smoothing is applied when the factor equals 1. The default is 0.0. | Double |
| Input_point_featuresin_point_features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| Z_value_field | The field that holds a height or magnitude value for each point. This can be a numeric field or the Shape field if the input point features contain z-values. | Field |
| Input_barrier_features(Optional) | The optional input barrier features to constrain the interpolation. | Feature Layer |
| Output_cell_sizecell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Smoothing_Factor(Optional) | The parameter that influences the smoothing of the output surface. No smoothing is applied when the value is zero and the maximum amount of smoothing is applied when the factor equals 1. The default is 0.0. | Double |

## Code Samples

### Example 1

```python
SplineWithBarriers(Input_point_features, Z_value_field, {Input_barrier_features}, {Output_cell_size}, {Smoothing_Factor})
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSplineBarriers = SplineWithBarriers("ca_ozone_pts.shp", "ozone", 
                                       "ca_ozone_barrier.shp", 2000)
outSplineBarriers.save("C:/sapyexamples/output/splinebarrierout.tif")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSplineBarriers = SplineWithBarriers("ca_ozone_pts.shp", "ozone", 
                                       "ca_ozone_barrier.shp", 2000)
outSplineBarriers.save("C:/sapyexamples/output/splinebarrierout.tif")
```

### Example 4

```python
# Name: SplineWithBarriers_Ex_02.py
# Description: Interpolate a series of point features onto a
#    rectangular raster, using optional barriers, using a
#    minimum curvature spline technique.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "ca_ozone_pts.shp"
zField = "ozone"
inBarrierFeature = "ca_ozone_barrier.shp"
cellSize = 2000.0

# Execute Spline with Barriers
outSplineBarriers = SplineWithBarriers(inPointFeatures,
                          zField, inBarrierFeature, cellSize)

# Save the output
outSplineBarriers.save("C:/sapyexamples/output/splinebout02")
```

### Example 5

```python
# Name: SplineWithBarriers_Ex_02.py
# Description: Interpolate a series of point features onto a
#    rectangular raster, using optional barriers, using a
#    minimum curvature spline technique.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "ca_ozone_pts.shp"
zField = "ozone"
inBarrierFeature = "ca_ozone_barrier.shp"
cellSize = 2000.0

# Execute Spline with Barriers
outSplineBarriers = SplineWithBarriers(inPointFeatures,
                          zField, inBarrierFeature, cellSize)

# Save the output
outSplineBarriers.save("C:/sapyexamples/output/splinebout02")
```

---

## Spline (Spatial Analyst)

## Summary

Interpolates a raster surface from points using a two-dimensional minimum curvature spline technique.

## Usage

- The greater the value of Number of Points, the smoother the surface of the output raster.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- The Regularized option of Spline type usually produces smoother surfaces than those created with the Tension option.With the Regularized option, higher values used for the weight parameter produce smoother surfaces. The values entered for this parameter must be equal to or greater than zero. Typical values used are 0, 0.001, 0.01, 0.1, and 0.5. The Weight is the square of the parameter referred to in the literature as tau (t).With the Tension option, higher values entered for the weight parameter result in somewhat coarser surfaces, but surfaces that closely conform to the control points. The values entered must be equal to or greater than zero. Typical values are 0, 1, 5, and 10. The Weight is the square of the parameter referred to in the literature as phi (Φ).
- With the Regularized option, higher values used for the weight parameter produce smoother surfaces. The values entered for this parameter must be equal to or greater than zero. Typical values used are 0, 0.001, 0.01, 0.1, and 0.5. The Weight is the square of the parameter referred to in the literature as tau (t).
- With the Tension option, higher values entered for the weight parameter result in somewhat coarser surfaces, but surfaces that closely conform to the control points. The values entered must be equal to or greater than zero. Typical values are 0, 1, 5, and 10. The Weight is the square of the parameter referred to in the literature as phi (Φ).
- Some input datasets may have several points with the same x,y coordinates. If the values of the points at the common location are the same, they are considered duplicates and have no effect on the output. If the values are different, they are considered coincident points.The various interpolation tools may handle this data condition differently. For example, in some cases, the first coincident point encountered is used for the calculation; in other cases, the last point encountered is used. This may cause some locations in the output raster to have different values than what you might expect. The solution is to prepare your data by removing these coincident points. The Collect Events tool in the Spatial Statistics toolbox is useful for identifying any coincident points in your data.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| Z value field | The field that holds a height or magnitude value for each point.This can be a numeric field or the Shape field if the input point features contain z-values. | Field |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Spline type(Optional) | The type of spline to be used.Regularized—Yields a smooth surface and smooth first derivatives.Tension—Tunes the stiffness of the interpolant according to the character of the modeled phenomenon. | String |
| Weight(Optional) | Parameter influencing the character of the surface interpolation. When the Regularized option is used, it defines the weight of the third derivatives of the surface in the curvature minimization expression. If the Tension option is used, it defines the weight of tension.The default weight is 0.1. | Double |
| Number of points(Optional) | The number of points per region used for local approximation.The default is 12. | Long |
| in_point_features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| z_field | The field that holds a height or magnitude value for each point.This can be a numeric field or the Shape field if the input point features contain z-values. | Field |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| spline_type(Optional) | The type of spline to be used.REGULARIZED—Yields a smooth surface and smooth first derivatives.TENSION—Tunes the stiffness of the interpolant according to the character of the modeled phenomenon. | String |
| weight(Optional) | Parameter influencing the character of the surface interpolation.When the REGULARIZED option is used, it defines the weight of the third derivatives of the surface in the curvature minimization expression. If the TENSION option is used, it defines the weight of tension.The default weight is 0.1. | Double |
| number_points(Optional) | The number of points per region used for local approximation.The default is 12. | Long |

## Code Samples

### Example 1

```python
Spline(in_point_features, z_field, {cell_size}, {spline_type}, {weight}, {number_points})
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSpline = Spline("ozone_pts.shp", "ozone", 2000, "REGULARIZED", 0.1)
outSpline.save("C:/sapyexamples/output/splineout.tif")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSpline = Spline("ozone_pts.shp", "ozone", 2000, "REGULARIZED", 0.1)
outSpline.save("C:/sapyexamples/output/splineout.tif")
```

### Example 4

```python
# Name: Spline_Ex_02.py
# Description: Interpolate a series of point features onto a 
#    rectangular raster using a minimum curvature spline technique.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPntFeat = "ozone_pts.shp"
zField = "ozone"
cellSize = 2000.0
splineType = "REGULARIZED"
weight = 0.1

# Execute Spline
outSpline = Spline(inPntFeat, zField, cellSize, splineType, weight)

# Save the output 
outSpline.save("C:/sapyexamples/output/splineout02")
```

### Example 5

```python
# Name: Spline_Ex_02.py
# Description: Interpolate a series of point features onto a 
#    rectangular raster using a minimum curvature spline technique.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPntFeat = "ozone_pts.shp"
zField = "ozone"
cellSize = 2000.0
splineType = "REGULARIZED"
weight = 0.1

# Execute Spline
outSpline = Spline(inPntFeat, zField, cellSize, splineType, weight)

# Save the output 
outSpline.save("C:/sapyexamples/output/splineout02")
```

---

## Square Root (Spatial Analyst)

## Summary

Calculates the square root of the cell values in a raster.

## Usage

- Input values that are less than 0 will be NoData in the output raster.
- The output raster from this tool is always floating-point type, regardless of the input value type.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input values to find the square root of.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input values to find the square root of.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
SquareRoot(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSquareRoot = SquareRoot("elevation")
outSquareRoot.save("C:/sapyexamples/output/outsqrt.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSquareRoot = SquareRoot("elevation")
outSquareRoot.save("C:/sapyexamples/output/outsqrt.img")
```

### Example 4

```python
# Name: SquareRoot_Ex_02.py
# Description: Calculates the square root of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"

# Execute SquareRoot
outSQRT = SquareRoot(inRaster)

# Save the output 
outSQRT.save("C:/sapyexamples/output/outsqrt")
```

### Example 5

```python
# Name: SquareRoot_Ex_02.py
# Description: Calculates the square root of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"

# Execute SquareRoot
outSQRT = SquareRoot(inRaster)

# Save the output 
outSQRT.save("C:/sapyexamples/output/outsqrt")
```

---

## Square (Spatial Analyst)

## Summary

Calculates the square of the cell values in a raster.

## Usage

- Output values are floating point if the input values are floating point; if the input values are integer, the output values are integer.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input values to find the square of.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input values to find the square of.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Square(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSquare = Square("degs")
outSquare.save("C:/sapyexamples/output/outsq")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outSquare = Square("degs")
outSquare.save("C:/sapyexamples/output/outsq")
```

### Example 4

```python
# Name: Square_Ex_02.py
# Description: Calculates the square of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Square
outSquare = Square(inRaster)

# Save the output 
outSquare.save("C:/sapyexamples/output/outsquare")
```

### Example 5

```python
# Name: Square_Ex_02.py
# Description: Calculates the square of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Square
outSquare = Square(inRaster)

# Save the output 
outSquare.save("C:/sapyexamples/output/outsquare")
```

---

## Storage Capacity (Spatial Analyst)

## Summary

Creates a table and a chart of elevations and corresponding storage capacities for an input surface raster. The tool calculates the surface area and total volume of the underlying region at a series of elevation increments.

## Usage

- The fields are ELEVATION, AREA, and VOLUME.
- The area and volume fields contain the storage capacity calculations at each elevation increment.
- The elevation and volume fields are calculated in z-units. The area field is calculated in the x,y units of the input surface raster.
- When no zones are specified, a ZONE_CODE field is added with a value of 1 for all records using the analysis extent as a single zone.
- If zones are specified, a field is added based on the Zone field parameter value (zone_field in Python). For an integer zone field, a field will be added with the same name in the output table. For a string zone field, a field will be added with the same name in the output table and an additional field ZONE_CODE will be added.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input surface raster | The input raster representing a continuous surface. | Raster Layer |
| Output table | The output table that contains for each zone the surface area and total volumes for each increment in elevation. | Table |
| Input raster or feature zone data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| Zone field(Optional) | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| Analysis type(Optional) | Specifies the analysis type.Area and Volume—Both surface areas and total volumes are calculated at each elevation increment. This is the default.Area—Surface area is calculated at each elevation increment.Volume—Total volume is calculated at each elevation increment. | String |
| Minimum elevation(Optional) | The minimum elevation from which storage capacities are assessed.By default, the tool uses the minimum surface raster value in each zone as the minimum elevation for that zone. If a value is provided, it is used as the minimum elevation across all zones. | Double |
| Maximum elevation(Optional) | The maximum elevation from which storage capacities are assessed.By default, the tool uses the maximum surface raster value in each zone as the maximum elevation for that zone. If a value is provided, it is used as the maximum elevation across all zones. | Double |
| Increment type(Optional) | Specifies the increment type to use when computing elevation increments between minimum and maximum elevations.Number of Increments—The number of increments between minimum and maximum elevations is used. This is the default.Value of Increment—The elevation difference between each increment is used. | String |
| Increment(Optional) | An incremental value that is either the number of increments or the difference in elevation between increments. The value is determined based on the increment type parameter value. | Double |
| Z unit(Optional) | Specifies the linear unit that will be used for vertical z-values.Inch—The linear unit will be inches.Foot—The linear unit will be feet.Yard—The linear unit will be yards.Mile US—The linear unit will be miles.Nautical mile—The linear unit will be nautical miles.Millimeter—The linear unit will be millimeters.Centimeter—The linear unit will be centimeters.Meter—The linear unit will be meters.Kilometer—The linear unit will be kilometers.Decimeter—The linear unit will be decimeters. | String |
| Output chart name(Optional) | The name of the output chart for display.The chart is listed in the Contents pane under Standalone Tables. | Chart |
| in_surface_raster | The input raster representing a continuous surface. | Raster Layer |
| out_table | The output table that contains for each zone the surface area and total volumes for each increment in elevation. | Table |
| in_zone_data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| zone_field(Optional) | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| analysis_type(Optional) | Specifies the analysis type.AREA_VOLUME—Both surface areas and total volumes are calculated at each elevation increment. This is the default.AREA—Surface area is calculated at each elevation increment.VOLUME—Total volume is calculated at each elevation increment. | String |
| min_elevation(Optional) | The minimum elevation from which storage capacities are assessed.By default, the tool uses the minimum surface raster value in each zone as the minimum elevation for that zone. If a value is provided, it is used as the minimum elevation across all zones. | Double |
| max_elevation(Optional) | The maximum elevation from which storage capacities are assessed.By default, the tool uses the maximum surface raster value in each zone as the maximum elevation for that zone. If a value is provided, it is used as the maximum elevation across all zones. | Double |
| increment_type(Optional) | Specifies the increment type to use when computing elevation increments between minimum and maximum elevations.NUMBER_OF_INCREMENTS—The number of increments between minimum and maximum elevations is used. This is the default.VALUE_OF_INCREMENT—The elevation difference between each increment is used. | String |
| increment(Optional) | An incremental value that is either the number of increments or the difference in elevation between increments. The value is determined based on the increment type parameter value. | Double |
| z_unit(Optional) | Specifies the linear unit that will be used for vertical z-values.INCH—The linear unit will be inches.FOOT—The linear unit will be feet.YARD—The linear unit will be yards.MILE_US—The linear unit will be miles.NAUTICAL_MILE—The linear unit will be nautical miles.MILLIMETER—The linear unit will be millimeters.CENTIMETER—The linear unit will be centimeters.METER—The linear unit will be meters.KILOMETER—The linear unit will be kilometers.DECIMETER—The linear unit will be decimeters. | String |
| out_chart(Optional) | The name of the output chart for display. | Chart |

## Code Samples

### Example 1

```python
StorageCapacity(in_surface_raster, out_table, in_zone_data, {zone_field}, {analysis_type}, {min_elevation}, {max_elevation}, {increment_type}, {increment}, {z_unit}, {out_chart})
```

### Example 2

```python
import arcpy
from arcpy.sa import *
arcpy.env.workspace = "C:/sapyexamples/data"
arcpy.sa.StorageCapacity("in_surface.tif", "out_table", "in_zones", "zone_id")
```

### Example 3

```python
import arcpy
from arcpy.sa import *
arcpy.env.workspace = "C:/sapyexamples/data"
arcpy.sa.StorageCapacity("in_surface.tif", "out_table", "in_zones", "zone_id")
```

### Example 4

```python
# Name: StorageCapacity_Standalone.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set the analysis environments
arcpy.CheckOutExtension("Spatial")
arcpy.env.workspace = "C:/arcpyExamples/data"

# Set local variables
in_surface_raster = "in_surface.tif"
out_table = "fgdb.gdb\out_table"
in_zones = "fgdb.gdb\in_zones"
zone_field = "zone_id"

# Execute StorageCapacity tool
arcpy.sa.StorageCapacity(in_surface_raster, out_table, in_zones, zone_field)
```

### Example 5

```python
# Name: StorageCapacity_Standalone.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set the analysis environments
arcpy.CheckOutExtension("Spatial")
arcpy.env.workspace = "C:/arcpyExamples/data"

# Set local variables
in_surface_raster = "in_surface.tif"
out_table = "fgdb.gdb\out_table"
in_zones = "fgdb.gdb\in_zones"
zone_field = "zone_id"

# Execute StorageCapacity tool
arcpy.sa.StorageCapacity(in_surface_raster, out_table, in_zones, zone_field)
```

---

## Stream Link (Spatial Analyst)

## Summary

Assigns unique values to sections of a raster linear network between intersections.

## Usage

- Links are the sections of a stream channel connecting two successive junctions, a junction and the outlet, or a junction and the drainage divide. Illustration of the links in a stream channel
- The input stream raster can be created by thresholding the results of the Flow Accumulation tool.
- The stream raster linear network should be represented as values greater than or equal to one on a background of NoData.
- The Stream Link tool only supports a D8 input flow direction raster. D8 flow directions can be created using the Flow Direction tool, run with default flow direction type D8.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. The Parallel processing with Spatial Analyst help topic includes details about this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrator privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input stream raster | An input raster that represents a linear stream network. | Raster Layer |
| Input flow direction raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool, run using the default flow direction type D8. | Raster Layer |
| in_stream_raster | An input raster that represents a linear stream network. | Raster Layer |
| in_flow_direction_raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool, run using the default flow direction type D8. | Raster Layer |

## Code Samples

### Example 1

```python
StreamLink(in_stream_raster, in_flow_direction_raster)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outStreamLink = StreamLink("stream", "flowdir")
outStreamLink.save("c:/sapyexamples/output/outstrmlnk01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outStreamLink = StreamLink("stream", "flowdir")
outStreamLink.save("c:/sapyexamples/output/outstrmlnk01")
```

### Example 4

```python
# Name: _Ex_02.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inStreamRaster = "stream"
inFlowDirection = "flowdir"

# Execute StreamLink
outStreamLink = StreamLink(inStreamRaster, inFlowDirection)

# Save the output 
outStreamLink.save("c:/sapyexamples/output/outstrmlnk02")
```

### Example 5

```python
# Name: _Ex_02.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inStreamRaster = "stream"
inFlowDirection = "flowdir"

# Execute StreamLink
outStreamLink = StreamLink(inStreamRaster, inFlowDirection)

# Save the output 
outStreamLink.save("c:/sapyexamples/output/outstrmlnk02")
```

---

## Stream Order (Spatial Analyst)

## Summary

Assigns a numeric order to segments of a raster representing branches of a linear network.

## Usage

- The output of Stream Order will be of higher quality if the input stream raster and input flow direction raster are derived from the same surface. If the stream raster is derived from a rasterized streams dataset, the output may not be usable because, on a cell-by-cell basis, the direction will not correspond with the location of stream cells.
- The results of the Flow Accumulation tool can be used to create a raster stream network by applying a threshold value to select cells with a high accumulated flow. For example, cells that have more than 100 cells flowing into them are used to define the stream network. Use the Con or Set Null tool to create a stream network raster in which flow accumulation values of 100 or greater go to 1 and the remainder are put to the background (NoData). The resulting stream network can be used in Stream Link and Stream to Feature.An analytical method for determining an appropriate threshold value for stream network delineation is presented in Tarboton, et al. (1991).
- The Stream Order tool only supports a D8 input flow direction raster. D8 flow directions can be created using the Flow Direction tool, run with default flow direction type D8.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- References:Tarboton D. G., Bras, R. L., Rodriguez–Iturbe, I. 1991. On the Extraction of Channel Networks from Digital Elevation Data. Hydrological Processes. 5: 81–100.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input stream raster | An input raster that represents a linear stream network.The input stream raster linear network should be represented as values greater than or equal to one on a background of NoData. | Raster Layer |
| Input flow direction raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool, run using the default flow direction type D8. | Raster Layer |
| Method of stream ordering(Optional) | The method used for assigning stream order.Strahler—The method of stream ordering proposed by Strahler in 1952. Stream order only increases when streams of the same order intersect. Therefore, the intersection of a first-order and second-order link will remain a second-order link, rather than creating a third-order link. This is the default.Shreve—The method of stream ordering by magnitude, proposed by Shreve in 1967. All links with no tributaries are assigned a magnitude (order) of one. Magnitudes are additive downslope. When two links intersect, their magnitudes are added and assigned to the downslope link. | String |
| in_stream_raster | An input raster that represents a linear stream network.The input stream raster linear network should be represented as values greater than or equal to one on a background of NoData. | Raster Layer |
| in_flow_direction_raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool, run using the default flow direction type D8. | Raster Layer |
| order_method(Optional) | The method used for assigning stream order.STRAHLER—The method of stream ordering proposed by Strahler in 1952. Stream order only increases when streams of the same order intersect. Therefore, the intersection of a first-order and second-order link will remain a second-order link, rather than creating a third-order link. This is the default.SHREVE—The method of stream ordering by magnitude, proposed by Shreve in 1967. All links with no tributaries are assigned a magnitude (order) of one. Magnitudes are additive downslope. When two links intersect, their magnitudes are added and assigned to the downslope link. | String |

## Code Samples

### Example 1

```python
StreamOrder(in_stream_raster, in_flow_direction_raster, {order_method})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outStreamOrder = StreamOrder("stream", "flowdir", "STRAHLER")
outStreamOrder.save("c:/sapyexamples/output/outstrmordr01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outStreamOrder = StreamOrder("stream", "flowdir", "STRAHLER")
outStreamOrder.save("c:/sapyexamples/output/outstrmordr01")
```

### Example 4

```python
# Name: StreamOrder_Ex_02.py
# Description: Assigns a numeric order to segments of a raster 
#              representing branches of a linear network.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inStreamRast = "stream"
inFlowDirectionRaster = "flowdir"
orderMethod = "STRAHLER"

# Execute StreamOrder
outStreamOrder = StreamOrder(inStreamRast, inFlowDirectionRaster, orderMethod)

# Save the output 
outStreamOrder.save("c:/sapyexamples/output/outstrmordr02")
```

### Example 5

```python
# Name: StreamOrder_Ex_02.py
# Description: Assigns a numeric order to segments of a raster 
#              representing branches of a linear network.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inStreamRast = "stream"
inFlowDirectionRaster = "flowdir"
orderMethod = "STRAHLER"

# Execute StreamOrder
outStreamOrder = StreamOrder(inStreamRast, inFlowDirectionRaster, orderMethod)

# Save the output 
outStreamOrder.save("c:/sapyexamples/output/outstrmordr02")
```

---

## Stream to Feature (Spatial Analyst)

## Summary

Converts a raster representing a linear network to features representing the linear network.

## Usage

- The input stream raster linear network should be represented as values greater than or equal to one on a background of NoData.
- The results of the Flow Accumulation tool can be used to create a raster stream network by applying a threshold value to select cells with a high accumulated flow. For example, cells that have more than 100 cells flowing into them are used to define the stream network. Use the Con or Set Null tool to create a stream network raster in which flow accumulation values of 100 or greater go to 1 and the remainder are put to the background (NoData). The resulting stream network can be used in Stream Link and Stream to Feature.
- There should be contiguous features with the same value, such as the results of the Stream Order or Stream Link tool. Stream to Feature should not be used on a raster in which there are few adjacent cells of the same value.
- The direction of the output features will point downstream.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input stream raster | An input raster that represents a linear stream network. | Raster Layer |
| Input flow direction raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool. | Raster Layer |
| Output polyline features | Output feature class that will hold the converted streams. | Feature Class |
| Simplify polylines(Optional) | Specifies whether weeding is used.Checked—The feature is weeded to reduce the number of vertices. The Douglas-Puecker algorithm for line generalization is used with a tolerance of sqrt(0.5) * cell size.Unchecked—No weeding is applied.By default, weeding is applied. | Boolean |
| in_stream_raster | An input raster that represents a linear stream network. | Raster Layer |
| in_flow_direction_raster | The input raster that shows the direction of flow out of each cell.The flow direction raster can be created using the Flow Direction tool. | Raster Layer |
| out_polyline_features | Output feature class that will hold the converted streams. | Feature Class |
| simplify(Optional) | Specifies whether weeding is used.SIMPLIFY— The feature is weeded to reduce the number of vertices. The Douglas-Puecker algorithm for line generalization is used with a tolerance of sqrt(0.5) * cell size.NO_SIMPLIFY— No weeding is applied.By default, weeding is applied. | Boolean |

## Code Samples

### Example 1

```python
StreamToFeature(in_stream_raster, in_flow_direction_raster, out_polyline_features, {simplify})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
StreamToFeature("stream", "flowdir", "c:/sapyexamples/output/outstrm01.shp", 
                "NO_SIMPLIFY")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
StreamToFeature("stream", "flowdir", "c:/sapyexamples/output/outstrm01.shp", 
                "NO_SIMPLIFY")
```

### Example 4

```python
# Name: _Ex_02.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inStreamRaster = "stream"
inFlowDir = "flowdir"
outStreamFeats = "c:/sapyexamples/output.gdb/outstrm02"


# Execute 
StreamToFeature(inStreamRaster, inFlowDir, outStreamFeats,
                 "NO_SIMPLIFY")
```

### Example 5

```python
# Name: _Ex_02.py
# Description: 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inStreamRaster = "stream"
inFlowDir = "flowdir"
outStreamFeats = "c:/sapyexamples/output.gdb/outstrm02"


# Execute 
StreamToFeature(inStreamRaster, inFlowDir, outStreamFeats,
                 "NO_SIMPLIFY")
```

---

## Surface Parameters (Spatial Analyst)

## Summary

Determines parameters of a raster surface such as aspect, slope, and curvatures.

## Usage


## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input surface raster | The input surface raster. | Raster Layer |
| Parameter type(Optional) | Specifies the output surface parameter type that will be computed.Slope—The rate of change in elevation will be computed. This is the default.Aspect—The downslope direction of the maximum rate of change for each cell will be computed.Mean curvature—The overall curvature of the surface will be measured. It is computed as the average of the minimum and maximum curvature. This curvature describes the intrinsic convexity or concavity of the surface, independent of direction or gravity influence.Tangential (normal contour) curvature—The geometric normal curvature perpendicular to the slope line, tangent to the contour line will be measured. This curvature is typically applied to characterize the convergence or divergence of flow across the surface.Profile (normal slope line) curvature—The geometric normal curvature along the slope line will be measured. This curvature is typically applied to characterize the acceleration and deceleration of flow down the surface.Plan (projected contour) curvature—The curvature along contour lines will be measured.Contour geodesic torsion—The rate of change in slope angle along contour lines will be measured.Gaussian curvature—The overall curvature of the surface will be measured. It is computed as the product of the minimum and maximum curvature.Casorati curvature—The general curvature of the surface will be measured. It can be zero or any other positive number. | String |
| Local surface type(Optional) | Specifies the type of surface function that will be fitted around the target cell.Quadratic—A quadratic surface function will be fitted to the neighborhood cells. This is the default.Biquadratic—A biquadratic surface function will be fitted to the neighborhood cells. | String |
| Neighborhood distance(Optional) | The output will be calculated over this distance from the target cell center. It determines the neighborhood size.The default value is the input raster cell size, resulting in a 3 by 3 neighborhood. | Linear Unit |
| Use adaptive neighborhood(Optional) | Specifies whether neighborhood distance will vary with landscape changes (adaptive). The maximum distance is determined by the neighborhood distance. The minimum distance is the input raster cell size. Unchecked—A single (fixed) neighborhood distance will be used at all locations. This is the default. Checked—An adaptive neighborhood distance will be used at all locations. | Boolean |
| Z unit(Optional) | Specifies the linear unit that will be used for vertical z-values.It is defined by a vertical coordinate system if it exists. If no vertical coordinate system exists, define the z-unit using the unit list to ensure correct geodesic computation. The default is meter.Inch—The linear unit will be inches.Foot—The linear unit will be feet.Yard—The linear unit will be yards.Mile US—The linear unit will be miles.Nautical mile—The linear unit will be nautical miles.Millimeter—The linear unit will be millimeters.Centimeter—The linear unit will be centimeters.Meter—The linear unit will be meters.Kilometer—The linear unit will be kilometers.Decimeter—The linear unit will be decimeters. | String |
| Slope measurement(Optional) | The measurement units (degrees or percentages) that will be used for the output slope raster.This parameter is only available if the Parameter type parameter is set to Slope.Degree—The inclination of slope will be calculated in degrees.Percent rise—The inclination of slope will be calculated as percent rise, also referred to as the percent slope. | String |
| Project geodesic azimuths(Optional) | Specifies whether geodesic azimuths will be projected to correct the angle distortion caused by the output spatial reference. Unchecked—Geodesic azimuths will not be projected. This is the default.Checked—Geodesic azimuths will be projected.This parameter is only available if the Parameter type parameter is set to Aspect. | Boolean |
| Use equatorial aspect(Optional) | Specifies whether aspect will be measured from a point on the equator or from the north pole. Unchecked—Aspect will be measured from the north pole. This is the default.Checked—Aspect will be measured from a point on the equator.This parameter is only available if the Parameter type parameter is set to Aspect. | Boolean |
| Input analysis mask(Optional) | The input data defining the locations where the analysis will occur.It can be a raster or feature dataset. If the input is a raster, it can be integer or floating-point type. If the input is feature data, it can be point, line, or polygon type.When the input mask data is a raster, the analysis will occur at locations that have a valid value, including zero. Cells that are NoData in the mask input will be NoData in the output. | Composite Geodataset |
| in_raster | The input surface raster. | Raster Layer |
| parameter_type(Optional) | Specifies the output surface parameter type that will be computed.SLOPE—The rate of change in elevation will be computed. This is the default.ASPECT—The downslope direction of the maximum rate of change for each cell will be computed.MEAN_CURVATURE—The overall curvature of the surface will be measured. It is computed as the average of the minimum and maximum curvature. This curvature describes the intrinsic convexity or concavity of the surface, independent of direction or gravity influence.TANGENTIAL_CURVATURE—The geometric normal curvature perpendicular to the slope line, tangent to the contour line will be measured. This curvature is typically applied to characterize the convergence or divergence of flow across the surface.PROFILE_CURVATURE—The geometric normal curvature along the slope line will be measured. This curvature is typically applied to characterize the acceleration and deceleration of flow down the surface.CONTOUR_CURVATURE—The curvature along contour lines will be measured.CONTOUR_GEODESIC_TORSION—The rate of change in slope angle along contour lines will be measured.GAUSSIAN_CURVATURE—The overall curvature of the surface will be measured. It is computed as the product of the minimum and maximum curvature.CASORATI_CURVATURE—The general curvature of the surface will be measured. It can be zero or any other positive number. | String |
| local_surface_type(Optional) | Specifies the type of surface function that will be fitted around the target cell.QUADRATIC—A quadratic surface function will be fitted to the neighborhood cells. This is the default.BIQUADRATIC—A biquadratic surface function will be fitted to the neighborhood cells. | String |
| neighborhood_distance(Optional) | The output will be calculated over this distance from the target cell center. It determines the neighborhood size.The default value is the input raster cell size, resulting in a 3 by 3 neighborhood. | Linear Unit |
| use_adaptive_neighborhood(Optional) | Specifies whether neighborhood distance will vary with landscape changes (adaptive). The maximum distance is determined by the neighborhood distance. The minimum distance is the input raster cell size. FIXED_NEIGHBORHOOD—A single (fixed) neighborhood distance will be used at all locations. This is the default.ADAPTIVE_NEIGHBORHOOD—An adaptive neighborhood distance will be used at all locations. | Boolean |
| z_unit(Optional) | Specifies the linear unit that will be used for vertical z-values.It is defined by a vertical coordinate system if it exists. If no vertical coordinate system exists, define the z-unit using the unit list to ensure correct geodesic computation. The default is meter.INCH—The linear unit will be inches.FOOT—The linear unit will be feet.YARD—The linear unit will be yards.MILE_US—The linear unit will be miles.NAUTICAL_MILE—The linear unit will be nautical miles.MILLIMETER—The linear unit will be millimeters.CENTIMETER—The linear unit will be centimeters.METER—The linear unit will be meters.KILOMETER—The linear unit will be kilometers.DECIMETER—The linear unit will be decimeters. | String |
| output_slope_measurement(Optional) | The measurement units (degrees or percentages) that will be used for the output slope raster.DEGREE—The inclination of slope will be calculated in degrees.PERCENT_RISE—The inclination of slope will be calculated as percent rise, also referred to as the percent slope.This parameter is only supported if the parameter_type parameter is set to SLOPE. | String |
| project_geodesic_azimuths(Optional) | Specifies whether geodesic azimuths will be projected to correct the angle distortion caused by the output spatial reference. GEODESIC_AZIMUTHS—Geodesic azimuths will not be projected. This is the default.PROJECT_GEODESIC_AZIMUTHS—Geodesic azimuths will be projected.This parameter is only supported if the parameter_type parameter is set to ASPECT. | Boolean |
| use_equatorial_aspect(Optional) | Specifies whether aspect will be measured from a point on the equator or from the north pole. NORTH_POLE_ASPECT—Aspect will be measured from the north pole. This is the default.EQUATORIAL_ASPECT—Aspect will be measured from a point on the equator.This parameter is only supported if the parameter_type parameter is set to ASPECT. | Boolean |
| in_analysis_mask(Optional) | The input data defining the locations where the analysis will occur.It can be a raster or feature dataset. If the input is a raster, it can be integer or floating-point type. If the input is feature data, it can be point, line, or polygon type.When the input mask data is a raster, the analysis will occur at locations that have a valid value, including zero. Cells that are NoData in the mask input will be NoData in the output. | Composite Geodataset |

## Code Samples

### Example 1

```python
SurfaceParameters(in_raster, {parameter_type}, {local_surface_type}, {neighborhood_distance}, {use_adaptive_neighborhood}, {z_unit}, {output_slope_measurement}, {project_geodesic_azimuths}, {use_equatorial_aspect}, {in_analysis_mask})
```

### Example 2

```python
from arcpy.sa import *
outSurfaceParameters = SurfaceParameters("elevation_1m.tif", "", "", "5 METERS",
                                         "ADAPTIVE_NEIGHBORHOOD", "", "PERCENT_RISE")
outSurfaceParameters.save("C:/sapyexamples/output/outsurfaceparameters01.tif")
```

### Example 3

```python
from arcpy.sa import *
outSurfaceParameters = SurfaceParameters("elevation_1m.tif", "", "", "5 METERS",
                                         "ADAPTIVE_NEIGHBORHOOD", "", "PERCENT_RISE")
outSurfaceParameters.save("C:/sapyexamples/output/outsurfaceparameters01.tif")
```

### Example 4

```python
# Name: SurfaceParameters_Ex_02.py
# Description: Derive profile (normal slope line) curvature for a 1m resolution
# elevation raster over an adaptive neighborhood distance of maximum 10m. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation_1m.tif"
inParameterType = "PROFILE_CURVATURE"
inNeighborhoodDistance = "10 METERS"
inUseAdaptiveNeighborhood = "ADAPTIVE_NEIGHBORHOOD"

# Execute the tool
outSurfaceParameters = SurfaceParameters(inRaster, inParameterType, "",
                                         inNeighborhoodDistance, inUseAdaptiveNeighborhood)

# Save the output 
outSurfaceParameters.save("C:/sapyexamples/output/outsurfaceparameters02.tif")
```

### Example 5

```python
# Name: SurfaceParameters_Ex_02.py
# Description: Derive profile (normal slope line) curvature for a 1m resolution
# elevation raster over an adaptive neighborhood distance of maximum 10m. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation_1m.tif"
inParameterType = "PROFILE_CURVATURE"
inNeighborhoodDistance = "10 METERS"
inUseAdaptiveNeighborhood = "ADAPTIVE_NEIGHBORHOOD"

# Execute the tool
outSurfaceParameters = SurfaceParameters(inRaster, inParameterType, "",
                                         inNeighborhoodDistance, inUseAdaptiveNeighborhood)

# Save the output 
outSurfaceParameters.save("C:/sapyexamples/output/outsurfaceparameters02.tif")
```

### Example 6

```python
# Name: SurfaceParameters_Ex_03.py
# Description: Derive aspect for an elevation surface over a distance of 5m, correct
# for direction distortion from non-conformal projection system. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation_1m.tif"
inParameterType = "ASPECT"
inNeighborhoodDistance = "5 METERS"
inProjectGeodesicAzimuths = "PROJECT_GEODESIC_AZIMUTHS"

# Execute the tool
outSurfaceParameters = SurfaceParameters(inRaster, inParameterType, "",
                                         inNeighborhoodDistance, "", "", "",
                                         inProjectGeodesicAzimuths)

# Save the output 
outSurfaceParameters.save("C:/sapyexamples/output/outsurfaceparameters03.tif")
```

### Example 7

```python
# Name: SurfaceParameters_Ex_03.py
# Description: Derive aspect for an elevation surface over a distance of 5m, correct
# for direction distortion from non-conformal projection system. 
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Set environment settings
arcpy.env.workspace = "C:/sapyexamples/data"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set local variables
inRaster = "elevation_1m.tif"
inParameterType = "ASPECT"
inNeighborhoodDistance = "5 METERS"
inProjectGeodesicAzimuths = "PROJECT_GEODESIC_AZIMUTHS"

# Execute the tool
outSurfaceParameters = SurfaceParameters(inRaster, inParameterType, "",
                                         inNeighborhoodDistance, "", "", "",
                                         inProjectGeodesicAzimuths)

# Save the output 
outSurfaceParameters.save("C:/sapyexamples/output/outsurfaceparameters03.tif")
```

---

## Tabulate Area (Spatial Analyst)

## Summary

Calculates cross-tabulated areas between two datasets and outputs a table.

## Usage

- A zone is defined as all areas in the input that have the same value. The areas do not have to be contiguous. Both rasters and features can be used for the zone input.
- If either of the inputs is a raster, it must have an integer data type.
- If either of the input datasets is a feature class, it is converted internally to a raster before the analysis is performed, using the Cell Size and the cell alignment of the other input raster.
- If both the inputs are rasters and their cells are not aligned, the inputs will be resampled during the analysis. If the environment Snap Raster hasn't been explicitly specified, the cells are aligned internally using the Input raster or feature class data (in_class_data in Python). If both the rasters are of the same cell size and the cells are aligned, there will be no resampling.
- If both of the input datasets are feature class, they are converted internally to a raster before the analysis is performed using the Processing Cell Size (processing_cell_size in Python) or from the raster analysis environment, if specified.
- If the Input raster or feature zone data (in_zone_data in Python) is a feature, for any of the zone features that do not overlap any cell centers of the class raster, those zones will not get converted to the internal zone raster. As a result, those zones will not be represented in the output. You can manage this by determining an appropriate value for the Cell Size environment that will preserve the desired level of detail of the feature zones, and specify it in the analysis environment.
- If the inputs have overlapping features, the zonal analysis will be performed for each individual feature.
- If point or line data is used as the input feature class, the area intersected by those features will be reported.
- When specifying the input zone or class data, the default field will be the first available integer or text field. If no other valid fields exist, the ObjectID field (for example, OID or FID) will be the default.
- The Processing Cell Size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size has not been specified, the default output cell size is determined based on the type of input dataset as follows:If the input dataset is a raster, the cell size of the dataset is used.If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the input dataset is a raster, the cell size of the dataset is used.
- If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- The Classes as rows in output table parameter (classes_as_rows in Python) allows you to select the type of output table schema. Check this parameter (CLASSES_AS_ROWS in Python) to represent the classes rows or uncheck it (CLASSES_AS_FIELDS in Python) to represent the classes as fields .When classes are represented in rows, the table output can be related and queried to extract area information by zone or class rasters.
- The output of this tool is a table.In this table, when the Classes as rows in output table parameter is unchecked (CLASSES_AS_FIELDS in Python), the following is true: There will be a record for each unique value of the zone dataset.There will be a field for each unique value of the class dataset.Each record will store the area of each class within each zone.When the Classes as rows in output table parameter is checked (CLASSES_AS_ROWS in Python), the following is true: There will be a record for each unique value of the zone dataset that has an unique value of the class dataset.There will be individual fields that identify the zone field, the class field, the count, and the area of each class within each zone.
- There will be a record for each unique value of the zone dataset.
- There will be a field for each unique value of the class dataset.
- Each record will store the area of each class within each zone.
- There will be a record for each unique value of the zone dataset that has an unique value of the class dataset.
- There will be individual fields that identify the zone field, the class field, the count, and the area of each class within each zone.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature zone data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| Zone field | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| Input raster or feature class data | The dataset that defines the classes that will have their area summarized within each zone.The class input can be an integer raster layer or a feature layer. | Raster Layer; Feature Layer |
| Class field | The field that holds the class values.It can be an integer or a string field of the input class data. | Field |
| Output table | The output table that will contain the summary of the area of each class in each zone.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table if in a geodatabase workspace, and a dBASE table if in a file workspace. | Table |
| Processing cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Classes as rows in output table(Optional) | Specifies how the values from the input class raster will be represented in the output table.Unchecked—Classes will be represented as fields. This is the default.Checked—Classes will be represented as rows. | Boolean |
| in_zone_data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| zone_field | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| in_class_data | The dataset that defines the classes that will have their area summarized within each zone.The class input can be an integer raster layer or a feature layer. | Raster Layer; Feature Layer |
| class_field | The field that holds the class values.It can be an integer or a string field of the input class data. | Field |
| out_table | The output table that will contain the summary of the area of each class in each zone.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table if in a geodatabase workspace, and a dBASE table if in a file workspace. | Table |
| processing_cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| classes_as_rows(Optional) | Specifies how the values from the input class raster will be represented in the output table.CLASSES_AS_FIELDS—Classes will be represented as fields. This is the default.CLASSES_AS_ROWS—Classes will be represented as rows. | Boolean |

## Code Samples

### Example 1

```python
TabulateArea(in_zone_data, zone_field, in_class_data, class_field, out_table, {processing_cell_size}, {classes_as_rows})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
TabulateArea("zonedata.shp", "IDStr", "valueraster", "VALUE",
             "C:/sapyexamples/output/areatable.dbf", 2)
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
TabulateArea("zonedata.shp", "IDStr", "valueraster", "VALUE",
             "C:/sapyexamples/output/areatable.dbf", 2)
```

### Example 4

```python
# Name: TabulateArea_Ex_02.py
# Description: Calculates cross tabulated areas between two datasets.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"
env.extent = "classgrid"
env.snapRaster = "classgrid"

# Set local variables
inZoneData = "zonedata.shp"
zoneField = "IDStr"
inClassData = "valueraster"
classField = "VALUE"
outTable = "C:/sapyexamples/output/areatable02.dbf"
processingCellSize = 2

# Execute TabulateArea
TabulateArea(inZoneData, zoneField, inClassData, classField, outTable,
             processingCellSize)
```

### Example 5

```python
# Name: TabulateArea_Ex_02.py
# Description: Calculates cross tabulated areas between two datasets.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"
env.extent = "classgrid"
env.snapRaster = "classgrid"

# Set local variables
inZoneData = "zonedata.shp"
zoneField = "IDStr"
inClassData = "valueraster"
classField = "VALUE"
outTable = "C:/sapyexamples/output/areatable02.dbf"
processingCellSize = 2

# Execute TabulateArea
TabulateArea(inZoneData, zoneField, inClassData, classField, outTable,
             processingCellSize)
```

---

## Tan (Spatial Analyst)

## Summary

Calculates the tangent of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -∞ < [in_value] < ∞ The Range is: -∞ < [out_value] < ∞ Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: -∞ < [in_value] < ∞
- The Range is: -∞ < [out_value] < ∞
- The input values for this tool are interpreted to be in radians. If the input you want to use is in degrees, the values must first be divided by the radians-to-degrees conversion factor of 180/pi, or approximately 57.296.For further assistance, a procedure to follow and examples of converting input values in degrees to radians are available.
- The output values from this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- Due to the range of values, applying a Histogram Equalized stretch renderer can be useful to best see the results.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input for which to calculate the tangent values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input for which to calculate the tangent values.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Tan(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTan = Tan("degs")
outTan.save("C:/sapyexamples/output/outtan")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTan = Tan("degs")
outTan.save("C:/sapyexamples/output/outtan")
```

### Example 4

```python
# Name: Tan_Ex_02.py
# Description: Calculates the tangent of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Tan
outTan = Tan(inRaster)

# Save the output 
outTan.save("C:/sapyexamples/output/outtan.tif")
```

### Example 5

```python
# Name: Tan_Ex_02.py
# Description: Calculates the tangent of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute Tan
outTan = Tan(inRaster)

# Save the output 
outTan.save("C:/sapyexamples/output/outtan.tif")
```

---

## TanH (Spatial Analyst)

## Summary

Calculates the hyperbolic tangent of cells in a raster.

## Usage

- In mathematics, all trigonometric functions have a defined range of valid input values called the domain. The output values from each function also have a defined range. For this tool, the following are true:The Domain is: -∞ < [in_value] < ∞ The Range is: -1 < [out_value] < 1 Note that -∞ and ∞ represent the smallest negative and largest positive values supported by the particular raster format, respectively.
- The Domain is: -∞ < [in_value] < ∞
- The Range is: -1 < [out_value] < 1
- The input and output values for this tool are interpreted as unitless.
- Output values are always floating point, regardless of the input data type.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value | The input to calculate the hyperbolic tangent values for.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant | The input to calculate the hyperbolic tangent values for.To use a number as an input for this parameter, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
TanH(in_raster_or_constant)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTanH = TanH("degs")
outTanH.save("C:/sapyexamples/output/outtanh")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTanH = TanH("degs")
outTanH.save("C:/sapyexamples/output/outtanh")
```

### Example 4

```python
# Name: TanH_Ex_02.py
# Description: Calculates the hyperbolic tangent of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute TanH
outTanH = TanH(inRaster)

# Save the output 
outTanH.save("C:/sapyexamples/output/outtanh.img")
```

### Example 5

```python
# Name: TanH_Ex_02.py
# Description: Calculates the hyperbolic tangent of cells in a raster
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"

# Execute TanH
outTanH = TanH(inRaster)

# Save the output 
outTanH.save("C:/sapyexamples/output/outtanh.img")
```

---

## Test (Spatial Analyst)

## Summary

Performs a Boolean evaluation of the input raster using a logical expression.

## Usage

- The test is specified by an SQL expression in the Where clause.
- The Where clause uses an SQL query. See the following topics for more details on creating queries: Build an SQL querySQL reference for query expressions used in ArcGIS
- Build an SQL query
- SQL reference for query expressions used in ArcGIS
- In order to use a {where_clause} in Python, it should be enclosed in quotes. For example, "Value > 5000".You can consult the help for more information on specifying a query in Python.
- If the input is a multiband raster, the output will be a multiband raster. The tool will perform the operation on each band in the input.
- If the input is multidimensional raster data, all slices from all variables will be processed. The output will be a multidimensional raster in CRF format.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster on which the Boolean evaluation is performed, based on a logical expression. | Raster Layer |
| Where clause | The logical expression that will determine which input cells will return a value of true (1) and which will be false (0).The Where clause follows the general form of an SQL expression. It can be entered directly, for example, VALUE > 100, if you click the Edit SQL mode button . If in the Edit Clause Mode , you can begin constructing the expression by clicking on the Add Clause Mode button. | SQL Expression |
| in_raster | The input raster on which the Boolean evaluation is performed, based on a logical expression. | Raster Layer |
| where_clause | The logical expression that will determine which input cells will return a value of true (1) and which will be false (0).The expression follows the general form of an SQL expression. An example of a where_clause is "VALUE > 100". | SQL Expression |

## Code Samples

### Example 1

```python
Test(in_raster, where_clause)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTest = Test("degs", "VALUE > 100")
outTest.save("C:/sapyexamples/output/outest.img")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTest = Test("degs", "VALUE > 100")
outTest.save("C:/sapyexamples/output/outest.img")
```

### Example 4

```python
# Name: Test_Ex_02.py
# Description: Perform a Boolean evaluation of the input raster based
#              on a where clause
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"
inWhereClause = "VALUE > 100"

# Execute Test
outTest = Test(inRaster, inWhereClause)

# Save the output 
outTest.save("C:/sapyexamples/output/outtest")
```

### Example 5

```python
# Name: Test_Ex_02.py
# Description: Perform a Boolean evaluation of the input raster based
#              on a where clause
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "degs"
inWhereClause = "VALUE > 100"

# Execute Test
outTest = Test(inRaster, inWhereClause)

# Save the output 
outTest.save("C:/sapyexamples/output/outtest")
```

---

## Thin (Spatial Analyst)

## Summary

Thins rasterized linear features by reducing the number of cells representing the width of the features.

## Usage

- A typical application for the Thin tool is for processing a scanned elevation contour map. Because of the resolution of the scanner and the width of the lines on the original map, the contours are represented in the resulting raster as linear elements from five to ten cells wide. After running Thin, each contour will be represented as a linear feature of a single cell width.
- If enabled, the filter option uses the same filtering algorithm as the Boundary Clean tool to remove short linear features extending from the major branch. It can also remove features narrower than three cells.
- Specifying the maximum thickness of input linear features is essential for thinning rasters where the thickness of linear features may exceed or stay below the default maximum thickness value. The best results can be expected when the maximum thickness fits the thickest linear features to be thinned.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- Reference:Zhan, Cixiang, 1993, A Hybrid Line Thinning Approach, Proceedings Auto-Carto 11, Minneapolis , pp. 396-405

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input raster to be thinned.It must be of integer type. | Raster Layer |
| Background value(Optional) | Specifies the cell value that will identify the background cells. The linear features are formed from the foreground cells.Zero—The background is composed of cells of 0 or less, or NoData. All cells whose value is greater than 0 are the foreground.NoData—The background is composed of NoData cells. All cells with valid values belong to the foreground. | String |
| Filter input first(Optional) | Specifies whether a filter will be applied as the first phase of thinning.Unchecked—No filter will be applied. This is the default.Checked—The raster will be filtered to smooth the boundaries between foreground and background cells. This option will eliminate minor irregularities from the output raster. | Boolean |
| Shape for corners(Optional) | Specifies whether round or sharp turns will be made at turns or junctions.It is also used during the vector conversion process to spline curves or create sharp intersections and corners.Round—Attempts to smooth corners and junctions. This is best for vectorizing natural features, such as contours or streams.Sharp—Attempts to preserve rectangular corners and junctions. This is best for vectorizing man-made features such as streets. | String |
| Maximum thickness of input linear features(Optional) | The maximum thickness, in map units, of linear features in the input raster.The default thickness is ten times the cell size. | Double |
| in_raster | The input raster to be thinned.It must be of integer type. | Raster Layer |
| background_value(Optional) | Specifies the cell value that will identify the background cells. The linear features are formed from the foreground cells.ZERO—The background is composed of cells of 0 or less, or NoData. All cells whose value is greater than 0 are the foreground.NODATA—The background is composed of NoData cells. All cells with valid values belong to the foreground. | String |
| filter(Optional) | Specifies whether a filter will be applied as the first phase of thinning.NO_FILTER—No filter will be applied.This is the default.FILTER—The raster will be filtered to smooth the boundaries between foreground and background cells. This option will eliminate minor irregularities from the output raster. | Boolean |
| corners(Optional) | Specifies whether round or sharp turns will be made at turns or junctions.It is also used during the vector conversion process to spline curves or create sharp intersections and corners.ROUND—Attempts to smooth corners and junctions. This is best for vectorizing natural features, such as contours or streams.SHARP—Attempts to preserve rectangular corners and junctions. This is best for vectorizing man-made features such as streets. | String |
| maximum_thickness(Optional) | The maximum thickness, in map units, of linear features in the input raster.The default thickness is ten times the cell size. | Double |

## Code Samples

### Example 1

```python
Thin(in_raster, {background_value}, {filter}, {corners}, {maximum_thickness})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
thinOut = Thin("land","NODATA", "FILTER", "SHARP", 300)
thinOut.save("c:/sapyexamples/output/thinout")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
thinOut = Thin("land","NODATA", "FILTER", "SHARP", 300)
thinOut.save("c:/sapyexamples/output/thinout")
```

### Example 4

```python
# Name: Thin_Ex_02.py
# Description: Thins rasterized linear features by 
#              reducing the number of cells 
#              representing the width of the features.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"
tolerance = 300

# Execute Thin
thinOut = Thin(inRaster, "NODATA", "FILTER", "SHARP", tolerance)

# Save the output 
thinOut.save("c:/sapyexamples/output/thinoutput")
```

### Example 5

```python
# Name: Thin_Ex_02.py
# Description: Thins rasterized linear features by 
#              reducing the number of cells 
#              representing the width of the features.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "land"
tolerance = 300

# Execute Thin
thinOut = Thin(inRaster, "NODATA", "FILTER", "SHARP", tolerance)

# Save the output 
thinOut.save("c:/sapyexamples/output/thinoutput")
```

---

## Times (Spatial Analyst)

## Summary

Multiplies the values of two rasters on a cell-by-cell basis.

## Usage

- The order of inputs is irrelevant for this tool.
- If both inputs are integer, the output will be an integer raster; otherwise, it will be a floating-point raster.
- If both inputs are single-band rasters or one of the inputs is a constant, the output will be a single-band raster.
- If both inputs are multiband rasters, the tool will perform the operation on each band from one input, and the output will be a multiband raster. The number of bands in each multiband input must be the same.
- If one of the inputs is a multiband raster and the other input is a constant, the tool will perform the operation using the constant value for each band in the multiband input, and the output will be a multiband raster.
- If both inputs are multidimensional raster data with the same number of variables, the tool will perform the operation for all slices with the same dimension value. The output will be a multidimensional raster in CRF format. The variables in the inputs must have at least one common dimension and one common dimensional value for this tool to process; otherwise, an error will occur.If both inputs have one variable but different names, uncheck the Match Multidimensional Variable geoprocessing environment (set arcpy.env.matchMultidimensionalVariable = False in Python) before running the tool.If one of the inputs is a multidimensional raster and the other input is a constant, the tool will perform the operation for all slices for all variables using the constant value, and the output will be a multidimensional raster.
- In map algebra, the equivalent operator symbol for this tool is "*" (link).
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or constant value 1 | The input containing the values to be multiplied.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| Input raster or constant value 2 | The input containing the values by which the first input will be multiplied.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant1 | The input containing the values to be multiplied.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |
| in_raster_or_constant2 | The input containing the values by which the first input will be multiplied.A number can be used as an input for this parameter, provided a raster is specified for the other parameter. To specify a number for both inputs, the cell size and extent must first be set in the environment. | Raster Layer; Constant |

## Code Samples

### Example 1

```python
Times(in_raster_or_constant1, in_raster_or_constant2)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTimes = Times("elevation", "0.3048")
outTimes.save("C:/sapyexamples/output/outtimes")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTimes = Times("elevation", "0.3048")
outTimes.save("C:/sapyexamples/output/outtimes")
```

### Example 4

```python
# Name: Times_Ex_02.py
# Description: Multiplies the values of two rasters on a cell-by-cell basis.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inConstant = 0.3048

# Execute Times
outTimes = Times(inRaster, inConstant)

# Save the output 
outTimes.save("C:/sapyexamples/output/timesout")
```

### Example 5

```python
# Name: Times_Ex_02.py
# Description: Multiplies the values of two rasters on a cell-by-cell basis.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inConstant = 0.3048

# Execute Times
outTimes = Times(inRaster, inConstant)

# Save the output 
outTimes.save("C:/sapyexamples/output/timesout")
```

---

## Topo to Raster by File (Spatial Analyst)

## Summary

Interpolates a hydrologically correct raster surface from point, line, and polygon data using parameters specified in a file.

## Usage

- The parameter file is structured with the input datasets listed first, followed by the various parameter settings, then the output options.The input data identifies the input datasets and, where applicable, fields. There are nine types of input: Contours, Points, Sinks, Streams, Lakes, Boundaries, Cliffs, Exclusion, and Coastal polygons. You can use as many inputs as you want, within reason. The order in which the inputs are entered does not have any bearing on the outcome. <Path> indicates a path to a dataset, <Item> indicates a field name, and <#> indicates a value to be entered.The following table lists all of the parameters, the definition of each, and their syntax.ParameterDefinitionSyntaxInput datasets:ContoursContour line dataset with item containing height values.Contour <Path> <Item>PointsPoint dataset with item containing height values.Point <Path> <Item>SinksPoint dataset containing sink locations. If the dataset has elevation values for the sinks, specify that field name as the <Item>. If only the locations of the sinks are to be used, use NONE for <Item>.Sink <Path> <Item>StreamsStream line dataset. Height values are not necessary.Stream <Path>LakesLake polygon dataset. Height values are not necessary.Lake <Path>BoundaryBoundary polygon dataset. Height values are not necessary.Boundary <Path>CliffLine dataset of the cliffs. There is no Field option for Cliff.Cliff <Path>ExclusionExclusion polygon dataset of the areas in which the input data should be ignored. There is no Field option for Exclusion.Exclusion <Path>CoastCoast polygon dataset containing the outline of a coastal area. There is no Field option for Coast. Boundary <Path>Parameter settings:EnforceControls whether drainage enforcement is applied.ENFORCE <ON | OFF | ON_WITH_SINK>DatatypePrimary type of input data.DATATYPE <CONTOUR | SPOT>IterationsThe maximum number of iterations the algorithm performs.ITERATIONS <#>Roughness penaltyThe measure of surface roughness.ROUGHNESS_PENALTY <#>Profile curvature roughness penaltyThe profile curvature roughness penalty is a locally adaptive penalty that can be use to partly replace total curvature.PROFILE_PENALTY <#>Discretisation error factorThe amount to adjust the data smoothing of the input data into a raster.DISCRETE_ERROR_FACTOR <#>Vertical standard errorThe amount of random error in the z-values of the input data.VERTICAL_STANDARD_ERROR <#>TolerancesThe first reflects the accuracy of elevation data in relation to surface drainage, and the other prevents drainage clearance through unrealistically high barriers.TOLERANCES <#> <#>Z-LimitsLower and upper height limits.ZLIMITS <#> <#>ExtentMinimum x, minimum y, maximum x, and maximum y coordinate limits.EXTENT <#> <#> <#> <#>Cell sizeThe resolution of the final output raster.CELL_SIZE <#>MarginDistance in cells to interpolate beyond the specified output extent and boundary.MARGIN <#>Outputs:Output stream featuresThe output line feature class of stream polyline features and ridge line features.OUT_STREAMOutput sink featuresThe output point feature class of the remaining sink point features.OUT_SINKOutput diagnostics fileThe location and name of the diagnostics file.OUT_DIAGNOSTICS <Path>Output residual point featuresThe output point feature class of all the large elevation residuals as scaled by the local discretisation error.OUT_RESIDUALSOutput stream and cliff point featuresThe output point feature class of locations where possible stream and cliff errors occur.OUT_STREAM_CLIFF_ERRORSOutput contour error point featuresThe output point feature class of possible errors pertaining to the input contour data.OUT_CONTOUR_ERRORS
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- Do not specify paths for the optional output feature datasets in the parameter file. Use the Output stream polyline features and Output remaining sink point features in the tool dialog box to identify these outputs.
- The contents of an example parameter file are: Contour D:\data\contours2\arc HEIGHT Point D:\data\points2\point SPOTS Sink D:\data\sinks_200.shp Stream D:\data\streams\arc Lake D:\data\lakes\polygon Boundary D:\data\clipcov\polygon Cliff D:\data\cliffs.shp ENFORCE ON DATATYPE CONTOUR ITERATIONS 40 ROUGHNESS_PENALTY 0.0 PROFILE_PENALTY 0.5 DISCRETE_ERROR_FACTOR 1.0 VERTICAL_STANDARD_ERROR 0.0 TOLERANCES 2.5 100.0 ZLIMITS -2000.0 13000.0 EXTENT -810480.625 8321785.0 810480.625 10140379.0 CELL_SIZE 1800.00000000000 MARGIN 20 OUT_DIAGNOSTICS D:\data\ttr_diag.txt
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input parameter file | The input ASCII text file containing the inputs and parameters to use for the interpolation.The file is typically created from a previous run of Topo to Raster with the optional output parameter file specified.In order to test the outcome of changing the parameters, it is easier to make edits to this file and rerun the interpolation than to correctly issue the Topo to Raster tool each time. | File |
| Output stream polyline features(Optional) | Output feature class of stream polyline features.The polyline features are coded as follows:1. Input stream line not over cliff.2. Input stream line over cliff (waterfall).3. Drainage enforcement clearing a spurious sink.4. Stream line determined from contour corner.5. Ridge line determined from contour corner.6. Code not used.7. Data stream line side conditions.8. Code not used.9. Line indicating large elevation data clearance. | Feature Class |
| Output remaining sink point features(Optional) | Output feature class of remaining sink point features. | Feature Class |
| Output residual point features(Optional) | The output point feature class of all the large elevation residuals as scaled by the local discretisation error.All the scaled residuals larger than 10 should be inspected for possible errors in input elevation and stream data. Large-scaled residuals indicate conflicts between input elevation data and streamline data. These may also be associated with poor automatic drainage enforcements. These conflicts can be remedied by providing additional streamline and/or point elevation data after first checking and correcting errors in existing input data. Large unscaled residuals usually indicate input elevation errors. | Feature Class |
| Output stream and cliff error point features(Optional) | The output point feature class of locations where possible stream and cliff errors occur.The locations where the streams have closed loops, distributaries, and streams over cliffs can be identified from the point feature class. Cliffs with neighboring cells that are inconsistent with the high and low sides of the cliff are also indicated. This can be a good indicator of cliffs with incorrect direction.Points are coded as follows:1. True circuit in data streamline network.2. Circuit in stream network as encoded on the out raster.3. Circuit in stream network via connecting lakes.4. Distributaries point.5. Stream over a cliff (waterfall).6. Points indicating multiple stream outflows from lakes.7. Code not used.8. Points beside cliffs with heights inconsistent with cliff direction.9. Code not used.10. Circular distributary removed.11. Distributary with no inflowing stream.12. Rasterized distributary in output cell different to where the data stream line distributary occurs.13. Error processing side conditions—an indicator of very complex streamline data. | Feature Class |
| Output contour error point features(Optional) | The output point feature class of possible errors pertaining to the input contour data.Contours with bias in height exceeding five times the standard deviation of the contour values as represented on the output raster are reported to this feature class. Contours that join other contours with a different elevation are flagged in this feature class by the code 1; this is a sure sign of a contour label error. | Feature Class |
| in_parameter_file | The input ASCII text file containing the inputs and parameters to use for the interpolation.The file is typically created from a previous run of Topo to Raster with the optional output parameter file specified.In order to test the outcome of changing the parameters, it is easier to make edits to this file and rerun the interpolation than to correctly issue the Topo to Raster tool each time. | File |
| out_stream_features(Optional) | Output feature class of stream polyline features.The polyline features are coded as follows:1. Input stream line not over cliff.2. Input stream line over cliff (waterfall).3. Drainage enforcement clearing a spurious sink.4. Stream line determined from contour corner.5. Ridge line determined from contour corner.6. Code not used.7. Data stream line side conditions.8. Code not used.9. Line indicating large elevation data clearance. | Feature Class |
| out_sink_features(Optional) | Output feature class of remaining sink point features. | Feature Class |
| out_residual_feature(Optional) | The output point feature class of all the large elevation residuals as scaled by the local discretisation error.All the scaled residuals larger than 10 should be inspected for possible errors in input elevation and stream data. Large-scaled residuals indicate conflicts between input elevation data and streamline data. These may also be associated with poor automatic drainage enforcements. These conflicts can be remedied by providing additional streamline and/or point elevation data after first checking and correcting errors in existing input data. Large unscaled residuals usually indicate input elevation errors. | Feature Class |
| out_stream_cliff_error_feature(Optional) | The output point feature class of locations where possible stream and cliff errors occur.The locations where the streams have closed loops, distributaries, and streams over cliffs can be identified from the point feature class. Cliffs with neighboring cells that are inconsistent with the high and low sides of the cliff are also indicated. This can be a good indicator of cliffs with incorrect direction.Points are coded as follows:1. True circuit in data streamline network.2. Circuit in stream network as encoded on the out raster.3. Circuit in stream network via connecting lakes.4. Distributaries point.5. Stream over a cliff (waterfall).6. Points indicating multiple stream outflows from lakes.7. Code not used.8. Points beside cliffs with heights inconsistent with cliff direction.9. Code not used.10. Circular distributary removed.11. Distributary with no inflowing stream.12. Rasterized distributary in output cell different to where the data stream line distributary occurs.13. Error processing side conditions—an indicator of very complex streamline data. | Feature Class |
| out_contour_error_feature(Optional) | The output point feature class of possible errors pertaining to the input contour data.Contours with bias in height exceeding five times the standard deviation of the contour values as represented on the output raster are reported to this feature class. Contours that join other contours with a different elevation are flagged in this feature class by the code 1; this is a sure sign of a contour label error. | Feature Class |

## Code Samples

### Example 1

```python
Contour D:\data\contours2\arc HEIGHT
     Point D:\data\points2\point SPOTS
     Sink D:\data\sinks_200.shp 
     Stream D:\data\streams\arc 
     Lake D:\data\lakes\polygon 
     Boundary D:\data\clipcov\polygon
     Cliff D:\data\cliffs.shp 
     ENFORCE ON
     DATATYPE CONTOUR
     ITERATIONS 40
     ROUGHNESS_PENALTY 0.0
     PROFILE_PENALTY 0.5
     DISCRETE_ERROR_FACTOR 1.0
     VERTICAL_STANDARD_ERROR 0.0
     TOLERANCES 2.5 100.0
     ZLIMITS -2000.0 13000.0
     EXTENT -810480.625 8321785.0 810480.625 10140379.0
     CELL_SIZE 1800.00000000000
     MARGIN 20
     OUT_DIAGNOSTICS D:\data\ttr_diag.txt
```

### Example 2

```python
TopoToRasterByFile(in_parameter_file, {out_stream_features}, {out_sink_features}, {out_residual_feature}, {out_stream_cliff_error_feature}, {out_contour_error_feature})
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTTRByFile = TopoToRasterByFile("topotorasterbyfile.txt", 
                   "C:/sapyexamples/output/out_streams.shp", "#",
                   "C:/sapyexamples/output/out_resids.shp")
outTTRByFile.save("C:/sapyexamples/output/ttrbyfout.tif")
```

### Example 4

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTTRByFile = TopoToRasterByFile("topotorasterbyfile.txt", 
                   "C:/sapyexamples/output/out_streams.shp", "#",
                   "C:/sapyexamples/output/out_resids.shp")
outTTRByFile.save("C:/sapyexamples/output/ttrbyfout.tif")
```

### Example 5

```python
# Name: TopoToRasterByFile_Ex_02.py
# Description: Interpolates a hydrologically correct 
#    surface from point, line, and polygon data using
#    parameters specified in a file.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inParameterFile = "topotorasterbyfile.txt"

# Execute TopoToRasterByFile
outTTRByFile = TopoToRasterByFile(inParameterFile)

# Save the output 
outTTRByFile.save("C:/sapyexamples/output/ttrbyfout02")
```

### Example 6

```python
# Name: TopoToRasterByFile_Ex_02.py
# Description: Interpolates a hydrologically correct 
#    surface from point, line, and polygon data using
#    parameters specified in a file.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inParameterFile = "topotorasterbyfile.txt"

# Execute TopoToRasterByFile
outTTRByFile = TopoToRasterByFile(inParameterFile)

# Save the output 
outTTRByFile.save("C:/sapyexamples/output/ttrbyfout02")
```

---

## Topo to Raster (Spatial Analyst)

## Summary

Interpolates a hydrologically correct raster surface from point, line, and polygon data.

## Usage

- The best results will be obtained if all input data is stored in the same planar coordinate system and has the same z-units. Unprojected data (latitude-longitude) can be used; however, the results may not be as accurate, particularly at high latitudes.
- If more than one input point falls within an output cell,Topo to Raster will use the average value for the interpolation (only the first 100 points that fall within a cell will be considered and the rest will be ignored). If too many points are encountered by the algorithm, an error may occur, indicating the point dataset has too many points. The maximum number of points that can be used is NRows * NCols, where NRows is the number of rows in the output raster and NCols is the number of columns.
- When the input feature data type is Contour, the algorithm first generates a generalized morphology of the surface based on the curvature of the contours. The algorithm then implements the contours as a source of elevation information. Contours are best suited for large-scale data where the contours and corners are reliable indicators of streams and ridges. At smaller scales it can be just as effective, and less expensive, to digitize corner points of contours and use them as an input point feature class.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- Representing braided streams or using arcs to represent two sides of a stream may not produce reliable results. Stream data always takes priority over point or contour data; therefore, elevation data points that conflict with descent down each stream are ignored. Stream data is a powerful way of adding topographic information to the interpolation, further ensuring the quality of the output DEM.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- Typical values for the Tolerance 1 and Tolerance 2 settings are:For point data at 1:100,000 scale, use 5.0 and 200.0.For less dense point data up to 1:500,000 scale, use 10.0 and 400.0.For contour data with contour spacing of 10, use 5.0 and 100.0.Tolerance 2 should be at least 6 times greater than Tolerance 1.
- For point data at 1:100,000 scale, use 5.0 and 200.0.
- For less dense point data up to 1:500,000 scale, use 10.0 and 400.0.
- For contour data with contour spacing of 10, use 5.0 and 100.0.
- To make experimentation with the inputs and parameters easier, use the Topo to Raster dialog box to create an output parameter file, which can be modified in any text editor and used as input to the Topo to Raster by File tool.
- This tool is a memory-intensive application and it is therefore not possible to create large output rasters. When large output is required, use the Margin parameter to produce smaller output rasters. For more details on how to do this, the creating and mosaicking rasters section of the How Topo to Raster works help.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input feature data | The input features containing the z-values to be interpolated into a surface raster.Each feature input can have a field specified that contains the z-values and one of six types specified.Feature layer—The input feature dataset.Field—The name of the field that stores the attributes, where appropriate.Type—The type of input feature dataset.There are nine types of accepted inputs:Point elevation—A point feature class representing surface elevations. The Field stores the elevations of the points.Contour—A line feature class that represents elevation contours. The Field stores the elevations of the contour lines.Stream—A line feature class of stream locations. All arcs must be oriented to point downstream. The feature class should only contain single arc streams. There is no Field option for this input type.Sink—A point feature class that represents known topographic depressions. The tool will not attempt to remove from the analysis any points explicitly identified as sinks. The Field used should be one that stores the elevation of the legitimate sink. If NONE is selected, only the location of the sink is used.Boundary—A feature class containing a single polygon that represents the outer boundary of the output raster. Cells in the output raster outside this boundary will be NoData. This option can be used for clipping out water areas along coastlines before making the final output raster. There is no Field option for this input type.Lake—A polygon feature class that specifies the location of lakes. All output raster cells within a lake will be assigned to the minimum elevation value of all cells along the shoreline. There is no Field option for this input type.Cliff—A line feature class of the cliffs. The cliff line features must be oriented so that the left-hand side of the line is on the low side of the cliff and the right-hand side is the high side of the cliff. There is no Field option for this input type.Exclusion—A polygon feature class of the areas in which the input data should be ignored. These polygons permit removal of elevation data from the interpolation process. This is typically used to remove elevation data associated with dam walls and bridges. This enables interpolation of the underlying valley with connected drainage structure. There is no Field option for this input type.Coast—A polygon feature class containing the outline of a coastal area. Cells in the final output raster that lie outside these polygons are set to a value that is less than the user-specified minimum height limit. There is no Field option for this input type. | TopoInput |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Output extent(Optional) | Extent for the output raster dataset.Interpolation will occur out to the x and y limits, and cells outside that extent will be NoData. For best interpolation results along the edges of the output raster, the x and y limits should be smaller than the extent of the input data by at least 10 cells on each side.The default extent is the largest of all extents of the input feature data. Current Display Extent —The extent will be based on the active map or scene.Draw Extent —The extent will be based on a rectangle drawn on the map or scene.Extent of a Layer —The extent will be based on an active map layer. Choose an available layer or use the Extent of data in all layers option. Each map layer has the following options:All Features —The extent of all features.Selected Features —The extent of the selected features.Visible Features —The extent of visible features.Browse —The extent will be based on a dataset.Clipboard —The extent can be copied to and from the clipboard. Copy Extent —Copies the extent and coordinate system to the clipboard.Paste Extent —Pastes the extent and coordinate system from the clipboard. If the clipboard does not include a coordinate system, the extent will use the map’s coordinate system.Reset Extent —The extent will be reset to the default value.When coordinates are manually provided, the coordinates must be numeric values and in the active map's coordinate system. The map may use different display units than the provided coordinates. Use a negative value sign for south and west coordinates. | Extent |
| Margin in cells(Optional) | Distance in cells to interpolate beyond the specified output extent and boundary.The value must be greater than or equal to 0 (zero). The default value is 20.If the Output extent and Boundary feature datasets are the same as the limit of the input data (the default), values interpolated along the edge of the DEM will not match well with adjacent DEM data. This is because they have been interpolated using one-half as much data as the points inside the raster, which are surrounded on all sides by input data. The Margin In Cells option allows input data beyond these limits to be used in the interpolation. | Long |
| Smallest z value to be used in interpolation(Optional) | The minimum z-value to be used in the interpolation.The default is 20 percent below the smallest of all the input values. | Double |
| Largest z value to be used in interpolation(Optional) | The maximum z-value to be used in the interpolation.The default is 20 percent above the largest of all input values. | Double |
| Drainage enforcement(Optional) | The type of drainage enforcement to apply.The drainage enforcement option can be set to attempt to remove all sinks or depressions so a hydrologically correct DEM can be created. If sink points have been explicitly identified in the input feature data, these depressions will not be filled.Enforce—The algorithm will attempt to remove all sinks it encounters, whether they are real or spurious. This is the default.Do not enforce—No sinks will be filled.Enforce with sink—Points identified as sinks in Input feature data represent known topographic depressions and will not be altered. Any sink not identified in input feature data is considered spurious, and the algorithm will attempt to fill it.Having more than 8,000 spurious sinks causes the tool to fail. | String |
| Primary type of input data(Optional) | The dominant elevation data type of the input feature data.Specifying the relevant selection optimizes the search method used during the generation of streams and ridges.Contour—The dominant type of input data will be elevation contours. This is the default.Spot—The dominant type of input will be point. | String |
| Maximum number of iterations(Optional) | The maximum number of interpolation iterations.The number of iterations must be greater than zero. A default of 20 is normally adequate for both contour and line data.A value of 30 will clear fewer sinks. Rarely, higher values (45–50) may be useful to clear more sinks or to set more ridges and streams. Iteration ceases for each grid resolution when the maximum number of iterations has been reached. | Long |
| Roughness penalty(Optional) | The integrated squared second derivative as a measure of roughness. The roughness penalty must be zero or greater. If the primary input data type is Contour, the default is zero. If the primary data type is Spot, the default is 0.5. Larger values are not normally recommended. | Double |
| Discretisation error factor(Optional) | The discrete error factor is used to adjust the amount of smoothing when converting the input data to a raster.The value must be greater than zero. The normal range of adjustment is 0.25 to 4, and the default is 1. A smaller value results in less data smoothing; a larger value causes greater smoothing. | Double |
| Vertical standard error(Optional) | The amount of random error in the z-values of the input data.The value must be zero or greater. The default is zero.The vertical standard error may be set to a small positive value if the data has significant random (non-systematic) vertical errors with uniform variance. In this case, set the vertical standard error to the standard deviation of these errors. For most elevation datasets, the vertical error should be set to zero, but it may be set to a small positive value to stabilize convergence when rasterizing point data with stream line data. | Double |
| Tolerance 1(Optional) | This tolerance reflects the accuracy and density of the elevation points in relation to surface drainage.For point datasets, set the tolerance to the standard error of the data heights. For contour datasets, use one-half the average contour interval. The value must be zero or greater. The default is 2.5 if the data type is Contour and zero if the data type is Spot. | Double |
| Tolerance 2(Optional) | This tolerance prevents drainage clearance through unrealistically high barriers. The value must be greater than zero. The default is 100 if the data type is Contour and 200 if the data type is Spot. | Double |
| Output stream polyline features(Optional) | The output line feature class of stream polyline features and ridge line features.The line features are created at the beginning of the interpolation process. It provides the general morphology of the surface for interpolation. It can be used to verify correct drainage and morphology by comparing known stream and ridge data.The polyline features are coded as follows:1. Input stream line not over cliff.2. Input stream line over cliff (waterfall).3. Drainage enforcement clearing a spurious sink.4. Stream line determined from contour corner.5. Ridge line determined from contour corner.6. Code not used.7. Data stream line side conditions.8. Code not used.9. Line indicating large elevation data clearance. | Feature Class |
| Output remaining sink point features(Optional) | The output point feature class of the remaining sink point features.These are the sinks that were not specified in the sink input feature data and were not cleared during drainage enforcement. Adjusting the values of the tolerances, Tolerance 1 and Tolerance 2, can reduce the number of remaining sinks. Remaining sinks often indicate errors in the input data that the drainage enforcement algorithm could not resolve. This can be an efficient way of detecting subtle elevation errors. | Feature Class |
| Output diagnostic file(Optional) | The output diagnostic file listing all inputs and parameters used and the number of sinks cleared at each resolution and iteration. | File |
| Output parameter file(Optional) | The output parameter file listing all inputs and parameters used, which can be used with Topo to Raster by File to run the interpolation again. | File |
| Profile curvature roughness penalty(Optional) | The profile curvature roughness penalty is a locally adaptive penalty that can be used to partly replace total curvature.It can yield good results with high-quality contour data but can lead to instability in convergence with poor data. Set to 0.0 for no profile curvature (the default), set to 0.5 for moderate profile curvature, and set to 0.8 for maximum profile curvature. Values larger than 0.8 are not recommended and should not be used. | Double |
| Output residual point features(Optional) | The output point feature class of all the large elevation residuals as scaled by the local discretisation error.All the scaled residuals larger than 10 should be inspected for possible errors in input elevation and stream data. Large-scaled residuals indicate conflicts between input elevation data and streamline data. These may also be associated with poor automatic drainage enforcements. These conflicts can be remedied by providing additional streamline and/or point elevation data after first checking and correcting errors in existing input data. Large unscaled residuals usually indicate input elevation errors. | Feature Class |
| Output stream and cliff error point features(Optional) | The output point feature class of locations where possible stream and cliff errors occur.The locations where the streams have closed loops, distributaries, and streams over cliffs can be identified from the point feature class. Cliffs with neighboring cells that are inconsistent with the high and low sides of the cliff are also indicated. This can be a good indicator of cliffs with incorrect direction.Points are coded as follows:1. True circuit in data streamline network.2. Circuit in stream network as encoded on the out raster.3. Circuit in stream network via connecting lakes.4. Distributaries point.5. Stream over a cliff (waterfall).6. Points indicating multiple stream outflows from lakes.7. Code not used.8. Points beside cliffs with heights inconsistent with cliff direction.9. Code not used.10. Circular distributary removed.11. Distributary with no inflowing stream.12. Rasterized distributary in output cell different to where the data stream line distributary occurs.13. Error processing side conditions—an indicator of very complex streamline data. | Feature Class |
| Output contour error point features(Optional) | The output point feature class of possible errors pertaining to the input contour data.Contours with bias in height exceeding five times the standard deviation of the contour values as represented on the output raster are reported to this feature class. Contours that join other contours with a different elevation are flagged in this feature class by the code 1; this is a sure sign of a contour label error. | Feature Class |
| in_topo_featurestopo_input | The Topo class specifies the input features containing the z-values to be interpolated into a surface raster.There are nine types of data accepted inputs to the Topo class: TopoPointElevation, TopoContour, TopoStream, TopoSink, TopoBoundary, TopoLake, TopoCliff, TopoExclusion, and TopoCoast.TopoPointElevation ([[inFeatures,{field}],...])A point feature class representing surface elevations.The field stores the elevations of the points.TopoContour ([[inFeatures,{field}],...])A line feature class that represents elevation contours.The field stores the elevations of the contour lines.TopoStream ([inFeatures,...])A line feature class of stream locations. All arcs must be oriented to point downstream. The feature class should only contain single arc streams.TopoSink ([[inFeatures,{field}],...])A point feature class that represents known topographic depressions. Topo to Raster will not attempt to remove from the analysis any points explicitly identified as sinks.The field used should be one that stores the elevation of the legitimate sink. If NONE is selected, only the location of the sink is used.TopoBoundary ([inFeatures,...])A boundary is a feature class containing a single polygon that represents the outer boundary of the output raster. Cells in the output raster outside this boundary will be NoData. This option can be used for clipping out water areas along coastlines before making the final output raster. TopoLake ([inFeatures,...])A polygon feature class that specifies the location of lakes. All output raster cells within a lake will be assigned to the minimum elevation value of all cells along the shoreline.TopoCliff ([inFeatures,...])A line feature class of the cliffs. The cliff line features must be oriented so that the left-hand side of the line is on the low side of the cliff and the right-hand side is the high side of the cliff.TopoExclusion ([inFeatures,...])A polygon feature class of the areas in which the input data should be ignored. These polygons permit removal of elevation data from the interpolation process. This is typically used to remove elevation data associated with dam walls and bridges. This enables interpolation of the underlying valley with connected drainage structure.TopoCoast ([inFeatures,...])A polygon feature class containing the outline of a coastal area. Cells in the final output raster that lie outside these polygons are set to a value that is less than the user-specified minimum height limit.The PointElevation, Contour, and Sink types of feature input can have a field specified that contains the z-values. There is no Field option for Boundary, Lake, Cliff, Coast, Exclusion, or Stream input types. | TopoInput |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| extent(Optional) | Extent for the output raster dataset.Interpolation will occur out to the x and y limits, and cells outside that extent will be NoData. For best interpolation results along the edges of the output raster, the x and y limits should be smaller than the extent of the input data by at least 10 cells on each side.The default extent is the largest of all extents of the input feature data. MAXOF—The maximum extent of all inputs will be used.MINOF—The minimum area common to all inputs will be used.DISPLAY—The extent is equal to the visible display.Layer name—The extent of the specified layer will be used.Extent object—The extent of the specified object will be used. Space delimited string of coordinates—The extent of the specified string will be used. Coordinates are expressed in the order of x-min, y-min, x-max, y-max. | Extent |
| Marginmargin(Optional) | Distance in cells to interpolate beyond the specified output extent and boundary.The value must be greater than or equal to 0 (zero). The default value is 20.If the Extent and TopoBoundary feature dataset are the same as the limit of the input data (the default), values interpolated along the edge of the DEM will not match well with adjacent DEM data. This is because they have been interpolated using one-half as much data as the points inside the raster, which are surrounded on all sides by input data. The Margin option allows input data beyond these limits to be used in the interpolation. | Long |
| minimum_z_value(Optional) | The minimum z-value to be used in the interpolation.The default is 20 percent below the smallest of all the input values. | Double |
| maximum_z_value(Optional) | The maximum z-value to be used in the interpolation.The default is 20 percent above the largest of all input values. | Double |
| enforce(Optional) | The type of drainage enforcement to apply.The drainage enforcement option can be set to attempt to remove all sinks or depressions so a hydrologically correct DEM can be created. If sink points have been explicitly identified in the input feature data, these depressions will not be filled.ENFORCE—The algorithm will attempt to remove all sinks it encounters, whether they are real or spurious. This is the default.NO_ENFORCE—No sinks will be filled.ENFORCE_WITH_SINK—Points identified as sinks in Input feature data represent known topographic depressions and will not be altered. Any sink not identified in input feature data is considered spurious, and the algorithm will attempt to fill it.Having more than 8,000 spurious sinks causes the tool to fail. | String |
| data_type(Optional) | The dominant elevation data type of the input feature data.CONTOUR—The dominant type of input data will be elevation contours. This is the default.SPOT—The dominant type of input will be point. Specifying the relevant selection optimizes the search method used during the generation of streams and ridges. | String |
| maximum_iterations(Optional) | The maximum number of interpolation iterations.The number of iterations must be greater than zero. A default of 20 is normally adequate for both contour and line data.A value of 30 will clear fewer sinks. Rarely, higher values (45–50) may be useful to clear more sinks or to set more ridges and streams. Iteration ceases for each grid resolution when the maximum number of iterations has been reached. | Long |
| roughness_penalty(Optional) | The integrated squared second derivative as a measure of roughness. The roughness penalty must be zero or greater. If the primary input data type is CONTOUR, the default is zero. If the primary data type is SPOT, the default is 0.5. Larger values are not normally recommended. | Double |
| discrete_error_factor(Optional) | The discrete error factor is used to adjust the amount of smoothing when converting the input data to a raster.The value must be greater than zero. The normal range of adjustment is 0.25 to 4, and the default is 1. A smaller value results in less data smoothing; a larger value causes greater smoothing. | Double |
| vertical_standard_error(Optional) | The amount of random error in the z-values of the input data.The value must be zero or greater. The default is zero.The vertical standard error may be set to a small positive value if the data has significant random (non-systematic) vertical errors with uniform variance. In this case, set the vertical standard error to the standard deviation of these errors. For most elevation datasets, the vertical error should be set to zero, but it may be set to a small positive value to stabilize convergence when rasterizing point data with stream line data. | Double |
| tolerance_1(Optional) | This tolerance reflects the accuracy and density of the elevation points in relation to surface drainage.For point datasets, set the tolerance to the standard error of the data heights. For contour datasets, use one-half the average contour interval. The value must be zero or greater. The default is 2.5 if the data type is CONTOUR and zero if the data type is SPOT. | Double |
| tolerance_2(Optional) | This tolerance prevents drainage clearance through unrealistically high barriers. The value must be greater than zero. The default is 100 if the data type is CONTOUR and 200 if the data type is SPOT. | Double |
| out_stream_features(Optional) | The output line feature class of stream polyline features and ridge line features.The line features are created at the beginning of the interpolation process. It provides the general morphology of the surface for interpolation. It can be used to verify correct drainage and morphology by comparing known stream and ridge data.The polyline features are coded as follows:1. Input stream line not over cliff.2. Input stream line over cliff (waterfall).3. Drainage enforcement clearing a spurious sink.4. Stream line determined from contour corner.5. Ridge line determined from contour corner.6. Code not used.7. Data stream line side conditions.8. Code not used.9. Line indicating large elevation data clearance. | Feature Class |
| out_sink_features(Optional) | The output point feature class of the remaining sink point features.These are the sinks that were not specified in the sink input feature data and were not cleared during drainage enforcement. Adjusting the values of the tolerances, tolerance_1 and tolerance_2, can reduce the number of remaining sinks. Remaining sinks often indicate errors in the input data that the drainage enforcement algorithm could not resolve. This can be an efficient way of detecting subtle elevation errors. | Feature Class |
| out_diagnostic_file(Optional) | The output diagnostic file listing all inputs and parameters used and the number of sinks cleared at each resolution and iteration. | File |
| out_parameter_file(Optional) | The output parameter file listing all inputs and parameters used, which can be used with Topo to Raster by File to run the interpolation again. | File |
| profile_penalty(Optional) | The profile curvature roughness penalty is a locally adaptive penalty that can be used to partly replace total curvature.It can yield good results with high-quality contour data but can lead to instability in convergence with poor data. Set to 0.0 for no profile curvature (the default), set to 0.5 for moderate profile curvature, and set to 0.8 for maximum profile curvature. Values larger than 0.8 are not recommended and should not be used. | Double |
| out_residual_feature(Optional) | The output point feature class of all the large elevation residuals as scaled by the local discretisation error.All the scaled residuals larger than 10 should be inspected for possible errors in input elevation and stream data. Large-scaled residuals indicate conflicts between input elevation data and streamline data. These may also be associated with poor automatic drainage enforcements. These conflicts can be remedied by providing additional streamline and/or point elevation data after first checking and correcting errors in existing input data. Large unscaled residuals usually indicate input elevation errors. | Feature Class |
| out_stream_cliff_error_feature(Optional) | The output point feature class of locations where possible stream and cliff errors occur.The locations where the streams have closed loops, distributaries, and streams over cliffs can be identified from the point feature class. Cliffs with neighboring cells that are inconsistent with the high and low sides of the cliff are also indicated. This can be a good indicator of cliffs with incorrect direction.Points are coded as follows:1. True circuit in data streamline network.2. Circuit in stream network as encoded on the out raster.3. Circuit in stream network via connecting lakes.4. Distributaries point.5. Stream over a cliff (waterfall).6. Points indicating multiple stream outflows from lakes.7. Code not used.8. Points beside cliffs with heights inconsistent with cliff direction.9. Code not used.10. Circular distributary removed.11. Distributary with no inflowing stream.12. Rasterized distributary in output cell different to where the data stream line distributary occurs.13. Error processing side conditions—an indicator of very complex streamline data. | Feature Class |
| out_contour_error_feature(Optional) | The output point feature class of possible errors pertaining to the input contour data.Contours with bias in height exceeding five times the standard deviation of the contour values as represented on the output raster are reported to this feature class. Contours that join other contours with a different elevation are flagged in this feature class by the code 1; this is a sure sign of a contour label error. | Feature Class |

## Code Samples

### Example 1

```python
TopoToRaster(in_topo_features, {cell_size}, {extent}, {Margin}, {minimum_z_value}, {maximum_z_value}, {enforce}, {data_type}, {maximum_iterations}, {roughness_penalty}, {discrete_error_factor}, {vertical_standard_error}, {tolerance_1}, {tolerance_2}, {out_stream_features}, {out_sink_features}, {out_diagnostic_file}, {out_parameter_file}, {profile_penalty}, {out_residual_feature}, {out_stream_cliff_error_feature}, {out_contour_error_feature})
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTTR = TopoToRaster([TopoPointElevation([['spots', 'spot_meter']]), 
                       TopoContour([['contours', 'spot_meter']]),
                       TopoCliff(['cliff'])], 60, 
                       "#", "#", "#", "#", "NO_ENFORCE")
outTTR.save("C:/sapyexamples/output/ttrout.tif")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTTR = TopoToRaster([TopoPointElevation([['spots', 'spot_meter']]), 
                       TopoContour([['contours', 'spot_meter']]),
                       TopoCliff(['cliff'])], 60, 
                       "#", "#", "#", "#", "NO_ENFORCE")
outTTR.save("C:/sapyexamples/output/ttrout.tif")
```

### Example 4

```python
# Name: TopoToRaster_Ex_02.py
# Description: Interpolates a hydrologically correct surface 
#    from point, line, and polygon data.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointElevations = TopoPointElevation([['spots.shp', 'spot_meter'], 
                                        ['spots2.shp', 'elev']])
inBoundary = TopoBoundary(['boundary.shp'])
inContours = TopoContour([['contours.shp', 'spot_meter']])
inLake = TopoLake(['lakes.shp'])
inSinks = TopoSink([['sink1.shp', 'elevation'], ['sink2.shp', 'none']])
inStream = TopoStream(['streams.shp'])

inFeatures = ([inPointElevations, inContours, inLake, inBoundary, inSinks])

# Execute TopoToRaster
outTTR = TopoToRaster(inFeatures)

# Save the output 
outTTR.save("C:/sapyexamples/output/ttrout03")
```

### Example 5

```python
# Name: TopoToRaster_Ex_02.py
# Description: Interpolates a hydrologically correct surface 
#    from point, line, and polygon data.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointElevations = TopoPointElevation([['spots.shp', 'spot_meter'], 
                                        ['spots2.shp', 'elev']])
inBoundary = TopoBoundary(['boundary.shp'])
inContours = TopoContour([['contours.shp', 'spot_meter']])
inLake = TopoLake(['lakes.shp'])
inSinks = TopoSink([['sink1.shp', 'elevation'], ['sink2.shp', 'none']])
inStream = TopoStream(['streams.shp'])

inFeatures = ([inPointElevations, inContours, inLake, inBoundary, inSinks])

# Execute TopoToRaster
outTTR = TopoToRaster(inFeatures)

# Save the output 
outTTR.save("C:/sapyexamples/output/ttrout03")
```

---

## Train ISO Cluster Classifier (Spatial Analyst)

## Summary

Generates an Esri classifier definition file (.ecd) using the Iso Cluster classification definition.

## Usage

- Any Esri-supported raster is accepted as input, including raster products, segmented raster, mosaics, image services, or generic raster datasets. Segmented rasters must be 8-bit rasters with 3-bands.
- The Segment Attributes parameter is only active if one of the raster layer inputs is a segmented image.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The raster dataset to classify. | Raster Layer; Mosaic Layer; Image Service; String |
| Max Number Of Classes / Clusters | Maximum number of desired classes to group pixels or segments. This should be set to be greater than the number of classes in your legend.It is possible that you will get fewer classes than what you specified for this parameter. If you need more, increase this value and aggregate classes after the training process is complete. | Long |
| Output Classifier Definition File | The output JSON format file that will contain attribute information, statistics, hyperplane vectors, and other information for the classifier. An .ecd file will be created. | File |
| Additional Input Raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional. | Raster Layer; Mosaic Layer; Image Service; String |
| Maximum Number Of Iterations(Optional) | The maximum number of iterations the clustering process will run.The recommended range is between 10 and 20 iterations. Increasing this value will linearly increase the processing time. | Long |
| Minimum Number of Samples Per Cluster(Optional) | The minimum number of pixels or segments in a valid cluster or class.The default value of 20 is effective in creating statistically significant classes. You can increase this number for more larger clusters and less slivers; however, it may limit the overall number of classes that are created. | Long |
| Skip Factor(Optional) | Number of pixels to skip for a pixel image input. If a segmented image is an input, specify the number of segments to skip. | Long |
| Segment Attributes Used(Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster.This parameter is only active if the Segmented key property is set to true on the input raster. If the only input to the tool is a segmented image, the default attributes are Converged color, Count of pixels, Compactness, and Rectangularity. If an Additional Input Raster value is included as an input with a segmented image, Mean digital number and Standard deviation are also available attributes.Converged color—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.Mean digital number—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.Standard deviation—The standard deviation will be derived from the optional pixel image on a per-segment basis.Count of pixels—The number of pixels composing the segment, on a per-segment basis.Compactness—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.Rectangularity—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle. | String |
| Maximum Number Of Cluster Merges per Iteration(Optional) | The maximum number of cluster merges per iteration. Increasing the number of merges will reduce the number of classes that are created. A lower value will result in more classes. | Long |
| Maximum Merge Distance(Optional) | The maximum distance between cluster centers in feature space. Increasing the distance will allow more clusters to merge, resulting in fewer classes. A lower value will result in more classes. Values from 0 to 5 typically return the best results. | Double |
| in_raster | The raster dataset to classify. | Raster Layer; Mosaic Layer; Image Service; String |
| max_classes | Maximum number of desired classes to group pixels or segments. This should be set to be greater than the number of classes in your legend.It is possible that you will get fewer classes than what you specified for this parameter. If you need more, increase this value and aggregate classes after the training process is complete. | Long |
| out_classifier_definition | The output JSON format file that will contain attribute information, statistics, hyperplane vectors, and other information for the classifier. An .ecd file will be created. | File |
| in_additional_raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional. | Raster Layer; Mosaic Layer; Image Service; String |
| max_iterations(Optional) | The maximum number of iterations the clustering process will run.The recommended range is between 10 and 20 iterations. Increasing this value will linearly increase the processing time. | Long |
| min_samples_per_cluster(Optional) | The minimum number of pixels or segments in a valid cluster or class.The default value of 20 is effective in creating statistically significant classes. You can increase this number for more larger clusters and less slivers; however, it may limit the overall number of classes that are created. | Long |
| skip_factor(Optional) | Number of pixels to skip for a pixel image input. If a segmented image is an input, specify the number of segments to skip. | Long |
| used_attributes[used_attributes;used_attributes,...](Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster.COLOR—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.MEAN—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.STD—The standard deviation will be derived from the optional pixel image on a per-segment basis.COUNT—The number of pixels composing the segment, on a per-segment basis.COMPACTNESS—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.RECTANGULARITY—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle.This parameter is only enabled if the Segmented key property is set to true on the input raster. If the only input to the tool is a segmented image, the default attributes are COLOR, COUNT, COMPACTNESS, and RECTANGULARITY. If an in_additional_raster value is included as an input with a segmented image, MEAN and STD are also available attributes. | String |
| max_merge_per_iter(Optional) | The maximum number of cluster merges per iteration. Increasing the number of merges will reduce the number of classes that are created. A lower value will result in more classes. | Long |
| max_merge_distance(Optional) | The maximum distance between cluster centers in feature space. Increasing the distance will allow more clusters to merge, resulting in fewer classes. A lower value will result in more classes. Values from 0 to 5 typically return the best results. | Double |

## Code Samples

### Example 1

```python
TrainIsoClusterClassifier(in_raster, max_classes, out_classifier_definition, {in_additional_raster}, {max_iterations}, {min_samples_per_cluster}, {skip_factor}, {used_attributes}, {max_merge_per_iter}, {max_merge_distance})
```

### Example 2

```python
import arcpy
from arcpy.sa import *

TrainIsoClusterClassifier("c:/test/moncton_seg.tif", "10", 
                "c:/output/moncton_sig_iso.ecd","c:/test/moncton.tif", 
                "5", "10", "2", "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")
```

### Example 3

```python
import arcpy
from arcpy.sa import *

TrainIsoClusterClassifier("c:/test/moncton_seg.tif", "10", 
                "c:/output/moncton_sig_iso.ecd","c:/test/moncton.tif", 
                "5", "10", "2", "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")
```

### Example 4

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
inSegRaster = "c:/test/moncton_seg.tif"
maxNumClasses = "10"
out_definition = "c:/output/moncton_sig_iso.ecd"
in_additional_raster = "moncton.tif"
maxIteration = "20"
minNumSamples = "10"
skipFactor = "5"
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"

# Execute 
TrainIsoClusterClassifier(inSegRaster, maxNumClasses, out_definition,
                          in_additional_raster, maxIteration, 
                          minNumSamples, skipFactor, attributes)
```

### Example 5

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
inSegRaster = "c:/test/moncton_seg.tif"
maxNumClasses = "10"
out_definition = "c:/output/moncton_sig_iso.ecd"
in_additional_raster = "moncton.tif"
maxIteration = "20"
minNumSamples = "10"
skipFactor = "5"
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"

# Execute 
TrainIsoClusterClassifier(inSegRaster, maxNumClasses, out_definition,
                          in_additional_raster, maxIteration, 
                          minNumSamples, skipFactor, attributes)
```

---

## Train K-Nearest Neighbor Classifier (Spatial Analyst)

## Summary

Generates an Esri classifier definition file (.ecd) using the K-Nearest Neighbor classification method.

## Usage

- The tool assigns training samples to their respective classes. The class of the input pixel is determined by a plurality vote of its K-nearest neighbors.
- Any Esri-supported raster is accepted as input, including raster products, segmented rasters, mosaics, image services, and generic raster datasets. Segmented rasters must be 8-bit rasters with three bands.
- The output of this tool is an .ecd file that is used to classify new rasters in the Classify Raster tool. The Classify Raster tool then calculates the distance from each input pixel or segment to all training samples.The training sample data must have been collected at multiple times using the Training Samples Manager. The dimension value for each sample is listed in a field in the training sample feature class, which is specified in the Dimension Value Field parameter.
- To create the training sample file, use the Training Samples Manager pane from the Classification Tools drop-down menu.
- For segmented rasters that have their key property set to Segmented, the tool computes the index image and associated segment attributes from the RGB segmented raster. The attributes are computed to generate the classifier definition file to be used in a separate classification tool. The attributes for each segment can be computed from any Esri-supported image.
- The Segment Attributes parameter is only active if one of the raster layer inputs is a segmented image.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The raster dataset to classify.The single band raster or segmented raster, multiband raster, or a multidimensional raster to be classified. | Mosaic Layer; Raster Layer; Image Service; String |
| Input Training Sample File | The training sample file or layer that delineates the training sites.These can be either shapefiles or feature classes that contain the training samples. The following field names are required in the training sample file: classname—A text field indicating the name of the class categoryclassvalue—A long integer field containing the integer value for each class category | Feature Layer |
| Output Classifier Definition File | A JSON formatted .ecd file that contains attribute information, statistics, or other information for the classifier. | File |
| Additional Input Raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional. | Raster Layer; Mosaic Layer; Image Service; String |
| K Nearest Neighbors(Optional) | The number of neighbors that will be used in searching for each input pixel or segment. Increasing the number of neighbors will decrease the influence of individual neighbors on the outcome of the classification. The default value is 1. | Long |
| Max Number of Samples Per Class(Optional) | The maximum number of training samples that will be used for each class. The default value of 1000 is recommended when the inputs are nonsegmented rasters. A value that is less than or equal to 0 means that the system will use all the samples from the training sites to train the classifier. | Long |
| Segment Attributes(Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster.This parameter is only active if the Segmented key property is set to true on the input raster. If the only input to the tool is a segmented image, the default attributes are Converged color, Count of pixels, Compactness, and Rectangularity. If an Additional Input Raster value is included as an input with a segmented image, Mean digital number and Standard deviation are also available attributes.Converged color—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.Mean digital number—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.Standard deviation—The standard deviation will be derived from the optional pixel image on a per-segment basis.Count of pixels—The number of pixels composing the segment, on a per-segment basis.Compactness—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.Rectangularity—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle. | String |
| Dimension Value Field(Optional) | Contains dimension values in the input training sample feature class.This parameter is required to classify a time series of raster data using the change analysis raster output from the Analyze Changes Using CCDC tool in the Image Analyst toolbox. | Field |
| in_raster | The raster dataset to classify.The single band raster or segmented raster, multiband raster, or a multidimensional raster to be classified. | Mosaic Layer; Raster Layer; Image Service; String |
| in_training_features | The training sample file or layer that delineates the training sites.These can be either shapefiles or feature classes that contain the training samples. The following field names are required in the training sample file: classname—A text field indicating the name of the class categoryclassvalue—A long integer field containing the integer value for each class category | Feature Layer |
| out_classifier_definition | A JSON formatted .ecd file that contains attribute information, statistics, or other information for the classifier. | File |
| in_additional_raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional. | Raster Layer; Mosaic Layer; Image Service; String |
| kNN(Optional) | The number of neighbors that will be used in searching for each input pixel or segment. Increasing the number of neighbors will decrease the influence of individual neighbors on the outcome of the classification. The default value is 1. | Long |
| max_samples_per_class(Optional) | The maximum number of training samples that will be used for each class. The default value of 1000 is recommended when the inputs are nonsegmented rasters. A value that is less than or equal to 0 means that the system will use all the samples from the training sites to train the classifier. | Long |
| used_attributes[used_attributes;used_attributes,...](Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster. COLOR—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.MEAN—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.STD—The standard deviation will be derived from the optional pixel image on a per-segment basis.COUNT—The number of pixels composing the segment, on a per-segment basis.COMPACTNESS—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.RECTANGULARITY—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle.This parameter is only enabled if the Segmented key property is set to true on the input raster. If the only input to the tool is a segmented image, the default attributes are COLOR, COUNT, COMPACTNESS, and RECTANGULARITY. If an in_additional_raster value is included as an input with a segmented image, MEAN and STD are also available attributes. | String |
| dimension_value_field(Optional) | Contains dimension values in the input training sample feature class.This parameter is required to classify a time series of raster data using the change analysis raster output from the Analyze Changes Using CCDC tool in the Image Analyst toolbox. | Field |

## Code Samples

### Example 1

```python
TrainKNearestNeighborClassifier(in_raster, in_training_features, out_classifier_definition, {in_additional_raster}, {kNN}, {max_samples_per_class}, {used_attributes}, {dimension_value_field})
```

### Example 2

```python
# Import system modules 
import arcpy 
from arcpy.sa import * 
 
# Check out the ArcGIS Spatial Analyst extension license 
arcpy.CheckOutExtension("Spatial") 
 
# Execute  
arcpy.sa.TrainKNearestNeighborClassifier("landsat.tif", "training_sample.shp", r"c:\data\trained_knn.ecd", 5, "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")
```

### Example 3

```python
# Import system modules 
import arcpy 
from arcpy.sa import * 
 
# Check out the ArcGIS Spatial Analyst extension license 
arcpy.CheckOutExtension("Spatial") 
 
# Execute  
arcpy.sa.TrainKNearestNeighborClassifier("landsat.tif", "training_sample.shp", r"c:\data\trained_knn.ecd", 5, "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")
```

### Example 4

```python
# Import system modules 
import arcpy 
from arcpy.sa import * 
 
# Check out the ArcGIS Spatial Analyst extension license 
arcpy.CheckOutExtension("Spatial") 
 
# Define input parameters 
in_raster = r"C:/Data/landsat.tif" 
in_training_features = r"C:/Data/training_sample.shp" 
out_classifier_definition = r"C:/Data/trained_knn.ecd" 
number_of_neighbors = 5
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"
     
# Execute  - train K-Nearest Neighbor Classifier
arcpy.sa.TrainKNearestNeighborClassifier(in_raster, in_training_features, 
                                         out_classifier_definition, 
                                         number_of_neighbors, attributes)
```

### Example 5

```python
# Import system modules 
import arcpy 
from arcpy.sa import * 
 
# Check out the ArcGIS Spatial Analyst extension license 
arcpy.CheckOutExtension("Spatial") 
 
# Define input parameters 
in_raster = r"C:/Data/landsat.tif" 
in_training_features = r"C:/Data/training_sample.shp" 
out_classifier_definition = r"C:/Data/trained_knn.ecd" 
number_of_neighbors = 5
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"
     
# Execute  - train K-Nearest Neighbor Classifier
arcpy.sa.TrainKNearestNeighborClassifier(in_raster, in_training_features, 
                                         out_classifier_definition, 
                                         number_of_neighbors, attributes)
```

---

## Train Maximum Likelihood Classifier (Spatial Analyst)

## Summary

Generates an Esri classifier definition file (.ecd) using the Maximum Likelihood Classifier (MLC) classification definition.

## Usage

- To complete the maximum likelihood classification process, use the same input raster and the output .ecd file from this tool in the Classify Raster tool.
- The input raster can be any Esri-supported raster with any valid bit depth.
- To create a segmented raster dataset, use the Segment Mean Shift tool.
- To create the training sample file, use the Training Samples Manager pane from the Classification Tools drop-down menu.
- The Output Classifier Definition File contains attribute statistics suitable for the Maximum Likelihood Classification tool.
- The Segment Attributes parameter is only active if one of the raster layer inputs is a segmented image.
- A two step process is necessary to classify time series raster data using the Continuous Change Detection and Classification (CCDC) algorithm. First, run the Analyze Changes Using CCDC tool, which is available with an Image Analyst extension license. Next, use those results as input to this training tool.The training sample data must have been collected at multiple times using the Training Samples Manager. The dimension value for each sample is listed in a field in the training sample feature class, which is specified in the Dimension Value Field parameter.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The raster dataset to classify. | Raster Layer; Mosaic Layer; Image Service; String |
| Input Training Sample File | The training sample file or layer that delineates the training sites.These can be either shapefiles or feature classes that contain the training samples. The following field names are required in the training sample file: classname—A text field indicating the name of the class categoryclassvalue—A long integer field containing the integer value for each class category | Feature Layer |
| Output Classifier Definition File | The output JSON format file that will contain attribute information, statistics, hyperplane vectors, and other information for the classifier. An .ecd file will be created. | File |
| Additional Input Raster(Optional) | Incorporates ancillary raster datasets, such as a segmented image or DEM. This parameter is optional. | Raster Layer; Mosaic Layer; Image Service; String |
| Segment Attributes Used(Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster.This parameter is only active if the Segmented key property is set to true on the input raster. If the only input to the tool is a segmented image, the default attributes are Converged color, Count of pixels, Compactness, and Rectangularity. If an Additional Input Raster value is included as an input with a segmented image, Mean digital number and Standard deviation are also available attributes.Converged color—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.Mean digital number—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.Standard deviation—The standard deviation will be derived from the optional pixel image on a per-segment basis.Count of pixels—The number of pixels composing the segment, on a per-segment basis.Compactness—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.Rectangularity—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle. | String |
| Dimension Value Field(Optional) | Contains dimension values in the input training sample feature class. This parameter is required to classify a time series of raster data using the change analysis raster output from the Analyze Changes Using CCDC tool in the Image Analyst toolbox. | Field |
| in_raster | The raster dataset to classify. | Raster Layer; Mosaic Layer; Image Service; String |
| in_training_features | The training sample file or layer that delineates the training sites.These can be either shapefiles or feature classes that contain the training samples. The following field names are required in the training sample file: classname—A text field indicating the name of the class categoryclassvalue—A long integer field containing the integer value for each class category | Feature Layer |
| out_classifier_definition | The output JSON format file that will contain attribute information, statistics, hyperplane vectors, and other information for the classifier. An .ecd file will be created. | File |
| in_additional_raster(Optional) | Incorporates ancillary raster datasets, such as a segmented image or DEM. This parameter is optional. | Raster Layer; Mosaic Layer; Image Service; String |
| used_attributes[used_attributes,...](Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster.COLOR—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.MEAN—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.STD—The standard deviation will be derived from the optional pixel image on a per-segment basis.COUNT—The number of pixels composing the segment, on a per-segment basis.COMPACTNESS—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.RECTANGULARITY—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle.This parameter is only enabled if the Segmented key property is set to true on the input raster. If the only input to the tool is a segmented image, the default attributes are COLOR, COUNT, COMPACTNESS, and RECTANGULARITY. If an in_additional_raster value is included as an input with a segmented image, MEAN and STD are also available attributes. | String |
| dimension_value_field(Optional) | Contains dimension values in the input training sample feature class. This parameter is required to classify a time series of raster data using the change analysis raster output from the Analyze Changes Using CCDC tool in the Image Analyst toolbox. | Field |

## Code Samples

### Example 1

```python
TrainMaximumLikelihoodClassifier(in_raster, in_training_features, out_classifier_definition, {in_additional_raster}, {used_attributes}, {dimension_value_field})
```

### Example 2

```python
import arcpy
from arcpy.sa import *

TrainMaximumLikelihoodClassifier(
    "c:/test/moncton_seg.tif", "c:/test/train.gdb/train_features", 
    "c:/output/moncton_sig.ecd", "c:/test/moncton.tif", 
    "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")
```

### Example 3

```python
import arcpy
from arcpy.sa import *

TrainMaximumLikelihoodClassifier(
    "c:/test/moncton_seg.tif", "c:/test/train.gdb/train_features", 
    "c:/output/moncton_sig.ecd", "c:/test/moncton.tif", 
    "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")
```

### Example 4

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
inSegRaster = "c:/test/moncton_seg.tif"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/moncton_sig.ecd"
in_additional_raster = "c:/moncton.tif"
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"

# Execute 
TrainMaximumLikelihoodClassifier(inSegRaster, train_features, out_definition, 
                                 in_additional_raster, attributes)
```

### Example 5

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
inSegRaster = "c:/test/moncton_seg.tif"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/moncton_sig.ecd"
in_additional_raster = "c:/moncton.tif"
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"

# Execute 
TrainMaximumLikelihoodClassifier(inSegRaster, train_features, out_definition, 
                                 in_additional_raster, attributes)
```

### Example 6

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")


# Set local variables
in_changeAnalysisRaster = "c:/test/LandsatCCDC.crf"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/change_detection.ecd"
additional_raster = ''
attributes = None
dimension_field = "DateTime"

# Execute
arcpy.sa.TrainMaximumLikelihoodClassifier(
	in_changeAnalysisRaster, train_features, out_definition,
	additional_raster, attributes, dimension_field)
```

### Example 7

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")


# Set local variables
in_changeAnalysisRaster = "c:/test/LandsatCCDC.crf"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/change_detection.ecd"
additional_raster = ''
attributes = None
dimension_field = "DateTime"

# Execute
arcpy.sa.TrainMaximumLikelihoodClassifier(
	in_changeAnalysisRaster, train_features, out_definition,
	additional_raster, attributes, dimension_field)
```

---

## Train Random Trees Classifier (Spatial Analyst)

## Summary

Generates an Esri classifier definition file (.ecd) using the Random Trees classification method.

## Usage

- The Random Trees classification method is a collection of individual decision trees in which each tree is generated from different samples and subsets of the training data. The idea behind calling these decision trees is that for every pixel that is classified, a number of decisions are made in rank order of importance. When you graph these for a pixel, it looks like a branch. When you classify the entire dataset, the branches form a tree. This method is called random trees because you are actually classifying the dataset a number of times based on a random subselection of training pixels, resulting in many decision trees. To make a final decision, each tree has a vote. This process works to mitigate overfitting. The Random Trees classification method is a supervised machine-learning classifier based on constructing a multitude of decision trees, choosing random subsets of variables for each tree, and using the most frequent tree output as the overall classification. The Random Trees classification method corrects for the decision trees' propensity for overfitting to their training sample data. With this method, a number of trees are grown—by an analogy, a forest—and variation among the trees is introduced by projecting the training data into a randomly chosen subspace before fitting each tree. The decision at each node is optimized by a randomized procedure.
- For segmented rasters that have their key property set to Segmented, the tool computes the index image and associated segment attributes from the RGB segmented raster. The attributes are computed to generate the classifier definition file to be used in a separate classification tool. The attributes for each segment can be computed from any Esri-supported image.
- Any Esri-supported raster is accepted as input, including raster products, segmented rasters, mosaics, image services, and generic raster datasets. Segmented rasters must be 8-bit rasters with 3 bands.
- To create the training sample file, use the Training Samples Manager pane from the Classification Tools drop-down menu.
- The Segment Attributes parameter is only active if one of the raster layer inputs is a segmented image.
- A two step process is necessary to classify time series raster data using the Continuous Change Detection and Classification (CCDC) algorithm. First, run the Analyze Changes Using CCDC tool, which is available with an Image Analyst extension license. Next, use those results as input to this training tool.The training sample data must have been collected at multiple times using the Training Samples Manager. The dimension value for each sample is listed in a field in the training sample feature class, which is specified in the Dimension Value Field parameter.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The raster dataset to classify.You can use any Esri-supported raster dataset. One option is a 3-band, 8-bit segmented raster dataset in which all the pixels in the same segment have the same color. The input can also be a single band, 8-bit, grayscale segmented raster. | Raster Layer; Mosaic Layer; Image Service; String |
| Input Training Sample File | The training sample file or layer that delineates the training sites.These can be either shapefiles or feature classes that contain the training samples. The following field names are required in the training sample file: classname—A text field indicating the name of the class categoryclassvalue—A long integer field containing the integer value for each class category | Feature Layer |
| Output Classifier Definition File | A JSON file that contains attribute information, statistics, or other information for the classifier. An .ecd file is created. | File |
| Additional Input Raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional. | Raster Layer; Mosaic Layer; Image Service; String |
| Max Number of Trees(Optional) | The maximum number of trees in the forest. Increasing the number of trees will lead to higher accuracy rates, although this improvement will level off eventually. The number of trees increases the processing time linearly. | Long |
| Max Tree Depth(Optional) | The maximum depth of each tree in the forest. Depth is another way of saying the number of rules each tree is allowed to create to come to a decision. Trees will not grow any deeper than this setting. | Long |
| Max Number of Samples Per Class(Optional) | The maximum number of samples that will be used to define each class.The default value of 1000 is recommended when the inputs are nonsegmented rasters. A value that is less than or equal to 0 means that the system will use all the samples from the training sites to train the classifier. | Long |
| Segment Attributes(Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster.This parameter is only active if the Segmented key property is set to true on the input raster. If the only input to the tool is a segmented image, the default attributes are Converged color, Count of pixels, Compactness, and Rectangularity. If an Additional Input Raster value is included as an input with a segmented image, Mean digital number and Standard deviation are also available attributes.Converged color—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.Mean digital number—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.Standard deviation—The standard deviation will be derived from the optional pixel image on a per-segment basis.Count of pixels—The number of pixels composing the segment, on a per-segment basis.Compactness—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.Rectangularity—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle. | String |
| Dimension Value Field(Optional) | Contains dimension values in the input training sample feature class.This parameter is required to classify a time series of raster data using the change analysis raster output from the Analyze Changes Using CCDC tool in the Image Analyst toolbox. | Field |
| in_raster | The raster dataset to classify.You can use any Esri-supported raster dataset. One option is a 3-band, 8-bit segmented raster dataset in which all the pixels in the same segment have the same color. The input can also be a single band, 8-bit, grayscale segmented raster. | Raster Layer; Mosaic Layer; Image Service; String |
| in_training_features | The training sample file or layer that delineates the training sites.These can be either shapefiles or feature classes that contain the training samples. The following field names are required in the training sample file: classname—A text field indicating the name of the class categoryclassvalue—A long integer field containing the integer value for each class category | Feature Layer |
| out_classifier_definition | A JSON file that contains attribute information, statistics, or other information for the classifier. An .ecd file is created. | File |
| in_additional_raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional. | Raster Layer; Mosaic Layer; Image Service; String |
| max_num_trees(Optional) | The maximum number of trees in the forest. Increasing the number of trees will lead to higher accuracy rates, although this improvement will level off eventually. The number of trees increases the processing time linearly. | Long |
| max_tree_depth(Optional) | The maximum depth of each tree in the forest. Depth is another way of saying the number of rules each tree is allowed to create to come to a decision. Trees will not grow any deeper than this setting. | Long |
| max_samples_per_class(Optional) | The maximum number of samples that will be used to define each class.The default value of 1000 is recommended when the inputs are nonsegmented rasters. A value that is less than or equal to 0 means that the system will use all the samples from the training sites to train the classifier. | Long |
| used_attributes[used_attributes;used_attributes,...](Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster. COLOR—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.MEAN—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.STD—The standard deviation will be derived from the optional pixel image on a per-segment basis.COUNT—The number of pixels composing the segment, on a per-segment basis.COMPACTNESS—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.RECTANGULARITY—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle.This parameter is only enabled if the Segmented key property is set to true on the input raster. If the only input to the tool is a segmented image, the default attributes are COLOR, COUNT, COMPACTNESS, and RECTANGULARITY. If an in_additional_raster value is included as an input with a segmented image, MEAN and STD are also available attributes. | String |
| dimension_value_field(Optional) | Contains dimension values in the input training sample feature class.This parameter is required to classify a time series of raster data using the change analysis raster output from the Analyze Changes Using CCDC tool in the Image Analyst toolbox. | Field |

## Code Samples

### Example 1

```python
TrainRandomTreesClassifier(in_raster, in_training_features, out_classifier_definition, {in_additional_raster}, {max_num_trees}, {max_tree_depth}, {max_samples_per_class}, {used_attributes}, {dimension_value_field})
```

### Example 2

```python
import arcpy
from arcpy.sa import *

TrainRandomTreesClassifier("c:/test/moncton_seg.tif",
                           "c:/test/train.gdb/train_features",
                           "c:/output/moncton_sig_SVM.ecd",
                           "c:/test/moncton.tif", "50", "30", "1000",
                           "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")
```

### Example 3

```python
import arcpy
from arcpy.sa import *

TrainRandomTreesClassifier("c:/test/moncton_seg.tif",
                           "c:/test/train.gdb/train_features",
                           "c:/output/moncton_sig_SVM.ecd",
                           "c:/test/moncton.tif", "50", "30", "1000",
                           "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")
```

### Example 4

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Set local variables
inSegRaster = "c:/test/cities_seg.tif"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/cities_sig.ecd"
in_additional_raster = "c:/cities.tif"
maxNumTrees = "50"
maxTreeDepth = "30"
maxSampleClass = "1000"
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute
TrainRandomTreesClassifier(inSegRaster, train_features,
                           out_definition, in_additional_raster, maxNumTrees,
                           maxTreeDepth, maxSampleClass, attributes)
```

### Example 5

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Set local variables
inSegRaster = "c:/test/cities_seg.tif"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/cities_sig.ecd"
in_additional_raster = "c:/cities.tif"
maxNumTrees = "50"
maxTreeDepth = "30"
maxSampleClass = "1000"
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute
TrainRandomTreesClassifier(inSegRaster, train_features,
                           out_definition, in_additional_raster, maxNumTrees,
                           maxTreeDepth, maxSampleClass, attributes)
```

### Example 6

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")


# Set local variables
in_changeAnalysisRaster = "c:/test/LandsatCCDC.crf"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/change_detection.ecd"
additional_raster = ''
maxNumTrees = 50
maxTreeDepth = 30
maxSampleClass = 1000
attributes = None
dimension_field = "DateTime"

# Execute
arcpy.sa.TrainRandomTreesClassifier(
	in_changeAnalysisRaster, train_features, 
	out_definition, additional_raster, maxNumTrees, 
	maxTreeDepth, maxSampleClass, attributes, dimension_field)
```

### Example 7

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")


# Set local variables
in_changeAnalysisRaster = "c:/test/LandsatCCDC.crf"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/change_detection.ecd"
additional_raster = ''
maxNumTrees = 50
maxTreeDepth = 30
maxSampleClass = 1000
attributes = None
dimension_field = "DateTime"

# Execute
arcpy.sa.TrainRandomTreesClassifier(
	in_changeAnalysisRaster, train_features, 
	out_definition, additional_raster, maxNumTrees, 
	maxTreeDepth, maxSampleClass, attributes, dimension_field)
```

---

## Train Support Vector Machine Classifier (Spatial Analyst)

## Summary

Generates an Esri classifier definition file (.ecd) using the Support Vector Machine (SVM) classification definition.

## Usage

- The SVM classifier is a supervised classification method. It is well suited for segmented raster input but can also handle standard imagery. It is a classification method commonly used in the research community.
- For standard image inputs, the tool accepts multiband imagery with any bit depth, and it will perform the SVM classification on a pixel basis, based on the input training feature file.
- For segmented rasters that have their key property set to Segmented, the tool computes the index image and associated segment attributes from the RGB segmented raster. The attributes are computed to generate the classifier definition file to be used in a separate classification tool. The attributes for each segment can be computed from any Esri-supported image.
- There are several advantages to using the SVM classifier rather than the maximum likelihood classification method: The SVM classifier needs fewer samples and does not require the samples to be normally distributed.It is less susceptible to noise, correlated bands, and an unbalanced number or size of training sites within each class.
- The SVM classifier needs fewer samples and does not require the samples to be normally distributed.
- It is less susceptible to noise, correlated bands, and an unbalanced number or size of training sites within each class.
- Any Esri-supported raster is accepted as input, including raster products, segmented rasters, mosaics, image services, or generic raster datasets. Segmented rasters must be 8-bit rasters with 3 bands.
- To create the training sample file, use the Training Samples Manager pane from the Classification Tools drop-down menu.
- The Segment Attributes parameter is only active if one of the raster layer inputs is a segmented image.
- A two step process is necessary to classify time series raster data using the Continuous Change Detection and Classification (CCDC) algorithm. First, run the Analyze Changes Using CCDC tool, which is available with an Image Analyst extension license. Next, use those results as input to this training tool.The training sample data must have been collected at multiple times using the Training Samples Manager. The dimension value for each sample is listed in a field in the training sample feature class, which is specified in the Dimension Value Field parameter.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster | The raster dataset to classify.The preferred input is a 3-band, 8-bit segmented raster dataset in which all the pixels in the same segment have the same color. The input can also be a 1-band, 8-bit grayscale segmented raster. If no segmented raster is available, you can use any Esri-supported raster dataset. | Raster Layer; Mosaic Layer; Image Service; String |
| Input Training Sample File | The training sample file or layer that delineates the training sites.These can be either shapefiles or feature classes that contain the training samples. The following field names are required in the training sample file: classname—A text field indicating the name of the class categoryclassvalue—A long integer field containing the integer value for each class category | Feature Layer |
| Output Classifier Definition File | The output JSON format file that will contain attribute information, statistics, hyperplane vectors, and other information for the classifier. An .ecd file will be created. | File |
| Additional Input Raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional. | Raster Layer; Mosaic Layer; Image Service; String |
| Maximum Number of Samples Per Class(Optional) | The maximum number of samples that will be used to define each class.The default value of 500 is recommended when the inputs are nonsegmented rasters. A value that is less than or equal to 0 means that the system will use all the samples from the training sites to train the classifier. | Long |
| Segment Attributes Used(Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster.This parameter is only active if the Segmented key property is set to true on the input raster. If the only input to the tool is a segmented image, the default attributes are Converged color, Count of pixels, Compactness, and Rectangularity. If an Additional Input Raster value is included as an input with a segmented image, Mean digital number and Standard deviation are also available attributes.Converged color—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.Mean digital number—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.Standard deviation—The standard deviation will be derived from the optional pixel image on a per-segment basis.Count of pixels—The number of pixels composing the segment, on a per-segment basis.Compactness—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.Rectangularity—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle. | String |
| Dimension Value Field(Optional) | Contains dimension values in the input training sample feature class. This parameter is required to classify a time series of raster data using the change analysis raster output from the Analyze Changes Using CCDC tool in the Image Analyst toolbox. | Field |
| in_raster | The raster dataset to classify.The preferred input is a 3-band, 8-bit segmented raster dataset in which all the pixels in the same segment have the same color. The input can also be a 1-band, 8-bit grayscale segmented raster. If no segmented raster is available, you can use any Esri-supported raster dataset. | Raster Layer; Mosaic Layer; Image Service; String |
| in_training_features | The training sample file or layer that delineates the training sites.These can be either shapefiles or feature classes that contain the training samples. The following field names are required in the training sample file: classname—A text field indicating the name of the class categoryclassvalue—A long integer field containing the integer value for each class category | Feature Layer |
| out_classifier_definition | The output JSON format file that will contain attribute information, statistics, hyperplane vectors, and other information for the classifier. An .ecd file will be created. | File |
| in_additional_raster(Optional) | Ancillary raster datasets, such as a multispectral image or a DEM, will be incorporated to generate attributes and other required information for classification. This parameter is optional. | Raster Layer; Mosaic Layer; Image Service; String |
| max_samples_per_class(Optional) | The maximum number of samples that will be used to define each class.The default value of 500 is recommended when the inputs are nonsegmented rasters. A value that is less than or equal to 0 means that the system will use all the samples from the training sites to train the classifier. | Long |
| used_attributes[used_attributes;used_attributes,...](Optional) | Specifies the attributes that will be included in the attribute table associated with the output raster. COLOR—The RGB color values will be derived from the input raster on a per-segment basis. This is also known as average chromaticity color.MEAN—The average digital number (DN) will be derived from the optional pixel image on a per-segment basis.STD—The standard deviation will be derived from the optional pixel image on a per-segment basis.COUNT—The number of pixels composing the segment, on a per-segment basis.COMPACTNESS—The degree to which a segment is compact or circular, on a per-segment basis. The values range from 0 to 1, in which 1 is a circle.RECTANGULARITY—The degree to which the segment is rectangular, on a per-segment basis. The values range from 0 to 1, in which 1 is a rectangle.This parameter is only enabled if the Segmented key property is set to true on the input raster. If the only input to the tool is a segmented image, the default attributes are COLOR, COUNT, COMPACTNESS, and RECTANGULARITY. If an in_additional_raster value is included as an input with a segmented image, MEAN and STD are also available attributes. | String |
| dimension_value_field(Optional) | Contains dimension values in the input training sample feature class. This parameter is required to classify a time series of raster data using the change analysis raster output from the Analyze Changes Using CCDC tool in the Image Analyst toolbox. | Field |

## Code Samples

### Example 1

```python
TrainSupportVectorMachineClassifier(in_raster, in_training_features, out_classifier_definition, {in_additional_raster}, {max_samples_per_class}, {used_attributes}, {dimension_value_field})
```

### Example 2

```python
import arcpy
from arcpy.sa import *

arcpy.gp.TrainSupportVectorMachineClassifier(
    "c:/test/moncton_seg.tif", "c:/test/train.gdb/train_features",
    "c:/output/moncton_sig_SVM.ecd", "c:/test/moncton.tif", "10",
    "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")
```

### Example 3

```python
import arcpy
from arcpy.sa import *

arcpy.gp.TrainSupportVectorMachineClassifier(
    "c:/test/moncton_seg.tif", "c:/test/train.gdb/train_features",
    "c:/output/moncton_sig_SVM.ecd", "c:/test/moncton.tif", "10",
    "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY")
```

### Example 4

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
inSegRaster = "c:/test/moncton_seg.tif"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/moncton_sig.ecd"
in_additional_raster = "c:/moncton.tif"
maxNumSamples = "10"
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"

#Execute
arcpy.gp.TrainSupportVectorMachineClassifier(
    inSegRaster, train_features, out_definition, 
    in_additional_raster, maxNumSamples, attributes)
```

### Example 5

```python
# Import system modules
import arcpy
from arcpy.sa import *


# Set local variables
inSegRaster = "c:/test/moncton_seg.tif"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/moncton_sig.ecd"
in_additional_raster = "c:/moncton.tif"
maxNumSamples = "10"
attributes = "COLOR;MEAN;STD;COUNT;COMPACTNESS;RECTANGULARITY"

#Execute
arcpy.gp.TrainSupportVectorMachineClassifier(
    inSegRaster, train_features, out_definition, 
    in_additional_raster, maxNumSamples, attributes)
```

### Example 6

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")


# Set local variables
in_changeAnalysisRaster = "c:/test/LandsatCCDC.crf"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/change_detection.ecd"
additional_raster = ''
attributes = None
dimension_field = "DateTime"

# Execute
arcpy.sa.TrainSupportVectorMachineClassifier(
    in_changeAnalysisRaster, train_features, out_definition, 
	additional_raster, attributes, dimension_field)
```

### Example 7

```python
# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")


# Set local variables
in_changeAnalysisRaster = "c:/test/LandsatCCDC.crf"
train_features = "c:/test/train.gdb/train_features"
out_definition = "c:/output/change_detection.ecd"
additional_raster = ''
attributes = None
dimension_field = "DateTime"

# Execute
arcpy.sa.TrainSupportVectorMachineClassifier(
    in_changeAnalysisRaster, train_features, out_definition, 
	additional_raster, attributes, dimension_field)
```

---

## Trend (Spatial Analyst)

## Summary

Interpolates a raster surface from points using a trend technique.

## Usage

- As the order of the polynomial is increased, the surface being fitted becomes progressively more complex. A higher-order polynomial will not always generate the most accurate surface; it is dependent on the data.
- For the Logistic option of Type of regression, the z-value field of input point features should have codes of zero (0) and one (1).
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, but the Snap Raster environment has been set, the cell size of the snap raster is used. If nothing is specified, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- The optional RMS file output contains information on the RMS (root mean square) error of the interpolation. This information can be used to determine the best value to use for the polynomial order, by changing the order value until you get the lowest RMS error. See the How Trend works topic for information on the RMS file.
- Some input datasets may have several points with the same x,y coordinates. If the values of the points at the common location are the same, they are considered duplicates and have no effect on the output. If the values are different, they are considered coincident points.The various interpolation tools may handle this data condition differently. For example, in some cases, the first coincident point encountered is used for the calculation; in other cases, the last point encountered is used. This may cause some locations in the output raster to have different values than what you might expect. The solution is to prepare your data by removing these coincident points. The Collect Events tool in the Spatial Statistics toolbox is useful for identifying any coincident points in your data.
- For data formats that support Null values, such as file geodatabase feature classes, a Null value will be ignored when used as input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input point features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| Z value field | The field that holds a height or magnitude value for each point.This can be a numeric field or the Shape field if the input point features contain z-values.If the regression type is Logistic, the values in the field can only be 0 or 1. | Field |
| Output cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| Polynomial order(Optional) | The order of the polynomial.This must be an integer between 1 and 12. A value of 1 will fit a flat plane to the points, and a higher value will fit a more complex surface. The default is 1. | Long |
| Type of regression(Optional) | The type of regression to be performed.Linear—Polynomial regression is performed to fit a least-squares surface to the set of input points. This is applicable for continuous types of data.Logistic—Logistic trend surface analysis is performed. It generates a continuous probability surface for binary, or dichotomous, types of data. | String |
| Output RMS file(Optional) | File name for the output text file that contains information about the RMS error and the Chi-Square of the interpolation.The extension must be .txt. | File |
| in_point_features | The input point features containing the z-values to be interpolated into a surface raster. | Feature Layer |
| z_field | The field that holds a height or magnitude value for each point.This can be a numeric field or the Shape field if the input point features contain z-values.If the regression type is Logistic, the values in the field can only be 0 or 1. | Field |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| order(Optional) | The order of the polynomial.This must be an integer between 1 and 12. A value of 1 will fit a flat plane to the points, and a higher value will fit a more complex surface. The default is 1. | Long |
| regression_type(Optional) | The type of regression to be performed.LINEAR—Polynomial regression is performed to fit a least-squares surface to the set of input points. This is applicable for continuous types of data.LOGISTIC—Logistic trend surface analysis is performed. It generates a continuous probability surface for binary, or dichotomous, types of data. | String |
| out_rms_file(Optional) | File name for the output text file that contains information about the RMS error and the Chi-Square of the interpolation.The extension must be .txt. | File |

## Code Samples

### Example 1

```python
Trend(in_point_features, z_field, {cell_size}, {order}, {regression_type}, {out_rms_file})
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTrend = Trend("ozone_pts.shp", "ozone", 2000, 2, "LINEAR")
outTrend.save("C:/sapyexamples/output/trendout.tif")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outTrend = Trend("ozone_pts.shp", "ozone", 2000, 2, "LINEAR")
outTrend.save("C:/sapyexamples/output/trendout.tif")
```

### Example 4

```python
# Name: Trend_Ex_02.py
# Description: Interpolate a series of point features 
#    onto a rectangular raster using a trend technique.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "ca_ozone_pts.shp"
zField = "ozone"
cellSize = 2000.0
PolynomialOrder = 2
regressionType = "LINEAR"


# Execute Trend
outTrend = Trend(inPointFeatures, zField, cellSize, 
                 PolynomialOrder, regressionType)

# Save the output 
outTrend.save("C:/sapyexamples/output/trendout02")
```

### Example 5

```python
# Name: Trend_Ex_02.py
# Description: Interpolate a series of point features 
#    onto a rectangular raster using a trend technique.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inPointFeatures = "ca_ozone_pts.shp"
zField = "ozone"
cellSize = 2000.0
PolynomialOrder = 2
regressionType = "LINEAR"


# Execute Trend
outTrend = Trend(inPointFeatures, zField, cellSize, 
                 PolynomialOrder, regressionType)

# Save the output 
outTrend.save("C:/sapyexamples/output/trendout02")
```

---

## Understanding path distance analysis

## Code Samples

### Example 1

```python
F * D = fuel_used
```

### Example 2

```python
F * D = fuel_used
```

### Example 3

```python
F * SD = fuel_used
```

### Example 4

```python
F * SD = fuel_used
```

### Example 5

```python
F * SD * HF = fuel_used
```

### Example 6

```python
F * SD * HF = fuel_used
```

### Example 7

```python
F * SD * HF * VF = fuel_used
```

### Example 8

```python
F * SD * HF * VF = fuel_used
```

---

## Update Accuracy Assessment Points (Spatial Analyst)

## Summary

Updates the Target field in the attribute table to compare reference points to the classified image.

## Usage

- Use this tool to update the attribute table of a feature class that represents accuracy assessment points. If you created the feature class using the Create Accuracy Assessment Points tool, a GROUND_TRUTH field and a CLASSIFIED field are included in the table. This tool can start with the reference data and compare it to the classified output, or it can start with the classified output and compare it to the reference data.You can then compare the two fields using the Compute Confusion Matrix tool.
- The accuracy assessment workflow usually uses the following three tools in this order: Create Accuracy Assessment Points, Update Accuracy Assessment Points, and Compute Confusion Matrix.
- When a polygon feature class is used for training or accuracy assessment, the feature class must have a Classvalue or value field that has a unique integer value for each class. For example, a polygon feature class with three different classes can have values such as [1, 2, 3] or [10, 20, 40].
- You can manually update the GROUND_TRUTH field to change or identify a set of points.
- When the Input Raster or Feature Class Data parameter value is a multidimensional raster, the time dimension (StdTime field) will be used automatically. If a fourth dimension exists (for example, Z field), the first dimension value will be used. You can use the Make Multidimensional Raster Layer tool or the Subset Multidimensional Raster tool to configure the input.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Class Data | The input classification image or other thematic GIS reference data. The input can be a raster or feature class. Typical data is a classification image of a single band, integer data type.If using polygons as input, only use those that are not used as training samples. You can also use land-cover data in shapefile or feature class format. | Raster Layer; Mosaic Layer; Feature Layer |
| Input Accuracy Assessment Points | The point feature class providing the accuracy assessment points to be updated. All points from this input will be copied to the updated output feature class, and the Target Field parameter value will be updated from the input raster or feature class data. | Feature Layer |
| Output Accuracy Assessment Points | The output point feature class that contains the updated random point field for accuracy assessment purposes. | Feature Class |
| Target Field(Optional) | Specifies whether the input data is a classified image or ground truth data.Classified—The input is a classified image. This is the default.Ground truth—The input is reference data. | String |
| Dimension Field for Feature Class(Optional) | The dimension field for the Input Accuracy Assessment Points parameter value. The assessment points will be updated based on the matching dimension values with this field. | Field |
| Dimension Field for Test Points(Optional) | The dimension field in the Input Accuracy Assessment Points parameter value. Input data with identical dimension values will be used to update corresponding points. When the Input Raster or Feature Class Data parameter value is a multidimensional raster, rasters with dimension values that match the dimension field in the test points will be used in updating. The multidimensional raster is expected to have one time dimension (StdTime field). Otherwise, the first dimension will be used to match the dimension field of the test points. | Field |
| in_class_data | The input classification image or other thematic GIS reference data. The input can be a raster or feature class. Typical data is a classification image of a single band, integer data type.If using polygons as input, only use those that are not used as training samples. You can also use land-cover data in shapefile or feature class format. | Raster Layer; Mosaic Layer; Feature Layer |
| in_points | The point feature class providing the accuracy assessment points to be updated. All points from this input will be copied to the updated output feature class, and the target_field parameter value will be updated from the input raster or feature class data. | Feature Layer |
| out_points | The output point feature class that contains the updated random point field for accuracy assessment purposes. | Feature Class |
| target_field(Optional) | Specifies whether the input data is a classified image or ground truth data.CLASSIFIED—The input is a classified image. This is the default.GROUND_TRUTH—The input is reference data. | String |
| polygon_dimension_field(Optional) | The dimension field for the in_points parameter value. The assessment points will be updated based on the matching dimension values with this field. | Field |
| point_dimension_field(Optional) | The dimension field in the in_points parameter value. Input data with identical dimension values will be used to update corresponding points. When the in_class_data parameter value is a multidimensional raster, rasters with dimension values that match the dimension field in the test points will be used in updating. The multidimensional raster is expected to have one time dimension (StdTime field). Otherwise, the first dimension will be used to match the dimension field of the test points. | Field |

## Code Samples

### Example 1

```python
UpdateAccuracyAssessmentPoints(in_class_data, in_points, out_points, {target_field}, {polygon_dimension_field}, {point_dimension_field})
```

### Example 2

```python
import arcpy
from arcpy.sa import *

arcpy.gp.UpdateAccuracyAssessmentPoints("aapnt1.shp", "grndtru.tif", "aapnt2.shp", "GROUND_TRUTH")
```

### Example 3

```python
import arcpy
from arcpy.sa import *

arcpy.gp.UpdateAccuracyAssessmentPoints("aapnt1.shp", "grndtru.tif", "aapnt2.shp", "GROUND_TRUTH")
```

---

## Using reclassification tables

## Code Samples

### Example 1

```python
Value  Symbol
     3     1
     5     2
    10     3
    15     4
```

### Example 2

```python
old input cell value : new output reclassified value
```

### Example 3

```python
# Example 1
    # Remap table for cell value reclassification.
    LOWEST-INPUT 3
    LOWEST-OUTPUT 2
    5
    6
    7
    15
```

### Example 4

```python
# Example 3
    # Remap table for cell value reclassification.
    LOWEST-INPUT 3
    5 : 10
    6 : 16
    7 : 62
    15 : 28
```

### Example 5

```python
# Example 4
    # Remap table for cell value reclassification.
    3 5 : 9
    5 9 : 8
    13 15 : 59
```

### Example 6

```python
# Invalid remap table for cell value reclassification
    LOWEST-INPUT 3
    LOWEST-OUTPUT 2
    5 
    6 9
    11
    15
```

### Example 7

```python
# Invalid remap table for cell value reclassification
    LOWEST-INPUT 3
    5 : 10
    6
    7 : 62
    15
```

---

## Using Viewshed and Observer Points for visibility analysis

## Code Samples

### Example 1

```python
ITEM NAME    WIDTH    OUTPUT    TYPE    N.DEC
OBSn         2        2         B       -
```

### Example 2

```python
Dist2               Dist2    
 Zactual = Zsurface - --------- + Rrefr * ---------
                      Diamearth           Diamearth
```

### Example 3

```python
Dist2               Dist2    
 Zactual = Zsurface - --------- + Rrefr * ---------
                      Diamearth           Diamearth
```

---

## Geodesic Viewshed (Spatial Analyst)

## Summary

Determines the raster surface locations visible to a set of observer features using geodesic methods.

## Usage

- This tool performs two types of visibility analysis, Frequency and Observers, that can be set using the Analysis type parameter.
- To ensure the accuracy of the output, assign a vertical coordinate system to the input raster if it does not already have one.
- This tool does not require a z-factor parameter. It will compute a z-factor internally using the vertical (z) unit and the map (xy) units from the spatial reference of the input raster.
- Input rasters that contain noise, most commonly seen in high-resolution data, may produce unexpected results. Before running this tool, you can correct the data in a preprocessing step.You can also smooth out the noise using the Focal Statistics tool or the Filter tool with the Low pass option before performing the viewshed operation.
- When the input raster needs to be resampled, the bilinear technique will be used. An example of when an input raster may be resampled is when the output coordinate system, extent, or cell size is different from that of the input.
- To enhance performance, you can explicitly set the Outer radius parameter to a value that represents the maximum viewing distance of interest for the analysis.
- By default, the Analysis Method parameter uses the All Sightlines option, which provides the most accurate output. To improve the performance of the tool in terms of processing time, use the Perimeter Sightlines option.
- The observer parameters related to height, such as Surface offset, Observer elevation and Observer offset, can be specified as a linear unit or as a field. During the calculation, the linear unit value will be converted internally to the z-unit of the input raster. However, if the linear unit is unknown or a numeric field is specified, the value is assumed to be in the z-unit of the input raster.
- The observer parameters related to viewing distances, such as Inner radius and Outer radius, can be specified as a linear unit or as a field. During the calculation, the linear unit value will be converted internally to the xy-units of the input raster. However, if the linear unit is unknown or a numeric field is specified, the value is assumed to be in the xy-unit of the input raster.
- The field specified for an observer parameter, such as Surface offset or Observer offset, can be string type that contains a numerical value and a unit. For example, if field obs_height is specified for Observer offset, it can contain values such as '6 Feet'.In scripting, the values for the observer parameters, such as observer_offset, can be specified in various forms of strings. In each form, a value and a linear unit is parsed from the string. The following table lists example input strings and how the linear unit is determined for each case. For other parameters, you can follow the same pattern.Example of input string for Observer offsetLinear unit used ' ' or '#'The default value and unit is used, which is 1 meter. '6'The Observer offset is 6 and since no unit is specified, the tool will use the default unit, meter. '6 Feet'The Observer offset is 6 feet. '6 Unknown'The Observer offset is 6 and since no unit is specified, the tool will use the default unit, meter.Examples of input strings and linear units
- This tool can be GPU accelerated, which means that if a compatible graphics processing unit (GPU) is available on your system, it will be used to enhance the performance of the tool. Use the Target device for analysis (analysis_target_device in Python) parameter to control whether the GPU or CPU will be used to run the tool.See GPU processing with Spatial Analyst for details on compatible GPUs, configuring and working with GPU devices, as well as troubleshooting tips.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input surface raster. It can be an integer or a floating-point raster.The input raster is transformed into a 3D geocentric coordinate system during the visibility calculation. NoData cells on the input raster do not block the visibility determination. | Raster Layer |
| Input point or polyline observer features | The input feature class that identifies the observer locations. It can be point, multipoint, or polyline features.The input feature class is transformed into a 3D geocentric coordinate system during the visibility calculation. Observers outside of the extent of the surface raster or located on NoData cells will be ignored in the calculation. | Feature Layer |
| Output above ground level raster(Optional) | The output above ground level (AGL) raster.The AGL result is a raster in which each cell value is the minimum height that must be added to a cell that is not visible to make it visible by at least one observer. Cells that are already visible will be assigned 0 in this output raster.When the vertical error parameter is 0, the output AGL raster will be a one-band raster. When the vertical error is greater than 0, to account for the random effects from the input raster, the output AGL raster will be created as a three-band raster. The first band represents the mean AGL values, the second band represents the minimum AGL values, and the third band represents the maximum AGL values. | Raster Dataset |
| Analysis type(Optional) | Specifies the type of visibility analysis that will be performed, either determining how visible each cell is to the observers or identifying the observers that are visible for each surface location.Frequency—The number of times that each cell location in the input surface raster can be seen by the input observation locations (as points or as vertices for polyline observer features) will be recorded in the output. This is the default.Observers—The observer points that are visible from each raster surface location will be identified in the output. The maximum number of input observer locations allowed for this analysis type is 32. | String |
| Vertical error(Optional) | The amount of uncertainty (the root mean square [RMS] error) in the surface elevation values. It is a floating-point value representing the expected error of the input elevation values. When this parameter is assigned a value greater than 0, the output visibility raster will be floating point. In this case, each cell value on the output visibility raster represents the sum of probabilities that the cell is visible to any of the observers. When the Analysis type parameter value is Observers or the Analysis method parameter value is Perimeter Sightlines, this parameter is disabled. | Linear Unit |
| Output observer-region relationship table(Optional) | The output table for identifying the regions that are visible to each observer. This table can be related to the input observer feature class and the output visibility raster for identifying the regions visible to given observers. This output is only created when the analysis type is Observers. | Table |
| Refractivity coefficient(Optional) | The coefficient of the refraction of visible light in air.The default value is 0.13. | Double |
| Surface offset(Optional) | A vertical distance that will be added to the z-value of each cell as it is considered for visibility. It must be a positive integer or floating-point value.You can select a field in the input observers dataset, or you can specify a numerical value.For example, if the object to be observed is a vehicle, specify the height of the vehicle here.When this parameter is set to a value, the value will be used by all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset.The default value is 0. | Linear Unit; Field |
| Observer elevation(Optional) | The surface elevations of the observer points or vertices.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is not specified, the observer elevation will be obtained from the surface raster using bilinear interpolation. If this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset. | Linear Unit; Field |
| Observer offset(Optional) | A vertical distance that will be added to the observer elevation. It must be a positive integer or floating-point value.You can select a field in the input observers dataset, or you can specify a numerical value.For example, if an observer is looking from a tower, specify the height of the tower here.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset.The default value is 1 meter. | Linear Unit; Field |
| Inner radius(Optional) | The start distance from which visibility will be determined. Cells closer than this distance will not be visible in the output but can still block visibility of the cells between inner radius and outer radius.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset.The default value is 0. | Linear Unit; Field |
| Inner radius is 3D distance(Optional) | Specifies the type of distance that will be used for the inner radius parameter. Unchecked—The inner radius will be interpreted as a 2D distance. This is the default. Checked—The inner radius will be interpreted as a 3D distance. | Boolean |
| Outer radius(Optional) | The maximum distance from which visibility will be determined. Cells beyond this distance will be excluded from the analysis.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset. | Linear Unit; Field |
| Outer radius is 3D distance(Optional) | Specifies the type of distance that will be used for the outer radius parameter. Unchecked—The outer radius will be interpreted as a 2D distance. This is the default. Checked—The outer radius will be interpreted as a 3D distance. | Boolean |
| Horizontal start angle(Optional) | The start angle of the horizontal scan range. Provide the value in degrees from 0 to 360 with 0 oriented to north. The value can be integer or floating point. The default value is 0.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset. | Double; Field |
| Horizontal end angle(Optional) | The end angle of the horizontal scan range. Provide the value in degrees from 0 to 360 with 0 oriented to north. The value can be integer or floating point. The default value is 360.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset. | Double; Field |
| Vertical upper angle(Optional) | The upper vertical angle limit of the scan relative to the horizontal plane. Provide the value in degrees from above -90 up to and including 90. The value can be integer or floating point. The default value is 90 (straight up).This parameter value must be greater than the Vertical lower angle parameter value.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset.The default value is 90 (straight up). | Double; Field |
| Vertical lower angle(Optional) | The lower vertical angle limit of the scan relative to the horizontal plane. Provide the value in degrees from -90 up to but not including 90. The value can be integer or floating point. The default value is -90 (straight down).This parameter value must be less than the Vertical upper angle parameter value.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset.The default value is -90 (straight down). | Double; Field |
| Analysis method(Optional) | Specifies the method that will be used to calculate visibility. This parameter allows you to decide on performance level.All Sightlines—A sightline will be run to every cell on the raster to establish visible areas, which may decrease performance depending on the number of sightlines. This is the default method.Perimeter Sightlines—Sightlines will only be run to the cells on the perimeter of the visible areas to establish visibility areas, which can increase performance because fewer sightlines are run in the calculation. | String |
| Target device for analysis(Optional) | Specifies the device that will be used to perform the calculation.GPU then CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU only—The calculation will only be performed on the CPU.GPU only—The calculation will only be performed on the GPU. | String |
| in_raster | The input surface raster. It can be an integer or a floating-point raster.The input raster is transformed into a 3D geocentric coordinate system during the visibility calculation. NoData cells on the input raster do not block the visibility determination. | Raster Layer |
| in_observer_features | The input feature class that identifies the observer locations. It can be point, multipoint, or polyline features.The input feature class is transformed into a 3D geocentric coordinate system during the visibility calculation. Observers outside of the extent of the surface raster or located on NoData cells will be ignored in the calculation. | Feature Layer |
| out_agl_raster(Optional) | The output above ground level (AGL) raster.The AGL result is a raster in which each cell value is the minimum height that must be added to a cell that is not visible to make it visible by at least one observer. Cells that are already visible will be assigned 0 in this output raster.When the vertical error parameter is 0, the output AGL raster will be a one-band raster. When the vertical error is greater than 0, to account for the random effects from the input raster, the output AGL raster will be created as a three-band raster. The first band represents the mean AGL values, the second band represents the minimum AGL values, and the third band represents the maximum AGL values. | Raster Dataset |
| analysis_type(Optional) | Specifies the type of visibility analysis that will be performed, either determining how visible each cell is to the observers or identifying the observers that are visible for each surface location.FREQUENCY—The number of times that each cell location in the input surface raster can be seen by the input observation locations (as points or as vertices for polyline observer features) will be recorded in the output. This is the default.OBSERVERS—The observer points that are visible from each raster surface location will be identified in the output. The maximum number of input observer locations allowed for this analysis type is 32. | String |
| vertical_error(Optional) | The amount of uncertainty (the root mean square [RMS] error) in the surface elevation values. It is a floating-point value representing the expected error of the input elevation values. When this parameter is assigned a value greater than 0, the output visibility raster will be floating point. In this case, each cell value on the output visibility raster represents the sum of probabilities that the cell is visible to any of the observers. When the analysis_type parameter value is OBSERVERS or the analysis_method parameter value is PERIMETER_SIGHTLINES, this parameter is disabled. | Linear Unit |
| out_observer_region_relationship_table(Optional) | The output table for identifying the regions that are visible to each observer. This table can be related to the input observer feature class and the output visibility raster for identifying the regions visible to given observers. This output is only created when the analysis type is OBSERVERS. | Table |
| refractivity_coefficient(Optional) | The coefficient of the refraction of visible light in air.The default value is 0.13. | Double |
| surface_offset(Optional) | A vertical distance that will be added to the z-value of each cell as it is considered for visibility. It must be a positive integer or floating-point value.You can select a field in the input observers dataset, or you can specify a numerical value.For example, if the object to be observed is a vehicle, specify the height of the vehicle here.When this parameter is set to a value, the value will be used by all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset.The default value is 0. | Linear Unit; Field |
| observer_elevation(Optional) | The surface elevations of the observer points or vertices.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is not specified, the observer elevation will be obtained from the surface raster using bilinear interpolation. If this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset. | Linear Unit; Field |
| observer_offset(Optional) | A vertical distance that will be added to the observer elevation. It must be a positive integer or floating-point value.You can select a field in the input observers dataset, or you can specify a numerical value.For example, if an observer is looking from a tower, specify the height of the tower here.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset.The default value is 1 meter. | Linear Unit; Field |
| inner_radius(Optional) | The start distance from which visibility will be determined. Cells closer than this distance will not be visible in the output but can still block visibility of the cells between inner radius and outer radius.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset.The default value is 0. | Linear Unit; Field |
| inner_radius_is_3d(Optional) | Specifies the type of distance that will be used for the inner radius parameter.GROUND—The inner radius will be interpreted as a 2D distance. This is the default.3D—The inner radius will be interpreted as a 3D distance. | Boolean |
| outer_radius(Optional) | The maximum distance from which visibility will be determined. Cells beyond this distance will be excluded from the analysis.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset. | Linear Unit; Field |
| outer_radius_is_3d(Optional) | Specifies the type of distance that will be used for the outer radius parameter.GROUND—The outer radius will be interpreted as a 2D distance. This is the default.3D—The outer radius will be interpreted as a 3D distance. | Boolean |
| horizontal_start_angle(Optional) | The start angle of the horizontal scan range. Provide the value in degrees from 0 to 360 with 0 oriented to north. The value can be integer or floating point. The default value is 0.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset. | Double; Field |
| horizontal_end_angle(Optional) | The end angle of the horizontal scan range. Provide the value in degrees from 0 to 360 with 0 oriented to north. The value can be integer or floating point. The default value is 360.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset. | Double; Field |
| vertical_upper_angle(Optional) | The upper vertical angle limit of the scan relative to the horizontal plane. Provide the value in degrees from above -90 up to and including 90. The value can be integer or floating point. The default value is 90 (straight up).This parameter value must be greater than the Vertical lower angle parameter value.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset.The default value is 90 (straight up). | Double; Field |
| vertical_lower_angle(Optional) | The lower vertical angle limit of the scan relative to the horizontal plane. Provide the value in degrees from -90 up to but not including 90. The value can be integer or floating point. The default value is -90 (straight down).This parameter value must be less than the Vertical upper angle parameter value.You can select a field in the input observers dataset, or you can specify a numerical value.When this parameter is set to a value, the value will be applied to all the observers. To specify different values for each observer, set this parameter to a field in the input observer features dataset.The default value is -90 (straight down). | Double; Field |
| analysis_method(Optional) | Specifies the method that will be used to calculate visibility. This parameter allows you to decide on performance level.ALL_SIGHTLINES—A sightline will be run to every cell on the raster to establish visible areas, which may decrease performance depending on the number of sightlines. This is the default method.PERIMETER_SIGHTLINES—Sightlines will only be run to the cells on the perimeter of the visible areas to establish visibility areas, which can increase performance because fewer sightlines are run in the calculation. | String |
| analysis_target_device(Optional) | Specifies the device that will be used to perform the calculation.GPU_THEN_CPU—If a compatible GPU is found, it will be used to perform the calculation. Otherwise, the CPU will be used. This is the default.CPU_ONLY—The calculation will only be performed on the CPU.GPU_ONLY—The calculation will only be performed on the GPU. | String |

## Code Samples

### Example 1

```python
Viewshed2(in_raster, in_observer_features, {out_agl_raster}, {analysis_type}, {vertical_error}, {out_observer_region_relationship_table}, {refractivity_coefficient}, {surface_offset}, {observer_elevation}, {observer_offset}, {inner_radius}, {inner_radius_is_3d}, {outer_radius}, {outer_radius_is_3d}, {horizontal_start_angle}, {horizontal_end_angle}, {vertical_upper_angle}, {vertical_lower_angle}, {analysis_method}, {analysis_target_device})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outViewshed2 = Viewshed2("elevation", "obser1.shp", "", "OBSERVERS", "",
                         "C:/sapyexamples/output/obstable01.dbf",
                         analysis_method="ALL_SIGHTLINES")
outViewshed2.save("C:/sapyexamples/output/outvwshd2_01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outViewshed2 = Viewshed2("elevation", "obser1.shp", "", "OBSERVERS", "",
                         "C:/sapyexamples/output/obstable01.dbf",
                         analysis_method="ALL_SIGHTLINES")
outViewshed2.save("C:/sapyexamples/output/outvwshd2_01")
```

### Example 4

```python
# Name: Viewshed2_Ex_02.py
# Description: Determines the raster surface locations visible to a set of
#              observer features.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# set local variables
inRaster = "elevation"
inObservers = "obser2.shp"
outAGL = ""
analysisType = "OBSERVERS"
verticalError = ""
outAnalysisRelationTable = "C:/sapyexamples/output/obser_region2.dbf"
refractCoeff = ""
surfaceOffset = "offsetb"
observerElevation = "spot"
observerOffset = "offseta"
innerRadius = "radius1"
innerIs3D = "False"
outerRadius = "radius2"
outerIs3D = "True"
horizStartAngle = "azimuth1"
horizEndAngle = "azimuth2"
vertUpperAngle = "vert1"
vertLowerAngle = "vert2"
analysisMethod = "ALL_SIGHTLINES"

# Execute Viewshed2
outViewshed2 = Viewshed2(inRaster, inObservers, outAGL, analysisType,
                         verticalError, outAnalysisRelationTable, refractCoeff,
                         surfaceOffset, observerElevation, observerOffset,
                         innerRadius, innerIs3D, outerRadius, outerIs3D,
                         horizStartAngle, horizEndAngle, vertUpperAngle,
                         vertLowerAngle, analysisMethod)

# Save the output
outViewshed2.save("C:/sapyexamples/output/outvwshd2_02")
```

### Example 5

```python
# Name: Viewshed2_Ex_02.py
# Description: Determines the raster surface locations visible to a set of
#              observer features.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# set local variables
inRaster = "elevation"
inObservers = "obser2.shp"
outAGL = ""
analysisType = "OBSERVERS"
verticalError = ""
outAnalysisRelationTable = "C:/sapyexamples/output/obser_region2.dbf"
refractCoeff = ""
surfaceOffset = "offsetb"
observerElevation = "spot"
observerOffset = "offseta"
innerRadius = "radius1"
innerIs3D = "False"
outerRadius = "radius2"
outerIs3D = "True"
horizStartAngle = "azimuth1"
horizEndAngle = "azimuth2"
vertUpperAngle = "vert1"
vertLowerAngle = "vert2"
analysisMethod = "ALL_SIGHTLINES"

# Execute Viewshed2
outViewshed2 = Viewshed2(inRaster, inObservers, outAGL, analysisType,
                         verticalError, outAnalysisRelationTable, refractCoeff,
                         surfaceOffset, observerElevation, observerOffset,
                         innerRadius, innerIs3D, outerRadius, outerIs3D,
                         horizStartAngle, horizEndAngle, vertUpperAngle,
                         vertLowerAngle, analysisMethod)

# Save the output
outViewshed2.save("C:/sapyexamples/output/outvwshd2_02")
```

---

## Viewshed (Spatial Analyst)

## Summary

Determines the raster surface locations visible to a set of observer features.

## Usage

- Determining observer points is a computer-intensive process. The processing time is dependent on the resolution. For preliminary studies, you can use a coarser cell size to reduce the number of cells in the input. Use the full-resolution raster when the final results are ready to be generated.
- If the input raster contains undesirable noise caused by sampling errors, you can smooth the raster with a low-pass filter, such as the Mean option of the Focal Statistics tool, before running this tool.
- The visibility of each cell center is determined by comparing the altitude angle to the cell center with the altitude angle to the local horizon. The local horizon is computed by considering the intervening terrain between the point of observation and the current cell center. If the point lies above the local horizon, it is considered visible.
- An optional above ground level (AGL) output raster is provided by the tool. Each cell on the AGL output raster records the minimum height that needs to be added to that cell to make it visible by at least one observer.When the input observer features contain multiple observers, the output value is the minimum of the AGL values from all of the individual observers.
- When the input raster needs to be resampled, the bilinear technique will be used. An example of when an input raster may be resampled is when the output coordinate system, extent, or cell size is different from that of the input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input surface raster. | Raster Layer |
| Input point or polyline observer features | The feature class that identifies the observer locations.The input can be point or polyline features. | Feature Layer |
| Z factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| Use earth curvature corrections(Optional) | Specifies whether correction for the earth's curvature will be applied.Unchecked—No curvature correction will be applied. This is the default.Checked—Curvature correction will be applied. | Boolean |
| Refractivity coefficient(Optional) | The coefficient of the refraction of visible light in air.The default value is 0.13. | Double |
| Output above ground level raster (Optional) | The output above ground level (AGL) raster.The AGL result is a raster where each cell value is the minimum height that must be added to an otherwise nonvisible cell to make it visible by at least one observer.Cells that were already visible will have a value of 0 in this output raster. | Raster Dataset |
| in_raster | The input surface raster. | Raster Layer |
| in_observer_features | The feature class that identifies the observer locations.The input can be point or polyline features. | Feature Layer |
| z_factor(Optional) | The number of ground x,y units in one surface z-unit.The z-factor adjusts the units of measure for the z-units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z-units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z-units are in different units of measure, the z-factor must be set to the appropriate factor or the results will be incorrect. For example, if the z-units are feet and the x,y units are meters, use a z-factor of 0.3048 to convert the z-units from feet to meters (1 foot = 0.3048 meter). | Double |
| curvature_correction(Optional) | Specifies whether correction for the earth's curvature will be applied.FLAT_EARTH—No curvature correction will be applied. This is the default.CURVED_EARTH—Curvature correction will be applied. | Boolean |
| refractivity_coefficient(Optional) | The coefficient of the refraction of visible light in air.The default value is 0.13. | Double |
| out_agl_raster(Optional) | The output above ground level (AGL) raster.The AGL result is a raster where each cell value is the minimum height that must be added to an otherwise nonvisible cell to make it visible by at least one observer.Cells that were already visible will have a value of 0 in this output raster. | Raster Dataset |

## Code Samples

### Example 1

```python
Viewshed(in_raster, in_observer_features, {z_factor}, {curvature_correction}, {refractivity_coefficient}, {out_agl_raster})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outViewshed = Viewshed("elevation","observers.shp",2,"CURVED_EARTH",0.15)
outViewshed.save("C:/sapyexamples/output/outvwshd01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outViewshed = Viewshed("elevation","observers.shp",2,"CURVED_EARTH",0.15)
outViewshed.save("C:/sapyexamples/output/outvwshd01")
```

### Example 4

```python
# Name: Viewshed_Ex_02.py
# Description: Determines the raster surface locations visible to a set of
#              observer features.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inObserverFeatures = "observers.shp"
zFactor = 2
useEarthCurvature = "CURVED_EARTH"
refractivityCoefficient = 0.15

# Execute Viewshed
outViewshed = Viewshed(inRaster, inObserverFeatures, zFactor, 
                       useEarthCurvature, refractivityCoefficient)

# Save the output 
outViewshed.save("C:/sapyexamples/output/outvwshd02")
```

### Example 5

```python
# Name: Viewshed_Ex_02.py
# Description: Determines the raster surface locations visible to a set of
#              observer features.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster = "elevation"
inObserverFeatures = "observers.shp"
zFactor = 2
useEarthCurvature = "CURVED_EARTH"
refractivityCoefficient = 0.15

# Execute Viewshed
outViewshed = Viewshed(inRaster, inObserverFeatures, zFactor, 
                       useEarthCurvature, refractivityCoefficient)

# Save the output 
outViewshed.save("C:/sapyexamples/output/outvwshd02")
```

---

## Visibility (Spatial Analyst)

## Summary

Determines the raster surface locations visible to a set of observer features, or identifies which observer points are visible from each raster surface location.

## Usage

- This tool supports two visibility analysis types, Frequency and Observers, which is controlled by the Analysis type tool parameter. For the first type, the tool determines which raster surface locations are visible to a set of observers. For the other, it identifies which observers are visible from each raster surface location.
- If the input raster contains undesirable noise caused by sampling errors, you can smooth the raster with a low-pass filter, such as the Mean option of the Focal Statistics tool, before running this tool.
- The visibility of each cell center is determined by comparing the altitude angle to the cell center with the altitude angle to the local horizon. The local horizon is computed by considering the intervening terrain between the point of observation and the current cell center. If the point lies above the local horizon, it is considered visible.
- An optional above-ground-level (AGL) output raster is provided by the tool. Each cell on the AGL output raster records the minimum height that needs to be added to that cell to make it visible by at least one observer.When the input observer features contain multiple observers, the output value is the minimum of the AGL values from all of the individual observers.
- Use the observer parameters to gain more control over the visibility analysis process. For example, through the observer offset parameter, you may specify an offset to the observer elevation in the visibility analysis.
- When the input raster needs to be resampled, the bilinear technique will be used. An example of when an input raster may be resampled is when the output coordinate system, extent, or cell size is different from that of the input.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster | The input surface raster. | Raster Layer |
| Input point or polyline observer features | The feature class that identifies the observer locations.The input can be point or polyline features. | Feature Layer |
| Output above ground level raster(Optional) | The output above-ground-level (AGL) raster.The AGL result is a raster where each cell value is the minimum height that must be added to an otherwise nonvisible cell to make it visible by at least one observer.Cells that were already visible will have a value of 0 in this output raster. | Raster Dataset |
| Analysis type(Optional) | The visibility analysis type.Frequency—The output records the number of times that each cell location in the input surface raster can be seen by the input observation locations (as points, or as vertices for polyline observer features). This is the default.Observers—The output identifies exactly which observer points are visible from each raster surface location. | String |
| Use NoData for non-visible cells(Optional) | Value assigned to nonvisible cells.Unchecked—0 is assigned to nonvisible cells. This is the default.Checked—NoData is assigned to nonvisible cells. | Boolean |
| Z factor(Optional) | Number of ground x,y units in one surface z unit.The z-factor adjusts the units of measure for the z units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z units are in different units of measure, the z-factor must be set to the appropriate factor, or the results will be incorrect. For example, if your z units are feet and your x,y units are meters, you would use a z-factor of 0.3048 to convert your z units from feet to meters (1 foot = 0.3048 meter). | Double |
| Use earth curvature corrections(Optional) | Specifies whether correction for the earth's curvature will be applied.Unchecked—No curvature correction will be applied. This is the default.Checked—Curvature correction will be applied. | Boolean |
| Refractivity coefficient(Optional) | The coefficient of the refraction of visible light in air.The default value is 0.13. | Double |
| Surface offset(Optional) | A vertical distance that will be added to the z-value of each cell as it is considered for visibility. It must be a positive integer or floating-point value.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field OFFSETB is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If no value is provided for this parameter and the default field does not exist in the input observer features attribute table, the default value is 0. | Double; Field |
| Observer elevation(Optional) | The surface elevations of the observer points or vertices.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field SPOT is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it will be estimated through bilinear interpolation with the surface elevation values in the neighboring cells of the observer location. | Double; Field |
| Observer offset(Optional) | A vertical distance that will be added to the observer elevation. It must be a positive integer or floating-point value.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field OFFSETA is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it defaults to 1. | Double; Field |
| Inner radius(Optional) | The start distance from which visibility will be determined. Cells closer than this distance will not be visible in the output but can still block visibility of the cells between inner radius and outer radius.It can be a positive or negative integer or floating point value. If it is a positive value, then it is interpreted as three-dimensional, line-of-sight distance. If it is a negative value, then it is interpreted as two-dimensional planimetric distance.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field RADIUS1 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If no value is provided for this parameter and the default field does not exist in the input observer features attribute table, the default value is 0. | Double; Field |
| Outer radius(Optional) | The maximum distance from which visibility will be determined. Cells beyond this distance will be excluded from the analysis.It can be a positive or negative integer or floating point value. If it is a positive value, then it is interpreted as three-dimensional, line-of-sight distance. If it is a negative value, then it is interpreted as two-dimensional planimetric distance.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field RADIUS2 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it defaults to infinity. | Double; Field |
| Horizontal start angle(Optional) | The start angle of the horizontal scan range. Provide the value in degrees from 0 to 360 with 0 oriented to north. The value can be integer or floating point. The default value is 0.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field AZIMUTH1 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If no value is provided for this parameter and the default field does not exist in the input observer features attribute table, the default value is 0. | Double; Field |
| Horizontal end angle(Optional) | The end angle of the horizontal scan range. Provide the value in degrees from 0 to 360 with 0 oriented to north. The value can be integer or floating point. The default value is 360.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field AZIMUTH2 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it defaults to 360. | Double; Field |
| Vertical upper angle(Optional) | The upper vertical angle limit of the scan relative to the horizontal plane. Provide the value in degrees from above -90 up to and including 90. The value can be integer or floating point. The default value is 90 (straight up).This parameter value must be greater than the Vertical lower angle parameter value.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field VERT1 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it defaults to 90. | Double; Field |
| Vertical lower angle(Optional) | The lower vertical angle limit of the scan relative to the horizontal plane. Provide the value in degrees from -90 up to but not including 90. The value can be integer or floating point. The default value is -90 (straight down).This parameter value must be less than the Vertical upper angle parameter value.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field VERT2 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it defaults to -90. | Double; Field |
| in_raster | The input surface raster. | Raster Layer |
| in_observer_features | The feature class that identifies the observer locations.The input can be point or polyline features. | Feature Layer |
| out_agl_raster(Optional) | The output above-ground-level (AGL) raster.The AGL result is a raster where each cell value is the minimum height that must be added to an otherwise nonvisible cell to make it visible by at least one observer.Cells that were already visible will have a value of 0 in this output raster. | Raster Dataset |
| analysis_type(Optional) | The visibility analysis type.FREQUENCY—The output records the number of times that each cell location in the input surface raster can be seen by the input observation locations (as points, or as vertices for polyline observer features). This is the default.OBSERVERS—The output identifies exactly which observer points are visible from each raster surface location. | String |
| nonvisible_cell_value(Optional) | Value assigned to non-visible cells.ZERO—0 is assigned to nonvisible cells. This is the default.NODATA—NoData is assigned to nonvisible cells. | Boolean |
| z_factor(Optional) | Number of ground x,y units in one surface z unit.The z-factor adjusts the units of measure for the z units when they are different from the x,y units of the input surface. The z-values of the input surface are multiplied by the z-factor when calculating the final output surface.If the x,y units and z units are in the same units of measure, the z-factor is 1. This is the default.If the x,y units and z units are in different units of measure, the z-factor must be set to the appropriate factor, or the results will be incorrect. For example, if your z units are feet and your x,y units are meters, you would use a z-factor of 0.3048 to convert your z units from feet to meters (1 foot = 0.3048 meter). | Double |
| curvature_correction(Optional) | Specifies whether correction for the earth's curvature will be applied.FLAT_EARTH—No curvature correction will be applied. This is the default.CURVED_EARTH—Curvature correction will be applied. | Boolean |
| refractivity_coefficient(Optional) | The coefficient of the refraction of visible light in air.The default value is 0.13. | Double |
| surface_offset(Optional) | A vertical distance that will be added to the z-value of each cell as it is considered for visibility. It must be a positive integer or floating-point value.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field OFFSETB is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If no value is provided for this parameter and the default field does not exist in the input observer features attribute table, the default value is 0. | Double; Field |
| observer_elevation(Optional) | The surface elevations of the observer points or vertices.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field SPOT is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it will be estimated through bilinear interpolation with the surface elevation values in the neighboring cells of the observer location. | Double; Field |
| observer_offset(Optional) | A vertical distance that will be added to the observer elevation. It must be a positive integer or floating-point value.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field OFFSETA is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it defaults to 1. | Double; Field |
| inner_radius(Optional) | The start distance from which visibility will be determined. Cells closer than this distance will not be visible in the output but can still block visibility of the cells between inner radius and outer radius.It can be a positive or negative integer or floating point value. If it is a positive value, then it is interpreted as three-dimensional, line-of-sight distance. If it is a negative value, then it is interpreted as two-dimensional planimetric distance.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field RADIUS1 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If no value is provided for this parameter and the default field does not exist in the input observer features attribute table, the default value is 0. | Double; Field |
| outer_radius(Optional) | The maximum distance from which visibility will be determined. Cells beyond this distance will be excluded from the analysis.It can be a positive or negative integer or floating point value. If it is a positive value, then it is interpreted as three-dimensional, line-of-sight distance. If it is a negative value, then it is interpreted as two-dimensional planimetric distance.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field RADIUS2 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it defaults to infinity. | Double; Field |
| horizontal_start_angle(Optional) | The start angle of the horizontal scan range. Provide the value in degrees from 0 to 360 with 0 oriented to north. The value can be integer or floating point. The default value is 0.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field AZIMUTH1 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If no value is provided for this parameter and the default field does not exist in the input observer features attribute table, the default value is 0. | Double; Field |
| horizontal_end_angle(Optional) | The end angle of the horizontal scan range. Provide the value in degrees from 0 to 360 with 0 oriented to north. The value can be integer or floating point. The default value is 360.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field AZIMUTH2 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it defaults to 360. | Double; Field |
| vertical_upper_angle(Optional) | The upper vertical angle limit of the scan relative to the horizontal plane. Provide the value in degrees from above -90 up to and including 90. The value can be integer or floating point. The default value is 90 (straight up).This parameter value must be greater than the Vertical lower angle parameter value.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field VERT1 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it defaults to 90. | Double; Field |
| vertical_lower_angle(Optional) | The lower vertical angle limit of the scan relative to the horizontal plane. Provide the value in degrees from -90 up to but not including 90. The value can be integer or floating point. The default value is -90 (straight down).This parameter value must be less than the Vertical upper angle parameter value.You can select a field in the input observers dataset, or you can specify a numerical value.By default, a numerical field VERT2 is used if it exists in the input observer features attribute table. You may overwrite it by specifying another numerical field or a value.If this parameter is unspecified and the default field does not exist in the input observer features attribute table, it defaults to -90. | Double; Field |

## Code Samples

### Example 1

```python
Visibility(in_raster, in_observer_features, {out_agl_raster}, {analysis_type}, {nonvisible_cell_value}, {z_factor}, {curvature_correction}, {refractivity_coefficient}, {surface_offset}, {observer_elevation}, {observer_offset}, {inner_radius}, {outer_radius}, {horizontal_start_angle}, {horizontal_end_angle}, {vertical_upper_angle}, {vertical_lower_angle})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *

env.workspace = "c:/sapyexamples/data"

outvis = arcpy.sa.Visibility("elevation", "observers.shp", "c:/sapyexamples/output/aglout1",
                            "FREQUENCY", "NODATA", "1", "CURVED_EARTH", "0.13",
                            "OFFSETB", "SPOT", "OFFSETA", "RADIUS1", "RADIUS2",
                            "AZIMUTH1", "AZIMUTH2", "VERT1", "VERT2")

outvis.save("c:/sapyexamples/output/visiout1")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *

env.workspace = "c:/sapyexamples/data"

outvis = arcpy.sa.Visibility("elevation", "observers.shp", "c:/sapyexamples/output/aglout1",
                            "FREQUENCY", "NODATA", "1", "CURVED_EARTH", "0.13",
                            "OFFSETB", "SPOT", "OFFSETA", "RADIUS1", "RADIUS2",
                            "AZIMUTH1", "AZIMUTH2", "VERT1", "VERT2")

outvis.save("c:/sapyexamples/output/visiout1")
```

### Example 4

```python
# Name: Visibility_Ex_02.py
# Description: Determines the raster surface locations visible to a set of
#                     observer features.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "c:/sapyexamples/data"

# set local variables
inRaster = "elevation"
inObserverFeatures = "observers.shp"
aglOutput = "c:/sapyexamples/output/aglout1"
analysisType = "OBSERVERS"
nonVisibleValue = "ZERO"
zFactor = 1
useEarthCurvature = "CURVED_EARTH"
refractivityCoefficient = 0.13
surfaceOffset = 500
observerElevation = 2000
observerOffset = 500
innerRadius = 20000
outerRadius = 100000
horizStartAngle = 45
horizEndAngle = 215
vertUpperAngle = 5
vertLowerAngle = -5

# Execute Visibility
outvis = arcpy.sa.Visibility(inRaster, inObserverFeatures, algOutput, analysisType,
                            nonVisibleValue, zFactor, useEarthCurvature,
                            refractivityCoefficient, surfaceOffset, observerElevation,
                            observerOffset, innerRadius, outerRadius, horizStartAngle,
                            horizEndAngle, vertUpperAngle, vertLowerAngle)

# Save the output
outvis.save("c:/sapyexamples/output/visiout1")
```

### Example 5

```python
# Name: Visibility_Ex_02.py
# Description: Determines the raster surface locations visible to a set of
#                     observer features.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "c:/sapyexamples/data"

# set local variables
inRaster = "elevation"
inObserverFeatures = "observers.shp"
aglOutput = "c:/sapyexamples/output/aglout1"
analysisType = "OBSERVERS"
nonVisibleValue = "ZERO"
zFactor = 1
useEarthCurvature = "CURVED_EARTH"
refractivityCoefficient = 0.13
surfaceOffset = 500
observerElevation = 2000
observerOffset = 500
innerRadius = 20000
outerRadius = 100000
horizStartAngle = 45
horizEndAngle = 215
vertUpperAngle = 5
vertLowerAngle = -5

# Execute Visibility
outvis = arcpy.sa.Visibility(inRaster, inObserverFeatures, algOutput, analysisType,
                            nonVisibleValue, zFactor, useEarthCurvature,
                            refractivityCoefficient, surfaceOffset, observerElevation,
                            observerOffset, innerRadius, outerRadius, horizStartAngle,
                            horizEndAngle, vertUpperAngle, vertLowerAngle)

# Save the output
outvis.save("c:/sapyexamples/output/visiout1")
```

---

## Watershed (Spatial Analyst)

## Summary

Determines the contributing area above a set of cells in a raster.

## Usage

- The value of each watershed will be taken from the value of the source in the input raster or feature pour point data. When the pour point is a raster dataset, the cell values will be used. When the pour point is a point feature dataset, the values will come from the specified field.
- The Watershed tool only supports a D8-type of input flow direction raster. This can be created using the Flow Direction tool, run with default flow direction type D8 (in Python, with the D8 option).
- Better results will be obtained if the Snap Pour Point tool is used beforehand to help locate the pour points to cells of high accumulated flow.
- When specifying the input pour point locations as feature data, the default field will be the first available valid field. If no valid field exists, the ObjectID field (for example, OID or FID) will be the default.
- This tool supports parallel processing. If your computer has multiple processors or processors with multiple cores, better performance may be achieved, particularly on larger datasets. The Parallel processing with Spatial Analyst help topic includes details about this capability and how to configure it.When using parallel processing, temporary data will be written to manage the data chunks being processed. The default temp folder location will be on your local C: drive. You can control the location of this folder by setting up a system environment variable named TempFolders and specifying the path to a folder to use (for example, E:\RasterCache). If you have administrator privileges on your machine, you can also use a registry key (for example, [HKEY_CURRENT_USER\SOFTWARE\ESRI\ArcGISPro\Raster]).By default, this tool will use 50 percent of the available cores. If the input data is smaller than 5,000 by 5,000 cells in size, fewer cores may be used. You can control the number of cores the tool uses with the Parallel processing factor environment.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input D8 flow direction raster | The input raster that shows the direction of flow out of each cell. The flow direction raster can be created using the Flow Direction tool, run using the default flow direction type D8. | Raster Layer |
| Input raster or feature pour point data | The input pour point locations.For a raster, this represents cells above which the contributing area, or catchment, will be determined. All cells that are not NoData will be used as source cells.For a point feature dataset, this represents locations above which the contributing area, or catchment, will be determined. | Raster Layer; Feature Layer |
| Pour point field(Optional) | The field used to assign values to the pour point locations.If the pour point dataset is a raster, use Value.If the pour point dataset is a feature, use a numeric field. If the field contains floating-point values, they will be truncated into integers. | Field |
| in_flow_direction_raster | The input raster that shows the direction of flow out of each cell. The flow direction raster can be created using the Flow Direction tool, run using the default flow direction type D8. | Raster Layer |
| in_pour_point_data | The input pour point locations.For a raster, this represents cells above which the contributing area, or catchment, will be determined. All cells that are not NoData will be used as source cells.For a point feature dataset, this represents locations above which the contributing area, or catchment, will be determined. | Raster Layer; Feature Layer |
| pour_point_field(Optional) | The field used to assign values to the pour point locations.If the pour point dataset is a raster, use Value.If the pour point dataset is a feature, use a numeric field. If the field contains floating-point values, they will be truncated into integers. | Field |

## Code Samples

### Example 1

```python
Watershed(in_flow_direction_raster, in_pour_point_data, {pour_point_field})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outWatershed = Watershed("flowdir", "pourpoint")
outWatershed.save("C:/sapyexamples/output/outwtrshd01")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outWatershed = Watershed("flowdir", "pourpoint")
outWatershed.save("C:/sapyexamples/output/outwtrshd01")
```

### Example 4

```python
# Name: Watershed_Ex_02.py
# Description: Determines the contributing area above a set of cells in a
#     raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFlowDirection = "flowdir"
inPourPointData = "pourpoint"
inPourPointField = "VALUE"

# Execute Watershed
outWatershed = Watershed(inFlowDirection, inPourPointData, inPourPointField)

# Save the output 
outWatershed.save("C:/sapyexamples/output/outwtrshd02.tif")
```

### Example 5

```python
# Name: Watershed_Ex_02.py
# Description: Determines the contributing area above a set of cells in a
#     raster.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inFlowDirection = "flowdir"
inPourPointData = "pourpoint"
inPourPointField = "VALUE"

# Execute Watershed
outWatershed = Watershed(inFlowDirection, inPourPointData, inPourPointField)

# Save the output 
outWatershed.save("C:/sapyexamples/output/outwtrshd02.tif")
```

---

## Weighted Overlay (Spatial Analyst)

## Summary

Overlays several rasters using a common measurement scale and weights each according to its importance.

## Usage

- All input rasters must be integer. A floating-point raster must first be converted to an integer raster before it can be used in Weighted Overlay. The Reclassification tools provide an effective way to do the conversion.
- Each value class in an input raster is assigned a new value based on an evaluation scale. These new values are reclassifications of the original input raster values. A restricted value is used for areas you want to exclude from the analysis.
- Each input raster is weighted according to its importance or its percent influence. The weight is a relative percentage, and the sum of the percent influence weights must equal 100. Influences are specified by integer values only. Decimal values are rounded down to the nearest integer.
- Changing the evaluation scales or the percentage influences can change the results of the weighted overlay analysis.
- By default, this tool will use multicore processors if available. The maximum number of cores that can be used is four.To use fewer cores, use the Parallel Processing Factor environment setting.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Weighted overlay table | The weighted overlay table allows the calculation of a multiple-criteria analysis between several rasters.Input Rasters:Rasters—List of input criteria rasters being weighted. Use the options to browse for raster datasets or add map layers to the list of inputs.%—The percent influence of the input raster compared to the other criteria rasters as a percentage of 100. Influences are specified by integer values only. Decimal values are rounded down to the nearest integer. The sum of influences must equal 100. Use the set equal influences option (the = sign button) to balance the percent influence of all rasters equally and sum them to 100.Remap Table:Field—The field of the input criteria to be weighted.Value—The input field value.Scale—The output scale value for the criterion, as specified by the Scale setting. Changing these values will alter the value in the input raster. You can enter a value directly or select from the drop-down list. In addition to numerical values, the following options are available: Restricted—Assigns the restricted value (the minimum value of the evaluation scale set, minus one) to cells in the output, regardless of whether other input rasters have a different scale value set for that cell.NoData—Assigns NoData to cells in the output, regardless of whether other input rasters have a different scale value set for that cell.Scale—Evaluation scale for defining the remap values. Select from a list of predefined evaluation scales. You can also define your own evaluation scale controls by typing in the parameter sign hyphens or spaces to separate values. A negative value must be preceded by a space. | WOTable |
| in_weighted_overlay_table | The Weighted Overlay tool allows the calculation of a multiple-criteria analysis between several rasters.An Overlay class is used to define the table. The WOTable object is used to specify the criteria rasters and their respective properties.The form of the object is: WOTable(weightedOverlayTable, evaluationScale) | WOTable |

## Code Samples

### Example 1

```python
WeightedOverlay(in_weighted_overlay_table)
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

outsuit = WeightedOverlay(WOTable(
           [
            ["snow", 50, 'VALUE', RemapValue([[1,"Nodata"],[5,3],[9,10],["NODATA","NODATA"]])], 
            ["land", 20, '', RemapValue([["water","1"],["forest",5],["open field",9],["NODATA", "NODATA"]])],
            ["soil", 30, 'VALUE', RemapValue([[1,"Restricted"],[5,5],[7,7],[9,9],["NODATA", "Restricted"]])]
           ],[1,9,1]))
outsuit.save("C:/sapyexamples/output/outsuit.img")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

outsuit = WeightedOverlay(WOTable(
           [
            ["snow", 50, 'VALUE', RemapValue([[1,"Nodata"],[5,3],[9,10],["NODATA","NODATA"]])], 
            ["land", 20, '', RemapValue([["water","1"],["forest",5],["open field",9],["NODATA", "NODATA"]])],
            ["soil", 30, 'VALUE', RemapValue([[1,"Restricted"],[5,5],[7,7],[9,9],["NODATA", "Restricted"]])]
           ],[1,9,1]))
outsuit.save("C:/sapyexamples/output/outsuit.img")
```

### Example 4

```python
# Name: WeightedOverlay_Ex_02.py
# Description: Overlays several rasters using a common scale and weighing 
#    each according to its importance.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "snow"
inRaster2 = "land"
inRaster3 = "soil"

remapsnow = RemapValue([[0,1],[1,1],[5,5],[9,9],["NODATA","NODATA"]])
remapland = RemapValue([[1,1],[5,5],[6,6],[7,7],[8,8],[9,9],["NODATA","Restricted"]])
remapsoil = RemapValue([[0,1],[1,1],[5,5],[6,6],[7,7],[8,8],[9,9],["NODATA", "NODATA"]])

myWOTable = WOTable([[inRaster1, 50, "VALUE", remapsnow],
                     [inRaster2, 20, "VALUE", remapland], 
                     [inRaster3, 30, "VALUE", remapsoil]
					          ], [1, 9, 1])    

# Execute WeightedOverlay
outWeightedOverlay = WeightedOverlay(myWOTable)

# Save the output
outWeightedOverlay.save("C:/sapyexamples/output/weightover2")
```

### Example 5

```python
# Name: WeightedOverlay_Ex_02.py
# Description: Overlays several rasters using a common scale and weighing 
#    each according to its importance.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "snow"
inRaster2 = "land"
inRaster3 = "soil"

remapsnow = RemapValue([[0,1],[1,1],[5,5],[9,9],["NODATA","NODATA"]])
remapland = RemapValue([[1,1],[5,5],[6,6],[7,7],[8,8],[9,9],["NODATA","Restricted"]])
remapsoil = RemapValue([[0,1],[1,1],[5,5],[6,6],[7,7],[8,8],[9,9],["NODATA", "NODATA"]])

myWOTable = WOTable([[inRaster1, 50, "VALUE", remapsnow],
                     [inRaster2, 20, "VALUE", remapland], 
                     [inRaster3, 30, "VALUE", remapsoil]
					          ], [1, 9, 1])    

# Execute WeightedOverlay
outWeightedOverlay = WeightedOverlay(myWOTable)

# Save the output
outWeightedOverlay.save("C:/sapyexamples/output/weightover2")
```

---

## Weighted Sum (Spatial Analyst)

## Summary

Overlays several rasters, multiplying each by their given weight and summing them together.

## Usage

- A useful way to add several rasters together is to input multiple rasters and set all weights equal to 1.
- Input rasters can be integer or floating point.
- The weight values can be any positive or negative decimal value. It is not restricted to a relative percentage nor does it need to be equal to 1.0.
- The weight will be applied to the specified field for the input raster. Fields can be of type short or long integer, double or float.
- By default, this tool will use multicore processors if available. The maximum number of cores that can be used is four.To use fewer cores, use the Parallel Processing Factor environment setting.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input rasters | The weighted sum table allows you to apply different weights to individual input rasters before they are summed together.Raster—The raster being weighted.Field—The field of the raster to use for weighting.Weight—The weight value by which to multiply the raster. It can be any positive or negative decimal value. | WSTable |
| in_rasters | TheWeighted Sum tool overlays several rasters, multiplying each by their given weight and summing them together.An Overlay class is used to define the table. The WSTable object is used to specify a Python list of input rasters and weight them accordingly.The form of the object is: WSTable(weightedSumTable) | WSTable |

## Code Samples

### Example 1

```python
WeightedSum(in_rasters)
```

### Example 2

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

# Execute WeightedSum
outWeightedSum = WeightedSum(WSTable([["snow", "VALUE", 0.25], ["land", "VALUE",0.25],
									  ["soil", "VALUE", 0.5]]))
outWeightedSum.save("C:/sapyexamples/output/outwsum")
```

### Example 3

```python
import arcpy
from arcpy import env  
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

# Execute WeightedSum
outWeightedSum = WeightedSum(WSTable([["snow", "VALUE", 0.25], ["land", "VALUE",0.25],
									  ["soil", "VALUE", 0.5]]))
outWeightedSum.save("C:/sapyexamples/output/outwsum")
```

### Example 4

```python
# Name: WeightedSum_Ex_02.py
# Description: Overlays several rasters multiplying each by their given
#    weight and summing them together.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "snow"
inRaster2 = "land"
inRaster3 = "soil"
WSumTableObj = WSTable([[inRaster1, "VALUE", 0.25], [inRaster2, "VALUE", 0.25],
                        [inRaster3, "VALUE", 0.5]])

# Execute WeightedSum
outWeightedSum = WeightedSum(WSumTableObj)

# Save the output 
outWeightedSum.save("C:/sapyexamples/output/weightsumout")
```

### Example 5

```python
# Name: WeightedSum_Ex_02.py
# Description: Overlays several rasters multiplying each by their given
#    weight and summing them together.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inRaster1 = "snow"
inRaster2 = "land"
inRaster3 = "soil"
WSumTableObj = WSTable([[inRaster1, "VALUE", 0.25], [inRaster2, "VALUE", 0.25],
                        [inRaster3, "VALUE", 0.5]])

# Execute WeightedSum
outWeightedSum = WeightedSum(WSumTableObj)

# Save the output 
outWeightedSum.save("C:/sapyexamples/output/weightsumout")
```

---

## Zonal Characterization (Spatial Analyst)

## Summary

Summarizes the values of multiple rasters within the zones of another dataset and reports the results as a table.

## Usage

- The following are example applications of the tool: Calculate the mean precipitation, maximum temperature, and sum of population within different ecosystem zones to estimate sustainable agricultural practices.Estimate the mean elevation, mean slope, and sum of NDVI values for each plot to locate areas suitable for planting shade trees.
- Calculate the mean precipitation, maximum temperature, and sum of population within different ecosystem zones to estimate sustainable agricultural practices.
- Estimate the mean elevation, mean slope, and sum of NDVI values for each plot to locate areas suitable for planting shade trees.
- A zone is defined as all areas in the input that have the same value. The areas do not have to be contiguous. Both rasters and features can be used for the zone input.
- If the Input Raster or Feature Zones (in_zone_raster_or_features in Python) parameter value is a raster, it must be an integer raster.
- If the Input Raster or Feature Zones parameter value is a feature, it will be converted to a raster internally using the cell size, cell alignment, and spatial reference from the Input Value Rasters (in_value_rasters_statistics in Python) parameter value with the smallest cell size, unless otherwise specified in the analysis environment. This will trigger an internal resampling before the zonal operation is performed.
- If the Input Raster or Feature Zones parameter value is a feature, for any of the zone features that do not overlap any cell centers of a value raster, those zones will not be converted to the internal zone raster. As a result, those zones will not be represented in the output. You can manage this by determining an appropriate value for the cell size environment that will preserve the desired level of detail of the feature zones, and specify it in the analysis environment.
- If the Input Raster or Feature Zones value is a point feature, more than one point may be contained in any particular cell of the input value rasters. For such cells, the zone value is determined by the point with the lowest ObjectID field (for example, OID or FID).
- If the Input Raster or Feature Zones value has overlapping features, the zonal analysis will be performed for each individual feature.
- When the cell size of the Input Raster or Feature Zones and the Input Value Rasters parameter values are different, the cell size, cell alignment and spatial reference from the Input Value Rasters parameter value with the smallest cell size will be used, unless otherwise specified in the analysis environment. This will trigger an internal resampling before the zonal operation is performed.When the zone and value inputs are all rasters of the same cell size and the cells are aligned, they will be used directly in the tool and will not be resampled internally during tool processing.
- When specifying the Input Raster or Feature Zones value, the default Zone Field (zone_field in Python) parameter value will be the first available integer field (for example, OID or FID) for features, and the VALUE field for raster. The zone field can be an integer or a string field type.
- The supported statistics type depends on the data type of the Input Value Rasters parameter value, and the statistics calculation type specified by the Calculate Circular Statistics parameter value.If the data type is integer, the arithmetic statistics calculation supports the Mean, Majority, Majority count, Majority percentage, Maximum, Median, Minimum, Minority, Minority count, Minority percentage, Percentile, Range, Standard deviation, Sum, and Variety options. The circular statistics calculation supports the Mean, Majority, Minority, Standard deviation, and Variety options.If the data type is float, the arithmetic statistics calculation supports the Mean, Maximum, Median, Minimum, Percentile, Range, Standard deviation, and Sum options. The circular statistics calculation supports the Mean and Standard deviation options.
- For majority and minority calculations, when there is a tie, the output will be the lowest of the tied values.
- To calculate more than one statistics type per value raster, the same value raster needs to be specified multiple times. If the same value raster and statistics type combination is duplicated, the tool will generate an error.
- To calculate circular statistics, check the Calculate Circular Statistics parameter (circular_calculation = "CIRCULAR" in Python), and specify a value for the Circular Wrap Value (circular_wrap_value in Python) parameter.If the Calculate Circular Statistics parameter is checked, circular statistics will be calculated for all value rasters with the specified circular wrap value applied.
- Supported multidimensional raster dataset types include multidimensional raster layer, mosaic, image service, and Esri CRF.
- The Output Statistics Table (out_statistics_table in Python) parameter value will have the following characteristics: The number of rows in the output table is the number of zones within the analysis extent.A series of fields will be created in the output table to represent the zones, with the count and statistics values for each Input Value Rasters value.The names of the fields are derived from the value raster name and statistics type by default, unless specified in the Field Name parameter. For circular statistics, the name of the field will include C_ before the specified statistic. For example, the field name will be ValueRasterName_MEAN for the arithmetic mean statistic and ValueRasterName_C_MEAN for the circular mean statistic.The maximum length of the field names in the output table will depend on the workspace.The data type for each value of the items in the output table will depend on the zonal calculation being performed. See How zonal statistics tools work for the specific behavior of a statistic.
- The number of rows in the output table is the number of zones within the analysis extent.
- A series of fields will be created in the output table to represent the zones, with the count and statistics values for each Input Value Rasters value.
- The names of the fields are derived from the value raster name and statistics type by default, unless specified in the Field Name parameter. For circular statistics, the name of the field will include C_ before the specified statistic. For example, the field name will be ValueRasterName_MEAN for the arithmetic mean statistic and ValueRasterName_C_MEAN for the circular mean statistic.
- The maximum length of the field names in the output table will depend on the workspace.
- The data type for each value of the items in the output table will depend on the zonal calculation being performed. See How zonal statistics tools work for the specific behavior of a statistic.
- For the Output Statistics Feature Class (out_statistics_features in Python) parameter value, if the zone input is a raster, the output feature class will be converted to features without generalizing and by honoring the analysis environment.
- This tool will use the following environment settings: The value raster with the smallest cell size will be used as the analysis cell size, output coordinate system, and snap raster by default.The default extent will be the intersection of the zone with the union of all the value rasters.By default, this tool will use multicore processors if available. The maximum number of cores that can be used is four.To use fewer cores, use the Parallel Processing Factor environment setting.See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.
- The value raster with the smallest cell size will be used as the analysis cell size, output coordinate system, and snap raster by default.
- The default extent will be the intersection of the zone with the union of all the value rasters.
- By default, this tool will use multicore processors if available. The maximum number of cores that can be used is four.To use fewer cores, use the Parallel Processing Factor environment setting.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster​ or Feature Zones​ | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| Input Value Rasters​ | The collection of rasters whose values will each be summarized by a statistic. This parameter has the following properties.Raster—An input value raster.Statistics Type—The statistic that will be calculated for the raster.Field Name—The field name for the raster in the output table.A statistic will be calculated for all cells in each input value raster that belong to the same zone as the output cell. The following are the available statistics types:Mean—The average value of the cells.Majority—The cell value that occurs most often.Majority count—The frequency of all cells that contain the majority value.Majority percentage—The percentage of cells that contain the majority value.Maximum—The largest cell value.Median—The median or middle cell valueMinimum—The smallest cell value.Minority—The cell value that occurs least often.Minority count—The frequency of all cells that contain the minority value.Minority percentage—The percentage of cells that contain the minority value.Percentile—The percentile of the cell values. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the Percentile Values parameter.Range—The difference between the largest and smallest cell values.Std—The standard deviation of the cell values.Sum—The total value of the cells.Variety—The number of unique cell values. The field names in the output statistics table will be derived from the value raster name and statistics type by default. | Value Table |
| Output Statistics Table | The output table that will contain the summary of the values in each zone for all value rasters.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table if in a geodatabase workspace, and a dBASE table if in a file workspace. | Table |
| Output Statistics Feature Class(Optional) | The output feature class that will be created by joining the output table to the input zone data. | Feature Class |
| Zone Field(Optional) | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| Ignore NoData in Calculations(Optional) | Specifies whether NoData values in the value input will be ignored in the results of the zone that they fall within.Checked—Within any particular zone, only cells that have a value in the input value raster will be used in determining the output value for that zone. NoData cells in the value raster will be ignored in the statistic calculation. This is the default.Unchecked—Within any particular zone, if NoData cells exist in the value raster, they will not be ignored and their existence indicates that there is insufficient information to perform statistical calculations for all the cells in that zone. Consequently, the entire zone will receive the NoData value on the output raster. | Boolean |
| Percentile Values(Optional) | The percentile that will be calculated. The default is 90, indicating the 90th percentile.The values can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to maximum. A value of 50 will produce essentially the same result as the median statistic.This parameter is only available if the Statistics type parameter is set to Percentile or All. | Double |
| Percentile Interpolation Type(Optional) | Specifies the method of interpolation that will be used when the percentile value falls between two cell values from the input value raster.Auto-detect—If the input value raster is of integer pixel type, the Nearest method will be used. If the input value raster is of floating point pixel type, the Linear method will be used. This is the default.Nearest—The nearest available value to the desired percentile will be used.Linear—The weighted average of the two surrounding values from the desired percentile will be used. | String |
| Calculate Circular Statistics(Optional) | Specifies how the input raster will be processed for circular data.Unchecked—Ordinary linear statistics will be calculated. This is the default.Checked—The statistics for angles or other cyclic quantities, such as compass direction in degrees, daytimes, and fractional parts of real numbers, will be calculated. | Boolean |
| Circular Wrap Value(Optional) | The value that will be used to round a linear value to the range of a given circular statistic. Its value must be a positive integer or a floating-point value. The default value is 360 degrees.This parameter is only supported if the Calculate Circular Statistics parameter is checked. | Double |
| Process as Multidimensional(Optional) | Specifies how the input rasters will be calculated if they are multidimensional. Unchecked—Statistics will be calculated from the current slice of the input multidimensional dataset. This is the default.Checked—Statistics will be calculated for all dimensions of the input multidimensional dataset. | Boolean |
| Append Zone Attributes to Output Features(Optional) | Specifies whether any of the additional zone attributes from the input zones will be appended to the output feature class. Unchecked—Only the zone ID field from the input zones will be appended to the output feature class. This is the default.Checked—Additional zone attributes from the input zones will be appended to the output feature class. | Boolean |
| in_zone_raster_or_features | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| in_value_rasters_statistics[in_value_rasters_statistics,...] | The collection of rasters whose values will each be summarized by a statistic. This parameter has the following properties.Raster—An input value raster.Statistics Type—The statistic that will be calculated for the raster.Field Name—The field name for the raster in the output table.A statistic will be calculated for all cells in each input value raster that belong to the same zone as the output cell. The following are the available statistics types:MEAN—The average value of the cells.MAJORITY—The cell value that occurs most often.MAJORITY_COUNT—The frequency of all cells that contain the majority value.MAJORITY_PERCENT—The percentage of cells that contain the majority value.MAXIMUM—The largest cell value.MEDIAN—The median or middle cell valueMINIMUM—The smallest cell value.MINORITY—The cell value that occurs least often.MINORITY_COUNT—The frequency of all cells that contain the minority value.MINORITY_PERCENT—The percentage of cells that contain the minority value.PERCENTILE—The percentile of the cell values. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the percentile_values parameter.RANGE—The difference between the largest and smallest cell values.STD—The standard deviation of the cell values.SUM—The total value of the cells.VARIETY—The number of unique cell values.The field names in the output statistics table will be derived from the value raster name and statistics type by default. | Value Table |
| out_statistics_table | The output table that will contain the summary of the values in each zone for all value rasters.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table if in a geodatabase workspace, and a dBASE table if in a file workspace. | Table |
| out_statistics_features(Optional) | The output feature class that will be created by joining the output table to the input zone data. | Feature Class |
| zone_field(Optional) | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| ignore_nodata(Optional) | Specifies whether NoData values in the value input will be ignored in the results of the zone that they fall within.DATA—Within any particular zone, only cells that have a value in the input value raster will be used in determining the output value for that zone. NoData cells in the value raster will be ignored in the statistic calculation. This is the default.NODATA—Within any particular zone, if NoData cells exist in the value raster, they will not be ignored and their existence indicates that there is insufficient information to perform statistical calculations for all the cells in that zone. Consequently, the entire zone will receive the NoData value on the output raster. | Boolean |
| percentile_values[percentile_values,...](Optional) | The percentile that will be calculated. The default is 90, indicating the 90th percentile.The values can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to maximum. A value of 50 will produce essentially the same result as the median statistic.This parameter is only supported if the statistics_type parameter is set to PERCENTILE or ALL. | Double |
| percentile_interpolation_type(Optional) | Specifies the method of interpolation that will be used when the percentile value falls between two cell values from the input value raster.AUTO_DETECT—If the input value raster is of integer pixel type, the NEAREST method will be used. If the input value raster is of floating point pixel type, the LINEAR method will be used. This is the default.NEAREST—The nearest available value to the desired percentile will be used.LINEAR—The weighted average of the two surrounding values from the desired percentile will be used. | String |
| circular_calculation(Optional) | Specifies how the input raster will be processed for circular data.ARITHMETIC—Ordinary linear statistics will be calculated. This is the default. CIRCULAR—The statistics for angles or other cyclic quantities, such as compass direction in degrees, daytimes, and fractional parts of real numbers, will be calculated. | Boolean |
| circular_wrap_value(Optional) | The value that will be used to round a linear value to the range of a given circular statistic. Its value must be a positive integer or a floating-point value. The default value is 360 degrees.This parameter is only supported if the circular_calculation parameter is set to CIRCULAR. | Double |
| process_as_multidimensional(Optional) | Specifies how the input rasters will be calculated if they are multidimensional. CURRENT_SLICE—Statistics will be calculated from the current slice of the input multidimensional dataset. This is the default.ALL_SLICES—Statistics will be calculated for all dimensions of the input multidimensional dataset. | Boolean |
| add_zone_attributes(Optional) | Specifies whether any of the additional zone attributes from the input zones will be appended to the output feature class. ZONE_FIELD_ONLY—Only the zone ID field from the input zones will be appended to the output feature class. This is the default.ALL—Additional zone attributes from the input zones will be appended to the output feature class. | Boolean |

## Code Samples

### Example 1

```python
ZonalCharacterization(in_zone_raster_or_features, in_value_rasters_statistics, out_statistics_table, {out_statistics_features}, {zone_field}, {ignore_nodata}, {percentile_values}, {percentile_interpolation_type}, {circular_calculation}, {circular_wrap_value}, {process_as_multidimensional}, {add_zone_attributes})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

outTable = ZonalCharacterization("zones.shp",
                "ValueRas1.tif MEAN ValueRas1_MEAN;ValueRas2.tif MAXIMUM ValueRas2_MAX;ValueRas3.tif STD ValueRas3_STD",
                "zonalcharacterout.dbf","featurestatout.shp","Id","DATA","",
                "AUTO_DETECT","ARITHMETIC","","CURRENT_SLICE","ZONE_FIELD_ONLY")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"

outTable = ZonalCharacterization("zones.shp",
                "ValueRas1.tif MEAN ValueRas1_MEAN;ValueRas2.tif MAXIMUM ValueRas2_MAX;ValueRas3.tif STD ValueRas3_STD",
                "zonalcharacterout.dbf","featurestatout.shp","Id","DATA","",
                "AUTO_DETECT","ARITHMETIC","","CURRENT_SLICE","ZONE_FIELD_ONLY")
```

### Example 4

```python
# Name: ZonalCharacterization_Ex_standalone.py
# Description: Summarizes the values of multiple rasters within the zones
#              of another dataset and reports the results as a table.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/sapyexamples/data"

# Set the local variables
inZoneData = "zones.tif"
zoneField = "Value"
inValueRas1 = "ValueRas1.tif"
inValueRas2 = "ValueRas2.tif"
inValueRas3 = "ValueRas3.tif"
outTable = "zonalcharactereizationout.dbf"
outFeatureClass = "featurestatout.shp"

# Execute ZonalCharacterization
outzonalchar = ZonalCharacterization(inZoneData, [[inValueRas1, "MEAN", 
            "ValueRas1_MEAN"], [inValueRas2, "STD", "ValueRas2_STD"], 
            [inValueRas3, "SUM", "ValueRas3_SUM"]], outTable, outFeatureClass, 
            zoneField, "NODATA", "", "", "ARITHMETIC", "", "CURRENT_SLICE", "ALL")
```

### Example 5

```python
# Name: ZonalCharacterization_Ex_standalone.py
# Description: Summarizes the values of multiple rasters within the zones
#              of another dataset and reports the results as a table.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/sapyexamples/data"

# Set the local variables
inZoneData = "zones.tif"
zoneField = "Value"
inValueRas1 = "ValueRas1.tif"
inValueRas2 = "ValueRas2.tif"
inValueRas3 = "ValueRas3.tif"
outTable = "zonalcharactereizationout.dbf"
outFeatureClass = "featurestatout.shp"

# Execute ZonalCharacterization
outzonalchar = ZonalCharacterization(inZoneData, [[inValueRas1, "MEAN", 
            "ValueRas1_MEAN"], [inValueRas2, "STD", "ValueRas2_STD"], 
            [inValueRas3, "SUM", "ValueRas3_SUM"]], outTable, outFeatureClass, 
            zoneField, "NODATA", "", "", "ARITHMETIC", "", "CURRENT_SLICE", "ALL")
```

---

## Zonal Fill (Spatial Analyst)

## Summary

Fills zones using the minimum cell value from a weight raster along the zone boundary.

## Usage

- The input zone raster can be integer or floating point type. This is an exception to the other zonal tools, which require the zone input to be integer type.
- The data type of the output is the same as that of the input weight raster. If the values on the weight raster are floating point, the resultant output raster will be floating point. If the weight raster is integer, the output will be integer.
- This tool can be used as part of a hydrological analysis to fill sinks to the minimum elevation of their watershed boundary.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Zone Raster | The input raster that defines the zones to be filled. | Raster Layer |
| Input Weight Raster | The weight, or value, to be assigned to each zone. | Raster Layer |
| in_zone_raster | The input raster that defines the zones to be filled. | Raster Layer |
| in_weight_raster | The weight, or value, to be assigned to each zone. | Raster Layer |

## Code Samples

### Example 1

```python
ZonalFill(in_zone_raster, in_weight_raster)
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZonalFill = ZonalFill("inzone", "zoneweight")
outZonalFill.save("C:/sapyexamples/output/zonefillout")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZonalFill = ZonalFill("inzone", "zoneweight")
outZonalFill.save("C:/sapyexamples/output/zonefillout")
```

### Example 4

```python
# Name: ZonalFill_Ex_02.py
# Description: Fills zones using the minimum cell value from a weight 
#   raster, along the zone boundary.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inZoneRaster = "inzone"
zoneWeightRaster = "zoneweight"

# Execute ZonalStatistics
outZonalFill = ZonalFill(inZoneRaster, zoneWeightRaster)

# Save the output 
outZonalFill.save("C:/sapyexamples/output/zonefillout3")
```

### Example 5

```python
# Name: ZonalFill_Ex_02.py
# Description: Fills zones using the minimum cell value from a weight 
#   raster, along the zone boundary.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inZoneRaster = "inzone"
zoneWeightRaster = "zoneweight"

# Execute ZonalStatistics
outZonalFill = ZonalFill(inZoneRaster, zoneWeightRaster)

# Save the output 
outZonalFill.save("C:/sapyexamples/output/zonefillout3")
```

---

## Zonal Geometry as Table (Spatial Analyst)

## Summary

Calculates the geometry measures (area, perimeter, thickness, and the characteristics of an ellipse) for each zone in a dataset and reports the results as a table.

## Usage

- A zone is defined as all areas in the input that have the same value. The areas do not have to be contiguous. Both rasters and features can be used for the zone input.
- The Processing Cell Size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size has not been specified, the default output cell size is determined based on the type of input dataset as follows:If the input dataset is a raster, the cell size of the dataset is used.If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the input dataset is a raster, the cell size of the dataset is used.
- If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- The calculations for each zone are recorded in the output table.
- If the Input Raster or Feature Zone Data value has overlapping polygons, the zonal analysis will not be performed for each individual polygon. Since the feature input is converted to a raster, each location can have only one value.An alternative method is to process the zonal operation iteratively for each of the polygon zones and collate the results.
- When specifying the Input Raster or Feature Zone Data value, the default zone field will be the first available integer or text field. If no other valid fields exist, the ObjectID field (for example, OID or FID) will be the default.
- In the output table, the value field always precedes the fields containing the zonal output calculations. The value field contains the values of the zones defined by the zone dataset.
- The values for the zonal calculations will be floating point.
- All the results in the output table are presented in map units, except for the ORIENTATION item, which is in degrees in a range of 0 to 180. The orientation is defined as an angle between the x-axis and the major axis of the ellipse. The values of the orientation angle increase counterclockwise, starting at 0 in the east (horizontal, to the right) and going through 90 when the major axis is vertical.
- If a particular zone consists of only one cell or if the zone is a single square block of cells, the orientation of the ellipse (which, in this case, is a circle) is set to 90 degrees.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature zone data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| Zone field | The field that contains the values that define each zone.It must be an integer field of the zone dataset. | Field |
| Output table | Output table that will contain the summary of the values in each zone.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table. If the path is not in a geodatabase, the format is determined by the extension. If the extension is .dbf, it will be in dBASE format. If no extension is provided, the output will be an INFO table. INFO tables are not supported as input in ArcGIS Pro and cannot be displayed | Table |
| Processing cell size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| in_zone_data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| zone_field | The field that contains the values that define each zone.It must be an integer field of the zone dataset. | Field |
| out_table | Output table that will contain the summary of the values in each zone.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table. If the path is not in a geodatabase, the format is determined by the extension. If the extension is .dbf, it will be in dBASE format. If no extension is provided, the output will be an INFO table. INFO tables are not supported as input in ArcGIS Pro and cannot be displayed | Table |
| processing_cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |

## Code Samples

### Example 1

```python
VALUE AREA  PERIMETER THICKNESS XCENTROID YCENTROID MAJORAXIS MINORAXIS ORIENTATION
0     5.0   14.0      0.5       2.300     2.100     2.338     0.681      60.714
1     5.0   14.0      0.5       1.900     2.100     2.668     0.596     126.061
2     3.0    8.0      0.5       3.167     2.167     1.286     0.743     135.000
4     2.0    6.0      0.5       0.500     1.000     1.128     0.564      90.000
```

### Example 2

```python
ZonalGeometryAsTable(in_zone_data, zone_field, out_table, {processing_cell_size})
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZonalGeometryAsTable = ZonalGeometryAsTable("zones.shp", "Classes", "zonalgeomout", 0.2)
```

### Example 4

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZonalGeometryAsTable = ZonalGeometryAsTable("zones.shp", "Classes", "zonalgeomout", 0.2)
```

### Example 5

```python
# Name: ZonalGeometryAsTable_Ex_02.py
# Description:Calculates for each zone in a dataset the specified geometry 
#   measure (area, perimeter,  thickness, or the characteristics 
#   of ellipse) and reports the results as a table.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inZoneData = "zones.shp"
zoneField = "Classes"
outTable = "zonalgeomout02.dbf"
processingCellSize = 0.2

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute ZonalGeometryAsTable
outZonalGeometryAsTable = ZonalGeometryAsTable(inZoneData, zoneField, outTable, processingCellSize)
```

### Example 6

```python
# Name: ZonalGeometryAsTable_Ex_02.py
# Description:Calculates for each zone in a dataset the specified geometry 
#   measure (area, perimeter,  thickness, or the characteristics 
#   of ellipse) and reports the results as a table.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inZoneData = "zones.shp"
zoneField = "Classes"
outTable = "zonalgeomout02.dbf"
processingCellSize = 0.2

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Execute ZonalGeometryAsTable
outZonalGeometryAsTable = ZonalGeometryAsTable(inZoneData, zoneField, outTable, processingCellSize)
```

---

## Zonal Geometry (Spatial Analyst)

## Summary

Calculates the specified geometry measure (area, perimeter, thickness, or the characteristics of an ellipse) for each zone in a dataset.

## Usage

- A zone is defined as all areas in the input that have the same value. The areas do not have to be contiguous. Both rasters and features can be used for the zone input.
- The Output cell size parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn’t been explicitly specified as the parameter value, it is derived from the Cell Size environment if it has been specified. If the parameter cell size or the environment cell size have not been specified, the default output cell size is determined based on the type of input dataset as follows:If the input dataset is a raster, the cell size of the dataset is used.If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the input dataset is a raster, the cell size of the dataset is used.
- If the input dataset is a feature and the Snap Raster environment has been set, the cell size of the snap raster is used. If no snap raster is set, the cell size is calculated from the shorter of the width or height of the extent divided by 250 in which the extent is in the output coordinate system specified in the environment.
- If the cell size is specified using a numeric value, the tool will use it directly for the output raster.If the cell size is specified using a raster dataset, the parameter will show the path of the raster dataset instead of the cell size value. The cell size of that raster dataset will be used directly in the analysis, provided the spatial reference of the dataset is the same as the output spatial reference. If the spatial reference of the dataset is different than the output spatial reference, it will be projected based on the specified Cell Size Projection Method value.
- If the Input Raster or Feature Zone Data value has overlapping polygons, the zonal analysis will not be performed for each individual polygon. Since the feature input is converted to a raster, each location can have only one value.An alternative method is to process the zonal operation iteratively for each of the polygon zones and collate the results.
- When specifying the Input Raster or Feature Zone Data value, the default zone field will be the first available integer or text field. If no other valid fields exist, the ObjectID field (for example, OID or FID) will be the default.
- The data type of the output raster for each of the geometry types will be floating point.
- If a particular zone consists of only one cell or if the zone is a single square block of cells, the orientation of the ellipse (which, in this case, is a circle) is set to 90 degrees.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Zone Data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| Zone Field | The field that contains the values that define each zone.It must be an integer field of the zone dataset. | Field |
| Geometry Type(Optional) | Specifies the geometry type that will be calculated.Area—The area for each zone will be calculated.Perimeter—The perimeter for each zone will be calculated.Thickness—The deepest (or thickest) point within the zone from its surrounding cells will be calculated.Centroid—The centroids of each zone will be calculated. | String |
| Output Cell Size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |
| in_zone_data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| zone_field | The field that contains the values that define each zone.It must be an integer field of the zone dataset. | Field |
| geometry_type(Optional) | Specifies the geometry type that will be calculated.AREA—The area for each zone will be calculated.PERIMETER—The perimeter for each zone will be calculated.THICKNESS—The deepest (or thickest) point within the zone from its surrounding cells will be calculated.CENTROID—The centroids of each zone will be calculated. | String |
| cell_size(Optional) | The cell size of the output raster that will be created.This parameter can be defined by a numeric value or obtained from an existing raster dataset. If the cell size hasn't been explicitly specified as the parameter value, the environment cell size value will be used if specified; otherwise, additional rules will be used to calculate it from the other inputs. See the usage section for more detail. | Analysis Cell Size |

## Code Samples

### Example 1

```python
ZonalGeometry(in_zone_data, zone_field, {geometry_type}, {cell_size})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZonalGeometry = ZonalGeometry("zones.shp", "Classes", "AREA", 0.2)
outZonalGeometry.save("C:/sapyexamples/output/zonegeomout3")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZonalGeometry = ZonalGeometry("zones.shp", "Classes", "AREA", 0.2)
outZonalGeometry.save("C:/sapyexamples/output/zonegeomout3")
```

### Example 4

```python
# Name: ZonalGeometry_Ex_02.py
# Description:Calculates for each zone in a dataset the specified geometry 
#   measure (area, perimeter, thickness, or the characteristics 
#   of ellipse).
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inZoneData = "zones.shp"
zoneField = "Classes"
cellSize = 0.2

# Execute ZonalStatistics
outZonalGeometry = ZonalGeometry(inZoneData, zoneField, "AREA", cellSize)  

# Save the output 
outZonalGeometry.save("C:/sapyexamples/output/zonegeomout2")
```

### Example 5

```python
# Name: ZonalGeometry_Ex_02.py
# Description:Calculates for each zone in a dataset the specified geometry 
#   measure (area, perimeter, thickness, or the characteristics 
#   of ellipse).
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inZoneData = "zones.shp"
zoneField = "Classes"
cellSize = 0.2

# Execute ZonalStatistics
outZonalGeometry = ZonalGeometry(inZoneData, zoneField, "AREA", cellSize)  

# Save the output 
outZonalGeometry.save("C:/sapyexamples/output/zonegeomout2")
```

---

## Zonal Histogram (Spatial Analyst)

## Summary

Creates a table and a histogram graph that show the frequency distribution of cell values on the value input for each unique zone.

## Usage

- A zonal histogram allows you to investigate the frequency distribution of values in one dataset within classes of another dataset. Examples include slope distribution within land use classes, rainfall distribution within elevation classes, or crime distribution by police beat.
- The number of classes in a zonal histogram depends on how the Input value raster (in_value_raster in Python) is specified.When specified as a raster dataset, the following conditions will apply:For an integer raster with less than 25 unique values, the number of classes will match the number of unique values from the value raster.For an integer raster with more than 25 unique values, the values will be divided into 256 classes, from 1 to 256. If the number of unique values is less than 256, some of the classes will have a frequency of 0.For a floating-point raster, the values will be divided into 256 classes, from 1 to 256.When specified as raster layer, the following conditions will apply: For Stretch symbology, the stretch type will be used and the values will be divided into 256 classes, from 1 to 256.For Classify or Unique Values symbology, the number of classes will match the classes or the unique values from the symbology.The zonal analysis will be performed within the value range specified by the Stretch, Classify, or Unique Values symbology. Any values in the value raster that are not displayed in the symbology will be ignored from the calculation.For Discrete or Vector Field symbology, the zonal analysis will ignore the symbology. The analysis will be performed considering only the data type and the number of unique values in the value raster, in the same way as when the input value raster is specified as a raster dataset.The zonal histogram will show the class values from the value raster layer symbology labels.
- For an integer raster with less than 25 unique values, the number of classes will match the number of unique values from the value raster.
- For an integer raster with more than 25 unique values, the values will be divided into 256 classes, from 1 to 256. If the number of unique values is less than 256, some of the classes will have a frequency of 0.
- For a floating-point raster, the values will be divided into 256 classes, from 1 to 256.
- For Stretch symbology, the stretch type will be used and the values will be divided into 256 classes, from 1 to 256.
- For Classify or Unique Values symbology, the number of classes will match the classes or the unique values from the symbology.
- The zonal analysis will be performed within the value range specified by the Stretch, Classify, or Unique Values symbology. Any values in the value raster that are not displayed in the symbology will be ignored from the calculation.
- For Discrete or Vector Field symbology, the zonal analysis will ignore the symbology. The analysis will be performed considering only the data type and the number of unique values in the value raster, in the same way as when the input value raster is specified as a raster dataset.
- The zonal histogram will show the class values from the value raster layer symbology labels.
- A zone is defined as all areas in the input that have the same value. The areas do not have to be contiguous. Both rasters and features can be used for the zone input.
- If the Input Raster or Feature Zone Data (in_zone_data in Python) value is a raster, it must be an integer raster.
- If the Input Raster or Feature Zone Data is a feature, it will be converted to a raster internally using the cell size and cell alignment from the Input Value raster (in_value_raster in Python) parameter.
- When the cell size of the Input Raster or Feature Zone Data and the Input Value Raster is different, the output cell size will be the Maximum Of Inputs value, and the Input Value Raster will be used as the snap raster internally. If the cell size is the same but the cells are not aligned, the Input Value Raster will be used as the snap raster internally. Either of these cases will trigger an internal resampling before the zonal operation is performed.When the zone and value inputs are both rasters of the same cell size and the cells are aligned, they will be used directly in the tool and will not be resampled internally during tool processing.
- If the Input Raster or Feature Zone Data value is a point feature, more than one point may be contained in any particular cell of the value input raster. For such cells, the zone value is determined by the point with the lowest ObjectID field (for example, OID or FID).
- If the Input Raster or Feature Zone Data value has overlapping polygons, the zonal analysis will not be performed for each individual polygon. Since the feature input is converted to a raster, each location can have only one value.An alternative method is to process the zonal operation iteratively for each of the polygon zones and collate the results.
- The Zone field parameter (zone_field in Python) value must be either integer or text type.When specifying the Input Raster or Feature Zone Data value, the default zone field will be the first available integer or text field. If no other valid fields exist, the ObjectID field (for example, OID or FID) will be the default.
- A zonal histogram graph is not generated by default. To create the graph, check the Zones as rows in output table parameter (set the zones_as_rows parameter to ZONES_AS_ROWS in Python) and specify an Output graph name (out_graph parameter in Python). The zonal histogram graph can only be created within the ArcGIS Pro application and is not supported from a stand-alone script.
- When the output table is created by unchecking the Zones as rows in output table parameter, the label field will contain the values from the value raster dataset or the layer symbology labels, depending on how the input value raster is specified.When the output table is created by checking the Zones as rows in output table parameter, the label field will contain the values from the zone raster.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input raster or feature zone data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| Zone field | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| Input value raster | The raster that contains the values used to create the histogram. | Raster Layer |
| Output table | The output table file.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table if in a geodatabase workspace, and a dBASE table if in a file workspace.The optional graph output is created from the information in the table. | Table |
| Output graph name(Optional) | The name of the output graph for display.The graph is listed in the Contents pane under Standalone Tables. | Graph |
| Zones as rows in output table(Optional) | Specifies how the values from the input value raster will be represented in the output table. Unchecked—Zones will be represented as fields. This is the default.Checked—Zones will be represented as rows. | Boolean |
| in_zone_data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| zone_field | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| in_value_raster | The raster that contains the values used to create the histogram. | Raster Layer |
| out_table | The output table file.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table if in a geodatabase workspace, and a dBASE table if in a file workspace.The optional graph output is created from the information in the table. | Table |
| out_graph(Optional) | The name of the output graph for display. | Graph |
| zones_as_rows(Optional) | Specifies how the values from the input value raster will be represented in the output table. ZONES_AS_FIELDS—Zones will be represented as fields. This is the default.ZONES_AS_ROWS—Zones will be represented as rows. | Boolean |

## Code Samples

### Example 1

```python
ZonalHistogram(in_zone_data, zone_field, in_value_raster, out_table, {out_graph}, {zones_as_rows})
```

### Example 2

```python
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZonalHist = ZonalHistogram("zoneras", "zonfield", "valueras", "znhist_tbl.dbf",
                              "znhist_graphl", "ZONES_AS_ROWS")
```

### Example 3

```python
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZonalHist = ZonalHistogram("zoneras", "zonfield", "valueras", "znhist_tbl.dbf",
                              "znhist_graphl", "ZONES_AS_ROWS")
```

### Example 4

```python
# Name: ZonalHistogram_Ex_02.py
# Description: Creates a zonal histogram output table
#              showing the amount of value cells 
#              for each unique input zone.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inZoneData = "zonras"
zoneField = "zonfield"
inValueRaster = "valueras" 
outTable = "C:/sapyexamples/output/zonehist_tb2.dbf" 

# Execute ZonalHistogram
ZonalHistogram(inZoneData, zoneField, inValueRaster, outTable)
```

### Example 5

```python
# Name: ZonalHistogram_Ex_02.py
# Description: Creates a zonal histogram output table
#              showing the amount of value cells 
#              for each unique input zone.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy import env
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set environment settings
env.workspace = "C:/sapyexamples/data"

# Set local variables
inZoneData = "zonras"
zoneField = "zonfield"
inValueRaster = "valueras" 
outTable = "C:/sapyexamples/output/zonehist_tb2.dbf" 

# Execute ZonalHistogram
ZonalHistogram(inZoneData, zoneField, inValueRaster, outTable)
```

---

## Zonal Statistics as Table (Spatial Analyst)

## Summary

Summarizes the values of a raster within the zones of another dataset and reports the results as a table.

## Usage

- A zone is defined as all areas in the input that have the same value. The areas do not have to be contiguous. Both rasters and features can be used for the zone input.
- If the Input Raster or Feature Zone Data (in_zone_data in Python) value is a raster, it must be an integer raster.
- If the Input Raster or Feature Zone Data is a feature, it will be converted to a raster internally using the cell size and cell alignment from the Input Value raster (in_value_raster in Python) parameter.
- When the cell size of the Input Raster or Feature Zone Data and the Input Value Raster is different, the output cell size will be the Maximum Of Inputs value, and the Input Value Raster will be used as the snap raster internally. If the cell size is the same but the cells are not aligned, the Input Value Raster will be used as the snap raster internally. Either of these cases will trigger an internal resampling before the zonal operation is performed.When the zone and value inputs are both rasters of the same cell size and the cells are aligned, they will be used directly in the tool and will not be resampled internally during tool processing.
- If the Input Raster or Feature Zone Data is a feature, for any of the zone features that do not overlap any cell centers of the value raster, those zones will not be converted to the internal zone raster. As a result, those zones will not be represented in the output. You can manage this by determining an appropriate value for the cell size environment that will preserve the desired level of detail of the feature zones, and specify it in the analysis environment.
- If the Input Raster or Feature Zone Data value is a point feature, more than one point may be contained in any particular cell of the value input raster. For such cells, the zone value is determined by the point with the lowest ObjectID field (for example, OID or FID).
- If the Input Raster or Feature Zone Data has overlapping features, the zonal analysis will be performed for each individual feature.
- When specifying the Input Raster or Feature Zone Data value, the default zone field will be the first available integer or text field. If no other valid fields exist, the ObjectID field (for example, OID or FID) will be the default.
- The supported statistics type depends on the data type of the Input Value Raster value, and the statistics calculation type specified by the Calculate Circular Statistics parameter.If the data type is integer, the arithmetic statistics calculation supports the Mean, Majority, Majority count, Majority percentage, Maximum, Median, Minimum, Minority, Minority count, Minority percentage, Percentile, Range, Standard deviation, Sum, and Variety options. The circular statistics calculation supports the Mean, Majority, Minority, Standard deviation, and Variety options.If the data type is float, the arithmetic statistics calculation supports the Mean, Maximum, Median, Minimum, Percentile, Range, Standard deviation, and Sum options. The circular statistics calculation supports the Mean and Standard deviation options.
- For majority and minority calculations, when there is a tie, the output will be the lowest of the tied values.
- To calculate circular statistics, check the Calculate Circular Statistics parameter (circular_calculation = "CIRCULAR" in Python), and specify a value for the Circular Wrap Value (circular_wrap_value in Python) parameter.
- Supported multidimensional raster dataset types include multidimensional raster layer, mosaic, image service, and Esri CRF.
- A field or series of fields will be created in the output table depending on the Statistics Type parameter setting (statisticType in Python).The name of the field is the same as the Statistics type for arithmetic statistics calculation. This is the default.However, for circular statistics the name of the field will be prefaced with C_, followed by the specified statistic. For example, the field name will be Median for the arithmetic median statistic and C_Median for the circular median statistic.
- The data type for each value of the items in the output table is dependent on the zonal calculation being performed. See How the zonal statistics tools work for the specific behavior of a statistic.
- The number of rows in the output table is the number of zones.
- By default, this tool will use multicore processors if available. The maximum number of cores that can be used is four.To use fewer cores, use the Parallel Processing Factor environment setting.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Zone Data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| Zone Field | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| Input Value Raster | The raster that contains the values for which a statistic will be calculated. | Raster Layer |
| Output Table | The output table that will contain the summary of the values in each zone.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table if in a geodatabase workspace, and a dBASE table if in a file workspace. | Table |
| Ignore NoData in Calculations(Optional) | Specifies whether NoData values in the value input will be ignored in the results of the zone that they fall within.Checked—Within any particular zone, only cells that have a value in the input value raster will be used in determining the output value for that zone. NoData cells in the value raster will be ignored in the statistic calculation. This is the default.Unchecked—Within any particular zone, if NoData cells exist in the value raster, they will not be ignored and their existence indicates that there is insufficient information to perform statistical calculations for all the cells in that zone. Consequently, the entire zone will receive the NoData value on the output raster. | Boolean |
| Statistics Type(Optional) | Specifies the statistic type to be calculated.All—All of the statistics will be calculated. This is the default.Mean—The average of all cells in the value raster that belong to the same zone as the output cell will be calculated.Majority—The value that occurs most often for all cells in the value raster that belong to the same zone as the output cell will be calculated.Majority count—The frequency of all cells that contain the majority value in the value raster that belong to the same zone as the output cell will be calculated.Majority percentage—The percentage of cells that contain the majority value in the value raster that belong to the same zone as the output cell will be calculated.Maximum—The largest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.Median—The median value of all cells in the value raster that belong to the same zone as the output cell will be calculated.Minimum—The smallest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.Minority—The value that occurs least often for all cells in the value raster that belong to the same zone as the output cell will be calculated.Minority count—The frequency of all cells that contain the minority value in the value raster that belong to the same zone as the output cell will be calculated.Minority percentage—The percentage of cells that contain the minority value in the value raster that belong to the same zone as the output cell will be calculated.Percentile—The percentile of all cells in the value raster that belong to the same zone as the output cell will be calculated. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the Percentile values parameter.Range—The difference between the largest and smallest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.Standard deviation—The standard deviation of all cells in the value raster that belong to the same zone as the output cell will be calculated.Sum—The total value of all cells in the value raster that belong to the same zone as the output cell will be calculated.Variety—The number of unique values for all cells in the value raster that belong to the same zone as the output cell will be calculated.Minimum and Maximum—Both the minimum and maximum statistics will be calculated.Mean and Standard deviation—Both the mean and standard deviation statistics will be calculated.Minimum, Maximum, and Mean—The minimum, maximum, and mean statistics will be calculated.Majority value, count, and percentage—The majority value, count, and percentage statistics will be calculated.Minority value, count, and percentage—The minority value, count, and percentage statistics will be calculated. | String |
| Process as Multidimensional(Optional) | Specifies how the input rasters will be calculated if they are multidimensional. Unchecked—Statistics will be calculated from the current slice of the input multidimensional dataset. This is the default.Checked—Statistics will be calculated for all dimensions of the input multidimensional dataset. | Boolean |
| Percentile Values(Optional) | The percentile that will be calculated. The default is 90, indicating the 90th percentile.The values can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to maximum. A value of 50 will produce essentially the same result as the median statistic.This parameter is only available if the Statistics type parameter is set to Percentile or All. | Double |
| Percentile Interpolation Type(Optional) | Specifies the method of interpolation that will be used when the percentile value falls between two cell values from the input value raster.Auto-detect—If the input value raster is of integer pixel type, the Nearest method will be used. If the input value raster is of floating point pixel type, the Linear method will be used. This is the default.Nearest—The nearest available value to the desired percentile is used.Linear—The weighted average of the two surrounding values from the desired percentile is used. | String |
| Calculate Circular Statistics(Optional) | Specifies how the input raster will be processed for circular data.Unchecked—Ordinary linear statistics will be calculated. This is the default.Checked—The statistics for angles or other cyclic quantities, such as compass direction in degrees, daytimes, and fractional parts of real numbers, will be calculated. | Boolean |
| Circular Wrap Value(Optional) | The value that will be used to round a linear value to the range of a given circular statistic. Its value must be a positive integer or a floating-point value. The default value is 360 degrees.This parameter is only supported if the Calculate Circular Statistics parameter is checked. | Double |
| Output Join Layer(Optional) | The output layer that will be created by joining the output table to the input zone data. | Raster Layer; Feature Layer |
| in_zone_data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| zone_field | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| in_value_raster | The raster that contains the values for which a statistic will be calculated. | Raster Layer |
| out_table | The output table that will contain the summary of the values in each zone.The format of the table is determined by the output location and path. By default, the output will be a geodatabase table if in a geodatabase workspace, and a dBASE table if in a file workspace. | Table |
| ignore_nodata(Optional) | Specifies whether NoData values in the value input will be ignored in the results of the zone that they fall within.DATA—Within any particular zone, only cells that have a value in the input value raster will be used in determining the output value for that zone. NoData cells in the value raster will be ignored in the statistic calculation. This is the default.NODATA—Within any particular zone, if NoData cells exist in the value raster, they will not be ignored and their existence indicates that there is insufficient information to perform statistical calculations for all the cells in that zone. Consequently, the entire zone will receive the NoData value on the output raster. | Boolean |
| statistics_type(Optional) | Specifies the statistic type to be calculated.ALL—All of the statistics will be calculated. This is the default.MEAN—The average of all cells in the value raster that belong to the same zone as the output cell will be calculated.MAJORITY—The value that occurs most often for all cells in the value raster that belong to the same zone as the output cell will be calculated.MAJORITY_COUNT—The frequency of all cells that contain the majority value in the value raster that belong to the same zone as the output cell will be calculated.MAJORITY_PERCENT—The percentage of cells that contain the majority value in the value raster that belong to the same zone as the output cell will be calculated.MAXIMUM—The largest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.MEDIAN—The median value of all cells in the value raster that belong to the same zone as the output cell will be calculated.MINIMUM—The smallest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.MINORITY—The value that occurs least often for all cells in the value raster that belong to the same zone as the output cell will be calculated.MINORITY_COUNT—The frequency of all cells that contain the minority value in the value raster that belong to the same zone as the output cell will be calculated.MINORITY_PERCENT—The percentage of cells that contain the minority value in the value raster that belong to the same zone as the output cell will be calculated.PERCENTILE—The percentile of all cells in the value raster that belong to the same zone as the output cell will be calculated. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the percentile_values parameter.RANGE—The difference between the largest and smallest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.STD—The standard deviation of all cells in the value raster that belong to the same zone as the output cell will be calculated.SUM—The total value of all cells in the value raster that belong to the same zone as the output cell will be calculated.VARIETY—The number of unique values for all cells in the value raster that belong to the same zone as the output cell will be calculated.MIN_MAX—Both the minimum and maximum statistics will be calculated.MEAN_STD—Both the mean and standard deviation statistics will be calculated.MIN_MAX_MEAN—The minimum, maximum, and mean statistics will be calculated.MAJORITY_VALUE_COUNT_PERCENT—The majority value, count, and percentage statistics will be calculated.MINORITY_VALUE_COUNT_PERCENT—The minority value, count, and percentage statistics will be calculated. | String |
| process_as_multidimensional(Optional) | Specifies how the input rasters will be calculated if they are multidimensional. CURRENT_SLICE—Statistics will be calculated from the current slice of the input multidimensional dataset. This is the default.ALL_SLICES—Statistics will be calculated for all dimensions of the input multidimensional dataset. | Boolean |
| percentile_values[percentile_values,...](Optional) | The percentile that will be calculated. The default is 90, indicating the 90th percentile.The values can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to maximum. A value of 50 will produce essentially the same result as the median statistic.This parameter is only supported if the statistics_type parameter is set to PERCENTILE or ALL. | Double |
| percentile_interpolation_type(Optional) | Specifies the method of interpolation that will be used when the percentile value falls between two cell values from the input value raster.AUTO_DETECT—If the input value raster is of integer pixel type, the NEAREST method will be used. If the input value raster is of floating point pixel type, the LINEAR method will be used. This is the default.NEAREST—The nearest available value to the desired percentile is used.LINEAR—The weighted average of the two surrounding values from the desired percentile is used. | String |
| circular_calculation(Optional) | Specifies how the input raster will be processed for circular data.ARITHMETIC—Ordinary linear statistics will be calculated. This is the default. CIRCULAR—The statistics for angles or other cyclic quantities, such as compass direction in degrees, daytimes, and fractional parts of real numbers, will be calculated. | Boolean |
| circular_wrap_value(Optional) | The value that will be used to round a linear value to the range of a given circular statistic. Its value must be a positive integer or a floating-point value. The default value is 360 degrees.This parameter is only supported if the circular_calculation parameter is set to CIRCULAR. | Double |
| out_join_layer(Optional) | The output layer that will be created by joining the output table to the input zone data. | Raster Layer; Feature Layer |

## Code Samples

### Example 1

```python
ZonalStatisticsAsTable(in_zone_data, zone_field, in_value_raster, out_table, {ignore_nodata}, {statistics_type}, {process_as_multidimensional}, {percentile_values}, {percentile_interpolation_type}, {circular_calculation}, {circular_wrap_value}, {out_join_layer})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZSaT = ZonalStatisticsAsTable("zones.shp", "Classes", "valueforzone",
                                  "zonalstattblout", "NODATA", "SUM")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZSaT = ZonalStatisticsAsTable("zones.shp", "Classes", "valueforzone",
                                  "zonalstattblout", "NODATA", "SUM")
```

### Example 4

```python
# Name: ZonalStatisticsAsTable_Ex_standalone.py
# Description: Summarizes values of a multidimensional raster within the zones 
#              of another dataset and reports the results to a table.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/sapyexamples/data"

# Set the local variables
inZoneData = "zones.shp"
zoneField = "sampleID"
inValueRaster = "multidimensional_valueraster.crf"
outTable = "zonalstattblout02.dbf"

# Execute ZonalStatisticsAsTable
outZSaT = ZonalStatisticsAsTable(inZoneData, zoneField, inValueRaster, 
                                 outTable, "NODATA", "MAXIMUM", "ALL_SLICES")
```

### Example 5

```python
# Name: ZonalStatisticsAsTable_Ex_standalone.py
# Description: Summarizes values of a multidimensional raster within the zones 
#              of another dataset and reports the results to a table.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/sapyexamples/data"

# Set the local variables
inZoneData = "zones.shp"
zoneField = "sampleID"
inValueRaster = "multidimensional_valueraster.crf"
outTable = "zonalstattblout02.dbf"

# Execute ZonalStatisticsAsTable
outZSaT = ZonalStatisticsAsTable(inZoneData, zoneField, inValueRaster, 
                                 outTable, "NODATA", "MAXIMUM", "ALL_SLICES")
```

---

## Zonal Statistics (Spatial Analyst)

## Summary

Summarizes the values of a raster within the zones of another dataset.

## Usage

- A zone is defined as all areas in the input that have the same value. The areas do not have to be contiguous. Both rasters and features can be used for the zone input.
- If the Input Raster or Feature Zone Data (in_zone_data in Python) value is a raster, it must be an integer raster.
- If the Input Raster or Feature Zone Data is a feature, it will be converted to a raster internally using the cell size and cell alignment from the Input Value raster (in_value_raster in Python) parameter.
- When the cell size of the Input Raster or Feature Zone Data and the Input Value Raster is different, the output cell size will be the Maximum Of Inputs value, and the Input Value Raster will be used as the snap raster internally. If the cell size is the same but the cells are not aligned, the Input Value Raster will be used as the snap raster internally. Either of these cases will trigger an internal resampling before the zonal operation is performed.When the zone and value inputs are both rasters of the same cell size and the cells are aligned, they will be used directly in the tool and will not be resampled internally during tool processing.
- If the Input Raster or Feature Zone Data is a feature, for any of the zone features that do not overlap any cell centers of the value raster, those zones will not be converted to the internal zone raster. As a result, those zones will not be represented in the output. You can manage this by determining an appropriate value for the cell size environment that will preserve the desired level of detail of the feature zones, and specify it in the analysis environment.
- If the Input Raster or Feature Zone Data value is a point feature, more than one point may be contained in any particular cell of the value input raster. For such cells, the zone value is determined by the point with the lowest ObjectID field (for example, OID or FID).
- If the Input Raster or Feature Zone Data value has overlapping polygons, the zonal analysis will not be performed for each individual polygon. Since the feature input is converted to a raster, each location can have only one value.An alternative method is to process the zonal operation iteratively for each of the polygon zones and collate the results.
- When specifying the Input Raster or Feature Zone Data value, the default zone field will be the first available integer or text field. If no other valid fields exist, the ObjectID field (for example, OID or FID) will be the default.
- The supported statistics type depends on the data type of the Input Value Raster value, and the statistics calculation type specified by the Calculate Circular Statistics parameter.If the data type is integer, the arithmetic statistics calculation supports the Mean, Majority, Majority count, Majority percentage, Maximum, Median, Minimum, Minority, Minority count, Minority percentage, Percentile, Range, Standard deviation, Sum, and Variety options. The circular statistics calculation supports the Mean, Majority, Minority, Standard deviation, and Variety options.If the data type is float, the arithmetic statistics calculation supports the Mean, Maximum, Median, Minimum, Percentile, Range, Standard deviation, and Sum options. The circular statistics calculation supports the Mean and Standard deviation options.
- For majority and minority calculations, when there is a tie, the output will be the lowest of the tied values.
- To calculate circular statistics, check the Calculate Circular Statistics parameter (circular_calculation = "CIRCULAR" in Python), and specify a value for the Circular Wrap Value (circular_wrap_value in Python) parameter.
- Supported multidimensional raster dataset types include multidimensional raster layer, mosaic, image service, and Esri CRF.
- The data type (integer or float) of the output is dependent on the zonal calculation being performed and the input value raster type. See How the zonal statistics tools work for the specific behavior of a statistic.
- By default, this tool will use multicore processors if available. The maximum number of cores that can be used is four.To use fewer cores, use the Parallel Processing Factor environment setting.
- When the output raster format is .crf, this tool supports the Pyramid raster storage environment. Pyramids will be created in the output by default. For any other output format, this environment is not supported, and pyramids will not be created.
- See Analysis environments and Spatial Analyst for additional details on the geoprocessing environments that apply to this tool.

## Parameters

| Parameter | Description | Data Type |
|-----------|-------------|-----------|
| Input Raster or Feature Zone Data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| Zone Field | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| Input Value Raster | The raster that contains the values for which a statistic will be calculated. | Raster Layer |
| Statistics Type(Optional) | Specifies the statistic type to be calculated.Mean—The average of all cells in the value raster that belong to the same zone as the output cell will be calculated.This is the default.Majority—The value that occurs most often for all cells in the value raster that belong to the same zone as the output cell will be calculated.Majority count—The frequency of all cells that contain the majority value in the value raster that belong to the same zone as the output cell will be calculated.Majority percentage—The percentage of cells that contain the majority value in the value raster that belong to the same zone as the output cell will be calculated.Maximum—The largest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.Median—The median value of all cells in the value raster that belong to the same zone as the output cell will be calculated.Minimum—The smallest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.Minority—The value that occurs least often for all cells in the value raster that belong to the same zone as the output cell will be calculated.Minority count—The frequency of all cells that contain the minority value in the value raster that belong to the same zone as the output cell will be calculated.Minority percentage—The percentage of cells that contain the minority value in the value raster that belong to the same zone as the output cell will be calculated.Percentile—The percentile of all cells in the value raster that belong to the same zone as the output cell will be calculated. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the Percentile Value parameter.Range—The difference between the largest and smallest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.Standard deviation—The standard deviation of all cells in the value raster that belong to the same zone as the output cell will be calculated.Sum—The total value of all cells in the value raster that belong to the same zone as the output cell will be calculated.Variety—The number of unique values for all cells in the value raster that belong to the same zone as the output cell will be calculated. | String |
| Ignore NoData in Calculations(Optional) | Specifies whether NoData values in the value input will be ignored in the results of the zone that they fall within.Checked—Within any particular zone, only cells that have a value in the input value raster will be used in determining the output value for that zone. NoData cells in the value raster will be ignored in the statistic calculation. This is the default.Unchecked—Within any particular zone, if NoData cells exist in the value raster, they will not be ignored and their existence indicates that there is insufficient information to perform statistical calculations for all the cells in that zone. Consequently, the entire zone will receive the NoData value on the output raster. | Boolean |
| Process as Multidimensional(Optional) | Specifies how the input rasters will be calculated if they are multidimensional.Unchecked—Statistics will be calculated from the current slice of the input multidimensional dataset. This is the default.Checked—Statistics will be calculated for all dimensions of the input multidimensional dataset. | Boolean |
| Percentile Value(Optional) | The percentile that will be calculated. The default is 90, indicating the 90th percentile.The values can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to maximum. A value of 50 will produce essentially the same result as the median statistic. This parameter is only available if the Statistics type parameter is set to Percentile. | Double |
| Percentile Interpolation Type(Optional) | Specifies the method of interpolation that will be used when the percentile value falls between two cell values from the input value raster.Auto-detect—If the input value raster is of integer pixel type, the Nearest method will be used. If the input value raster is of floating point pixel type, the Linear method will be used. This is the default.Nearest—The nearest available value to the desired percentile is used. In this case, the output pixel type is the same as that of the input value raster.Linear—The weighted average of the two surrounding values from the desired percentile is used. In this case, the output pixel type is floating point. | String |
| Calculate Circular Statistics(Optional) | Specifies how the input raster will be processed for circular data.Unchecked—Ordinary linear statistics will be calculated. This is the default.Checked—The statistics for angles or other cyclic quantities, such as compass direction in degrees, daytimes, and fractional parts of real numbers, will be calculated. | Boolean |
| Circular Wrap Value(Optional) | The value that will be used to round a linear value to the range of a given circular statistic. Its value must be a positive integer or a floating-point value. The default value is 360 degrees.This parameter is only supported if the Calculate Circular Statistics parameter is checked. | Double |
| in_zone_data | The dataset that defines the zones.The zones can be defined by an integer raster or a feature layer. | Raster Layer; Feature Layer |
| zone_field | The field that contains the values that define each zone.It can be an integer or a string field of the zone dataset. | Field |
| in_value_raster | The raster that contains the values for which a statistic will be calculated. | Raster Layer |
| statistics_type(Optional) | Specifies the statistic type to be calculated.MEAN—The average of all cells in the value raster that belong to the same zone as the output cell will be calculated.This is the default.MAJORITY—The value that occurs most often for all cells in the value raster that belong to the same zone as the output cell will be calculated.MAJORITY_COUNT—The frequency of all cells that contain the majority value in the value raster that belong to the same zone as the output cell will be calculated.MAJORITY_PERCENT—The percentage of cells that contain the majority value in the value raster that belong to the same zone as the output cell will be calculated.MAXIMUM—The largest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.MEDIAN—The median value of all cells in the value raster that belong to the same zone as the output cell will be calculated.MINIMUM—The smallest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.MINORITY—The value that occurs least often for all cells in the value raster that belong to the same zone as the output cell will be calculated.MINORITY_COUNT—The frequency of all cells that contain the minority value in the value raster that belong to the same zone as the output cell will be calculated.MINORITY_PERCENT—The percentage of cells that contain the minority value in the value raster that belong to the same zone as the output cell will be calculated.PERCENTILE—The percentile of all cells in the value raster that belong to the same zone as the output cell will be calculated. The 90th percentile is calculated by default. You can specify other values (from 0 to 100) using the Percentile Value parameter.RANGE—The difference between the largest and smallest value of all cells in the value raster that belong to the same zone as the output cell will be calculated.STD—The standard deviation of all cells in the value raster that belong to the same zone as the output cell will be calculated.SUM—The total value of all cells in the value raster that belong to the same zone as the output cell will be calculated.VARIETY—The number of unique values for all cells in the value raster that belong to the same zone as the output cell will be calculated. | String |
| ignore_nodata(Optional) | Specifies whether NoData values in the value input will be ignored in the results of the zone that they fall within.DATA—Within any particular zone, only cells that have a value in the input value raster will be used in determining the output value for that zone. NoData cells in the value raster will be ignored in the statistic calculation. This is the default.NODATA—Within any particular zone, if NoData cells exist in the value raster, they will not be ignored and their existence indicates that there is insufficient information to perform statistical calculations for all the cells in that zone. Consequently, the entire zone will receive the NoData value on the output raster. | Boolean |
| process_as_multidimensional(Optional) | Specifies how the input rasters will be calculated if they are multidimensional.CURRENT_SLICE—Statistics will be calculated from the current slice of the input multidimensional dataset. This is the default.ALL_SLICES—Statistics will be calculated for all dimensions of the input multidimensional dataset. | Boolean |
| percentile_value(Optional) | The percentile that will be calculated. The default is 90, indicating the 90th percentile.The values can range from 0 to 100. The 0th percentile is essentially equivalent to the minimum statistic, and the 100th percentile is equivalent to maximum. A value of 50 will produce essentially the same result as the median statistic. This parameter is only supported if the statistics_type parameter is set to PERCENTILE. | Double |
| percentile_interpolation_type(Optional) | Specifies the method of interpolation that will be used when the percentile value falls between two cell values from the input value raster.AUTO_DETECT—If the input value raster is of integer pixel type, the NEAREST method will be used. If the input value raster is of floating point pixel type, the LINEAR method will be used. This is the default.NEAREST—The nearest available value to the desired percentile is used. In this case, the output pixel type is the same as that of the input value raster.LINEAR—The weighted average of the two surrounding values from the desired percentile is used. In this case, the output pixel type is floating point. | String |
| circular_calculation(Optional) | Specifies how the input raster will be processed for circular data.ARITHMETIC—Ordinary linear statistics will be calculated. This is the default. CIRCULAR—The statistics for angles or other cyclic quantities, such as compass direction in degrees, daytimes, and fractional parts of real numbers, will be calculated. | Boolean |
| circular_wrap_value(Optional) | The value that will be used to round a linear value to the range of a given circular statistic. Its value must be a positive integer or a floating-point value. The default value is 360 degrees.This parameter is only supported if the circular_calculation parameter is set to CIRCULAR. | Double |

## Code Samples

### Example 1

```python
ZonalStatistics(in_zone_data, zone_field, in_value_raster, {statistics_type}, {ignore_nodata}, {process_as_multidimensional}, {percentile_value}, {percentile_interpolation_type}, {circular_calculation}, {circular_wrap_value})
```

### Example 2

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZonalStats = ZonalStatistics("zone", "value", "valueraster", "RANGE",
                                "NODATA")
outZonalStats.save("C:/sapyexamples/output/zonestatout")
```

### Example 3

```python
import arcpy
from arcpy import env
from arcpy.sa import *
env.workspace = "C:/sapyexamples/data"
outZonalStats = ZonalStatistics("zone", "value", "valueraster", "RANGE",
                                "NODATA")
outZonalStats.save("C:/sapyexamples/output/zonestatout")
```

### Example 4

```python
# Name: ZonalStatistics_Ex_standalone.py
# Description: Summarizes values of a multidimensional raster within the zones 
#              of another dataset.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/sapyexamples/data"

# Set the local variables
inZoneData = "zones.shp"
zoneField = "sampleID"
inValueRaster = "multidimensional_valueraster.crf" 

# Execute ZonalStatistics
outZonalStatistics = ZonalStatistics(inZoneData, zoneField, inValueRaster,
                                     "MAXIMUM", "NODATA", "ALL_SLICES")

# Save the output 
outZonalStatistics.save("C:/sapyexamples/output/zonestatout2.crf")
```

### Example 5

```python
# Name: ZonalStatistics_Ex_standalone.py
# Description: Summarizes values of a multidimensional raster within the zones 
#              of another dataset.
# Requirements: Spatial Analyst Extension

# Import system modules
import arcpy
from arcpy.sa import *

# Check out the ArcGIS Spatial Analyst extension license
arcpy.CheckOutExtension("Spatial")

# Set the analysis environments
arcpy.env.workspace = "C:/sapyexamples/data"

# Set the local variables
inZoneData = "zones.shp"
zoneField = "sampleID"
inValueRaster = "multidimensional_valueraster.crf" 

# Execute ZonalStatistics
outZonalStatistics = ZonalStatistics(inZoneData, zoneField, inValueRaster,
                                     "MAXIMUM", "NODATA", "ALL_SLICES")

# Save the output 
outZonalStatistics.save("C:/sapyexamples/output/zonestatout2.crf")
```

---
